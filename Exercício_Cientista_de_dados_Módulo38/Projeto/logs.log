2024-06-09 18:32:50,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-09 18:32:50,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-09 18:32:50,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-09 18:32:50,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-09 18:33:17,898:INFO:PyCaret ClassificationExperiment
2024-06-09 18:33:17,898:INFO:Logging name: clf-default-name
2024-06-09 18:33:17,907:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-09 18:33:17,907:INFO:version 3.3.2
2024-06-09 18:33:17,908:INFO:Initializing setup()
2024-06-09 18:33:17,908:INFO:self.USI: 7b44
2024-06-09 18:33:17,909:INFO:self._variable_keys: {'memory', 'html_param', 'fold_generator', 'gpu_param', 'data', 'is_multiclass', 'log_plots_param', 'fold_shuffle_param', 'y_train', 'gpu_n_jobs_param', 'X_test', 'y_test', 'idx', 'X', '_available_plots', 'exp_id', 'X_train', '_ml_usecase', 'logging_param', 'fold_groups_param', 'USI', 'seed', 'fix_imbalance', 'exp_name_log', 'y', 'target_param', 'n_jobs_param', 'pipeline'}
2024-06-09 18:33:17,909:INFO:Checking environment
2024-06-09 18:33:17,909:INFO:python_version: 3.11.9
2024-06-09 18:33:17,909:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-09 18:33:17,910:INFO:machine: AMD64
2024-06-09 18:33:17,931:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-09 18:33:17,933:INFO:Memory: svmem(total=34056318976, available=24747200512, percent=27.3, used=9309118464, free=24747200512)
2024-06-09 18:33:17,933:INFO:Physical Core: 6
2024-06-09 18:33:17,933:INFO:Logical Core: 12
2024-06-09 18:33:17,934:INFO:Checking libraries
2024-06-09 18:33:17,934:INFO:System:
2024-06-09 18:33:17,934:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-09 18:33:17,934:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-09 18:33:17,934:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-09 18:33:17,934:INFO:PyCaret required dependencies:
2024-06-09 18:33:17,964:INFO:                 pip: 24.0
2024-06-09 18:33:17,964:INFO:          setuptools: 69.5.1
2024-06-09 18:33:17,964:INFO:             pycaret: 3.3.2
2024-06-09 18:33:17,964:INFO:             IPython: 8.25.0
2024-06-09 18:33:17,964:INFO:          ipywidgets: 8.1.3
2024-06-09 18:33:17,964:INFO:                tqdm: 4.66.4
2024-06-09 18:33:17,965:INFO:               numpy: 1.26.4
2024-06-09 18:33:17,965:INFO:              pandas: 2.1.4
2024-06-09 18:33:17,965:INFO:              jinja2: 3.1.4
2024-06-09 18:33:17,965:INFO:               scipy: 1.11.4
2024-06-09 18:33:17,965:INFO:              joblib: 1.3.2
2024-06-09 18:33:17,965:INFO:             sklearn: 1.4.2
2024-06-09 18:33:17,965:INFO:                pyod: 2.0.0
2024-06-09 18:33:17,965:INFO:            imblearn: 0.12.3
2024-06-09 18:33:17,965:INFO:   category_encoders: 2.6.3
2024-06-09 18:33:17,965:INFO:            lightgbm: 4.3.0
2024-06-09 18:33:17,965:INFO:               numba: 0.59.1
2024-06-09 18:33:17,965:INFO:            requests: 2.32.3
2024-06-09 18:33:17,965:INFO:          matplotlib: 3.7.5
2024-06-09 18:33:17,966:INFO:          scikitplot: 0.3.7
2024-06-09 18:33:17,966:INFO:         yellowbrick: 1.5
2024-06-09 18:33:17,966:INFO:              plotly: 5.22.0
2024-06-09 18:33:17,966:INFO:    plotly-resampler: Not installed
2024-06-09 18:33:17,966:INFO:             kaleido: 0.2.1
2024-06-09 18:33:17,966:INFO:           schemdraw: 0.15
2024-06-09 18:33:17,966:INFO:         statsmodels: 0.14.2
2024-06-09 18:33:17,966:INFO:              sktime: 0.26.0
2024-06-09 18:33:17,966:INFO:               tbats: 1.1.3
2024-06-09 18:33:17,966:INFO:            pmdarima: 2.0.4
2024-06-09 18:33:17,966:INFO:              psutil: 5.9.8
2024-06-09 18:33:17,966:INFO:          markupsafe: 2.1.5
2024-06-09 18:33:17,966:INFO:             pickle5: Not installed
2024-06-09 18:33:17,966:INFO:         cloudpickle: 3.0.0
2024-06-09 18:33:17,966:INFO:         deprecation: 2.1.0
2024-06-09 18:33:17,966:INFO:              xxhash: 3.4.1
2024-06-09 18:33:17,966:INFO:           wurlitzer: Not installed
2024-06-09 18:33:17,966:INFO:PyCaret optional dependencies:
2024-06-09 18:33:17,979:INFO:                shap: Not installed
2024-06-09 18:33:17,979:INFO:           interpret: Not installed
2024-06-09 18:33:17,980:INFO:                umap: Not installed
2024-06-09 18:33:17,980:INFO:     ydata_profiling: Not installed
2024-06-09 18:33:17,980:INFO:  explainerdashboard: Not installed
2024-06-09 18:33:17,980:INFO:             autoviz: Not installed
2024-06-09 18:33:17,980:INFO:           fairlearn: Not installed
2024-06-09 18:33:17,980:INFO:          deepchecks: Not installed
2024-06-09 18:33:17,980:INFO:             xgboost: Not installed
2024-06-09 18:33:17,980:INFO:            catboost: Not installed
2024-06-09 18:33:17,980:INFO:              kmodes: Not installed
2024-06-09 18:33:17,980:INFO:             mlxtend: Not installed
2024-06-09 18:33:17,980:INFO:       statsforecast: Not installed
2024-06-09 18:33:17,980:INFO:        tune_sklearn: Not installed
2024-06-09 18:33:17,980:INFO:                 ray: Not installed
2024-06-09 18:33:17,980:INFO:            hyperopt: Not installed
2024-06-09 18:33:17,980:INFO:              optuna: Not installed
2024-06-09 18:33:17,980:INFO:               skopt: Not installed
2024-06-09 18:33:17,980:INFO:              mlflow: Not installed
2024-06-09 18:33:17,980:INFO:              gradio: Not installed
2024-06-09 18:33:17,980:INFO:             fastapi: Not installed
2024-06-09 18:33:17,981:INFO:             uvicorn: Not installed
2024-06-09 18:33:17,981:INFO:              m2cgen: Not installed
2024-06-09 18:33:17,981:INFO:           evidently: Not installed
2024-06-09 18:33:17,981:INFO:               fugue: Not installed
2024-06-09 18:33:17,981:INFO:           streamlit: 1.35.0
2024-06-09 18:33:17,981:INFO:             prophet: Not installed
2024-06-09 18:33:17,981:INFO:None
2024-06-09 18:33:17,981:INFO:Set up data.
2024-06-09 18:33:18,020:INFO:Set up folding strategy.
2024-06-09 18:33:18,020:INFO:Set up train/test split.
2024-06-09 18:33:18,044:INFO:Set up index.
2024-06-09 18:33:18,044:INFO:Assigning column types.
2024-06-09 18:33:18,054:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-09 18:33:18,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-09 18:33:18,104:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:33:18,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,196:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-09 18:33:18,197:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:33:18,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,233:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-09 18:33:18,278:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:33:18,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,351:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:33:18,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,381:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-09 18:33:18,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:18,531:INFO:Preparing preprocessing pipeline...
2024-06-09 18:33:18,533:INFO:Set up simple imputation.
2024-06-09 18:33:18,543:INFO:Set up encoding of ordinal features.
2024-06-09 18:33:18,552:INFO:Set up encoding of categorical features.
2024-06-09 18:33:18,552:INFO:Set up removing outliers.
2024-06-09 18:33:18,553:INFO:Set up imbalanced handling.
2024-06-09 18:33:18,553:INFO:Set up PCA.
2024-06-09 18:33:18,780:INFO:Finished creating preprocessing pipeline.
2024-06-09 18:33:18,820:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-09 18:33:18,820:INFO:Creating final display dataframe.
2024-06-09 18:33:18,964:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (76276, 30)
5   Transformed train set shape       (61276, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                          PCA              True
21                   PCA method            linear
22               PCA components              None
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              7b44
2024-06-09 18:33:19,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,109:INFO:setup() successfully completed in 1.26s...............
2024-06-09 18:33:19,121:INFO:gpu_param set to False
2024-06-09 18:33:19,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,287:INFO:gpu_param set to False
2024-06-09 18:33:19,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,437:INFO:gpu_param set to False
2024-06-09 18:33:19,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,579:INFO:gpu_param set to False
2024-06-09 18:33:19,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,723:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:33:19,728:INFO:Initializing create_model()
2024-06-09 18:33:19,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-09 18:33:19,728:INFO:Checking exceptions
2024-06-09 18:33:19,731:INFO:Importing libraries
2024-06-09 18:33:19,731:INFO:Copying training dataset
2024-06-09 18:33:19,748:INFO:Defining folds
2024-06-09 18:33:19,748:INFO:Declaring metric variables
2024-06-09 18:33:19,748:INFO:Importing untrained model
2024-06-09 18:33:19,748:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-09 18:33:19,749:INFO:Starting cross validation
2024-06-09 18:33:19,750:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-09 18:33:27,955:INFO:Calculating mean and std
2024-06-09 18:33:27,956:INFO:Creating metrics dataframe
2024-06-09 18:33:27,959:INFO:Finalizing model
2024-06-09 18:33:29,405:INFO:[LightGBM] [Info] Number of positive: 30638, number of negative: 30638
2024-06-09 18:33:29,411:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004647 seconds.
2024-06-09 18:33:29,411:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-09 18:33:29,411:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-09 18:33:29,412:INFO:[LightGBM] [Info] Number of data points in the train set: 61276, number of used features: 29
2024-06-09 18:33:29,413:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-09 18:33:29,761:INFO:Uploading results into container
2024-06-09 18:33:29,761:INFO:Uploading model into container now
2024-06-09 18:33:29,775:INFO:_master_model_container: 1
2024-06-09 18:33:29,775:INFO:_display_container: 2
2024-06-09 18:33:29,776:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-09 18:33:29,776:INFO:create_model() successfully completed......................................
2024-06-09 18:33:29,892:INFO:Initializing tune_model()
2024-06-09 18:33:29,892:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-09 18:33:29,892:INFO:Checking exceptions
2024-06-09 18:33:29,911:INFO:Copying training dataset
2024-06-09 18:33:29,931:INFO:Checking base model
2024-06-09 18:33:29,932:INFO:Base model : Light Gradient Boosting Machine
2024-06-09 18:33:29,932:INFO:Declaring metric variables
2024-06-09 18:33:29,933:INFO:Defining Hyperparameters
2024-06-09 18:33:30,024:INFO:Tuning with n_jobs=-1
2024-06-09 18:33:30,024:INFO:Initializing RandomizedSearchCV
2024-06-09 18:35:07,012:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-09 18:35:07,013:INFO:Hyperparameter search completed
2024-06-09 18:35:07,013:INFO:SubProcess create_model() called ==================================
2024-06-09 18:35:07,014:INFO:Initializing create_model()
2024-06-09 18:35:07,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B42341E790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-09 18:35:07,014:INFO:Checking exceptions
2024-06-09 18:35:07,015:INFO:Importing libraries
2024-06-09 18:35:07,015:INFO:Copying training dataset
2024-06-09 18:35:07,052:INFO:Defining folds
2024-06-09 18:35:07,052:INFO:Declaring metric variables
2024-06-09 18:35:07,053:INFO:Importing untrained model
2024-06-09 18:35:07,053:INFO:Declaring custom model
2024-06-09 18:35:07,054:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-09 18:35:07,055:INFO:Starting cross validation
2024-06-09 18:35:07,059:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-09 18:35:13,703:INFO:Calculating mean and std
2024-06-09 18:35:13,704:INFO:Creating metrics dataframe
2024-06-09 18:35:13,707:INFO:Finalizing model
2024-06-09 18:35:14,860:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-09 18:35:14,860:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-09 18:35:14,860:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-09 18:35:14,936:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-09 18:35:14,937:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-09 18:35:14,937:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-09 18:35:14,937:INFO:[LightGBM] [Info] Number of positive: 30638, number of negative: 30638
2024-06-09 18:35:14,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004167 seconds.
2024-06-09 18:35:14,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-09 18:35:14,944:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-09 18:35:14,945:INFO:[LightGBM] [Info] Number of data points in the train set: 61276, number of used features: 29
2024-06-09 18:35:14,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-09 18:35:15,708:INFO:Uploading results into container
2024-06-09 18:35:15,709:INFO:Uploading model into container now
2024-06-09 18:35:15,710:INFO:_master_model_container: 2
2024-06-09 18:35:15,710:INFO:_display_container: 3
2024-06-09 18:35:15,711:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-09 18:35:15,711:INFO:create_model() successfully completed......................................
2024-06-09 18:35:15,817:INFO:SubProcess create_model() end ==================================
2024-06-09 18:35:15,817:INFO:choose_better activated
2024-06-09 18:35:15,818:INFO:SubProcess create_model() called ==================================
2024-06-09 18:35:15,818:INFO:Initializing create_model()
2024-06-09 18:35:15,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-09 18:35:15,819:INFO:Checking exceptions
2024-06-09 18:35:15,819:INFO:Importing libraries
2024-06-09 18:35:15,820:INFO:Copying training dataset
2024-06-09 18:35:15,838:INFO:Defining folds
2024-06-09 18:35:15,838:INFO:Declaring metric variables
2024-06-09 18:35:15,838:INFO:Importing untrained model
2024-06-09 18:35:15,838:INFO:Declaring custom model
2024-06-09 18:35:15,839:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-09 18:35:15,840:INFO:Starting cross validation
2024-06-09 18:35:15,842:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-09 18:35:22,905:INFO:Calculating mean and std
2024-06-09 18:35:22,905:INFO:Creating metrics dataframe
2024-06-09 18:35:22,909:INFO:Finalizing model
2024-06-09 18:35:24,471:INFO:[LightGBM] [Info] Number of positive: 30638, number of negative: 30638
2024-06-09 18:35:24,482:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010268 seconds.
2024-06-09 18:35:24,482:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-09 18:35:24,483:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-09 18:35:24,484:INFO:[LightGBM] [Info] Number of data points in the train set: 61276, number of used features: 29
2024-06-09 18:35:24,486:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-09 18:35:25,975:INFO:Uploading results into container
2024-06-09 18:35:25,976:INFO:Uploading model into container now
2024-06-09 18:35:25,977:INFO:_master_model_container: 3
2024-06-09 18:35:25,977:INFO:_display_container: 4
2024-06-09 18:35:25,979:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-09 18:35:25,979:INFO:create_model() successfully completed......................................
2024-06-09 18:35:26,126:INFO:SubProcess create_model() end ==================================
2024-06-09 18:35:26,127:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2563
2024-06-09 18:35:26,128:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2562
2024-06-09 18:35:26,129:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-09 18:35:26,129:INFO:choose_better completed
2024-06-09 18:35:26,129:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-09 18:35:26,150:INFO:_master_model_container: 3
2024-06-09 18:35:26,151:INFO:_display_container: 3
2024-06-09 18:35:26,152:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-09 18:35:26,152:INFO:tune_model() successfully completed......................................
2024-06-09 18:35:26,350:INFO:Initializing plot_model()
2024-06-09 18:35:26,350:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:35:26,351:INFO:Checking exceptions
2024-06-09 18:35:26,366:INFO:Preloading libraries
2024-06-09 18:35:26,381:INFO:Copying training dataset
2024-06-09 18:35:26,381:INFO:Plot type: auc
2024-06-09 18:35:26,687:INFO:Fitting Model
2024-06-09 18:35:26,690:INFO:Scoring test/hold-out set
2024-06-09 18:35:26,821:INFO:Saving './output\AUC.png'
2024-06-09 18:35:27,247:INFO:Visual Rendered Successfully
2024-06-09 18:35:27,344:INFO:plot_model() successfully completed......................................
2024-06-09 18:35:27,354:INFO:Initializing plot_model()
2024-06-09 18:35:27,354:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=ks, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:35:27,354:INFO:Checking exceptions
2024-06-09 18:35:27,367:INFO:Preloading libraries
2024-06-09 18:35:27,387:INFO:Copying training dataset
2024-06-09 18:35:27,388:INFO:Plot type: ks
2024-06-09 18:35:27,388:INFO:Generating predictions / predict_proba on X_test
2024-06-09 18:35:27,959:INFO:Saving './output\KS Statistic Plot.png'
2024-06-09 18:35:28,608:INFO:Visual Rendered Successfully
2024-06-09 18:35:28,759:INFO:plot_model() successfully completed......................................
2024-06-09 18:35:28,907:INFO:Initializing plot_model()
2024-06-09 18:35:28,908:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:35:28,908:INFO:Checking exceptions
2024-06-09 18:35:28,926:INFO:Preloading libraries
2024-06-09 18:35:28,953:INFO:Copying training dataset
2024-06-09 18:35:28,953:INFO:Plot type: pr
2024-06-09 18:35:29,419:INFO:Fitting Model
2024-06-09 18:35:29,429:INFO:Scoring test/hold-out set
2024-06-09 18:35:29,570:INFO:Saving './output\Precision Recall.png'
2024-06-09 18:35:30,124:INFO:Visual Rendered Successfully
2024-06-09 18:35:30,266:INFO:plot_model() successfully completed......................................
2024-06-09 18:35:30,279:INFO:Initializing plot_model()
2024-06-09 18:35:30,279:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:35:30,279:INFO:Checking exceptions
2024-06-09 18:35:30,290:INFO:Preloading libraries
2024-06-09 18:35:30,303:INFO:Copying training dataset
2024-06-09 18:35:30,303:INFO:Plot type: feature
2024-06-09 18:35:30,304:WARNING:No coef_ found. Trying feature_importances_
2024-06-09 18:35:30,526:INFO:Saving './output\Feature Importance.png'
2024-06-09 18:35:30,938:INFO:Visual Rendered Successfully
2024-06-09 18:35:31,070:INFO:plot_model() successfully completed......................................
2024-06-09 18:35:31,173:INFO:Initializing plot_model()
2024-06-09 18:35:31,173:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:35:31,174:INFO:Checking exceptions
2024-06-09 18:35:31,192:INFO:Preloading libraries
2024-06-09 18:35:31,220:INFO:Copying training dataset
2024-06-09 18:35:31,220:INFO:Plot type: confusion_matrix
2024-06-09 18:35:31,624:INFO:Fitting Model
2024-06-09 18:35:31,625:INFO:Scoring test/hold-out set
2024-06-09 18:35:31,754:INFO:Saving './output\Confusion Matrix.png'
2024-06-09 18:35:31,999:INFO:Visual Rendered Successfully
2024-06-09 18:35:32,121:INFO:plot_model() successfully completed......................................
2024-06-09 18:35:32,133:INFO:Initializing finalize_model()
2024-06-09 18:35:32,133:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-09 18:35:32,133:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-09 18:35:32,149:INFO:Initializing create_model()
2024-06-09 18:35:32,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-09 18:35:32,149:INFO:Checking exceptions
2024-06-09 18:35:32,151:INFO:Importing libraries
2024-06-09 18:35:32,151:INFO:Copying training dataset
2024-06-09 18:35:32,152:INFO:Defining folds
2024-06-09 18:35:32,152:INFO:Declaring metric variables
2024-06-09 18:35:32,153:INFO:Importing untrained model
2024-06-09 18:35:32,153:INFO:Declaring custom model
2024-06-09 18:35:32,155:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-09 18:35:32,160:INFO:Cross validation set to False
2024-06-09 18:35:32,160:INFO:Fitting Model
2024-06-09 18:35:35,090:INFO:[LightGBM] [Info] Number of positive: 43775, number of negative: 43775
2024-06-09 18:35:35,105:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013586 seconds.
2024-06-09 18:35:35,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-09 18:35:35,106:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-09 18:35:35,107:INFO:[LightGBM] [Info] Number of data points in the train set: 87550, number of used features: 29
2024-06-09 18:35:35,109:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-09 18:35:36,616:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-09 18:35:36,616:INFO:create_model() successfully completed......................................
2024-06-09 18:35:36,724:INFO:_master_model_container: 3
2024-06-09 18:35:36,724:INFO:_display_container: 3
2024-06-09 18:35:36,788:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-09 18:35:36,788:INFO:finalize_model() successfully completed......................................
2024-06-09 18:35:36,890:INFO:Initializing predict_model()
2024-06-09 18:35:36,891:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B44252F740>)
2024-06-09 18:35:36,891:INFO:Checking exceptions
2024-06-09 18:35:36,891:INFO:Preloading libraries
2024-06-09 18:35:37,377:INFO:Initializing plot_model()
2024-06-09 18:35:37,377:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:35:37,378:INFO:Checking exceptions
2024-06-09 18:35:37,390:INFO:Preloading libraries
2024-06-09 18:35:37,403:INFO:Copying training dataset
2024-06-09 18:35:37,403:INFO:Plot type: auc
2024-06-09 18:35:37,685:INFO:Fitting Model
2024-06-09 18:35:37,688:INFO:Scoring test/hold-out set
2024-06-09 18:35:37,847:INFO:Saving './output\AUC.png'
2024-06-09 18:35:38,244:INFO:Visual Rendered Successfully
2024-06-09 18:35:38,332:INFO:plot_model() successfully completed......................................
2024-06-09 18:35:38,407:INFO:Initializing evaluate_model()
2024-06-09 18:35:38,407:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=5, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-09 18:35:38,474:INFO:Initializing plot_model()
2024-06-09 18:35:38,474:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B446536A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-09 18:35:38,474:INFO:Checking exceptions
2024-06-09 18:35:38,484:INFO:Preloading libraries
2024-06-09 18:35:38,494:INFO:Copying training dataset
2024-06-09 18:35:38,494:INFO:Plot type: pipeline
2024-06-09 18:35:38,736:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:582: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2024-06-09 18:35:38,736:INFO:Visual Rendered Successfully
2024-06-09 18:35:38,817:INFO:plot_model() successfully completed......................................
2024-06-09 18:40:49,572:INFO:PyCaret ClassificationExperiment
2024-06-09 18:40:49,572:INFO:Logging name: clf-default-name
2024-06-09 18:40:49,572:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-09 18:40:49,572:INFO:version 3.3.2
2024-06-09 18:40:49,572:INFO:Initializing setup()
2024-06-09 18:40:49,572:INFO:self.USI: 4ab9
2024-06-09 18:40:49,572:INFO:self._variable_keys: {'memory', 'html_param', 'fold_generator', 'gpu_param', 'data', 'is_multiclass', 'log_plots_param', 'fold_shuffle_param', 'y_train', 'gpu_n_jobs_param', 'X_test', 'y_test', 'idx', 'X', '_available_plots', 'exp_id', 'X_train', '_ml_usecase', 'logging_param', 'fold_groups_param', 'USI', 'seed', 'fix_imbalance', 'exp_name_log', 'y', 'target_param', 'n_jobs_param', 'pipeline'}
2024-06-09 18:40:49,572:INFO:Checking environment
2024-06-09 18:40:49,572:INFO:python_version: 3.11.9
2024-06-09 18:40:49,572:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-09 18:40:49,572:INFO:machine: AMD64
2024-06-09 18:40:49,572:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-09 18:40:49,574:INFO:Memory: svmem(total=34056318976, available=21859045376, percent=35.8, used=12197273600, free=21859045376)
2024-06-09 18:40:49,575:INFO:Physical Core: 6
2024-06-09 18:40:49,575:INFO:Logical Core: 12
2024-06-09 18:40:49,575:INFO:Checking libraries
2024-06-09 18:40:49,575:INFO:System:
2024-06-09 18:40:49,575:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-09 18:40:49,575:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-09 18:40:49,575:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-09 18:40:49,575:INFO:PyCaret required dependencies:
2024-06-09 18:40:49,575:INFO:                 pip: 24.0
2024-06-09 18:40:49,575:INFO:          setuptools: 69.5.1
2024-06-09 18:40:49,575:INFO:             pycaret: 3.3.2
2024-06-09 18:40:49,575:INFO:             IPython: 8.25.0
2024-06-09 18:40:49,575:INFO:          ipywidgets: 8.1.3
2024-06-09 18:40:49,575:INFO:                tqdm: 4.66.4
2024-06-09 18:40:49,575:INFO:               numpy: 1.26.4
2024-06-09 18:40:49,575:INFO:              pandas: 2.1.4
2024-06-09 18:40:49,575:INFO:              jinja2: 3.1.4
2024-06-09 18:40:49,575:INFO:               scipy: 1.11.4
2024-06-09 18:40:49,575:INFO:              joblib: 1.3.2
2024-06-09 18:40:49,575:INFO:             sklearn: 1.4.2
2024-06-09 18:40:49,575:INFO:                pyod: 2.0.0
2024-06-09 18:40:49,576:INFO:            imblearn: 0.12.3
2024-06-09 18:40:49,576:INFO:   category_encoders: 2.6.3
2024-06-09 18:40:49,576:INFO:            lightgbm: 4.3.0
2024-06-09 18:40:49,576:INFO:               numba: 0.59.1
2024-06-09 18:40:49,576:INFO:            requests: 2.32.3
2024-06-09 18:40:49,576:INFO:          matplotlib: 3.7.5
2024-06-09 18:40:49,576:INFO:          scikitplot: 0.3.7
2024-06-09 18:40:49,576:INFO:         yellowbrick: 1.5
2024-06-09 18:40:49,576:INFO:              plotly: 5.22.0
2024-06-09 18:40:49,576:INFO:    plotly-resampler: Not installed
2024-06-09 18:40:49,576:INFO:             kaleido: 0.2.1
2024-06-09 18:40:49,576:INFO:           schemdraw: 0.15
2024-06-09 18:40:49,576:INFO:         statsmodels: 0.14.2
2024-06-09 18:40:49,576:INFO:              sktime: 0.26.0
2024-06-09 18:40:49,576:INFO:               tbats: 1.1.3
2024-06-09 18:40:49,576:INFO:            pmdarima: 2.0.4
2024-06-09 18:40:49,576:INFO:              psutil: 5.9.8
2024-06-09 18:40:49,576:INFO:          markupsafe: 2.1.5
2024-06-09 18:40:49,576:INFO:             pickle5: Not installed
2024-06-09 18:40:49,576:INFO:         cloudpickle: 3.0.0
2024-06-09 18:40:49,576:INFO:         deprecation: 2.1.0
2024-06-09 18:40:49,576:INFO:              xxhash: 3.4.1
2024-06-09 18:40:49,576:INFO:           wurlitzer: Not installed
2024-06-09 18:40:49,576:INFO:PyCaret optional dependencies:
2024-06-09 18:40:49,576:INFO:                shap: Not installed
2024-06-09 18:40:49,577:INFO:           interpret: Not installed
2024-06-09 18:40:49,577:INFO:                umap: Not installed
2024-06-09 18:40:49,577:INFO:     ydata_profiling: Not installed
2024-06-09 18:40:49,577:INFO:  explainerdashboard: Not installed
2024-06-09 18:40:49,577:INFO:             autoviz: Not installed
2024-06-09 18:40:49,577:INFO:           fairlearn: Not installed
2024-06-09 18:40:49,577:INFO:          deepchecks: Not installed
2024-06-09 18:40:49,577:INFO:             xgboost: Not installed
2024-06-09 18:40:49,577:INFO:            catboost: Not installed
2024-06-09 18:40:49,577:INFO:              kmodes: Not installed
2024-06-09 18:40:49,577:INFO:             mlxtend: Not installed
2024-06-09 18:40:49,577:INFO:       statsforecast: Not installed
2024-06-09 18:40:49,577:INFO:        tune_sklearn: Not installed
2024-06-09 18:40:49,577:INFO:                 ray: Not installed
2024-06-09 18:40:49,577:INFO:            hyperopt: Not installed
2024-06-09 18:40:49,577:INFO:              optuna: Not installed
2024-06-09 18:40:49,577:INFO:               skopt: Not installed
2024-06-09 18:40:49,577:INFO:              mlflow: Not installed
2024-06-09 18:40:49,577:INFO:              gradio: Not installed
2024-06-09 18:40:49,577:INFO:             fastapi: Not installed
2024-06-09 18:40:49,577:INFO:             uvicorn: Not installed
2024-06-09 18:40:49,577:INFO:              m2cgen: Not installed
2024-06-09 18:40:49,578:INFO:           evidently: Not installed
2024-06-09 18:40:49,578:INFO:               fugue: Not installed
2024-06-09 18:40:49,578:INFO:           streamlit: 1.35.0
2024-06-09 18:40:49,578:INFO:             prophet: Not installed
2024-06-09 18:40:49,578:INFO:None
2024-06-09 18:40:49,578:INFO:Set up data.
2024-06-09 18:40:49,612:INFO:Set up folding strategy.
2024-06-09 18:40:49,612:INFO:Set up train/test split.
2024-06-09 18:40:49,639:INFO:Set up index.
2024-06-09 18:40:49,640:INFO:Assigning column types.
2024-06-09 18:40:49,654:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-09 18:40:49,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-09 18:40:49,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:40:49,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:49,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:49,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-09 18:40:49,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:40:49,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:49,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:49,822:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-09 18:40:49,868:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:40:49,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:49,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:49,955:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:40:49,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:49,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:49,985:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-09 18:40:50,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,131:INFO:Preparing preprocessing pipeline...
2024-06-09 18:40:50,133:INFO:Set up simple imputation.
2024-06-09 18:40:50,143:INFO:Set up encoding of ordinal features.
2024-06-09 18:40:50,151:INFO:Set up encoding of categorical features.
2024-06-09 18:40:50,152:INFO:Set up removing outliers.
2024-06-09 18:40:50,152:INFO:Set up imbalanced handling.
2024-06-09 18:40:50,152:INFO:Set up PCA.
2024-06-09 18:40:50,360:INFO:Finished creating preprocessing pipeline.
2024-06-09 18:40:50,398:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-09 18:40:50,398:INFO:Creating final display dataframe.
2024-06-09 18:40:50,545:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (76276, 30)
5   Transformed train set shape       (61276, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                          PCA              True
21                   PCA method            linear
22               PCA components              None
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              4ab9
2024-06-09 18:40:50,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,706:INFO:setup() successfully completed in 1.2s...............
2024-06-09 18:40:50,720:INFO:gpu_param set to False
2024-06-09 18:40:50,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,871:INFO:gpu_param set to False
2024-06-09 18:40:50,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:50,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,033:INFO:gpu_param set to False
2024-06-09 18:40:51,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,175:INFO:gpu_param set to False
2024-06-09 18:40:51,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:40:51,393:INFO:Initializing plot_model()
2024-06-09 18:40:51,393:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:40:51,393:INFO:Checking exceptions
2024-06-09 18:40:51,411:INFO:Preloading libraries
2024-06-09 18:40:51,420:INFO:Copying training dataset
2024-06-09 18:40:51,421:INFO:Plot type: auc
2024-06-09 18:40:51,613:INFO:Fitting Model
2024-06-09 18:40:51,615:INFO:Scoring test/hold-out set
2024-06-09 18:40:51,703:INFO:Saving './output\AUC.png'
2024-06-09 18:40:51,959:INFO:Visual Rendered Successfully
2024-06-09 18:40:52,042:INFO:plot_model() successfully completed......................................
2024-06-09 18:40:52,048:INFO:Initializing plot_model()
2024-06-09 18:40:52,048:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=ks, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:40:52,049:INFO:Checking exceptions
2024-06-09 18:40:52,054:INFO:Preloading libraries
2024-06-09 18:40:52,063:INFO:Copying training dataset
2024-06-09 18:40:52,064:INFO:Plot type: ks
2024-06-09 18:40:52,064:INFO:Generating predictions / predict_proba on X_test
2024-06-09 18:40:52,419:INFO:Saving './output\KS Statistic Plot.png'
2024-06-09 18:40:52,616:INFO:Visual Rendered Successfully
2024-06-09 18:40:52,690:INFO:plot_model() successfully completed......................................
2024-06-09 18:40:52,735:INFO:Initializing plot_model()
2024-06-09 18:40:52,735:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:40:52,735:INFO:Checking exceptions
2024-06-09 18:40:52,741:INFO:Preloading libraries
2024-06-09 18:40:52,747:INFO:Copying training dataset
2024-06-09 18:40:52,747:INFO:Plot type: pr
2024-06-09 18:40:52,920:INFO:Fitting Model
2024-06-09 18:40:52,922:INFO:Scoring test/hold-out set
2024-06-09 18:40:52,992:INFO:Saving './output\Precision Recall.png'
2024-06-09 18:40:53,190:INFO:Visual Rendered Successfully
2024-06-09 18:40:53,261:INFO:plot_model() successfully completed......................................
2024-06-09 18:40:53,269:INFO:Initializing plot_model()
2024-06-09 18:40:53,269:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:40:53,269:INFO:Checking exceptions
2024-06-09 18:40:53,275:INFO:Preloading libraries
2024-06-09 18:40:53,283:INFO:Copying training dataset
2024-06-09 18:40:53,283:INFO:Plot type: feature
2024-06-09 18:40:53,283:WARNING:No coef_ found. Trying feature_importances_
2024-06-09 18:40:53,381:INFO:Saving './output\Feature Importance.png'
2024-06-09 18:40:53,517:INFO:Visual Rendered Successfully
2024-06-09 18:40:53,586:INFO:plot_model() successfully completed......................................
2024-06-09 18:40:53,622:INFO:Initializing plot_model()
2024-06-09 18:40:53,622:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:40:53,622:INFO:Checking exceptions
2024-06-09 18:40:53,628:INFO:Preloading libraries
2024-06-09 18:40:53,635:INFO:Copying training dataset
2024-06-09 18:40:53,636:INFO:Plot type: confusion_matrix
2024-06-09 18:40:53,809:INFO:Fitting Model
2024-06-09 18:40:53,810:INFO:Scoring test/hold-out set
2024-06-09 18:40:53,879:INFO:Saving './output\Confusion Matrix.png'
2024-06-09 18:40:54,011:INFO:Visual Rendered Successfully
2024-06-09 18:40:54,082:INFO:plot_model() successfully completed......................................
2024-06-09 18:40:54,088:INFO:Initializing finalize_model()
2024-06-09 18:40:54,088:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-09 18:40:54,088:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-09 18:40:54,095:INFO:Initializing create_model()
2024-06-09 18:40:54,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-09 18:40:54,095:INFO:Checking exceptions
2024-06-09 18:40:54,096:INFO:Importing libraries
2024-06-09 18:40:54,096:INFO:Copying training dataset
2024-06-09 18:40:54,097:INFO:Defining folds
2024-06-09 18:40:54,097:INFO:Declaring metric variables
2024-06-09 18:40:54,097:INFO:Importing untrained model
2024-06-09 18:40:54,097:INFO:Declaring custom model
2024-06-09 18:40:54,098:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-09 18:40:54,100:INFO:Cross validation set to False
2024-06-09 18:40:54,100:INFO:Fitting Model
2024-06-09 18:40:56,390:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-09 18:40:56,390:INFO:create_model() successfully completed......................................
2024-06-09 18:40:56,470:INFO:_master_model_container: 0
2024-06-09 18:40:56,470:INFO:_display_container: 1
2024-06-09 18:40:56,525:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-09 18:40:56,525:INFO:finalize_model() successfully completed......................................
2024-06-09 18:40:56,602:INFO:Initializing predict_model()
2024-06-09 18:40:56,602:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B406325E40>)
2024-06-09 18:40:56,602:INFO:Checking exceptions
2024-06-09 18:40:56,602:INFO:Preloading libraries
2024-06-09 18:40:56,879:INFO:Initializing plot_model()
2024-06-09 18:40:56,879:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:40:56,879:INFO:Checking exceptions
2024-06-09 18:40:56,886:INFO:Preloading libraries
2024-06-09 18:40:56,892:INFO:Copying training dataset
2024-06-09 18:40:56,893:INFO:Plot type: auc
2024-06-09 18:40:57,069:INFO:Fitting Model
2024-06-09 18:40:57,071:INFO:Scoring test/hold-out set
2024-06-09 18:40:57,167:INFO:Saving './output\AUC.png'
2024-06-09 18:40:57,409:INFO:Visual Rendered Successfully
2024-06-09 18:40:57,484:INFO:plot_model() successfully completed......................................
2024-06-09 18:40:57,541:INFO:Initializing evaluate_model()
2024-06-09 18:40:57,542:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=5, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-09 18:40:57,681:INFO:Initializing plot_model()
2024-06-09 18:40:57,681:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43657DC90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-09 18:40:57,681:INFO:Checking exceptions
2024-06-09 18:40:57,686:INFO:Preloading libraries
2024-06-09 18:40:57,694:INFO:Copying training dataset
2024-06-09 18:40:57,694:INFO:Plot type: pipeline
2024-06-09 18:40:57,863:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:582: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2024-06-09 18:40:57,863:INFO:Visual Rendered Successfully
2024-06-09 18:40:57,933:INFO:plot_model() successfully completed......................................
2024-06-09 18:41:20,246:INFO:PyCaret ClassificationExperiment
2024-06-09 18:41:20,246:INFO:Logging name: clf-default-name
2024-06-09 18:41:20,246:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-09 18:41:20,246:INFO:version 3.3.2
2024-06-09 18:41:20,246:INFO:Initializing setup()
2024-06-09 18:41:20,246:INFO:self.USI: 8d9d
2024-06-09 18:41:20,247:INFO:self._variable_keys: {'memory', 'html_param', 'fold_generator', 'gpu_param', 'data', 'is_multiclass', 'log_plots_param', 'fold_shuffle_param', 'y_train', 'gpu_n_jobs_param', 'X_test', 'y_test', 'idx', 'X', '_available_plots', 'exp_id', 'X_train', '_ml_usecase', 'logging_param', 'fold_groups_param', 'USI', 'seed', 'fix_imbalance', 'exp_name_log', 'y', 'target_param', 'n_jobs_param', 'pipeline'}
2024-06-09 18:41:20,247:INFO:Checking environment
2024-06-09 18:41:20,247:INFO:python_version: 3.11.9
2024-06-09 18:41:20,247:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-09 18:41:20,247:INFO:machine: AMD64
2024-06-09 18:41:20,247:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-09 18:41:20,250:INFO:Memory: svmem(total=34056318976, available=22490394624, percent=34.0, used=11565924352, free=22490394624)
2024-06-09 18:41:20,250:INFO:Physical Core: 6
2024-06-09 18:41:20,250:INFO:Logical Core: 12
2024-06-09 18:41:20,251:INFO:Checking libraries
2024-06-09 18:41:20,251:INFO:System:
2024-06-09 18:41:20,251:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-09 18:41:20,251:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-09 18:41:20,251:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-09 18:41:20,251:INFO:PyCaret required dependencies:
2024-06-09 18:41:20,252:INFO:                 pip: 24.0
2024-06-09 18:41:20,252:INFO:          setuptools: 69.5.1
2024-06-09 18:41:20,252:INFO:             pycaret: 3.3.2
2024-06-09 18:41:20,252:INFO:             IPython: 8.25.0
2024-06-09 18:41:20,252:INFO:          ipywidgets: 8.1.3
2024-06-09 18:41:20,252:INFO:                tqdm: 4.66.4
2024-06-09 18:41:20,252:INFO:               numpy: 1.26.4
2024-06-09 18:41:20,252:INFO:              pandas: 2.1.4
2024-06-09 18:41:20,252:INFO:              jinja2: 3.1.4
2024-06-09 18:41:20,252:INFO:               scipy: 1.11.4
2024-06-09 18:41:20,252:INFO:              joblib: 1.3.2
2024-06-09 18:41:20,252:INFO:             sklearn: 1.4.2
2024-06-09 18:41:20,253:INFO:                pyod: 2.0.0
2024-06-09 18:41:20,253:INFO:            imblearn: 0.12.3
2024-06-09 18:41:20,253:INFO:   category_encoders: 2.6.3
2024-06-09 18:41:20,253:INFO:            lightgbm: 4.3.0
2024-06-09 18:41:20,253:INFO:               numba: 0.59.1
2024-06-09 18:41:20,253:INFO:            requests: 2.32.3
2024-06-09 18:41:20,253:INFO:          matplotlib: 3.7.5
2024-06-09 18:41:20,253:INFO:          scikitplot: 0.3.7
2024-06-09 18:41:20,254:INFO:         yellowbrick: 1.5
2024-06-09 18:41:20,254:INFO:              plotly: 5.22.0
2024-06-09 18:41:20,254:INFO:    plotly-resampler: Not installed
2024-06-09 18:41:20,254:INFO:             kaleido: 0.2.1
2024-06-09 18:41:20,254:INFO:           schemdraw: 0.15
2024-06-09 18:41:20,255:INFO:         statsmodels: 0.14.2
2024-06-09 18:41:20,255:INFO:              sktime: 0.26.0
2024-06-09 18:41:20,255:INFO:               tbats: 1.1.3
2024-06-09 18:41:20,255:INFO:            pmdarima: 2.0.4
2024-06-09 18:41:20,255:INFO:              psutil: 5.9.8
2024-06-09 18:41:20,255:INFO:          markupsafe: 2.1.5
2024-06-09 18:41:20,255:INFO:             pickle5: Not installed
2024-06-09 18:41:20,256:INFO:         cloudpickle: 3.0.0
2024-06-09 18:41:20,256:INFO:         deprecation: 2.1.0
2024-06-09 18:41:20,256:INFO:              xxhash: 3.4.1
2024-06-09 18:41:20,256:INFO:           wurlitzer: Not installed
2024-06-09 18:41:20,256:INFO:PyCaret optional dependencies:
2024-06-09 18:41:20,256:INFO:                shap: Not installed
2024-06-09 18:41:20,257:INFO:           interpret: Not installed
2024-06-09 18:41:20,257:INFO:                umap: Not installed
2024-06-09 18:41:20,257:INFO:     ydata_profiling: Not installed
2024-06-09 18:41:20,257:INFO:  explainerdashboard: Not installed
2024-06-09 18:41:20,257:INFO:             autoviz: Not installed
2024-06-09 18:41:20,257:INFO:           fairlearn: Not installed
2024-06-09 18:41:20,258:INFO:          deepchecks: Not installed
2024-06-09 18:41:20,258:INFO:             xgboost: Not installed
2024-06-09 18:41:20,258:INFO:            catboost: Not installed
2024-06-09 18:41:20,258:INFO:              kmodes: Not installed
2024-06-09 18:41:20,258:INFO:             mlxtend: Not installed
2024-06-09 18:41:20,258:INFO:       statsforecast: Not installed
2024-06-09 18:41:20,258:INFO:        tune_sklearn: Not installed
2024-06-09 18:41:20,259:INFO:                 ray: Not installed
2024-06-09 18:41:20,259:INFO:            hyperopt: Not installed
2024-06-09 18:41:20,259:INFO:              optuna: Not installed
2024-06-09 18:41:20,259:INFO:               skopt: Not installed
2024-06-09 18:41:20,259:INFO:              mlflow: Not installed
2024-06-09 18:41:20,259:INFO:              gradio: Not installed
2024-06-09 18:41:20,259:INFO:             fastapi: Not installed
2024-06-09 18:41:20,260:INFO:             uvicorn: Not installed
2024-06-09 18:41:20,260:INFO:              m2cgen: Not installed
2024-06-09 18:41:20,260:INFO:           evidently: Not installed
2024-06-09 18:41:20,260:INFO:               fugue: Not installed
2024-06-09 18:41:20,260:INFO:           streamlit: 1.35.0
2024-06-09 18:41:20,261:INFO:             prophet: Not installed
2024-06-09 18:41:20,261:INFO:None
2024-06-09 18:41:20,261:INFO:Set up data.
2024-06-09 18:41:20,302:INFO:Set up folding strategy.
2024-06-09 18:41:20,302:INFO:Set up train/test split.
2024-06-09 18:41:20,330:INFO:Set up index.
2024-06-09 18:41:20,331:INFO:Assigning column types.
2024-06-09 18:41:20,341:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-09 18:41:20,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-09 18:41:20,392:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:41:20,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-09 18:41:20,470:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:41:20,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,500:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-09 18:41:20,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:41:20,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,622:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-09 18:41:20,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,649:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-09 18:41:20,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,720:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:20,788:INFO:Preparing preprocessing pipeline...
2024-06-09 18:41:20,790:INFO:Set up simple imputation.
2024-06-09 18:41:20,800:INFO:Set up encoding of ordinal features.
2024-06-09 18:41:20,808:INFO:Set up encoding of categorical features.
2024-06-09 18:41:20,808:INFO:Set up removing outliers.
2024-06-09 18:41:20,809:INFO:Set up imbalanced handling.
2024-06-09 18:41:20,809:INFO:Set up PCA.
2024-06-09 18:41:21,010:INFO:Finished creating preprocessing pipeline.
2024-06-09 18:41:21,053:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-09 18:41:21,054:INFO:Creating final display dataframe.
2024-06-09 18:41:21,196:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (76276, 30)
5   Transformed train set shape       (61276, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                          PCA              True
21                   PCA method            linear
22               PCA components              None
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              8d9d
2024-06-09 18:41:21,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,333:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,334:INFO:setup() successfully completed in 1.17s...............
2024-06-09 18:41:21,345:INFO:gpu_param set to False
2024-06-09 18:41:21,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,485:INFO:gpu_param set to False
2024-06-09 18:41:21,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,631:INFO:gpu_param set to False
2024-06-09 18:41:21,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,776:INFO:gpu_param set to False
2024-06-09 18:41:21,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-09 18:41:21,980:INFO:Initializing plot_model()
2024-06-09 18:41:21,980:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:41:21,980:INFO:Checking exceptions
2024-06-09 18:41:21,997:INFO:Preloading libraries
2024-06-09 18:41:22,004:INFO:Copying training dataset
2024-06-09 18:41:22,005:INFO:Plot type: auc
2024-06-09 18:41:22,191:INFO:Fitting Model
2024-06-09 18:41:22,192:INFO:Scoring test/hold-out set
2024-06-09 18:41:22,275:INFO:Saving './output\AUC.png'
2024-06-09 18:41:22,506:INFO:Visual Rendered Successfully
2024-06-09 18:41:22,580:INFO:plot_model() successfully completed......................................
2024-06-09 18:41:22,586:INFO:Initializing plot_model()
2024-06-09 18:41:22,587:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=ks, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:41:22,587:INFO:Checking exceptions
2024-06-09 18:41:22,592:INFO:Preloading libraries
2024-06-09 18:41:22,599:INFO:Copying training dataset
2024-06-09 18:41:22,599:INFO:Plot type: ks
2024-06-09 18:41:22,600:INFO:Generating predictions / predict_proba on X_test
2024-06-09 18:41:22,961:INFO:Saving './output\KS Statistic Plot.png'
2024-06-09 18:41:23,158:INFO:Visual Rendered Successfully
2024-06-09 18:41:23,240:INFO:plot_model() successfully completed......................................
2024-06-09 18:41:23,284:INFO:Initializing plot_model()
2024-06-09 18:41:23,284:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:41:23,284:INFO:Checking exceptions
2024-06-09 18:41:23,290:INFO:Preloading libraries
2024-06-09 18:41:23,296:INFO:Copying training dataset
2024-06-09 18:41:23,296:INFO:Plot type: pr
2024-06-09 18:41:23,459:INFO:Fitting Model
2024-06-09 18:41:23,462:INFO:Scoring test/hold-out set
2024-06-09 18:41:23,519:INFO:Saving './output\Precision Recall.png'
2024-06-09 18:41:23,712:INFO:Visual Rendered Successfully
2024-06-09 18:41:23,788:INFO:plot_model() successfully completed......................................
2024-06-09 18:41:23,795:INFO:Initializing plot_model()
2024-06-09 18:41:23,795:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:41:23,795:INFO:Checking exceptions
2024-06-09 18:41:23,802:INFO:Preloading libraries
2024-06-09 18:41:23,808:INFO:Copying training dataset
2024-06-09 18:41:23,808:INFO:Plot type: feature
2024-06-09 18:41:23,808:WARNING:No coef_ found. Trying feature_importances_
2024-06-09 18:41:23,897:INFO:Saving './output\Feature Importance.png'
2024-06-09 18:41:24,032:INFO:Visual Rendered Successfully
2024-06-09 18:41:24,106:INFO:plot_model() successfully completed......................................
2024-06-09 18:41:24,143:INFO:Initializing plot_model()
2024-06-09 18:41:24,143:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:41:24,143:INFO:Checking exceptions
2024-06-09 18:41:24,149:INFO:Preloading libraries
2024-06-09 18:41:24,155:INFO:Copying training dataset
2024-06-09 18:41:24,155:INFO:Plot type: confusion_matrix
2024-06-09 18:41:24,326:INFO:Fitting Model
2024-06-09 18:41:24,327:INFO:Scoring test/hold-out set
2024-06-09 18:41:24,375:INFO:Saving './output\Confusion Matrix.png'
2024-06-09 18:41:24,528:INFO:Visual Rendered Successfully
2024-06-09 18:41:24,610:INFO:plot_model() successfully completed......................................
2024-06-09 18:41:24,616:INFO:Initializing finalize_model()
2024-06-09 18:41:24,616:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-09 18:41:24,616:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-09 18:41:24,623:INFO:Initializing create_model()
2024-06-09 18:41:24,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-09 18:41:24,624:INFO:Checking exceptions
2024-06-09 18:41:24,624:INFO:Importing libraries
2024-06-09 18:41:24,625:INFO:Copying training dataset
2024-06-09 18:41:24,625:INFO:Defining folds
2024-06-09 18:41:24,625:INFO:Declaring metric variables
2024-06-09 18:41:24,625:INFO:Importing untrained model
2024-06-09 18:41:24,625:INFO:Declaring custom model
2024-06-09 18:41:24,626:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-09 18:41:24,628:INFO:Cross validation set to False
2024-06-09 18:41:24,628:INFO:Fitting Model
2024-06-09 18:41:26,877:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-09 18:41:26,877:INFO:create_model() successfully completed......................................
2024-06-09 18:41:26,960:INFO:_master_model_container: 0
2024-06-09 18:41:26,960:INFO:_display_container: 1
2024-06-09 18:41:27,004:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-09 18:41:27,005:INFO:finalize_model() successfully completed......................................
2024-06-09 18:41:27,079:INFO:Initializing predict_model()
2024-06-09 18:41:27,079:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B46E5F31A0>)
2024-06-09 18:41:27,079:INFO:Checking exceptions
2024-06-09 18:41:27,079:INFO:Preloading libraries
2024-06-09 18:41:27,390:INFO:Initializing plot_model()
2024-06-09 18:41:27,390:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-09 18:41:27,390:INFO:Checking exceptions
2024-06-09 18:41:27,395:INFO:Preloading libraries
2024-06-09 18:41:27,402:INFO:Copying training dataset
2024-06-09 18:41:27,402:INFO:Plot type: auc
2024-06-09 18:41:27,570:INFO:Fitting Model
2024-06-09 18:41:27,572:INFO:Scoring test/hold-out set
2024-06-09 18:41:27,693:INFO:Saving './output\AUC.png'
2024-06-09 18:41:27,937:INFO:Visual Rendered Successfully
2024-06-09 18:41:28,012:INFO:plot_model() successfully completed......................................
2024-06-09 18:41:28,079:INFO:Initializing evaluate_model()
2024-06-09 18:41:28,079:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=5, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-09 18:41:28,154:INFO:Initializing plot_model()
2024-06-09 18:41:28,154:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B43CB16050>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-09 18:41:28,154:INFO:Checking exceptions
2024-06-09 18:41:28,160:INFO:Preloading libraries
2024-06-09 18:41:28,169:INFO:Copying training dataset
2024-06-09 18:41:28,169:INFO:Plot type: pipeline
2024-06-09 18:41:28,352:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:582: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2024-06-09 18:41:28,352:INFO:Visual Rendered Successfully
2024-06-09 18:41:28,429:INFO:plot_model() successfully completed......................................
2024-06-10 17:02:00,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:02:00,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:02:00,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:02:00,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:03:47,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:03:47,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:03:47,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:03:47,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:05:52,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:05:52,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:05:52,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:05:52,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:05:53,868:INFO:PyCaret ClassificationExperiment
2024-06-10 17:05:53,868:INFO:Logging name: clf-default-name
2024-06-10 17:05:53,868:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:05:53,868:INFO:version 3.3.2
2024-06-10 17:05:53,868:INFO:Initializing setup()
2024-06-10 17:05:53,868:INFO:self.USI: 90b0
2024-06-10 17:05:53,868:INFO:self._variable_keys: {'seed', 'html_param', 'logging_param', 'log_plots_param', 'gpu_param', 'y_test', 'memory', 'fold_groups_param', 'target_param', 'is_multiclass', 'idx', 'USI', 'X_train', 'gpu_n_jobs_param', 'data', '_ml_usecase', 'exp_id', 'fold_shuffle_param', 'exp_name_log', 'y', 'fix_imbalance', 'y_train', 'X', 'X_test', 'n_jobs_param', '_available_plots', 'pipeline', 'fold_generator'}
2024-06-10 17:05:53,868:INFO:Checking environment
2024-06-10 17:05:53,868:INFO:python_version: 3.11.9
2024-06-10 17:05:53,868:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:05:53,868:INFO:machine: AMD64
2024-06-10 17:05:53,868:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:05:53,869:INFO:Memory: svmem(total=34056318976, available=24553885696, percent=27.9, used=9502433280, free=24553885696)
2024-06-10 17:05:53,869:INFO:Physical Core: 6
2024-06-10 17:05:53,869:INFO:Logical Core: 12
2024-06-10 17:05:53,869:INFO:Checking libraries
2024-06-10 17:05:53,869:INFO:System:
2024-06-10 17:05:53,869:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:05:53,869:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:05:53,870:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:05:53,870:INFO:PyCaret required dependencies:
2024-06-10 17:05:53,908:INFO:                 pip: 24.0
2024-06-10 17:05:53,908:INFO:          setuptools: 69.5.1
2024-06-10 17:05:53,909:INFO:             pycaret: 3.3.2
2024-06-10 17:05:53,909:INFO:             IPython: 8.25.0
2024-06-10 17:05:53,909:INFO:          ipywidgets: 8.1.3
2024-06-10 17:05:53,909:INFO:                tqdm: 4.66.4
2024-06-10 17:05:53,909:INFO:               numpy: 1.26.4
2024-06-10 17:05:53,909:INFO:              pandas: 2.1.4
2024-06-10 17:05:53,909:INFO:              jinja2: 3.1.4
2024-06-10 17:05:53,909:INFO:               scipy: 1.11.4
2024-06-10 17:05:53,910:INFO:              joblib: 1.3.2
2024-06-10 17:05:53,910:INFO:             sklearn: 1.4.2
2024-06-10 17:05:53,910:INFO:                pyod: 2.0.0
2024-06-10 17:05:53,910:INFO:            imblearn: 0.12.3
2024-06-10 17:05:53,910:INFO:   category_encoders: 2.6.3
2024-06-10 17:05:53,910:INFO:            lightgbm: 4.3.0
2024-06-10 17:05:53,910:INFO:               numba: 0.59.1
2024-06-10 17:05:53,910:INFO:            requests: 2.32.3
2024-06-10 17:05:53,910:INFO:          matplotlib: 3.7.5
2024-06-10 17:05:53,910:INFO:          scikitplot: 0.3.7
2024-06-10 17:05:53,910:INFO:         yellowbrick: 1.5
2024-06-10 17:05:53,911:INFO:              plotly: 5.22.0
2024-06-10 17:05:53,911:INFO:    plotly-resampler: Not installed
2024-06-10 17:05:53,911:INFO:             kaleido: 0.2.1
2024-06-10 17:05:53,911:INFO:           schemdraw: 0.15
2024-06-10 17:05:53,911:INFO:         statsmodels: 0.14.2
2024-06-10 17:05:53,911:INFO:              sktime: 0.26.0
2024-06-10 17:05:53,911:INFO:               tbats: 1.1.3
2024-06-10 17:05:53,911:INFO:            pmdarima: 2.0.4
2024-06-10 17:05:53,911:INFO:              psutil: 5.9.8
2024-06-10 17:05:53,911:INFO:          markupsafe: 2.1.5
2024-06-10 17:05:53,911:INFO:             pickle5: Not installed
2024-06-10 17:05:53,911:INFO:         cloudpickle: 3.0.0
2024-06-10 17:05:53,911:INFO:         deprecation: 2.1.0
2024-06-10 17:05:53,911:INFO:              xxhash: 3.4.1
2024-06-10 17:05:53,911:INFO:           wurlitzer: Not installed
2024-06-10 17:05:53,911:INFO:PyCaret optional dependencies:
2024-06-10 17:05:53,923:INFO:                shap: Not installed
2024-06-10 17:05:53,923:INFO:           interpret: Not installed
2024-06-10 17:05:53,923:INFO:                umap: Not installed
2024-06-10 17:05:53,923:INFO:     ydata_profiling: Not installed
2024-06-10 17:05:53,923:INFO:  explainerdashboard: Not installed
2024-06-10 17:05:53,923:INFO:             autoviz: Not installed
2024-06-10 17:05:53,923:INFO:           fairlearn: Not installed
2024-06-10 17:05:53,923:INFO:          deepchecks: Not installed
2024-06-10 17:05:53,923:INFO:             xgboost: Not installed
2024-06-10 17:05:53,923:INFO:            catboost: Not installed
2024-06-10 17:05:53,924:INFO:              kmodes: Not installed
2024-06-10 17:05:53,924:INFO:             mlxtend: Not installed
2024-06-10 17:05:53,924:INFO:       statsforecast: Not installed
2024-06-10 17:05:53,924:INFO:        tune_sklearn: Not installed
2024-06-10 17:05:53,924:INFO:                 ray: Not installed
2024-06-10 17:05:53,924:INFO:            hyperopt: Not installed
2024-06-10 17:05:53,924:INFO:              optuna: Not installed
2024-06-10 17:05:53,924:INFO:               skopt: Not installed
2024-06-10 17:05:53,924:INFO:              mlflow: Not installed
2024-06-10 17:05:53,924:INFO:              gradio: Not installed
2024-06-10 17:05:53,924:INFO:             fastapi: Not installed
2024-06-10 17:05:53,924:INFO:             uvicorn: Not installed
2024-06-10 17:05:53,924:INFO:              m2cgen: Not installed
2024-06-10 17:05:53,924:INFO:           evidently: Not installed
2024-06-10 17:05:53,924:INFO:               fugue: Not installed
2024-06-10 17:05:53,924:INFO:           streamlit: 1.35.0
2024-06-10 17:05:53,924:INFO:             prophet: Not installed
2024-06-10 17:05:53,924:INFO:None
2024-06-10 17:05:53,924:INFO:Set up data.
2024-06-10 17:05:54,456:INFO:Set up folding strategy.
2024-06-10 17:05:54,456:INFO:Set up train/test split.
2024-06-10 17:05:54,965:INFO:Set up index.
2024-06-10 17:05:54,990:INFO:Assigning column types.
2024-06-10 17:05:55,158:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:05:55,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:05:55,215:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:05:55,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,332:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:05:55,333:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:05:55,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,362:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:05:55,407:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:05:55,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,492:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:05:55,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,522:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:05:55,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:05:55,682:INFO:Preparing preprocessing pipeline...
2024-06-10 17:05:55,707:INFO:Set up date feature engineering.
2024-06-10 17:05:55,707:INFO:Set up simple imputation.
2024-06-10 17:05:55,882:INFO:Set up encoding of ordinal features.
2024-06-10 17:05:56,020:INFO:Set up encoding of categorical features.
2024-06-10 17:05:56,020:INFO:Set up removing outliers.
2024-06-10 17:05:56,020:INFO:Set up imbalanced handling.
2024-06-10 17:05:56,020:INFO:Set up feature normalization.
2024-06-10 17:05:58,457:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:05:58,500:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MaxAbsScaler(copy=True)))],
         verbose=False)
2024-06-10 17:05:58,500:INFO:Creating final display dataframe.
2024-06-10 17:06:02,322:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 15)
4        Transformed data shape     (1144816, 34)
5   Transformed train set shape      (919816, 34)
6    Transformed test set shape      (225000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             16.8%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            maxabs
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              90b0
2024-06-10 17:06:02,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:06:02,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:06:02,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:06:02,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:06:02,473:INFO:setup() successfully completed in 8.85s...............
2024-06-10 17:06:02,692:INFO:Initializing create_model()
2024-06-10 17:06:02,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EB4C82350>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:06:02,693:INFO:Checking exceptions
2024-06-10 17:06:02,715:INFO:Importing libraries
2024-06-10 17:06:02,715:INFO:Copying training dataset
2024-06-10 17:06:03,098:INFO:Defining folds
2024-06-10 17:06:03,098:INFO:Declaring metric variables
2024-06-10 17:06:03,102:INFO:Importing untrained model
2024-06-10 17:06:03,105:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:06:03,114:INFO:Starting cross validation
2024-06-10 17:06:03,117:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:06:58,145:INFO:Calculating mean and std
2024-06-10 17:06:58,150:INFO:Creating metrics dataframe
2024-06-10 17:06:58,168:INFO:Finalizing model
2024-06-10 17:07:16,858:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-10 17:07:16,860:INFO:[LightGBM] [Info] Number of positive: 459908, number of negative: 459908
2024-06-10 17:07:17,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081094 seconds.
2024-06-10 17:07:17,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-10 17:07:17,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-10 17:07:17,061:INFO:[LightGBM] [Info] Total Bins 7228
2024-06-10 17:07:17,061:INFO:[LightGBM] [Info] Number of data points in the train set: 919816, number of used features: 32
2024-06-10 17:07:17,070:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:07:21,286:INFO:Uploading results into container
2024-06-10 17:07:21,288:INFO:Uploading model into container now
2024-06-10 17:07:21,309:INFO:_master_model_container: 1
2024-06-10 17:07:21,311:INFO:_display_container: 2
2024-06-10 17:07:21,312:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:07:21,312:INFO:create_model() successfully completed......................................
2024-06-10 17:07:21,903:INFO:Initializing tune_model()
2024-06-10 17:07:21,903:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EB4C82350>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 17:07:21,903:INFO:Checking exceptions
2024-06-10 17:07:22,126:INFO:Copying training dataset
2024-06-10 17:07:22,350:INFO:Checking base model
2024-06-10 17:07:22,351:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 17:07:22,354:INFO:Declaring metric variables
2024-06-10 17:07:22,358:INFO:Defining Hyperparameters
2024-06-10 17:07:22,440:INFO:Tuning with n_jobs=-1
2024-06-10 17:07:22,441:INFO:Initializing RandomizedSearchCV
2024-06-10 17:13:08,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:13:08,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:13:08,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:13:08,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:13:33,819:INFO:PyCaret ClassificationExperiment
2024-06-10 17:13:33,819:INFO:Logging name: clf-default-name
2024-06-10 17:13:33,819:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:13:33,819:INFO:version 3.3.2
2024-06-10 17:13:33,819:INFO:Initializing setup()
2024-06-10 17:13:33,819:INFO:self.USI: 2397
2024-06-10 17:13:33,819:INFO:self._variable_keys: {'y', 'y_train', 'X', '_available_plots', 'memory', 'html_param', 'pipeline', 'idx', 'fold_groups_param', '_ml_usecase', 'fold_shuffle_param', 'exp_name_log', 'data', 'exp_id', 'X_test', 'X_train', 'seed', 'logging_param', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'fix_imbalance', 'y_test', 'log_plots_param', 'n_jobs_param', 'is_multiclass', 'fold_generator', 'target_param'}
2024-06-10 17:13:33,819:INFO:Checking environment
2024-06-10 17:13:33,819:INFO:python_version: 3.11.9
2024-06-10 17:13:33,821:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:13:33,821:INFO:machine: AMD64
2024-06-10 17:13:33,821:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:13:33,821:INFO:Memory: svmem(total=34056318976, available=24283443200, percent=28.7, used=9772875776, free=24283443200)
2024-06-10 17:13:33,821:INFO:Physical Core: 6
2024-06-10 17:13:33,821:INFO:Logical Core: 12
2024-06-10 17:13:33,821:INFO:Checking libraries
2024-06-10 17:13:33,821:INFO:System:
2024-06-10 17:13:33,822:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:13:33,822:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:13:33,822:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:13:33,822:INFO:PyCaret required dependencies:
2024-06-10 17:13:33,849:INFO:                 pip: 24.0
2024-06-10 17:13:33,851:INFO:          setuptools: 69.5.1
2024-06-10 17:13:33,851:INFO:             pycaret: 3.3.2
2024-06-10 17:13:33,851:INFO:             IPython: 8.25.0
2024-06-10 17:13:33,851:INFO:          ipywidgets: 8.1.3
2024-06-10 17:13:33,851:INFO:                tqdm: 4.66.4
2024-06-10 17:13:33,851:INFO:               numpy: 1.26.4
2024-06-10 17:13:33,851:INFO:              pandas: 2.1.4
2024-06-10 17:13:33,851:INFO:              jinja2: 3.1.4
2024-06-10 17:13:33,851:INFO:               scipy: 1.11.4
2024-06-10 17:13:33,851:INFO:              joblib: 1.3.2
2024-06-10 17:13:33,851:INFO:             sklearn: 1.4.2
2024-06-10 17:13:33,851:INFO:                pyod: 2.0.0
2024-06-10 17:13:33,851:INFO:            imblearn: 0.12.3
2024-06-10 17:13:33,851:INFO:   category_encoders: 2.6.3
2024-06-10 17:13:33,852:INFO:            lightgbm: 4.3.0
2024-06-10 17:13:33,852:INFO:               numba: 0.59.1
2024-06-10 17:13:33,852:INFO:            requests: 2.32.3
2024-06-10 17:13:33,852:INFO:          matplotlib: 3.7.5
2024-06-10 17:13:33,852:INFO:          scikitplot: 0.3.7
2024-06-10 17:13:33,852:INFO:         yellowbrick: 1.5
2024-06-10 17:13:33,852:INFO:              plotly: 5.22.0
2024-06-10 17:13:33,852:INFO:    plotly-resampler: Not installed
2024-06-10 17:13:33,852:INFO:             kaleido: 0.2.1
2024-06-10 17:13:33,852:INFO:           schemdraw: 0.15
2024-06-10 17:13:33,852:INFO:         statsmodels: 0.14.2
2024-06-10 17:13:33,852:INFO:              sktime: 0.26.0
2024-06-10 17:13:33,852:INFO:               tbats: 1.1.3
2024-06-10 17:13:33,852:INFO:            pmdarima: 2.0.4
2024-06-10 17:13:33,852:INFO:              psutil: 5.9.8
2024-06-10 17:13:33,852:INFO:          markupsafe: 2.1.5
2024-06-10 17:13:33,852:INFO:             pickle5: Not installed
2024-06-10 17:13:33,852:INFO:         cloudpickle: 3.0.0
2024-06-10 17:13:33,853:INFO:         deprecation: 2.1.0
2024-06-10 17:13:33,853:INFO:              xxhash: 3.4.1
2024-06-10 17:13:33,853:INFO:           wurlitzer: Not installed
2024-06-10 17:13:33,853:INFO:PyCaret optional dependencies:
2024-06-10 17:13:33,866:INFO:                shap: Not installed
2024-06-10 17:13:33,866:INFO:           interpret: Not installed
2024-06-10 17:13:33,866:INFO:                umap: Not installed
2024-06-10 17:13:33,866:INFO:     ydata_profiling: Not installed
2024-06-10 17:13:33,867:INFO:  explainerdashboard: Not installed
2024-06-10 17:13:33,867:INFO:             autoviz: Not installed
2024-06-10 17:13:33,867:INFO:           fairlearn: Not installed
2024-06-10 17:13:33,867:INFO:          deepchecks: Not installed
2024-06-10 17:13:33,867:INFO:             xgboost: Not installed
2024-06-10 17:13:33,867:INFO:            catboost: Not installed
2024-06-10 17:13:33,867:INFO:              kmodes: Not installed
2024-06-10 17:13:33,867:INFO:             mlxtend: Not installed
2024-06-10 17:13:33,867:INFO:       statsforecast: Not installed
2024-06-10 17:13:33,867:INFO:        tune_sklearn: Not installed
2024-06-10 17:13:33,867:INFO:                 ray: Not installed
2024-06-10 17:13:33,867:INFO:            hyperopt: Not installed
2024-06-10 17:13:33,867:INFO:              optuna: Not installed
2024-06-10 17:13:33,867:INFO:               skopt: Not installed
2024-06-10 17:13:33,867:INFO:              mlflow: Not installed
2024-06-10 17:13:33,867:INFO:              gradio: Not installed
2024-06-10 17:13:33,867:INFO:             fastapi: Not installed
2024-06-10 17:13:33,867:INFO:             uvicorn: Not installed
2024-06-10 17:13:33,867:INFO:              m2cgen: Not installed
2024-06-10 17:13:33,867:INFO:           evidently: Not installed
2024-06-10 17:13:33,867:INFO:               fugue: Not installed
2024-06-10 17:13:33,867:INFO:           streamlit: 1.35.0
2024-06-10 17:13:33,867:INFO:             prophet: Not installed
2024-06-10 17:13:33,868:INFO:None
2024-06-10 17:13:33,868:INFO:Set up data.
2024-06-10 17:13:34,351:INFO:Set up folding strategy.
2024-06-10 17:13:34,351:INFO:Set up train/test split.
2024-06-10 17:13:34,821:INFO:Set up index.
2024-06-10 17:13:34,840:INFO:Assigning column types.
2024-06-10 17:13:34,966:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:13:35,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:13:35,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:13:35,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,088:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:13:35,089:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:13:35,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,116:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:13:35,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:13:35,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,225:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:13:35,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,253:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:13:35,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:35,419:INFO:Preparing preprocessing pipeline...
2024-06-10 17:13:35,444:INFO:Set up date feature engineering.
2024-06-10 17:13:35,444:INFO:Set up simple imputation.
2024-06-10 17:13:35,590:INFO:Set up encoding of ordinal features.
2024-06-10 17:13:35,718:INFO:Set up encoding of categorical features.
2024-06-10 17:13:35,719:INFO:Set up removing outliers.
2024-06-10 17:13:35,719:INFO:Set up feature normalization.
2024-06-10 17:13:35,719:INFO:Set up PCA.
2024-06-10 17:13:40,045:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:13:40,079:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 17:13:40,079:INFO:Creating final display dataframe.
2024-06-10 17:13:43,704:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 15)
4        Transformed data shape      (723750, 34)
5   Transformed train set shape      (498750, 34)
6    Transformed test set shape      (225000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             16.8%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21                          PCA              True
22                   PCA method       incremental
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              2397
2024-06-10 17:13:43,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:43,785:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:43,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:43,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:13:43,863:INFO:setup() successfully completed in 10.11s...............
2024-06-10 17:13:56,128:INFO:Initializing create_model()
2024-06-10 17:13:56,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ED1C82F950>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:13:56,128:INFO:Checking exceptions
2024-06-10 17:13:56,151:INFO:Importing libraries
2024-06-10 17:13:56,151:INFO:Copying training dataset
2024-06-10 17:13:56,493:INFO:Defining folds
2024-06-10 17:13:56,493:INFO:Declaring metric variables
2024-06-10 17:13:56,496:INFO:Importing untrained model
2024-06-10 17:13:56,500:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:13:56,515:INFO:Starting cross validation
2024-06-10 17:13:56,522:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:14:38,982:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:14:40,610:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:14:40,876:INFO:Calculating mean and std
2024-06-10 17:14:40,878:INFO:Creating metrics dataframe
2024-06-10 17:14:40,889:INFO:Finalizing model
2024-06-10 17:14:58,381:INFO:[LightGBM] [Info] Number of positive: 38842, number of negative: 459908
2024-06-10 17:14:58,460:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076046 seconds.
2024-06-10 17:14:58,460:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:14:58,463:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:14:58,463:INFO:[LightGBM] [Info] Number of data points in the train set: 498750, number of used features: 33
2024-06-10 17:14:58,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077879 -> initscore=-2.471524
2024-06-10 17:14:58,470:INFO:[LightGBM] [Info] Start training from score -2.471524
2024-06-10 17:15:03,300:INFO:Uploading results into container
2024-06-10 17:15:03,303:INFO:Uploading model into container now
2024-06-10 17:15:03,324:INFO:_master_model_container: 1
2024-06-10 17:15:03,324:INFO:_display_container: 2
2024-06-10 17:15:03,326:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:15:03,326:INFO:create_model() successfully completed......................................
2024-06-10 17:15:03,500:INFO:Initializing tune_model()
2024-06-10 17:15:03,500:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ED1C82F950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 17:15:03,500:INFO:Checking exceptions
2024-06-10 17:15:03,733:INFO:Copying training dataset
2024-06-10 17:15:03,980:INFO:Checking base model
2024-06-10 17:15:03,980:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 17:15:03,984:INFO:Declaring metric variables
2024-06-10 17:15:03,989:INFO:Defining Hyperparameters
2024-06-10 17:15:04,101:INFO:Tuning with n_jobs=-1
2024-06-10 17:15:04,101:INFO:Initializing RandomizedSearchCV
2024-06-10 17:16:37,396:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:16:37,787:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:16:38,016:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:16:44,523:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:16:51,623:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:17:57,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:57,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:57,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:57,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:58,372:INFO:PyCaret ClassificationExperiment
2024-06-10 17:17:58,372:INFO:Logging name: clf-default-name
2024-06-10 17:17:58,372:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:17:58,372:INFO:version 3.3.2
2024-06-10 17:17:58,372:INFO:Initializing setup()
2024-06-10 17:17:58,372:INFO:self.USI: e5b0
2024-06-10 17:17:58,372:INFO:self._variable_keys: {'_available_plots', 'is_multiclass', 'USI', 'fold_generator', 'fix_imbalance', 'n_jobs_param', 'seed', 'html_param', 'target_param', 'X_train', 'y_test', 'fold_shuffle_param', 'data', 'logging_param', 'X_test', 'exp_name_log', 'log_plots_param', 'y', 'idx', 'X', 'pipeline', 'gpu_n_jobs_param', 'gpu_param', 'exp_id', 'memory', 'fold_groups_param', 'y_train', '_ml_usecase'}
2024-06-10 17:17:58,372:INFO:Checking environment
2024-06-10 17:17:58,372:INFO:python_version: 3.11.9
2024-06-10 17:17:58,372:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:17:58,372:INFO:machine: AMD64
2024-06-10 17:17:58,373:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:17:58,373:INFO:Memory: svmem(total=34056318976, available=24095051776, percent=29.2, used=9961267200, free=24095051776)
2024-06-10 17:17:58,373:INFO:Physical Core: 6
2024-06-10 17:17:58,373:INFO:Logical Core: 12
2024-06-10 17:17:58,373:INFO:Checking libraries
2024-06-10 17:17:58,373:INFO:System:
2024-06-10 17:17:58,373:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:17:58,374:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:17:58,374:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:17:58,374:INFO:PyCaret required dependencies:
2024-06-10 17:17:58,403:INFO:                 pip: 24.0
2024-06-10 17:17:58,403:INFO:          setuptools: 69.5.1
2024-06-10 17:17:58,403:INFO:             pycaret: 3.3.2
2024-06-10 17:17:58,403:INFO:             IPython: 8.25.0
2024-06-10 17:17:58,403:INFO:          ipywidgets: 8.1.3
2024-06-10 17:17:58,403:INFO:                tqdm: 4.66.4
2024-06-10 17:17:58,403:INFO:               numpy: 1.26.4
2024-06-10 17:17:58,403:INFO:              pandas: 2.1.4
2024-06-10 17:17:58,403:INFO:              jinja2: 3.1.4
2024-06-10 17:17:58,403:INFO:               scipy: 1.11.4
2024-06-10 17:17:58,403:INFO:              joblib: 1.3.2
2024-06-10 17:17:58,403:INFO:             sklearn: 1.4.2
2024-06-10 17:17:58,403:INFO:                pyod: 2.0.0
2024-06-10 17:17:58,403:INFO:            imblearn: 0.12.3
2024-06-10 17:17:58,403:INFO:   category_encoders: 2.6.3
2024-06-10 17:17:58,403:INFO:            lightgbm: 4.3.0
2024-06-10 17:17:58,403:INFO:               numba: 0.59.1
2024-06-10 17:17:58,403:INFO:            requests: 2.32.3
2024-06-10 17:17:58,403:INFO:          matplotlib: 3.7.5
2024-06-10 17:17:58,404:INFO:          scikitplot: 0.3.7
2024-06-10 17:17:58,404:INFO:         yellowbrick: 1.5
2024-06-10 17:17:58,404:INFO:              plotly: 5.22.0
2024-06-10 17:17:58,404:INFO:    plotly-resampler: Not installed
2024-06-10 17:17:58,404:INFO:             kaleido: 0.2.1
2024-06-10 17:17:58,404:INFO:           schemdraw: 0.15
2024-06-10 17:17:58,404:INFO:         statsmodels: 0.14.2
2024-06-10 17:17:58,404:INFO:              sktime: 0.26.0
2024-06-10 17:17:58,404:INFO:               tbats: 1.1.3
2024-06-10 17:17:58,404:INFO:            pmdarima: 2.0.4
2024-06-10 17:17:58,404:INFO:              psutil: 5.9.8
2024-06-10 17:17:58,405:INFO:          markupsafe: 2.1.5
2024-06-10 17:17:58,405:INFO:             pickle5: Not installed
2024-06-10 17:17:58,405:INFO:         cloudpickle: 3.0.0
2024-06-10 17:17:58,405:INFO:         deprecation: 2.1.0
2024-06-10 17:17:58,405:INFO:              xxhash: 3.4.1
2024-06-10 17:17:58,405:INFO:           wurlitzer: Not installed
2024-06-10 17:17:58,405:INFO:PyCaret optional dependencies:
2024-06-10 17:17:58,419:INFO:                shap: Not installed
2024-06-10 17:17:58,419:INFO:           interpret: Not installed
2024-06-10 17:17:58,419:INFO:                umap: Not installed
2024-06-10 17:17:58,419:INFO:     ydata_profiling: Not installed
2024-06-10 17:17:58,420:INFO:  explainerdashboard: Not installed
2024-06-10 17:17:58,420:INFO:             autoviz: Not installed
2024-06-10 17:17:58,420:INFO:           fairlearn: Not installed
2024-06-10 17:17:58,420:INFO:          deepchecks: Not installed
2024-06-10 17:17:58,420:INFO:             xgboost: Not installed
2024-06-10 17:17:58,420:INFO:            catboost: Not installed
2024-06-10 17:17:58,420:INFO:              kmodes: Not installed
2024-06-10 17:17:58,420:INFO:             mlxtend: Not installed
2024-06-10 17:17:58,420:INFO:       statsforecast: Not installed
2024-06-10 17:17:58,420:INFO:        tune_sklearn: Not installed
2024-06-10 17:17:58,420:INFO:                 ray: Not installed
2024-06-10 17:17:58,420:INFO:            hyperopt: Not installed
2024-06-10 17:17:58,420:INFO:              optuna: Not installed
2024-06-10 17:17:58,420:INFO:               skopt: Not installed
2024-06-10 17:17:58,420:INFO:              mlflow: Not installed
2024-06-10 17:17:58,420:INFO:              gradio: Not installed
2024-06-10 17:17:58,420:INFO:             fastapi: Not installed
2024-06-10 17:17:58,420:INFO:             uvicorn: Not installed
2024-06-10 17:17:58,420:INFO:              m2cgen: Not installed
2024-06-10 17:17:58,420:INFO:           evidently: Not installed
2024-06-10 17:17:58,420:INFO:               fugue: Not installed
2024-06-10 17:17:58,420:INFO:           streamlit: 1.35.0
2024-06-10 17:17:58,420:INFO:             prophet: Not installed
2024-06-10 17:17:58,420:INFO:None
2024-06-10 17:17:58,420:INFO:Set up GPU usage.
2024-06-10 17:17:58,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:58,421:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-06-10 17:17:58,421:INFO:Set up data.
2024-06-10 17:17:59,059:INFO:Set up folding strategy.
2024-06-10 17:17:59,059:INFO:Set up train/test split.
2024-06-10 17:17:59,559:INFO:Set up index.
2024-06-10 17:17:59,583:INFO:Assigning column types.
2024-06-10 17:17:59,752:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:17:59,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:59,820:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:17:59,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:59,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:59,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:17:59,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:59,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:59,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:17:59,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:09,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:09,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,600:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:18:09,600:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,600:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,602:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:18:09,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:09,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:09,711:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:18:09,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,786:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:18:09,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:09,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:09,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,919:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:18:09,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:09,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:09,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:09,985:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:18:09,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:10,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:10,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:10,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:10,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:10,256:INFO:Preparing preprocessing pipeline...
2024-06-10 17:18:10,293:INFO:Set up date feature engineering.
2024-06-10 17:18:10,293:INFO:Set up simple imputation.
2024-06-10 17:18:10,476:INFO:Set up encoding of ordinal features.
2024-06-10 17:18:10,601:INFO:Set up encoding of categorical features.
2024-06-10 17:18:10,603:INFO:Set up removing outliers.
2024-06-10 17:18:10,603:INFO:Set up imbalanced handling.
2024-06-10 17:18:10,603:INFO:Set up feature normalization.
2024-06-10 17:18:10,603:INFO:Set up PCA.
2024-06-10 17:18:18,997:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:18:19,046:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 17:18:19,046:INFO:Creating final display dataframe.
2024-06-10 17:18:24,231:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 15)
4        Transformed data shape     (1144816, 34)
5   Transformed train set shape      (919816, 34)
6    Transformed test set shape      (225000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             16.8%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU              True
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              e5b0
2024-06-10 17:18:24,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:24,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:24,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:18:24,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:24,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:18:24,510:INFO:setup() successfully completed in 26.21s...............
2024-06-10 17:18:38,292:INFO:Initializing create_model()
2024-06-10 17:18:38,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205FCF6C810>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:18:38,293:INFO:Checking exceptions
2024-06-10 17:18:38,313:INFO:Importing libraries
2024-06-10 17:18:38,313:INFO:Copying training dataset
2024-06-10 17:18:38,655:INFO:Defining folds
2024-06-10 17:18:38,655:INFO:Declaring metric variables
2024-06-10 17:18:38,658:INFO:Importing untrained model
2024-06-10 17:18:38,661:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:18:38,669:INFO:Starting cross validation
2024-06-10 17:18:38,670:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-06-10 17:18:59,043:INFO:[LightGBM] [Info] Number of positive: 368006, number of negative: 368006
2024-06-10 17:18:59,045:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:18:59,050:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:18:59,052:INFO:[LightGBM] [Info] Number of data points in the train set: 736012, number of used features: 33
2024-06-10 17:18:59,060:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:18:59,060:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:19:06,457:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:19:06,466:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:19:06,520:INFO:[LightGBM] [Info] 33 dense feature groups (25.27 MB) transferred to GPU in 0.052767 secs. 0 sparse feature groups
2024-06-10 17:19:06,524:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:19:37,382:INFO:[LightGBM] [Info] Number of positive: 367854, number of negative: 367854
2024-06-10 17:19:37,382:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:19:37,385:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:19:37,386:INFO:[LightGBM] [Info] Number of data points in the train set: 735708, number of used features: 33
2024-06-10 17:19:37,386:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:19:37,386:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:19:37,433:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:19:37,439:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:19:37,480:INFO:[LightGBM] [Info] 33 dense feature groups (25.26 MB) transferred to GPU in 0.040358 secs. 0 sparse feature groups
2024-06-10 17:19:37,485:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:20:04,876:INFO:[LightGBM] [Info] Number of positive: 367923, number of negative: 367923
2024-06-10 17:20:04,876:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:20:04,879:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:20:04,881:INFO:[LightGBM] [Info] Number of data points in the train set: 735846, number of used features: 33
2024-06-10 17:20:04,881:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:20:04,881:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:20:04,884:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:20:04,891:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:20:04,937:INFO:[LightGBM] [Info] 33 dense feature groups (25.26 MB) transferred to GPU in 0.045377 secs. 0 sparse feature groups
2024-06-10 17:20:04,941:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:20:31,125:INFO:[LightGBM] [Info] Number of positive: 367887, number of negative: 367887
2024-06-10 17:20:31,125:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:20:31,129:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:20:31,131:INFO:[LightGBM] [Info] Number of data points in the train set: 735774, number of used features: 33
2024-06-10 17:20:31,131:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:20:31,131:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:20:31,141:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:20:31,149:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:20:31,216:INFO:[LightGBM] [Info] 33 dense feature groups (25.26 MB) transferred to GPU in 0.065715 secs. 0 sparse feature groups
2024-06-10 17:20:31,222:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:21:37,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:37,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:37,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:37,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,207:INFO:PyCaret ClassificationExperiment
2024-06-10 17:21:40,207:INFO:Logging name: clf-default-name
2024-06-10 17:21:40,207:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:21:40,207:INFO:version 3.3.2
2024-06-10 17:21:40,207:INFO:Initializing setup()
2024-06-10 17:21:40,207:INFO:self.USI: e039
2024-06-10 17:21:40,207:INFO:self._variable_keys: {'fold_groups_param', '_available_plots', 'is_multiclass', 'y_train', 'y_test', 'data', 'gpu_n_jobs_param', 'seed', 'memory', 'target_param', 'fold_shuffle_param', 'logging_param', 'y', 'X', 'USI', 'X_test', 'X_train', 'fold_generator', 'html_param', 'fix_imbalance', 'pipeline', 'exp_name_log', 'n_jobs_param', 'idx', 'exp_id', '_ml_usecase', 'log_plots_param', 'gpu_param'}
2024-06-10 17:21:40,208:INFO:Checking environment
2024-06-10 17:21:40,208:INFO:python_version: 3.11.9
2024-06-10 17:21:40,208:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:21:40,208:INFO:machine: AMD64
2024-06-10 17:21:40,208:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:21:40,208:INFO:Memory: svmem(total=34056318976, available=24112947200, percent=29.2, used=9943371776, free=24112947200)
2024-06-10 17:21:40,208:INFO:Physical Core: 6
2024-06-10 17:21:40,208:INFO:Logical Core: 12
2024-06-10 17:21:40,208:INFO:Checking libraries
2024-06-10 17:21:40,208:INFO:System:
2024-06-10 17:21:40,208:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:21:40,208:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:21:40,208:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:21:40,208:INFO:PyCaret required dependencies:
2024-06-10 17:21:40,237:INFO:                 pip: 24.0
2024-06-10 17:21:40,237:INFO:          setuptools: 69.5.1
2024-06-10 17:21:40,237:INFO:             pycaret: 3.3.2
2024-06-10 17:21:40,237:INFO:             IPython: 8.25.0
2024-06-10 17:21:40,237:INFO:          ipywidgets: 8.1.3
2024-06-10 17:21:40,237:INFO:                tqdm: 4.66.4
2024-06-10 17:21:40,237:INFO:               numpy: 1.26.4
2024-06-10 17:21:40,237:INFO:              pandas: 2.1.4
2024-06-10 17:21:40,237:INFO:              jinja2: 3.1.4
2024-06-10 17:21:40,237:INFO:               scipy: 1.11.4
2024-06-10 17:21:40,237:INFO:              joblib: 1.3.2
2024-06-10 17:21:40,237:INFO:             sklearn: 1.4.2
2024-06-10 17:21:40,237:INFO:                pyod: 2.0.0
2024-06-10 17:21:40,237:INFO:            imblearn: 0.12.3
2024-06-10 17:21:40,237:INFO:   category_encoders: 2.6.3
2024-06-10 17:21:40,237:INFO:            lightgbm: 4.3.0
2024-06-10 17:21:40,237:INFO:               numba: 0.59.1
2024-06-10 17:21:40,237:INFO:            requests: 2.32.3
2024-06-10 17:21:40,238:INFO:          matplotlib: 3.7.5
2024-06-10 17:21:40,238:INFO:          scikitplot: 0.3.7
2024-06-10 17:21:40,238:INFO:         yellowbrick: 1.5
2024-06-10 17:21:40,238:INFO:              plotly: 5.22.0
2024-06-10 17:21:40,238:INFO:    plotly-resampler: Not installed
2024-06-10 17:21:40,238:INFO:             kaleido: 0.2.1
2024-06-10 17:21:40,238:INFO:           schemdraw: 0.15
2024-06-10 17:21:40,238:INFO:         statsmodels: 0.14.2
2024-06-10 17:21:40,238:INFO:              sktime: 0.26.0
2024-06-10 17:21:40,238:INFO:               tbats: 1.1.3
2024-06-10 17:21:40,238:INFO:            pmdarima: 2.0.4
2024-06-10 17:21:40,238:INFO:              psutil: 5.9.8
2024-06-10 17:21:40,238:INFO:          markupsafe: 2.1.5
2024-06-10 17:21:40,238:INFO:             pickle5: Not installed
2024-06-10 17:21:40,238:INFO:         cloudpickle: 3.0.0
2024-06-10 17:21:40,238:INFO:         deprecation: 2.1.0
2024-06-10 17:21:40,238:INFO:              xxhash: 3.4.1
2024-06-10 17:21:40,238:INFO:           wurlitzer: Not installed
2024-06-10 17:21:40,238:INFO:PyCaret optional dependencies:
2024-06-10 17:21:40,249:INFO:                shap: Not installed
2024-06-10 17:21:40,249:INFO:           interpret: Not installed
2024-06-10 17:21:40,249:INFO:                umap: Not installed
2024-06-10 17:21:40,249:INFO:     ydata_profiling: Not installed
2024-06-10 17:21:40,249:INFO:  explainerdashboard: Not installed
2024-06-10 17:21:40,249:INFO:             autoviz: Not installed
2024-06-10 17:21:40,249:INFO:           fairlearn: Not installed
2024-06-10 17:21:40,249:INFO:          deepchecks: Not installed
2024-06-10 17:21:40,249:INFO:             xgboost: Not installed
2024-06-10 17:21:40,249:INFO:            catboost: Not installed
2024-06-10 17:21:40,249:INFO:              kmodes: Not installed
2024-06-10 17:21:40,249:INFO:             mlxtend: Not installed
2024-06-10 17:21:40,249:INFO:       statsforecast: Not installed
2024-06-10 17:21:40,249:INFO:        tune_sklearn: Not installed
2024-06-10 17:21:40,249:INFO:                 ray: Not installed
2024-06-10 17:21:40,249:INFO:            hyperopt: Not installed
2024-06-10 17:21:40,249:INFO:              optuna: Not installed
2024-06-10 17:21:40,249:INFO:               skopt: Not installed
2024-06-10 17:21:40,249:INFO:              mlflow: Not installed
2024-06-10 17:21:40,249:INFO:              gradio: Not installed
2024-06-10 17:21:40,249:INFO:             fastapi: Not installed
2024-06-10 17:21:40,249:INFO:             uvicorn: Not installed
2024-06-10 17:21:40,249:INFO:              m2cgen: Not installed
2024-06-10 17:21:40,249:INFO:           evidently: Not installed
2024-06-10 17:21:40,249:INFO:               fugue: Not installed
2024-06-10 17:21:40,249:INFO:           streamlit: 1.35.0
2024-06-10 17:21:40,249:INFO:             prophet: Not installed
2024-06-10 17:21:40,249:INFO:None
2024-06-10 17:21:40,249:INFO:Set up GPU usage.
2024-06-10 17:21:40,249:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,249:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-06-10 17:21:40,249:INFO:Set up data.
2024-06-10 17:21:40,288:INFO:Set up folding strategy.
2024-06-10 17:21:40,288:INFO:Set up train/test split.
2024-06-10 17:21:40,313:INFO:Set up index.
2024-06-10 17:21:40,314:INFO:Assigning column types.
2024-06-10 17:21:40,325:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:21:40,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,388:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:21:40,388:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,396:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:21:40,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,435:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:40,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:40,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:21:40,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,685:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:21:40,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:40,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:40,740:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:21:40,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:21:40,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,855:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:40,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:40,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,923:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:21:40,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,951:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:40,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:40,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:40,971:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:21:40,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,039:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,071:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:41,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:41,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:41,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:41,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:41,217:INFO:Preparing preprocessing pipeline...
2024-06-10 17:21:41,221:INFO:Set up date feature engineering.
2024-06-10 17:21:41,221:INFO:Set up simple imputation.
2024-06-10 17:21:41,239:INFO:Set up encoding of ordinal features.
2024-06-10 17:21:41,254:INFO:Set up encoding of categorical features.
2024-06-10 17:21:41,254:INFO:Set up removing outliers.
2024-06-10 17:21:41,254:INFO:Set up imbalanced handling.
2024-06-10 17:21:41,254:INFO:Set up feature normalization.
2024-06-10 17:21:41,254:INFO:Set up PCA.
2024-06-10 17:21:43,330:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:21:43,363:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 17:21:43,363:INFO:Creating final display dataframe.
2024-06-10 17:21:46,523:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU              True
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              e039
2024-06-10 17:21:46,530:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:46,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:46,648:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,707:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,707:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,708:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:21:46,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:46,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:21:46,775:INFO:setup() successfully completed in 6.64s...............
2024-06-10 17:21:46,793:INFO:Initializing create_model()
2024-06-10 17:21:46,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019B2A3F5390>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:21:46,794:INFO:Checking exceptions
2024-06-10 17:21:46,820:INFO:Importing libraries
2024-06-10 17:21:46,820:INFO:Copying training dataset
2024-06-10 17:21:46,859:INFO:Defining folds
2024-06-10 17:21:46,859:INFO:Declaring metric variables
2024-06-10 17:21:46,865:INFO:Importing untrained model
2024-06-10 17:21:46,872:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:21:46,881:INFO:Starting cross validation
2024-06-10 17:21:46,900:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-06-10 17:21:48,119:INFO:[LightGBM] [Info] Number of positive: 24492, number of negative: 24492
2024-06-10 17:21:48,119:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:21:48,120:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:21:48,120:INFO:[LightGBM] [Info] Number of data points in the train set: 48984, number of used features: 33
2024-06-10 17:21:48,121:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:21:48,121:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:21:48,124:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:21:48,127:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:21:48,133:INFO:[LightGBM] [Info] 33 dense feature groups (1.68 MB) transferred to GPU in 0.005895 secs. 0 sparse feature groups
2024-06-10 17:21:48,134:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:21:51,721:INFO:[LightGBM] [Info] Number of positive: 24509, number of negative: 24509
2024-06-10 17:21:51,722:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:21:51,722:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:21:51,723:INFO:[LightGBM] [Info] Number of data points in the train set: 49018, number of used features: 33
2024-06-10 17:21:51,723:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:21:51,723:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:21:51,727:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:21:51,729:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:21:51,733:INFO:[LightGBM] [Info] 33 dense feature groups (1.68 MB) transferred to GPU in 0.003053 secs. 0 sparse feature groups
2024-06-10 17:21:51,733:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:21:55,388:INFO:[LightGBM] [Info] Number of positive: 24500, number of negative: 24500
2024-06-10 17:21:55,388:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:21:55,389:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:21:55,390:INFO:[LightGBM] [Info] Number of data points in the train set: 49000, number of used features: 33
2024-06-10 17:21:55,390:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:21:55,390:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:21:55,394:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:21:55,396:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:21:55,400:INFO:[LightGBM] [Info] 33 dense feature groups (1.68 MB) transferred to GPU in 0.003317 secs. 0 sparse feature groups
2024-06-10 17:21:55,401:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:21:59,515:INFO:[LightGBM] [Info] Number of positive: 24491, number of negative: 24491
2024-06-10 17:21:59,515:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:21:59,516:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:21:59,517:INFO:[LightGBM] [Info] Number of data points in the train set: 48982, number of used features: 33
2024-06-10 17:21:59,517:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:21:59,517:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:21:59,522:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:21:59,523:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:21:59,528:INFO:[LightGBM] [Info] 33 dense feature groups (1.68 MB) transferred to GPU in 0.003596 secs. 0 sparse feature groups
2024-06-10 17:21:59,529:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:22:03,721:INFO:[LightGBM] [Info] Number of positive: 24501, number of negative: 24501
2024-06-10 17:22:03,721:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:22:03,721:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:22:03,722:INFO:[LightGBM] [Info] Number of data points in the train set: 49002, number of used features: 33
2024-06-10 17:22:03,722:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:22:03,722:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:22:03,728:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:22:03,730:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:22:03,735:INFO:[LightGBM] [Info] 33 dense feature groups (1.68 MB) transferred to GPU in 0.003744 secs. 0 sparse feature groups
2024-06-10 17:22:03,736:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:22:07,154:INFO:Calculating mean and std
2024-06-10 17:22:07,157:INFO:Creating metrics dataframe
2024-06-10 17:22:07,167:INFO:Finalizing model
2024-06-10 17:22:09,200:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 17:22:09,200:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-06-10 17:22:09,200:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:22:09,201:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 17:22:09,202:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 630, Vendor: Intel(R) Corporation
2024-06-10 17:22:09,202:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-06-10 17:22:09,208:INFO:[LightGBM] [Info] GPU programs have been built
2024-06-10 17:22:09,210:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-06-10 17:22:09,215:INFO:[LightGBM] [Info] 33 dense feature groups (2.10 MB) transferred to GPU in 0.004522 secs. 0 sparse feature groups
2024-06-10 17:22:09,216:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:22:12,320:INFO:Uploading results into container
2024-06-10 17:22:12,322:INFO:Uploading model into container now
2024-06-10 17:22:12,338:INFO:_master_model_container: 1
2024-06-10 17:22:12,338:INFO:_display_container: 2
2024-06-10 17:22:12,340:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:22:12,340:INFO:create_model() successfully completed......................................
2024-06-10 17:22:12,525:INFO:Initializing tune_model()
2024-06-10 17:22:12,525:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019B2A3F5390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=123, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 17:22:12,525:INFO:Checking exceptions
2024-06-10 17:22:12,556:INFO:Copying training dataset
2024-06-10 17:22:12,577:INFO:Checking base model
2024-06-10 17:22:12,577:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 17:22:12,585:INFO:Declaring metric variables
2024-06-10 17:22:12,592:INFO:Defining Hyperparameters
2024-06-10 17:22:12,711:INFO:Tuning with n_jobs=1
2024-06-10 17:22:12,711:INFO:Initializing RandomizedSearchCV
2024-06-10 17:25:35,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:25:35,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:25:35,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:25:35,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 17:25:41,293:INFO:PyCaret ClassificationExperiment
2024-06-10 17:25:41,293:INFO:Logging name: clf-default-name
2024-06-10 17:25:41,293:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:25:41,293:INFO:version 3.3.2
2024-06-10 17:25:41,293:INFO:Initializing setup()
2024-06-10 17:25:41,293:INFO:self.USI: 2afb
2024-06-10 17:25:41,293:INFO:self._variable_keys: {'USI', 'idx', '_available_plots', 'y_test', 'y_train', 'fold_groups_param', 'is_multiclass', 'memory', 'X_test', 'n_jobs_param', '_ml_usecase', 'X_train', 'logging_param', 'fix_imbalance', 'fold_generator', 'seed', 'X', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'data', 'exp_id', 'fold_shuffle_param', 'html_param', 'y', 'gpu_param', 'gpu_n_jobs_param'}
2024-06-10 17:25:41,293:INFO:Checking environment
2024-06-10 17:25:41,293:INFO:python_version: 3.11.9
2024-06-10 17:25:41,293:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:25:41,293:INFO:machine: AMD64
2024-06-10 17:25:41,293:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:25:41,293:INFO:Memory: svmem(total=34056318976, available=24108064768, percent=29.2, used=9948254208, free=24108064768)
2024-06-10 17:25:41,293:INFO:Physical Core: 6
2024-06-10 17:25:41,294:INFO:Logical Core: 12
2024-06-10 17:25:41,294:INFO:Checking libraries
2024-06-10 17:25:41,294:INFO:System:
2024-06-10 17:25:41,294:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:25:41,294:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:25:41,294:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:25:41,294:INFO:PyCaret required dependencies:
2024-06-10 17:25:41,319:INFO:                 pip: 24.0
2024-06-10 17:25:41,319:INFO:          setuptools: 69.5.1
2024-06-10 17:25:41,319:INFO:             pycaret: 3.3.2
2024-06-10 17:25:41,319:INFO:             IPython: 8.25.0
2024-06-10 17:25:41,319:INFO:          ipywidgets: 8.1.3
2024-06-10 17:25:41,320:INFO:                tqdm: 4.66.4
2024-06-10 17:25:41,320:INFO:               numpy: 1.26.4
2024-06-10 17:25:41,320:INFO:              pandas: 2.1.4
2024-06-10 17:25:41,320:INFO:              jinja2: 3.1.4
2024-06-10 17:25:41,320:INFO:               scipy: 1.11.4
2024-06-10 17:25:41,320:INFO:              joblib: 1.3.2
2024-06-10 17:25:41,320:INFO:             sklearn: 1.4.2
2024-06-10 17:25:41,320:INFO:                pyod: 2.0.0
2024-06-10 17:25:41,320:INFO:            imblearn: 0.12.3
2024-06-10 17:25:41,320:INFO:   category_encoders: 2.6.3
2024-06-10 17:25:41,320:INFO:            lightgbm: 4.3.0
2024-06-10 17:25:41,320:INFO:               numba: 0.59.1
2024-06-10 17:25:41,320:INFO:            requests: 2.32.3
2024-06-10 17:25:41,320:INFO:          matplotlib: 3.7.5
2024-06-10 17:25:41,320:INFO:          scikitplot: 0.3.7
2024-06-10 17:25:41,320:INFO:         yellowbrick: 1.5
2024-06-10 17:25:41,320:INFO:              plotly: 5.22.0
2024-06-10 17:25:41,320:INFO:    plotly-resampler: Not installed
2024-06-10 17:25:41,320:INFO:             kaleido: 0.2.1
2024-06-10 17:25:41,320:INFO:           schemdraw: 0.15
2024-06-10 17:25:41,320:INFO:         statsmodels: 0.14.2
2024-06-10 17:25:41,320:INFO:              sktime: 0.26.0
2024-06-10 17:25:41,320:INFO:               tbats: 1.1.3
2024-06-10 17:25:41,320:INFO:            pmdarima: 2.0.4
2024-06-10 17:25:41,320:INFO:              psutil: 5.9.8
2024-06-10 17:25:41,321:INFO:          markupsafe: 2.1.5
2024-06-10 17:25:41,321:INFO:             pickle5: Not installed
2024-06-10 17:25:41,321:INFO:         cloudpickle: 3.0.0
2024-06-10 17:25:41,321:INFO:         deprecation: 2.1.0
2024-06-10 17:25:41,321:INFO:              xxhash: 3.4.1
2024-06-10 17:25:41,321:INFO:           wurlitzer: Not installed
2024-06-10 17:25:41,321:INFO:PyCaret optional dependencies:
2024-06-10 17:25:41,331:INFO:                shap: Not installed
2024-06-10 17:25:41,331:INFO:           interpret: Not installed
2024-06-10 17:25:41,331:INFO:                umap: Not installed
2024-06-10 17:25:41,331:INFO:     ydata_profiling: Not installed
2024-06-10 17:25:41,331:INFO:  explainerdashboard: Not installed
2024-06-10 17:25:41,331:INFO:             autoviz: Not installed
2024-06-10 17:25:41,331:INFO:           fairlearn: Not installed
2024-06-10 17:25:41,331:INFO:          deepchecks: Not installed
2024-06-10 17:25:41,332:INFO:             xgboost: Not installed
2024-06-10 17:25:41,332:INFO:            catboost: Not installed
2024-06-10 17:25:41,332:INFO:              kmodes: Not installed
2024-06-10 17:25:41,332:INFO:             mlxtend: Not installed
2024-06-10 17:25:41,332:INFO:       statsforecast: Not installed
2024-06-10 17:25:41,332:INFO:        tune_sklearn: Not installed
2024-06-10 17:25:41,332:INFO:                 ray: Not installed
2024-06-10 17:25:41,332:INFO:            hyperopt: Not installed
2024-06-10 17:25:41,332:INFO:              optuna: Not installed
2024-06-10 17:25:41,332:INFO:               skopt: Not installed
2024-06-10 17:25:41,332:INFO:              mlflow: Not installed
2024-06-10 17:25:41,332:INFO:              gradio: Not installed
2024-06-10 17:25:41,332:INFO:             fastapi: Not installed
2024-06-10 17:25:41,332:INFO:             uvicorn: Not installed
2024-06-10 17:25:41,332:INFO:              m2cgen: Not installed
2024-06-10 17:25:41,332:INFO:           evidently: Not installed
2024-06-10 17:25:41,332:INFO:               fugue: Not installed
2024-06-10 17:25:41,332:INFO:           streamlit: 1.35.0
2024-06-10 17:25:41,332:INFO:             prophet: Not installed
2024-06-10 17:25:41,332:INFO:None
2024-06-10 17:25:41,332:INFO:Set up data.
2024-06-10 17:25:41,370:INFO:Set up folding strategy.
2024-06-10 17:25:41,370:INFO:Set up train/test split.
2024-06-10 17:25:41,395:INFO:Set up index.
2024-06-10 17:25:41,396:INFO:Assigning column types.
2024-06-10 17:25:41,406:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:25:41,447:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:25:41,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:25:41,481:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:25:41,523:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:25:41,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,548:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:25:41,588:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:25:41,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,655:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:25:41,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,684:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:25:41,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:41,820:INFO:Preparing preprocessing pipeline...
2024-06-10 17:25:41,823:INFO:Set up date feature engineering.
2024-06-10 17:25:41,823:INFO:Set up simple imputation.
2024-06-10 17:25:41,834:INFO:Set up encoding of ordinal features.
2024-06-10 17:25:41,845:INFO:Set up encoding of categorical features.
2024-06-10 17:25:41,845:INFO:Set up removing outliers.
2024-06-10 17:25:41,845:INFO:Set up imbalanced handling.
2024-06-10 17:25:41,845:INFO:Set up feature normalization.
2024-06-10 17:25:41,845:INFO:Set up PCA.
2024-06-10 17:25:42,352:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:25:42,387:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 17:25:42,387:INFO:Creating final display dataframe.
2024-06-10 17:25:43,229:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              2afb
2024-06-10 17:25:43,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:43,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:43,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:43,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:25:43,397:INFO:setup() successfully completed in 2.17s...............
2024-06-10 17:25:43,422:INFO:Initializing create_model()
2024-06-10 17:25:43,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:25:43,423:INFO:Checking exceptions
2024-06-10 17:25:43,454:INFO:Importing libraries
2024-06-10 17:25:43,454:INFO:Copying training dataset
2024-06-10 17:25:43,481:INFO:Defining folds
2024-06-10 17:25:43,481:INFO:Declaring metric variables
2024-06-10 17:25:43,486:INFO:Importing untrained model
2024-06-10 17:25:43,489:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:25:43,497:INFO:Starting cross validation
2024-06-10 17:25:43,499:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:25:51,865:INFO:Calculating mean and std
2024-06-10 17:25:51,868:INFO:Creating metrics dataframe
2024-06-10 17:25:51,876:INFO:Finalizing model
2024-06-10 17:25:53,537:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 17:25:53,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005218 seconds.
2024-06-10 17:25:53,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:25:53,544:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:25:53,544:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 17:25:53,545:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:25:54,047:INFO:Uploading results into container
2024-06-10 17:25:54,049:INFO:Uploading model into container now
2024-06-10 17:25:54,064:INFO:_master_model_container: 1
2024-06-10 17:25:54,064:INFO:_display_container: 2
2024-06-10 17:25:54,065:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:25:54,065:INFO:create_model() successfully completed......................................
2024-06-10 17:25:54,222:INFO:Initializing tune_model()
2024-06-10 17:25:54,222:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 17:25:54,222:INFO:Checking exceptions
2024-06-10 17:25:54,252:INFO:Copying training dataset
2024-06-10 17:25:54,267:INFO:Checking base model
2024-06-10 17:25:54,267:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 17:25:54,271:INFO:Declaring metric variables
2024-06-10 17:25:54,278:INFO:Defining Hyperparameters
2024-06-10 17:25:54,376:INFO:Tuning with n_jobs=-1
2024-06-10 17:25:54,376:INFO:Initializing RandomizedSearchCV
2024-06-10 17:27:23,867:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 17:27:23,868:INFO:Hyperparameter search completed
2024-06-10 17:27:23,869:INFO:SubProcess create_model() called ==================================
2024-06-10 17:27:23,871:INFO:Initializing create_model()
2024-06-10 17:27:23,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001667CED0110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-10 17:27:23,872:INFO:Checking exceptions
2024-06-10 17:27:23,872:INFO:Importing libraries
2024-06-10 17:27:23,873:INFO:Copying training dataset
2024-06-10 17:27:23,928:INFO:Defining folds
2024-06-10 17:27:23,928:INFO:Declaring metric variables
2024-06-10 17:27:23,937:INFO:Importing untrained model
2024-06-10 17:27:23,937:INFO:Declaring custom model
2024-06-10 17:27:23,947:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:27:23,965:INFO:Starting cross validation
2024-06-10 17:27:23,971:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:27:35,924:INFO:Calculating mean and std
2024-06-10 17:27:35,928:INFO:Creating metrics dataframe
2024-06-10 17:27:35,941:INFO:Finalizing model
2024-06-10 17:27:37,611:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:27:37,611:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:27:37,611:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:27:37,731:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:27:37,731:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:27:37,731:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:27:37,731:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 17:27:37,739:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005918 seconds.
2024-06-10 17:27:37,739:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:27:37,741:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:27:37,741:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 17:27:37,746:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:27:39,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:27:39,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:27:39,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:27:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:27:39,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:27:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:27:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:27:39,638:INFO:Uploading results into container
2024-06-10 17:27:39,640:INFO:Uploading model into container now
2024-06-10 17:27:39,641:INFO:_master_model_container: 2
2024-06-10 17:27:39,642:INFO:_display_container: 3
2024-06-10 17:27:39,643:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:27:39,643:INFO:create_model() successfully completed......................................
2024-06-10 17:27:39,756:INFO:SubProcess create_model() end ==================================
2024-06-10 17:27:39,756:INFO:choose_better activated
2024-06-10 17:27:39,760:INFO:SubProcess create_model() called ==================================
2024-06-10 17:27:39,761:INFO:Initializing create_model()
2024-06-10 17:27:39,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:27:39,761:INFO:Checking exceptions
2024-06-10 17:27:39,763:INFO:Importing libraries
2024-06-10 17:27:39,764:INFO:Copying training dataset
2024-06-10 17:27:39,788:INFO:Defining folds
2024-06-10 17:27:39,788:INFO:Declaring metric variables
2024-06-10 17:27:39,788:INFO:Importing untrained model
2024-06-10 17:27:39,788:INFO:Declaring custom model
2024-06-10 17:27:39,789:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:27:39,789:INFO:Starting cross validation
2024-06-10 17:27:39,792:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:27:46,000:INFO:Calculating mean and std
2024-06-10 17:27:46,000:INFO:Creating metrics dataframe
2024-06-10 17:27:46,005:INFO:Finalizing model
2024-06-10 17:27:47,657:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 17:27:47,664:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006549 seconds.
2024-06-10 17:27:47,664:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:27:47,665:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:27:47,666:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 17:27:47,667:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:27:48,420:INFO:Uploading results into container
2024-06-10 17:27:48,423:INFO:Uploading model into container now
2024-06-10 17:27:48,424:INFO:_master_model_container: 3
2024-06-10 17:27:48,424:INFO:_display_container: 4
2024-06-10 17:27:48,425:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:27:48,425:INFO:create_model() successfully completed......................................
2024-06-10 17:27:48,545:INFO:SubProcess create_model() end ==================================
2024-06-10 17:27:48,547:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.1789
2024-06-10 17:27:48,547:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.1805
2024-06-10 17:27:48,548:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 17:27:48,548:INFO:choose_better completed
2024-06-10 17:27:48,560:INFO:_master_model_container: 3
2024-06-10 17:27:48,561:INFO:_display_container: 3
2024-06-10 17:27:48,561:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:27:48,561:INFO:tune_model() successfully completed......................................
2024-06-10 17:27:48,748:INFO:Initializing plot_model()
2024-06-10 17:27:48,748:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:27:48,748:INFO:Checking exceptions
2024-06-10 17:27:48,762:INFO:Preloading libraries
2024-06-10 17:27:48,827:INFO:Copying training dataset
2024-06-10 17:27:48,827:INFO:Plot type: auc
2024-06-10 17:27:49,087:INFO:Fitting Model
2024-06-10 17:27:49,089:INFO:Scoring test/hold-out set
2024-06-10 17:27:49,091:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:27:49,091:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:27:49,091:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:27:49,173:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:27:49,173:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:27:49,173:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:27:49,603:INFO:Visual Rendered Successfully
2024-06-10 17:27:49,688:INFO:plot_model() successfully completed......................................
2024-06-10 17:27:49,733:INFO:Initializing finalize_model()
2024-06-10 17:27:49,733:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 17:27:49,733:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:27:49,748:INFO:Initializing create_model()
2024-06-10 17:27:49,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:27:49,748:INFO:Checking exceptions
2024-06-10 17:27:49,749:INFO:Importing libraries
2024-06-10 17:27:49,749:INFO:Copying training dataset
2024-06-10 17:27:49,751:INFO:Defining folds
2024-06-10 17:27:49,751:INFO:Declaring metric variables
2024-06-10 17:27:49,751:INFO:Importing untrained model
2024-06-10 17:27:49,751:INFO:Declaring custom model
2024-06-10 17:27:49,752:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:27:49,754:INFO:Cross validation set to False
2024-06-10 17:27:49,754:INFO:Fitting Model
2024-06-10 17:27:51,902:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:27:51,902:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:27:51,902:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:27:52,059:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:27:52,059:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:27:52,059:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:27:52,060:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-10 17:27:52,072:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009272 seconds.
2024-06-10 17:27:52,072:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:27:52,073:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:27:52,075:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-10 17:27:52,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:27:54,613:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:27:54,614:INFO:create_model() successfully completed......................................
2024-06-10 17:27:54,707:INFO:_master_model_container: 3
2024-06-10 17:27:54,707:INFO:_display_container: 3
2024-06-10 17:27:54,752:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:27:54,752:INFO:finalize_model() successfully completed......................................
2024-06-10 17:27:54,917:INFO:Initializing evaluate_model()
2024-06-10 17:27:54,917:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 17:27:54,984:INFO:Initializing plot_model()
2024-06-10 17:27:54,984:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:27:54,984:INFO:Checking exceptions
2024-06-10 17:27:54,994:INFO:Preloading libraries
2024-06-10 17:27:55,054:INFO:Copying training dataset
2024-06-10 17:27:55,054:INFO:Plot type: pipeline
2024-06-10 17:27:55,426:INFO:Visual Rendered Successfully
2024-06-10 17:27:55,510:INFO:plot_model() successfully completed......................................
2024-06-10 17:27:55,571:INFO:Initializing plot_model()
2024-06-10 17:27:55,571:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:27:55,571:INFO:Checking exceptions
2024-06-10 17:27:55,583:INFO:Preloading libraries
2024-06-10 17:27:55,656:INFO:Copying training dataset
2024-06-10 17:27:55,656:INFO:Plot type: confusion_matrix
2024-06-10 17:27:55,947:INFO:Fitting Model
2024-06-10 17:27:55,948:INFO:Scoring test/hold-out set
2024-06-10 17:27:55,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:27:55,951:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:27:55,951:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:27:56,040:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:27:56,040:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:27:56,040:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:27:56,351:INFO:Visual Rendered Successfully
2024-06-10 17:27:56,441:INFO:plot_model() successfully completed......................................
2024-06-10 17:28:04,344:INFO:Initializing plot_model()
2024-06-10 17:28:04,344:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:28:04,344:INFO:Checking exceptions
2024-06-10 17:28:04,353:INFO:Preloading libraries
2024-06-10 17:28:04,414:INFO:Copying training dataset
2024-06-10 17:28:04,414:INFO:Plot type: auc
2024-06-10 17:28:04,632:INFO:Fitting Model
2024-06-10 17:28:04,634:INFO:Scoring test/hold-out set
2024-06-10 17:28:04,636:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:28:04,636:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:28:04,636:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:28:04,725:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:28:04,725:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:28:04,726:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:28:05,031:INFO:Visual Rendered Successfully
2024-06-10 17:28:05,109:INFO:plot_model() successfully completed......................................
2024-06-10 17:28:16,964:INFO:Initializing plot_model()
2024-06-10 17:28:16,964:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001667FC3D190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:28:16,964:INFO:Checking exceptions
2024-06-10 17:28:16,972:INFO:Preloading libraries
2024-06-10 17:28:17,015:INFO:Copying training dataset
2024-06-10 17:28:17,015:INFO:Plot type: confusion_matrix
2024-06-10 17:28:17,214:INFO:Fitting Model
2024-06-10 17:28:17,215:INFO:Scoring test/hold-out set
2024-06-10 17:28:17,216:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:28:17,216:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:28:17,216:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:28:17,291:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:28:17,291:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:28:17,291:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:28:17,500:INFO:Visual Rendered Successfully
2024-06-10 17:28:17,580:INFO:plot_model() successfully completed......................................
2024-06-10 17:28:59,277:INFO:PyCaret ClassificationExperiment
2024-06-10 17:28:59,277:INFO:Logging name: clf-default-name
2024-06-10 17:28:59,277:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:28:59,277:INFO:version 3.3.2
2024-06-10 17:28:59,277:INFO:Initializing setup()
2024-06-10 17:28:59,277:INFO:self.USI: c6fc
2024-06-10 17:28:59,277:INFO:self._variable_keys: {'USI', 'idx', '_available_plots', 'y_test', 'y_train', 'fold_groups_param', 'is_multiclass', 'memory', 'X_test', 'n_jobs_param', '_ml_usecase', 'X_train', 'logging_param', 'fix_imbalance', 'fold_generator', 'seed', 'X', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'data', 'exp_id', 'fold_shuffle_param', 'html_param', 'y', 'gpu_param', 'gpu_n_jobs_param'}
2024-06-10 17:28:59,277:INFO:Checking environment
2024-06-10 17:28:59,277:INFO:python_version: 3.11.9
2024-06-10 17:28:59,277:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:28:59,278:INFO:machine: AMD64
2024-06-10 17:28:59,278:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:28:59,278:INFO:Memory: svmem(total=34056318976, available=21915992064, percent=35.6, used=12140326912, free=21915992064)
2024-06-10 17:28:59,278:INFO:Physical Core: 6
2024-06-10 17:28:59,278:INFO:Logical Core: 12
2024-06-10 17:28:59,278:INFO:Checking libraries
2024-06-10 17:28:59,278:INFO:System:
2024-06-10 17:28:59,278:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:28:59,278:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:28:59,278:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:28:59,278:INFO:PyCaret required dependencies:
2024-06-10 17:28:59,278:INFO:                 pip: 24.0
2024-06-10 17:28:59,278:INFO:          setuptools: 69.5.1
2024-06-10 17:28:59,278:INFO:             pycaret: 3.3.2
2024-06-10 17:28:59,278:INFO:             IPython: 8.25.0
2024-06-10 17:28:59,278:INFO:          ipywidgets: 8.1.3
2024-06-10 17:28:59,278:INFO:                tqdm: 4.66.4
2024-06-10 17:28:59,278:INFO:               numpy: 1.26.4
2024-06-10 17:28:59,279:INFO:              pandas: 2.1.4
2024-06-10 17:28:59,279:INFO:              jinja2: 3.1.4
2024-06-10 17:28:59,279:INFO:               scipy: 1.11.4
2024-06-10 17:28:59,279:INFO:              joblib: 1.3.2
2024-06-10 17:28:59,279:INFO:             sklearn: 1.4.2
2024-06-10 17:28:59,279:INFO:                pyod: 2.0.0
2024-06-10 17:28:59,279:INFO:            imblearn: 0.12.3
2024-06-10 17:28:59,279:INFO:   category_encoders: 2.6.3
2024-06-10 17:28:59,279:INFO:            lightgbm: 4.3.0
2024-06-10 17:28:59,279:INFO:               numba: 0.59.1
2024-06-10 17:28:59,279:INFO:            requests: 2.32.3
2024-06-10 17:28:59,279:INFO:          matplotlib: 3.7.5
2024-06-10 17:28:59,279:INFO:          scikitplot: 0.3.7
2024-06-10 17:28:59,279:INFO:         yellowbrick: 1.5
2024-06-10 17:28:59,279:INFO:              plotly: 5.22.0
2024-06-10 17:28:59,279:INFO:    plotly-resampler: Not installed
2024-06-10 17:28:59,279:INFO:             kaleido: 0.2.1
2024-06-10 17:28:59,279:INFO:           schemdraw: 0.15
2024-06-10 17:28:59,279:INFO:         statsmodels: 0.14.2
2024-06-10 17:28:59,279:INFO:              sktime: 0.26.0
2024-06-10 17:28:59,279:INFO:               tbats: 1.1.3
2024-06-10 17:28:59,280:INFO:            pmdarima: 2.0.4
2024-06-10 17:28:59,280:INFO:              psutil: 5.9.8
2024-06-10 17:28:59,280:INFO:          markupsafe: 2.1.5
2024-06-10 17:28:59,280:INFO:             pickle5: Not installed
2024-06-10 17:28:59,281:INFO:         cloudpickle: 3.0.0
2024-06-10 17:28:59,281:INFO:         deprecation: 2.1.0
2024-06-10 17:28:59,281:INFO:              xxhash: 3.4.1
2024-06-10 17:28:59,281:INFO:           wurlitzer: Not installed
2024-06-10 17:28:59,281:INFO:PyCaret optional dependencies:
2024-06-10 17:28:59,281:INFO:                shap: Not installed
2024-06-10 17:28:59,281:INFO:           interpret: Not installed
2024-06-10 17:28:59,281:INFO:                umap: Not installed
2024-06-10 17:28:59,281:INFO:     ydata_profiling: Not installed
2024-06-10 17:28:59,281:INFO:  explainerdashboard: Not installed
2024-06-10 17:28:59,281:INFO:             autoviz: Not installed
2024-06-10 17:28:59,281:INFO:           fairlearn: Not installed
2024-06-10 17:28:59,281:INFO:          deepchecks: Not installed
2024-06-10 17:28:59,281:INFO:             xgboost: Not installed
2024-06-10 17:28:59,283:INFO:            catboost: Not installed
2024-06-10 17:28:59,283:INFO:              kmodes: Not installed
2024-06-10 17:28:59,283:INFO:             mlxtend: Not installed
2024-06-10 17:28:59,283:INFO:       statsforecast: Not installed
2024-06-10 17:28:59,283:INFO:        tune_sklearn: Not installed
2024-06-10 17:28:59,284:INFO:                 ray: Not installed
2024-06-10 17:28:59,284:INFO:            hyperopt: Not installed
2024-06-10 17:28:59,284:INFO:              optuna: Not installed
2024-06-10 17:28:59,284:INFO:               skopt: Not installed
2024-06-10 17:28:59,284:INFO:              mlflow: Not installed
2024-06-10 17:28:59,284:INFO:              gradio: Not installed
2024-06-10 17:28:59,285:INFO:             fastapi: Not installed
2024-06-10 17:28:59,285:INFO:             uvicorn: Not installed
2024-06-10 17:28:59,286:INFO:              m2cgen: Not installed
2024-06-10 17:28:59,286:INFO:           evidently: Not installed
2024-06-10 17:28:59,286:INFO:               fugue: Not installed
2024-06-10 17:28:59,286:INFO:           streamlit: 1.35.0
2024-06-10 17:28:59,286:INFO:             prophet: Not installed
2024-06-10 17:28:59,286:INFO:None
2024-06-10 17:28:59,287:INFO:Set up data.
2024-06-10 17:28:59,328:INFO:Set up folding strategy.
2024-06-10 17:28:59,328:INFO:Set up train/test split.
2024-06-10 17:28:59,352:INFO:Set up index.
2024-06-10 17:28:59,353:INFO:Assigning column types.
2024-06-10 17:28:59,363:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:28:59,403:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:28:59,405:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:28:59,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:28:59,474:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:28:59,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,499:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:28:59,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:28:59,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,613:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:28:59,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,640:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:28:59,711:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:28:59,788:INFO:Preparing preprocessing pipeline...
2024-06-10 17:28:59,792:INFO:Set up date feature engineering.
2024-06-10 17:28:59,792:INFO:Set up simple imputation.
2024-06-10 17:28:59,804:INFO:Set up encoding of ordinal features.
2024-06-10 17:28:59,815:INFO:Set up encoding of categorical features.
2024-06-10 17:28:59,815:INFO:Set up removing outliers.
2024-06-10 17:28:59,815:INFO:Set up imbalanced handling.
2024-06-10 17:28:59,815:INFO:Set up feature normalization.
2024-06-10 17:28:59,815:INFO:Set up PCA.
2024-06-10 17:29:00,655:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:29:00,704:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MaxAbsScaler(copy=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 17:29:00,705:INFO:Creating final display dataframe.
2024-06-10 17:29:01,644:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            maxabs
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              c6fc
2024-06-10 17:29:01,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:29:01,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:29:01,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:29:01,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:29:01,795:INFO:setup() successfully completed in 2.58s...............
2024-06-10 17:29:04,261:INFO:Initializing create_model()
2024-06-10 17:29:04,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:29:04,261:INFO:Checking exceptions
2024-06-10 17:29:04,286:INFO:Importing libraries
2024-06-10 17:29:04,286:INFO:Copying training dataset
2024-06-10 17:29:04,321:INFO:Defining folds
2024-06-10 17:29:04,322:INFO:Declaring metric variables
2024-06-10 17:29:04,326:INFO:Importing untrained model
2024-06-10 17:29:04,329:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:29:04,342:INFO:Starting cross validation
2024-06-10 17:29:04,345:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:29:09,538:INFO:Calculating mean and std
2024-06-10 17:29:09,539:INFO:Creating metrics dataframe
2024-06-10 17:29:09,549:INFO:Finalizing model
2024-06-10 17:29:11,078:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 17:29:11,087:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007786 seconds.
2024-06-10 17:29:11,087:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:29:11,088:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:29:11,088:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 17:29:11,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:29:11,673:INFO:Uploading results into container
2024-06-10 17:29:11,674:INFO:Uploading model into container now
2024-06-10 17:29:11,693:INFO:_master_model_container: 1
2024-06-10 17:29:11,693:INFO:_display_container: 2
2024-06-10 17:29:11,694:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:29:11,694:INFO:create_model() successfully completed......................................
2024-06-10 17:29:11,821:INFO:Initializing tune_model()
2024-06-10 17:29:11,821:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 17:29:11,821:INFO:Checking exceptions
2024-06-10 17:29:11,849:INFO:Copying training dataset
2024-06-10 17:29:11,870:INFO:Checking base model
2024-06-10 17:29:11,871:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 17:29:11,875:INFO:Declaring metric variables
2024-06-10 17:29:11,881:INFO:Defining Hyperparameters
2024-06-10 17:29:12,005:INFO:Tuning with n_jobs=-1
2024-06-10 17:29:12,005:INFO:Initializing RandomizedSearchCV
2024-06-10 17:30:35,704:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-10 17:30:35,706:INFO:Hyperparameter search completed
2024-06-10 17:30:35,706:INFO:SubProcess create_model() called ==================================
2024-06-10 17:30:35,708:INFO:Initializing create_model()
2024-06-10 17:30:35,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016602918610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-10 17:30:35,708:INFO:Checking exceptions
2024-06-10 17:30:35,710:INFO:Importing libraries
2024-06-10 17:30:35,710:INFO:Copying training dataset
2024-06-10 17:30:35,764:INFO:Defining folds
2024-06-10 17:30:35,764:INFO:Declaring metric variables
2024-06-10 17:30:35,773:INFO:Importing untrained model
2024-06-10 17:30:35,774:INFO:Declaring custom model
2024-06-10 17:30:35,783:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:30:35,796:INFO:Starting cross validation
2024-06-10 17:30:35,801:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:30:43,261:INFO:Calculating mean and std
2024-06-10 17:30:43,263:INFO:Creating metrics dataframe
2024-06-10 17:30:43,275:INFO:Finalizing model
2024-06-10 17:30:44,844:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:30:44,845:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:30:44,845:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:30:44,928:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:30:44,928:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:30:44,928:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:30:44,929:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 17:30:44,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005263 seconds.
2024-06-10 17:30:44,936:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:30:44,937:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:30:44,939:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 17:30:44,941:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:30:45,881:INFO:Uploading results into container
2024-06-10 17:30:45,883:INFO:Uploading model into container now
2024-06-10 17:30:45,884:INFO:_master_model_container: 2
2024-06-10 17:30:45,885:INFO:_display_container: 3
2024-06-10 17:30:45,886:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:30:45,886:INFO:create_model() successfully completed......................................
2024-06-10 17:30:46,007:INFO:SubProcess create_model() end ==================================
2024-06-10 17:30:46,007:INFO:choose_better activated
2024-06-10 17:30:46,011:INFO:SubProcess create_model() called ==================================
2024-06-10 17:30:46,013:INFO:Initializing create_model()
2024-06-10 17:30:46,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:30:46,013:INFO:Checking exceptions
2024-06-10 17:30:46,015:INFO:Importing libraries
2024-06-10 17:30:46,015:INFO:Copying training dataset
2024-06-10 17:30:46,040:INFO:Defining folds
2024-06-10 17:30:46,040:INFO:Declaring metric variables
2024-06-10 17:30:46,041:INFO:Importing untrained model
2024-06-10 17:30:46,041:INFO:Declaring custom model
2024-06-10 17:30:46,043:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:30:46,043:INFO:Starting cross validation
2024-06-10 17:30:46,046:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:30:51,903:INFO:Calculating mean and std
2024-06-10 17:30:51,904:INFO:Creating metrics dataframe
2024-06-10 17:30:51,908:INFO:Finalizing model
2024-06-10 17:30:53,617:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 17:30:53,627:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009341 seconds.
2024-06-10 17:30:53,627:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:30:53,627:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:30:53,628:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 17:30:53,630:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:30:54,283:INFO:Uploading results into container
2024-06-10 17:30:54,285:INFO:Uploading model into container now
2024-06-10 17:30:54,285:INFO:_master_model_container: 3
2024-06-10 17:30:54,285:INFO:_display_container: 4
2024-06-10 17:30:54,286:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:30:54,286:INFO:create_model() successfully completed......................................
2024-06-10 17:30:54,399:INFO:SubProcess create_model() end ==================================
2024-06-10 17:30:54,400:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.1638
2024-06-10 17:30:54,401:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.1963
2024-06-10 17:30:54,401:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 17:30:54,401:INFO:choose_better completed
2024-06-10 17:30:54,411:INFO:_master_model_container: 3
2024-06-10 17:30:54,412:INFO:_display_container: 3
2024-06-10 17:30:54,412:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:30:54,413:INFO:tune_model() successfully completed......................................
2024-06-10 17:30:55,061:INFO:Initializing plot_model()
2024-06-10 17:30:55,061:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:30:55,061:INFO:Checking exceptions
2024-06-10 17:30:55,073:INFO:Preloading libraries
2024-06-10 17:30:55,090:INFO:Copying training dataset
2024-06-10 17:30:55,090:INFO:Plot type: auc
2024-06-10 17:30:55,337:INFO:Fitting Model
2024-06-10 17:30:55,339:INFO:Scoring test/hold-out set
2024-06-10 17:30:55,340:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:30:55,340:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:30:55,340:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:30:55,369:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:30:55,369:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:30:55,370:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:30:55,678:INFO:Visual Rendered Successfully
2024-06-10 17:30:55,773:INFO:plot_model() successfully completed......................................
2024-06-10 17:30:55,817:INFO:Initializing finalize_model()
2024-06-10 17:30:55,818:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 17:30:55,819:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:30:55,832:INFO:Initializing create_model()
2024-06-10 17:30:55,832:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:30:55,833:INFO:Checking exceptions
2024-06-10 17:30:55,835:INFO:Importing libraries
2024-06-10 17:30:55,835:INFO:Copying training dataset
2024-06-10 17:30:55,836:INFO:Defining folds
2024-06-10 17:30:55,836:INFO:Declaring metric variables
2024-06-10 17:30:55,836:INFO:Importing untrained model
2024-06-10 17:30:55,836:INFO:Declaring custom model
2024-06-10 17:30:55,837:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:30:55,839:INFO:Cross validation set to False
2024-06-10 17:30:55,839:INFO:Fitting Model
2024-06-10 17:30:57,774:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:30:57,774:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:30:57,774:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:30:57,905:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:30:57,906:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:30:57,906:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:30:57,906:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-10 17:30:57,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007878 seconds.
2024-06-10 17:30:57,916:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:30:57,917:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:30:57,919:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-10 17:30:57,923:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 17:30:58,947:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:30:58,948:INFO:create_model() successfully completed......................................
2024-06-10 17:30:59,040:INFO:_master_model_container: 3
2024-06-10 17:30:59,041:INFO:_display_container: 3
2024-06-10 17:30:59,086:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:30:59,086:INFO:finalize_model() successfully completed......................................
2024-06-10 17:31:09,616:INFO:Initializing evaluate_model()
2024-06-10 17:31:09,616:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 17:31:09,666:INFO:Initializing plot_model()
2024-06-10 17:31:09,666:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:31:09,667:INFO:Checking exceptions
2024-06-10 17:31:09,674:INFO:Preloading libraries
2024-06-10 17:31:09,688:INFO:Copying training dataset
2024-06-10 17:31:09,688:INFO:Plot type: pipeline
2024-06-10 17:31:09,947:INFO:Visual Rendered Successfully
2024-06-10 17:31:10,028:INFO:plot_model() successfully completed......................................
2024-06-10 17:31:15,301:INFO:Initializing plot_model()
2024-06-10 17:31:15,301:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:31:15,301:INFO:Checking exceptions
2024-06-10 17:31:15,311:INFO:Preloading libraries
2024-06-10 17:31:15,327:INFO:Copying training dataset
2024-06-10 17:31:15,327:INFO:Plot type: confusion_matrix
2024-06-10 17:31:15,518:INFO:Fitting Model
2024-06-10 17:31:15,518:INFO:Scoring test/hold-out set
2024-06-10 17:31:15,521:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:31:15,521:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:31:15,521:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:31:15,550:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:31:15,550:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:31:15,551:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:31:15,721:INFO:Visual Rendered Successfully
2024-06-10 17:31:15,800:INFO:plot_model() successfully completed......................................
2024-06-10 17:31:18,503:INFO:Initializing plot_model()
2024-06-10 17:31:18,503:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:31:18,503:INFO:Checking exceptions
2024-06-10 17:31:18,511:INFO:Preloading libraries
2024-06-10 17:31:18,525:INFO:Copying training dataset
2024-06-10 17:31:18,526:INFO:Plot type: auc
2024-06-10 17:31:18,739:INFO:Fitting Model
2024-06-10 17:31:18,740:INFO:Scoring test/hold-out set
2024-06-10 17:31:18,743:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:31:18,743:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:31:18,743:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:31:18,782:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:31:18,782:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:31:18,782:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:31:19,064:INFO:Visual Rendered Successfully
2024-06-10 17:31:19,151:INFO:plot_model() successfully completed......................................
2024-06-10 17:31:21,667:INFO:Initializing plot_model()
2024-06-10 17:31:21,667:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602A11AD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:31:21,667:INFO:Checking exceptions
2024-06-10 17:31:21,677:INFO:Preloading libraries
2024-06-10 17:31:21,691:INFO:Copying training dataset
2024-06-10 17:31:21,691:INFO:Plot type: confusion_matrix
2024-06-10 17:31:21,901:INFO:Fitting Model
2024-06-10 17:31:21,903:INFO:Scoring test/hold-out set
2024-06-10 17:31:21,905:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:31:21,905:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:31:21,905:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:31:21,939:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 17:31:21,939:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 17:31:21,939:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 17:31:22,148:INFO:Visual Rendered Successfully
2024-06-10 17:31:22,279:INFO:plot_model() successfully completed......................................
2024-06-10 17:31:49,090:INFO:PyCaret ClassificationExperiment
2024-06-10 17:31:49,090:INFO:Logging name: clf-default-name
2024-06-10 17:31:49,090:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:31:49,090:INFO:version 3.3.2
2024-06-10 17:31:49,091:INFO:Initializing setup()
2024-06-10 17:31:49,091:INFO:self.USI: 1906
2024-06-10 17:31:49,091:INFO:self._variable_keys: {'USI', 'idx', '_available_plots', 'y_test', 'y_train', 'fold_groups_param', 'is_multiclass', 'memory', 'X_test', 'n_jobs_param', '_ml_usecase', 'X_train', 'logging_param', 'fix_imbalance', 'fold_generator', 'seed', 'X', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'data', 'exp_id', 'fold_shuffle_param', 'html_param', 'y', 'gpu_param', 'gpu_n_jobs_param'}
2024-06-10 17:31:49,091:INFO:Checking environment
2024-06-10 17:31:49,091:INFO:python_version: 3.11.9
2024-06-10 17:31:49,091:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:31:49,091:INFO:machine: AMD64
2024-06-10 17:31:49,091:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:31:49,091:INFO:Memory: svmem(total=34056318976, available=22047567872, percent=35.3, used=12008751104, free=22047567872)
2024-06-10 17:31:49,091:INFO:Physical Core: 6
2024-06-10 17:31:49,091:INFO:Logical Core: 12
2024-06-10 17:31:49,091:INFO:Checking libraries
2024-06-10 17:31:49,091:INFO:System:
2024-06-10 17:31:49,091:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:31:49,091:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:31:49,091:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:31:49,091:INFO:PyCaret required dependencies:
2024-06-10 17:31:49,091:INFO:                 pip: 24.0
2024-06-10 17:31:49,091:INFO:          setuptools: 69.5.1
2024-06-10 17:31:49,093:INFO:             pycaret: 3.3.2
2024-06-10 17:31:49,093:INFO:             IPython: 8.25.0
2024-06-10 17:31:49,093:INFO:          ipywidgets: 8.1.3
2024-06-10 17:31:49,093:INFO:                tqdm: 4.66.4
2024-06-10 17:31:49,093:INFO:               numpy: 1.26.4
2024-06-10 17:31:49,093:INFO:              pandas: 2.1.4
2024-06-10 17:31:49,093:INFO:              jinja2: 3.1.4
2024-06-10 17:31:49,093:INFO:               scipy: 1.11.4
2024-06-10 17:31:49,093:INFO:              joblib: 1.3.2
2024-06-10 17:31:49,093:INFO:             sklearn: 1.4.2
2024-06-10 17:31:49,093:INFO:                pyod: 2.0.0
2024-06-10 17:31:49,093:INFO:            imblearn: 0.12.3
2024-06-10 17:31:49,093:INFO:   category_encoders: 2.6.3
2024-06-10 17:31:49,093:INFO:            lightgbm: 4.3.0
2024-06-10 17:31:49,093:INFO:               numba: 0.59.1
2024-06-10 17:31:49,093:INFO:            requests: 2.32.3
2024-06-10 17:31:49,093:INFO:          matplotlib: 3.7.5
2024-06-10 17:31:49,093:INFO:          scikitplot: 0.3.7
2024-06-10 17:31:49,093:INFO:         yellowbrick: 1.5
2024-06-10 17:31:49,094:INFO:              plotly: 5.22.0
2024-06-10 17:31:49,094:INFO:    plotly-resampler: Not installed
2024-06-10 17:31:49,094:INFO:             kaleido: 0.2.1
2024-06-10 17:31:49,094:INFO:           schemdraw: 0.15
2024-06-10 17:31:49,094:INFO:         statsmodels: 0.14.2
2024-06-10 17:31:49,094:INFO:              sktime: 0.26.0
2024-06-10 17:31:49,094:INFO:               tbats: 1.1.3
2024-06-10 17:31:49,094:INFO:            pmdarima: 2.0.4
2024-06-10 17:31:49,094:INFO:              psutil: 5.9.8
2024-06-10 17:31:49,094:INFO:          markupsafe: 2.1.5
2024-06-10 17:31:49,094:INFO:             pickle5: Not installed
2024-06-10 17:31:49,094:INFO:         cloudpickle: 3.0.0
2024-06-10 17:31:49,094:INFO:         deprecation: 2.1.0
2024-06-10 17:31:49,094:INFO:              xxhash: 3.4.1
2024-06-10 17:31:49,094:INFO:           wurlitzer: Not installed
2024-06-10 17:31:49,094:INFO:PyCaret optional dependencies:
2024-06-10 17:31:49,094:INFO:                shap: Not installed
2024-06-10 17:31:49,094:INFO:           interpret: Not installed
2024-06-10 17:31:49,094:INFO:                umap: Not installed
2024-06-10 17:31:49,094:INFO:     ydata_profiling: Not installed
2024-06-10 17:31:49,095:INFO:  explainerdashboard: Not installed
2024-06-10 17:31:49,095:INFO:             autoviz: Not installed
2024-06-10 17:31:49,095:INFO:           fairlearn: Not installed
2024-06-10 17:31:49,095:INFO:          deepchecks: Not installed
2024-06-10 17:31:49,095:INFO:             xgboost: Not installed
2024-06-10 17:31:49,095:INFO:            catboost: Not installed
2024-06-10 17:31:49,095:INFO:              kmodes: Not installed
2024-06-10 17:31:49,095:INFO:             mlxtend: Not installed
2024-06-10 17:31:49,095:INFO:       statsforecast: Not installed
2024-06-10 17:31:49,095:INFO:        tune_sklearn: Not installed
2024-06-10 17:31:49,095:INFO:                 ray: Not installed
2024-06-10 17:31:49,095:INFO:            hyperopt: Not installed
2024-06-10 17:31:49,095:INFO:              optuna: Not installed
2024-06-10 17:31:49,095:INFO:               skopt: Not installed
2024-06-10 17:31:49,095:INFO:              mlflow: Not installed
2024-06-10 17:31:49,095:INFO:              gradio: Not installed
2024-06-10 17:31:49,095:INFO:             fastapi: Not installed
2024-06-10 17:31:49,095:INFO:             uvicorn: Not installed
2024-06-10 17:31:49,095:INFO:              m2cgen: Not installed
2024-06-10 17:31:49,095:INFO:           evidently: Not installed
2024-06-10 17:31:49,095:INFO:               fugue: Not installed
2024-06-10 17:31:49,096:INFO:           streamlit: 1.35.0
2024-06-10 17:31:49,096:INFO:             prophet: Not installed
2024-06-10 17:31:49,096:INFO:None
2024-06-10 17:31:49,096:INFO:Set up data.
2024-06-10 17:31:49,154:INFO:Set up folding strategy.
2024-06-10 17:31:49,154:INFO:Set up train/test split.
2024-06-10 17:31:49,177:INFO:Set up index.
2024-06-10 17:31:49,179:INFO:Assigning column types.
2024-06-10 17:31:49,190:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:31:49,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:31:49,235:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:31:49,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:31:49,308:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:31:49,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,346:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:31:49,411:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:31:49,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,497:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:31:49,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,531:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:31:49,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:49,744:INFO:Preparing preprocessing pipeline...
2024-06-10 17:31:49,749:INFO:Set up date feature engineering.
2024-06-10 17:31:49,749:INFO:Set up simple imputation.
2024-06-10 17:31:49,773:INFO:Set up encoding of ordinal features.
2024-06-10 17:31:49,794:INFO:Set up encoding of categorical features.
2024-06-10 17:31:49,794:INFO:Set up removing outliers.
2024-06-10 17:31:49,794:INFO:Set up feature normalization.
2024-06-10 17:31:49,794:INFO:Set up PCA.
2024-06-10 17:31:50,398:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:31:50,451:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MaxAbsScaler(copy=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 17:31:50,451:INFO:Creating final display dataframe.
2024-06-10 17:31:51,285:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48250, 34)
5   Transformed train set shape       (33250, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            maxabs
21                          PCA              True
22                   PCA method       incremental
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              1906
2024-06-10 17:31:51,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:51,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:51,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:51,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:31:51,434:INFO:setup() successfully completed in 2.42s...............
2024-06-10 17:31:51,489:INFO:Initializing create_model()
2024-06-10 17:31:51,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:31:51,489:INFO:Checking exceptions
2024-06-10 17:31:51,505:INFO:Importing libraries
2024-06-10 17:31:51,506:INFO:Copying training dataset
2024-06-10 17:31:51,523:INFO:Defining folds
2024-06-10 17:31:51,524:INFO:Declaring metric variables
2024-06-10 17:31:51,527:INFO:Importing untrained model
2024-06-10 17:31:51,530:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:31:51,536:INFO:Starting cross validation
2024-06-10 17:31:51,539:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:31:54,777:INFO:Calculating mean and std
2024-06-10 17:31:54,778:INFO:Creating metrics dataframe
2024-06-10 17:31:54,787:INFO:Finalizing model
2024-06-10 17:31:55,982:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:31:55,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003867 seconds.
2024-06-10 17:31:55,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:31:55,986:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:31:55,988:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:31:55,988:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:31:55,989:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:31:56,237:INFO:Uploading results into container
2024-06-10 17:31:56,238:INFO:Uploading model into container now
2024-06-10 17:31:56,251:INFO:_master_model_container: 1
2024-06-10 17:31:56,251:INFO:_display_container: 2
2024-06-10 17:31:56,252:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:31:56,252:INFO:create_model() successfully completed......................................
2024-06-10 17:31:56,388:INFO:Initializing tune_model()
2024-06-10 17:31:56,388:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 17:31:56,388:INFO:Checking exceptions
2024-06-10 17:31:56,415:INFO:Copying training dataset
2024-06-10 17:31:56,428:INFO:Checking base model
2024-06-10 17:31:56,428:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 17:31:56,432:INFO:Declaring metric variables
2024-06-10 17:31:56,434:INFO:Defining Hyperparameters
2024-06-10 17:31:56,518:INFO:Tuning with n_jobs=-1
2024-06-10 17:31:56,518:INFO:Initializing RandomizedSearchCV
2024-06-10 17:32:01,906:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:07,813:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:07,841:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:10,804:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:10,906:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:10,971:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:10,988:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:13,545:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:13,648:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:16,226:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:16,332:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:16,927:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:17,685:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:18,947:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:20,482:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:20,690:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:21,827:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:23,232:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:23,899:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:24,976:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:25,655:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:45,577:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:46,553:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:47,563:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:47,716:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:47,716:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:48,408:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:48,609:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:49,154:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:49,259:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:49,897:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:32:49,916:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 17:32:49,918:INFO:Hyperparameter search completed
2024-06-10 17:32:49,919:INFO:SubProcess create_model() called ==================================
2024-06-10 17:32:49,920:INFO:Initializing create_model()
2024-06-10 17:32:49,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016602B31D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-10 17:32:49,921:INFO:Checking exceptions
2024-06-10 17:32:49,921:INFO:Importing libraries
2024-06-10 17:32:49,921:INFO:Copying training dataset
2024-06-10 17:32:49,971:INFO:Defining folds
2024-06-10 17:32:49,971:INFO:Declaring metric variables
2024-06-10 17:32:49,978:INFO:Importing untrained model
2024-06-10 17:32:49,978:INFO:Declaring custom model
2024-06-10 17:32:49,985:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:32:50,003:INFO:Starting cross validation
2024-06-10 17:32:50,008:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:32:58,275:INFO:Calculating mean and std
2024-06-10 17:32:58,277:INFO:Creating metrics dataframe
2024-06-10 17:32:58,286:INFO:Finalizing model
2024-06-10 17:32:59,578:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:32:59,578:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:32:59,578:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:32:59,631:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:32:59,631:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:32:59,631:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:32:59,631:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:32:59,636:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003442 seconds.
2024-06-10 17:32:59,636:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:32:59,637:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:32:59,638:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:32:59,641:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:32:59,641:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:32:59,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:32:59,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:00,453:INFO:Uploading results into container
2024-06-10 17:33:00,454:INFO:Uploading model into container now
2024-06-10 17:33:00,455:INFO:_master_model_container: 2
2024-06-10 17:33:00,455:INFO:_display_container: 3
2024-06-10 17:33:00,456:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:33:00,457:INFO:create_model() successfully completed......................................
2024-06-10 17:33:00,569:INFO:SubProcess create_model() end ==================================
2024-06-10 17:33:00,569:INFO:choose_better activated
2024-06-10 17:33:00,573:INFO:SubProcess create_model() called ==================================
2024-06-10 17:33:00,574:INFO:Initializing create_model()
2024-06-10 17:33:00,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:33:00,574:INFO:Checking exceptions
2024-06-10 17:33:00,576:INFO:Importing libraries
2024-06-10 17:33:00,576:INFO:Copying training dataset
2024-06-10 17:33:00,600:INFO:Defining folds
2024-06-10 17:33:00,600:INFO:Declaring metric variables
2024-06-10 17:33:00,600:INFO:Importing untrained model
2024-06-10 17:33:00,600:INFO:Declaring custom model
2024-06-10 17:33:00,601:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:33:00,601:INFO:Starting cross validation
2024-06-10 17:33:00,603:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:33:04,174:INFO:Calculating mean and std
2024-06-10 17:33:04,175:INFO:Creating metrics dataframe
2024-06-10 17:33:04,178:INFO:Finalizing model
2024-06-10 17:33:05,575:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:33:05,581:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004971 seconds.
2024-06-10 17:33:05,581:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:33:05,583:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:33:05,583:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:33:05,584:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:33:05,584:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:33:06,101:INFO:Uploading results into container
2024-06-10 17:33:06,101:INFO:Uploading model into container now
2024-06-10 17:33:06,103:INFO:_master_model_container: 3
2024-06-10 17:33:06,103:INFO:_display_container: 4
2024-06-10 17:33:06,104:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:33:06,104:INFO:create_model() successfully completed......................................
2024-06-10 17:33:06,234:INFO:SubProcess create_model() end ==================================
2024-06-10 17:33:06,235:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.287
2024-06-10 17:33:06,236:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.3195
2024-06-10 17:33:06,236:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 17:33:06,237:INFO:choose_better completed
2024-06-10 17:33:06,252:INFO:_master_model_container: 3
2024-06-10 17:33:06,253:INFO:_display_container: 3
2024-06-10 17:33:06,253:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:33:06,254:INFO:tune_model() successfully completed......................................
2024-06-10 17:33:06,454:INFO:Initializing plot_model()
2024-06-10 17:33:06,455:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:33:06,455:INFO:Checking exceptions
2024-06-10 17:33:06,473:INFO:Preloading libraries
2024-06-10 17:33:06,559:INFO:Copying training dataset
2024-06-10 17:33:06,560:INFO:Plot type: auc
2024-06-10 17:33:06,884:INFO:Fitting Model
2024-06-10 17:33:06,886:INFO:Scoring test/hold-out set
2024-06-10 17:33:06,889:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:06,889:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:06,889:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:06,983:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:06,983:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:06,983:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:07,399:INFO:Visual Rendered Successfully
2024-06-10 17:33:07,512:INFO:plot_model() successfully completed......................................
2024-06-10 17:33:07,587:INFO:Initializing finalize_model()
2024-06-10 17:33:07,588:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 17:33:07,590:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:33:07,613:INFO:Initializing create_model()
2024-06-10 17:33:07,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:33:07,614:INFO:Checking exceptions
2024-06-10 17:33:07,616:INFO:Importing libraries
2024-06-10 17:33:07,616:INFO:Copying training dataset
2024-06-10 17:33:07,617:INFO:Defining folds
2024-06-10 17:33:07,617:INFO:Declaring metric variables
2024-06-10 17:33:07,617:INFO:Importing untrained model
2024-06-10 17:33:07,618:INFO:Declaring custom model
2024-06-10 17:33:07,618:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:33:07,623:INFO:Cross validation set to False
2024-06-10 17:33:07,623:INFO:Fitting Model
2024-06-10 17:33:09,354:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:09,354:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:09,354:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:09,438:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:09,438:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:09,439:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:09,439:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 17:33:09,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005387 seconds.
2024-06-10 17:33:09,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:33:09,447:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:33:09,448:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 17:33:09,450:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 17:33:09,450:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 17:33:09,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:09,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:33:10,695:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:33:10,695:INFO:create_model() successfully completed......................................
2024-06-10 17:33:10,794:INFO:_master_model_container: 3
2024-06-10 17:33:10,794:INFO:_display_container: 3
2024-06-10 17:33:10,836:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:33:10,837:INFO:finalize_model() successfully completed......................................
2024-06-10 17:33:11,004:INFO:Initializing evaluate_model()
2024-06-10 17:33:11,005:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 17:33:11,057:INFO:Initializing plot_model()
2024-06-10 17:33:11,057:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:33:11,057:INFO:Checking exceptions
2024-06-10 17:33:11,064:INFO:Preloading libraries
2024-06-10 17:33:11,105:INFO:Copying training dataset
2024-06-10 17:33:11,105:INFO:Plot type: pipeline
2024-06-10 17:33:11,370:INFO:Visual Rendered Successfully
2024-06-10 17:33:11,447:INFO:plot_model() successfully completed......................................
2024-06-10 17:33:11,522:INFO:Initializing plot_model()
2024-06-10 17:33:11,522:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:33:11,522:INFO:Checking exceptions
2024-06-10 17:33:11,538:INFO:Preloading libraries
2024-06-10 17:33:11,594:INFO:Copying training dataset
2024-06-10 17:33:11,594:INFO:Plot type: confusion_matrix
2024-06-10 17:33:11,809:INFO:Fitting Model
2024-06-10 17:33:11,810:INFO:Scoring test/hold-out set
2024-06-10 17:33:11,812:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:11,812:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:11,813:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:11,879:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:11,879:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:11,879:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:12,139:INFO:Visual Rendered Successfully
2024-06-10 17:33:12,228:INFO:plot_model() successfully completed......................................
2024-06-10 17:33:14,686:INFO:Initializing plot_model()
2024-06-10 17:33:14,686:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:33:14,686:INFO:Checking exceptions
2024-06-10 17:33:14,695:INFO:Preloading libraries
2024-06-10 17:33:14,735:INFO:Copying training dataset
2024-06-10 17:33:14,735:INFO:Plot type: auc
2024-06-10 17:33:14,934:INFO:Fitting Model
2024-06-10 17:33:14,935:INFO:Scoring test/hold-out set
2024-06-10 17:33:14,937:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:14,937:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:14,937:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:15,016:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:15,016:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:15,018:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:15,336:INFO:Visual Rendered Successfully
2024-06-10 17:33:15,425:INFO:plot_model() successfully completed......................................
2024-06-10 17:33:21,365:INFO:Initializing plot_model()
2024-06-10 17:33:21,365:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:33:21,365:INFO:Checking exceptions
2024-06-10 17:33:21,371:INFO:Preloading libraries
2024-06-10 17:33:21,405:INFO:Copying training dataset
2024-06-10 17:33:21,405:INFO:Plot type: confusion_matrix
2024-06-10 17:33:21,584:INFO:Fitting Model
2024-06-10 17:33:21,584:INFO:Scoring test/hold-out set
2024-06-10 17:33:21,587:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:21,587:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:21,587:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:21,651:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:33:21,651:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:33:21,652:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:33:21,859:INFO:Visual Rendered Successfully
2024-06-10 17:33:21,945:INFO:plot_model() successfully completed......................................
2024-06-10 17:35:05,410:INFO:Initializing plot_model()
2024-06-10 17:35:05,411:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:35:05,411:INFO:Checking exceptions
2024-06-10 17:35:05,416:INFO:Preloading libraries
2024-06-10 17:35:05,452:INFO:Copying training dataset
2024-06-10 17:35:05,452:INFO:Plot type: auc
2024-06-10 17:35:05,628:INFO:Fitting Model
2024-06-10 17:35:05,629:INFO:Scoring test/hold-out set
2024-06-10 17:35:05,631:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:35:05,631:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:35:05,631:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:35:05,697:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:35:05,697:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:35:05,697:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:35:05,963:INFO:Visual Rendered Successfully
2024-06-10 17:35:06,045:INFO:plot_model() successfully completed......................................
2024-06-10 17:35:16,849:INFO:Initializing plot_model()
2024-06-10 17:35:16,849:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:35:16,849:INFO:Checking exceptions
2024-06-10 17:35:16,856:INFO:Preloading libraries
2024-06-10 17:35:16,887:INFO:Copying training dataset
2024-06-10 17:35:16,887:INFO:Plot type: confusion_matrix
2024-06-10 17:35:17,057:INFO:Fitting Model
2024-06-10 17:35:17,058:INFO:Scoring test/hold-out set
2024-06-10 17:35:17,059:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:35:17,059:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:35:17,059:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:35:17,114:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:35:17,114:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:35:17,114:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:35:17,313:INFO:Visual Rendered Successfully
2024-06-10 17:35:17,397:INFO:plot_model() successfully completed......................................
2024-06-10 17:35:22,465:INFO:Initializing plot_model()
2024-06-10 17:35:22,466:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:35:22,466:INFO:Checking exceptions
2024-06-10 17:35:22,473:INFO:Preloading libraries
2024-06-10 17:35:22,507:INFO:Copying training dataset
2024-06-10 17:35:22,507:INFO:Plot type: auc
2024-06-10 17:35:22,696:INFO:Fitting Model
2024-06-10 17:35:22,697:INFO:Scoring test/hold-out set
2024-06-10 17:35:22,699:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:35:22,699:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:35:22,699:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:35:22,766:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:35:22,766:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:35:22,766:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:35:23,071:INFO:Visual Rendered Successfully
2024-06-10 17:35:23,146:INFO:plot_model() successfully completed......................................
2024-06-10 17:43:59,619:INFO:Initializing plot_model()
2024-06-10 17:43:59,619:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602BA25D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:43:59,619:INFO:Checking exceptions
2024-06-10 17:43:59,626:INFO:Preloading libraries
2024-06-10 17:43:59,661:INFO:Copying training dataset
2024-06-10 17:43:59,661:INFO:Plot type: confusion_matrix
2024-06-10 17:43:59,852:INFO:Fitting Model
2024-06-10 17:43:59,853:INFO:Scoring test/hold-out set
2024-06-10 17:43:59,855:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:43:59,855:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:43:59,855:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:43:59,935:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:43:59,935:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:43:59,935:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:44:00,147:INFO:Visual Rendered Successfully
2024-06-10 17:44:00,235:INFO:plot_model() successfully completed......................................
2024-06-10 17:46:22,085:INFO:PyCaret ClassificationExperiment
2024-06-10 17:46:22,085:INFO:Logging name: clf-default-name
2024-06-10 17:46:22,085:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:46:22,085:INFO:version 3.3.2
2024-06-10 17:46:22,086:INFO:Initializing setup()
2024-06-10 17:46:22,086:INFO:self.USI: 657b
2024-06-10 17:46:22,086:INFO:self._variable_keys: {'USI', 'idx', '_available_plots', 'y_test', 'y_train', 'fold_groups_param', 'is_multiclass', 'memory', 'X_test', 'n_jobs_param', '_ml_usecase', 'X_train', 'logging_param', 'fix_imbalance', 'fold_generator', 'seed', 'X', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'data', 'exp_id', 'fold_shuffle_param', 'html_param', 'y', 'gpu_param', 'gpu_n_jobs_param'}
2024-06-10 17:46:22,086:INFO:Checking environment
2024-06-10 17:46:22,086:INFO:python_version: 3.11.9
2024-06-10 17:46:22,086:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:46:22,086:INFO:machine: AMD64
2024-06-10 17:46:22,086:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:46:22,087:INFO:Memory: svmem(total=34056318976, available=24346804224, percent=28.5, used=9709514752, free=24346804224)
2024-06-10 17:46:22,087:INFO:Physical Core: 6
2024-06-10 17:46:22,087:INFO:Logical Core: 12
2024-06-10 17:46:22,087:INFO:Checking libraries
2024-06-10 17:46:22,087:INFO:System:
2024-06-10 17:46:22,087:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:46:22,087:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:46:22,087:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:46:22,087:INFO:PyCaret required dependencies:
2024-06-10 17:46:22,088:INFO:                 pip: 24.0
2024-06-10 17:46:22,088:INFO:          setuptools: 69.5.1
2024-06-10 17:46:22,088:INFO:             pycaret: 3.3.2
2024-06-10 17:46:22,088:INFO:             IPython: 8.25.0
2024-06-10 17:46:22,088:INFO:          ipywidgets: 8.1.3
2024-06-10 17:46:22,088:INFO:                tqdm: 4.66.4
2024-06-10 17:46:22,088:INFO:               numpy: 1.26.4
2024-06-10 17:46:22,088:INFO:              pandas: 2.1.4
2024-06-10 17:46:22,088:INFO:              jinja2: 3.1.4
2024-06-10 17:46:22,089:INFO:               scipy: 1.11.4
2024-06-10 17:46:22,089:INFO:              joblib: 1.3.2
2024-06-10 17:46:22,089:INFO:             sklearn: 1.4.2
2024-06-10 17:46:22,089:INFO:                pyod: 2.0.0
2024-06-10 17:46:22,089:INFO:            imblearn: 0.12.3
2024-06-10 17:46:22,089:INFO:   category_encoders: 2.6.3
2024-06-10 17:46:22,089:INFO:            lightgbm: 4.3.0
2024-06-10 17:46:22,089:INFO:               numba: 0.59.1
2024-06-10 17:46:22,089:INFO:            requests: 2.32.3
2024-06-10 17:46:22,089:INFO:          matplotlib: 3.7.5
2024-06-10 17:46:22,089:INFO:          scikitplot: 0.3.7
2024-06-10 17:46:22,090:INFO:         yellowbrick: 1.5
2024-06-10 17:46:22,090:INFO:              plotly: 5.22.0
2024-06-10 17:46:22,090:INFO:    plotly-resampler: Not installed
2024-06-10 17:46:22,090:INFO:             kaleido: 0.2.1
2024-06-10 17:46:22,090:INFO:           schemdraw: 0.15
2024-06-10 17:46:22,090:INFO:         statsmodels: 0.14.2
2024-06-10 17:46:22,090:INFO:              sktime: 0.26.0
2024-06-10 17:46:22,090:INFO:               tbats: 1.1.3
2024-06-10 17:46:22,090:INFO:            pmdarima: 2.0.4
2024-06-10 17:46:22,090:INFO:              psutil: 5.9.8
2024-06-10 17:46:22,090:INFO:          markupsafe: 2.1.5
2024-06-10 17:46:22,091:INFO:             pickle5: Not installed
2024-06-10 17:46:22,091:INFO:         cloudpickle: 3.0.0
2024-06-10 17:46:22,091:INFO:         deprecation: 2.1.0
2024-06-10 17:46:22,091:INFO:              xxhash: 3.4.1
2024-06-10 17:46:22,091:INFO:           wurlitzer: Not installed
2024-06-10 17:46:22,091:INFO:PyCaret optional dependencies:
2024-06-10 17:46:22,091:INFO:                shap: Not installed
2024-06-10 17:46:22,091:INFO:           interpret: Not installed
2024-06-10 17:46:22,091:INFO:                umap: Not installed
2024-06-10 17:46:22,091:INFO:     ydata_profiling: Not installed
2024-06-10 17:46:22,091:INFO:  explainerdashboard: Not installed
2024-06-10 17:46:22,091:INFO:             autoviz: Not installed
2024-06-10 17:46:22,091:INFO:           fairlearn: Not installed
2024-06-10 17:46:22,091:INFO:          deepchecks: Not installed
2024-06-10 17:46:22,091:INFO:             xgboost: Not installed
2024-06-10 17:46:22,091:INFO:            catboost: Not installed
2024-06-10 17:46:22,092:INFO:              kmodes: Not installed
2024-06-10 17:46:22,092:INFO:             mlxtend: Not installed
2024-06-10 17:46:22,092:INFO:       statsforecast: Not installed
2024-06-10 17:46:22,092:INFO:        tune_sklearn: Not installed
2024-06-10 17:46:22,092:INFO:                 ray: Not installed
2024-06-10 17:46:22,092:INFO:            hyperopt: Not installed
2024-06-10 17:46:22,092:INFO:              optuna: Not installed
2024-06-10 17:46:22,092:INFO:               skopt: Not installed
2024-06-10 17:46:22,092:INFO:              mlflow: Not installed
2024-06-10 17:46:22,092:INFO:              gradio: Not installed
2024-06-10 17:46:22,092:INFO:             fastapi: Not installed
2024-06-10 17:46:22,092:INFO:             uvicorn: Not installed
2024-06-10 17:46:22,092:INFO:              m2cgen: Not installed
2024-06-10 17:46:22,092:INFO:           evidently: Not installed
2024-06-10 17:46:22,093:INFO:               fugue: Not installed
2024-06-10 17:46:22,093:INFO:           streamlit: 1.35.0
2024-06-10 17:46:22,093:INFO:             prophet: Not installed
2024-06-10 17:46:22,093:INFO:None
2024-06-10 17:46:22,093:INFO:Set up data.
2024-06-10 17:46:22,144:INFO:Set up folding strategy.
2024-06-10 17:46:22,145:INFO:Set up train/test split.
2024-06-10 17:46:22,177:INFO:Set up index.
2024-06-10 17:46:22,178:INFO:Assigning column types.
2024-06-10 17:46:22,192:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:46:22,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:46:22,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:46:22,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:46:22,355:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:46:22,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,388:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:46:22,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:46:22,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,525:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:46:22,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,607:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:46:22,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:22,881:INFO:Preparing preprocessing pipeline...
2024-06-10 17:46:22,884:INFO:Set up date feature engineering.
2024-06-10 17:46:22,884:INFO:Set up simple imputation.
2024-06-10 17:46:22,897:INFO:Set up encoding of ordinal features.
2024-06-10 17:46:22,910:INFO:Set up encoding of categorical features.
2024-06-10 17:46:22,910:INFO:Set up removing outliers.
2024-06-10 17:46:22,910:INFO:Set up feature normalization.
2024-06-10 17:46:22,910:INFO:Set up PCA.
2024-06-10 17:46:23,490:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:46:23,529:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 17:46:23,529:INFO:Creating final display dataframe.
2024-06-10 17:46:24,341:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48250, 34)
5   Transformed train set shape       (33250, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21                          PCA              True
22                   PCA method       incremental
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              657b
2024-06-10 17:46:24,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:24,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:24,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:24,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:46:24,506:INFO:setup() successfully completed in 2.52s...............
2024-06-10 17:46:24,525:INFO:Initializing create_model()
2024-06-10 17:46:24,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:46:24,525:INFO:Checking exceptions
2024-06-10 17:46:24,541:INFO:Importing libraries
2024-06-10 17:46:24,541:INFO:Copying training dataset
2024-06-10 17:46:24,561:INFO:Defining folds
2024-06-10 17:46:24,561:INFO:Declaring metric variables
2024-06-10 17:46:24,564:INFO:Importing untrained model
2024-06-10 17:46:24,568:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:46:24,574:INFO:Starting cross validation
2024-06-10 17:46:24,577:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:46:31,587:INFO:Calculating mean and std
2024-06-10 17:46:31,588:INFO:Creating metrics dataframe
2024-06-10 17:46:31,598:INFO:Finalizing model
2024-06-10 17:46:32,785:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:46:32,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003932 seconds.
2024-06-10 17:46:32,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:46:32,790:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:46:32,790:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:46:32,791:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:46:32,792:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:46:32,991:INFO:Uploading results into container
2024-06-10 17:46:32,992:INFO:Uploading model into container now
2024-06-10 17:46:33,004:INFO:_master_model_container: 1
2024-06-10 17:46:33,004:INFO:_display_container: 2
2024-06-10 17:46:33,005:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:46:33,006:INFO:create_model() successfully completed......................................
2024-06-10 17:46:33,117:INFO:Initializing tune_model()
2024-06-10 17:46:33,117:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 17:46:33,117:INFO:Checking exceptions
2024-06-10 17:46:33,148:INFO:Copying training dataset
2024-06-10 17:46:33,162:INFO:Checking base model
2024-06-10 17:46:33,162:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 17:46:33,166:INFO:Declaring metric variables
2024-06-10 17:46:33,169:INFO:Defining Hyperparameters
2024-06-10 17:46:33,248:INFO:Tuning with n_jobs=-1
2024-06-10 17:46:33,248:INFO:Initializing RandomizedSearchCV
2024-06-10 17:46:48,040:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:46:50,960:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:46:56,012:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:46:56,143:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:46:59,896:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:46:59,970:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:00,214:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:00,784:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:01,111:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:03,415:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:04,258:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:04,721:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:05,553:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:06,539:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:07,663:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:08,527:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:08,783:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:11,630:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:11,687:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:11,714:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:12,756:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:15,051:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:39,720:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:39,771:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:40,078:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:40,661:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:41,138:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:41,822:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:42,018:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:42,130:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:42,663:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:44,115:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:44,122:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 17:47:44,123:INFO:Hyperparameter search completed
2024-06-10 17:47:44,124:INFO:SubProcess create_model() called ==================================
2024-06-10 17:47:44,126:INFO:Initializing create_model()
2024-06-10 17:47:44,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001667FC6A810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2024-06-10 17:47:44,127:INFO:Checking exceptions
2024-06-10 17:47:44,127:INFO:Importing libraries
2024-06-10 17:47:44,128:INFO:Copying training dataset
2024-06-10 17:47:44,179:INFO:Defining folds
2024-06-10 17:47:44,179:INFO:Declaring metric variables
2024-06-10 17:47:44,185:INFO:Importing untrained model
2024-06-10 17:47:44,185:INFO:Declaring custom model
2024-06-10 17:47:44,196:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:47:44,214:INFO:Starting cross validation
2024-06-10 17:47:44,220:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:47:49,566:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:49,752:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:47:49,785:INFO:Calculating mean and std
2024-06-10 17:47:49,787:INFO:Creating metrics dataframe
2024-06-10 17:47:49,798:INFO:Finalizing model
2024-06-10 17:47:51,163:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:47:51,163:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:47:51,163:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:47:51,229:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:47:51,229:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:47:51,229:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:47:51,230:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:47:51,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005275 seconds.
2024-06-10 17:47:51,236:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:47:51,236:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:47:51,237:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:47:51,239:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:47:51,239:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:47:51,793:INFO:Uploading results into container
2024-06-10 17:47:51,796:INFO:Uploading model into container now
2024-06-10 17:47:51,797:INFO:_master_model_container: 2
2024-06-10 17:47:51,797:INFO:_display_container: 3
2024-06-10 17:47:51,799:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:47:51,799:INFO:create_model() successfully completed......................................
2024-06-10 17:47:51,934:INFO:SubProcess create_model() end ==================================
2024-06-10 17:47:51,934:INFO:choose_better activated
2024-06-10 17:47:51,938:INFO:SubProcess create_model() called ==================================
2024-06-10 17:47:51,939:INFO:Initializing create_model()
2024-06-10 17:47:51,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:47:51,940:INFO:Checking exceptions
2024-06-10 17:47:51,942:INFO:Importing libraries
2024-06-10 17:47:51,942:INFO:Copying training dataset
2024-06-10 17:47:51,980:INFO:Defining folds
2024-06-10 17:47:51,980:INFO:Declaring metric variables
2024-06-10 17:47:51,980:INFO:Importing untrained model
2024-06-10 17:47:51,980:INFO:Declaring custom model
2024-06-10 17:47:51,981:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:47:51,982:INFO:Starting cross validation
2024-06-10 17:47:51,985:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:47:56,850:INFO:Calculating mean and std
2024-06-10 17:47:56,851:INFO:Creating metrics dataframe
2024-06-10 17:47:56,854:INFO:Finalizing model
2024-06-10 17:47:58,254:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:47:58,259:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004705 seconds.
2024-06-10 17:47:58,260:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:47:58,260:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:47:58,261:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:47:58,262:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:47:58,262:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:47:58,676:INFO:Uploading results into container
2024-06-10 17:47:58,677:INFO:Uploading model into container now
2024-06-10 17:47:58,678:INFO:_master_model_container: 3
2024-06-10 17:47:58,679:INFO:_display_container: 4
2024-06-10 17:47:58,679:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:47:58,680:INFO:create_model() successfully completed......................................
2024-06-10 17:47:58,805:INFO:SubProcess create_model() end ==================================
2024-06-10 17:47:58,806:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2659
2024-06-10 17:47:58,807:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.4
2024-06-10 17:47:58,807:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 17:47:58,807:INFO:choose_better completed
2024-06-10 17:47:58,819:INFO:_master_model_container: 3
2024-06-10 17:47:58,819:INFO:_display_container: 3
2024-06-10 17:47:58,820:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:47:58,820:INFO:tune_model() successfully completed......................................
2024-06-10 17:47:58,993:INFO:Initializing plot_model()
2024-06-10 17:47:58,994:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:47:58,994:INFO:Checking exceptions
2024-06-10 17:47:59,007:INFO:Preloading libraries
2024-06-10 17:47:59,018:INFO:Copying training dataset
2024-06-10 17:47:59,019:INFO:Plot type: auc
2024-06-10 17:47:59,261:INFO:Fitting Model
2024-06-10 17:47:59,262:INFO:Scoring test/hold-out set
2024-06-10 17:47:59,265:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:47:59,265:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:47:59,265:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:47:59,294:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:47:59,294:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:47:59,294:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:47:59,598:INFO:Visual Rendered Successfully
2024-06-10 17:47:59,692:INFO:plot_model() successfully completed......................................
2024-06-10 17:47:59,724:INFO:Initializing finalize_model()
2024-06-10 17:47:59,724:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 17:47:59,724:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:47:59,740:INFO:Initializing create_model()
2024-06-10 17:47:59,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:47:59,741:INFO:Checking exceptions
2024-06-10 17:47:59,743:INFO:Importing libraries
2024-06-10 17:47:59,743:INFO:Copying training dataset
2024-06-10 17:47:59,744:INFO:Defining folds
2024-06-10 17:47:59,744:INFO:Declaring metric variables
2024-06-10 17:47:59,744:INFO:Importing untrained model
2024-06-10 17:47:59,745:INFO:Declaring custom model
2024-06-10 17:47:59,745:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:47:59,749:INFO:Cross validation set to False
2024-06-10 17:47:59,749:INFO:Fitting Model
2024-06-10 17:48:01,266:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:48:01,266:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:48:01,266:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:48:01,335:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:48:01,335:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:48:01,335:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:48:01,336:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 17:48:01,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005812 seconds.
2024-06-10 17:48:01,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:48:01,343:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:48:01,343:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 17:48:01,345:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 17:48:01,345:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 17:48:01,925:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:48:01,925:INFO:create_model() successfully completed......................................
2024-06-10 17:48:02,015:INFO:_master_model_container: 3
2024-06-10 17:48:02,015:INFO:_display_container: 3
2024-06-10 17:48:02,061:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:48:02,061:INFO:finalize_model() successfully completed......................................
2024-06-10 17:48:02,208:INFO:Initializing evaluate_model()
2024-06-10 17:48:02,209:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 17:48:02,273:INFO:Initializing plot_model()
2024-06-10 17:48:02,273:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:48:02,273:INFO:Checking exceptions
2024-06-10 17:48:02,282:INFO:Preloading libraries
2024-06-10 17:48:02,290:INFO:Copying training dataset
2024-06-10 17:48:02,290:INFO:Plot type: pipeline
2024-06-10 17:48:02,565:INFO:Visual Rendered Successfully
2024-06-10 17:48:02,651:INFO:plot_model() successfully completed......................................
2024-06-10 17:48:02,751:INFO:Initializing plot_model()
2024-06-10 17:48:02,751:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:48:02,751:INFO:Checking exceptions
2024-06-10 17:48:02,769:INFO:Preloading libraries
2024-06-10 17:48:02,781:INFO:Copying training dataset
2024-06-10 17:48:02,781:INFO:Plot type: confusion_matrix
2024-06-10 17:48:03,011:INFO:Fitting Model
2024-06-10 17:48:03,012:INFO:Scoring test/hold-out set
2024-06-10 17:48:03,015:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:48:03,015:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:48:03,015:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:48:03,054:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:48:03,055:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:48:03,055:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:48:03,253:INFO:Visual Rendered Successfully
2024-06-10 17:48:03,347:INFO:plot_model() successfully completed......................................
2024-06-10 17:48:20,295:INFO:Initializing plot_model()
2024-06-10 17:48:20,295:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602957A90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:48:20,296:INFO:Checking exceptions
2024-06-10 17:48:20,302:INFO:Preloading libraries
2024-06-10 17:48:20,308:INFO:Copying training dataset
2024-06-10 17:48:20,308:INFO:Plot type: auc
2024-06-10 17:48:20,493:INFO:Fitting Model
2024-06-10 17:48:20,494:INFO:Scoring test/hold-out set
2024-06-10 17:48:20,497:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:48:20,497:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:48:20,497:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:48:20,527:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:48:20,527:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:48:20,527:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:48:20,791:INFO:Visual Rendered Successfully
2024-06-10 17:48:20,876:INFO:plot_model() successfully completed......................................
2024-06-10 17:49:17,818:INFO:PyCaret ClassificationExperiment
2024-06-10 17:49:17,818:INFO:Logging name: clf-default-name
2024-06-10 17:49:17,818:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:49:17,818:INFO:version 3.3.2
2024-06-10 17:49:17,818:INFO:Initializing setup()
2024-06-10 17:49:17,818:INFO:self.USI: 3caf
2024-06-10 17:49:17,819:INFO:self._variable_keys: {'USI', 'idx', '_available_plots', 'y_test', 'y_train', 'fold_groups_param', 'is_multiclass', 'memory', 'X_test', 'n_jobs_param', '_ml_usecase', 'X_train', 'logging_param', 'fix_imbalance', 'fold_generator', 'seed', 'X', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'data', 'exp_id', 'fold_shuffle_param', 'html_param', 'y', 'gpu_param', 'gpu_n_jobs_param'}
2024-06-10 17:49:17,819:INFO:Checking environment
2024-06-10 17:49:17,819:INFO:python_version: 3.11.9
2024-06-10 17:49:17,819:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:49:17,819:INFO:machine: AMD64
2024-06-10 17:49:17,819:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:49:17,819:INFO:Memory: svmem(total=34056318976, available=22505996288, percent=33.9, used=11550322688, free=22505996288)
2024-06-10 17:49:17,819:INFO:Physical Core: 6
2024-06-10 17:49:17,819:INFO:Logical Core: 12
2024-06-10 17:49:17,820:INFO:Checking libraries
2024-06-10 17:49:17,820:INFO:System:
2024-06-10 17:49:17,820:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:49:17,820:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:49:17,820:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:49:17,820:INFO:PyCaret required dependencies:
2024-06-10 17:49:17,820:INFO:                 pip: 24.0
2024-06-10 17:49:17,820:INFO:          setuptools: 69.5.1
2024-06-10 17:49:17,820:INFO:             pycaret: 3.3.2
2024-06-10 17:49:17,820:INFO:             IPython: 8.25.0
2024-06-10 17:49:17,820:INFO:          ipywidgets: 8.1.3
2024-06-10 17:49:17,821:INFO:                tqdm: 4.66.4
2024-06-10 17:49:17,821:INFO:               numpy: 1.26.4
2024-06-10 17:49:17,821:INFO:              pandas: 2.1.4
2024-06-10 17:49:17,821:INFO:              jinja2: 3.1.4
2024-06-10 17:49:17,821:INFO:               scipy: 1.11.4
2024-06-10 17:49:17,821:INFO:              joblib: 1.3.2
2024-06-10 17:49:17,821:INFO:             sklearn: 1.4.2
2024-06-10 17:49:17,821:INFO:                pyod: 2.0.0
2024-06-10 17:49:17,821:INFO:            imblearn: 0.12.3
2024-06-10 17:49:17,821:INFO:   category_encoders: 2.6.3
2024-06-10 17:49:17,821:INFO:            lightgbm: 4.3.0
2024-06-10 17:49:17,821:INFO:               numba: 0.59.1
2024-06-10 17:49:17,821:INFO:            requests: 2.32.3
2024-06-10 17:49:17,821:INFO:          matplotlib: 3.7.5
2024-06-10 17:49:17,821:INFO:          scikitplot: 0.3.7
2024-06-10 17:49:17,821:INFO:         yellowbrick: 1.5
2024-06-10 17:49:17,822:INFO:              plotly: 5.22.0
2024-06-10 17:49:17,822:INFO:    plotly-resampler: Not installed
2024-06-10 17:49:17,822:INFO:             kaleido: 0.2.1
2024-06-10 17:49:17,822:INFO:           schemdraw: 0.15
2024-06-10 17:49:17,822:INFO:         statsmodels: 0.14.2
2024-06-10 17:49:17,822:INFO:              sktime: 0.26.0
2024-06-10 17:49:17,822:INFO:               tbats: 1.1.3
2024-06-10 17:49:17,822:INFO:            pmdarima: 2.0.4
2024-06-10 17:49:17,822:INFO:              psutil: 5.9.8
2024-06-10 17:49:17,822:INFO:          markupsafe: 2.1.5
2024-06-10 17:49:17,822:INFO:             pickle5: Not installed
2024-06-10 17:49:17,822:INFO:         cloudpickle: 3.0.0
2024-06-10 17:49:17,822:INFO:         deprecation: 2.1.0
2024-06-10 17:49:17,822:INFO:              xxhash: 3.4.1
2024-06-10 17:49:17,823:INFO:           wurlitzer: Not installed
2024-06-10 17:49:17,823:INFO:PyCaret optional dependencies:
2024-06-10 17:49:17,823:INFO:                shap: Not installed
2024-06-10 17:49:17,823:INFO:           interpret: Not installed
2024-06-10 17:49:17,823:INFO:                umap: Not installed
2024-06-10 17:49:17,823:INFO:     ydata_profiling: Not installed
2024-06-10 17:49:17,823:INFO:  explainerdashboard: Not installed
2024-06-10 17:49:17,823:INFO:             autoviz: Not installed
2024-06-10 17:49:17,823:INFO:           fairlearn: Not installed
2024-06-10 17:49:17,823:INFO:          deepchecks: Not installed
2024-06-10 17:49:17,823:INFO:             xgboost: Not installed
2024-06-10 17:49:17,823:INFO:            catboost: Not installed
2024-06-10 17:49:17,823:INFO:              kmodes: Not installed
2024-06-10 17:49:17,823:INFO:             mlxtend: Not installed
2024-06-10 17:49:17,823:INFO:       statsforecast: Not installed
2024-06-10 17:49:17,824:INFO:        tune_sklearn: Not installed
2024-06-10 17:49:17,824:INFO:                 ray: Not installed
2024-06-10 17:49:17,824:INFO:            hyperopt: Not installed
2024-06-10 17:49:17,824:INFO:              optuna: Not installed
2024-06-10 17:49:17,824:INFO:               skopt: Not installed
2024-06-10 17:49:17,824:INFO:              mlflow: Not installed
2024-06-10 17:49:17,824:INFO:              gradio: Not installed
2024-06-10 17:49:17,824:INFO:             fastapi: Not installed
2024-06-10 17:49:17,824:INFO:             uvicorn: Not installed
2024-06-10 17:49:17,824:INFO:              m2cgen: Not installed
2024-06-10 17:49:17,824:INFO:           evidently: Not installed
2024-06-10 17:49:17,824:INFO:               fugue: Not installed
2024-06-10 17:49:17,824:INFO:           streamlit: 1.35.0
2024-06-10 17:49:17,824:INFO:             prophet: Not installed
2024-06-10 17:49:17,824:INFO:None
2024-06-10 17:49:17,824:INFO:Set up data.
2024-06-10 17:49:17,864:INFO:Set up folding strategy.
2024-06-10 17:49:17,864:INFO:Set up train/test split.
2024-06-10 17:49:17,889:INFO:Set up index.
2024-06-10 17:49:17,890:INFO:Assigning column types.
2024-06-10 17:49:17,900:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:49:17,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:49:17,949:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:49:17,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:17,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:49:18,031:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:49:18,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,066:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:49:18,117:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:49:18,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,224:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:49:18,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,253:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:49:18,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:18,421:INFO:Preparing preprocessing pipeline...
2024-06-10 17:49:18,423:INFO:Set up date feature engineering.
2024-06-10 17:49:18,423:INFO:Set up simple imputation.
2024-06-10 17:49:18,435:INFO:Set up encoding of ordinal features.
2024-06-10 17:49:18,446:INFO:Set up encoding of categorical features.
2024-06-10 17:49:18,446:INFO:Set up removing outliers.
2024-06-10 17:49:18,446:INFO:Set up feature normalization.
2024-06-10 17:49:18,446:INFO:Set up PCA.
2024-06-10 17:49:18,996:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:49:19,028:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 17:49:19,028:INFO:Creating final display dataframe.
2024-06-10 17:49:19,762:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48250, 34)
5   Transformed train set shape       (33250, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            minmax
21                          PCA              True
22                   PCA method       incremental
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              3caf
2024-06-10 17:49:19,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:19,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:19,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:19,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:49:19,905:INFO:setup() successfully completed in 2.16s...............
2024-06-10 17:49:19,933:INFO:Initializing create_model()
2024-06-10 17:49:19,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:49:19,934:INFO:Checking exceptions
2024-06-10 17:49:19,949:INFO:Importing libraries
2024-06-10 17:49:19,949:INFO:Copying training dataset
2024-06-10 17:49:19,967:INFO:Defining folds
2024-06-10 17:49:19,967:INFO:Declaring metric variables
2024-06-10 17:49:19,970:INFO:Importing untrained model
2024-06-10 17:49:19,974:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:49:19,980:INFO:Starting cross validation
2024-06-10 17:49:19,985:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:49:23,100:INFO:Calculating mean and std
2024-06-10 17:49:23,102:INFO:Creating metrics dataframe
2024-06-10 17:49:23,110:INFO:Finalizing model
2024-06-10 17:49:24,243:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:49:24,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002952 seconds.
2024-06-10 17:49:24,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:49:24,247:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:49:24,248:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:49:24,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:49:24,248:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:49:24,446:INFO:Uploading results into container
2024-06-10 17:49:24,447:INFO:Uploading model into container now
2024-06-10 17:49:24,460:INFO:_master_model_container: 1
2024-06-10 17:49:24,460:INFO:_display_container: 2
2024-06-10 17:49:24,461:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:49:24,461:INFO:create_model() successfully completed......................................
2024-06-10 17:49:24,579:INFO:Initializing tune_model()
2024-06-10 17:49:24,579:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 17:49:24,579:INFO:Checking exceptions
2024-06-10 17:49:24,603:INFO:Copying training dataset
2024-06-10 17:49:24,617:INFO:Checking base model
2024-06-10 17:49:24,617:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 17:49:24,621:INFO:Declaring metric variables
2024-06-10 17:49:24,625:INFO:Defining Hyperparameters
2024-06-10 17:49:24,734:INFO:Tuning with n_jobs=-1
2024-06-10 17:49:24,735:INFO:Initializing RandomizedSearchCV
2024-06-10 17:49:30,895:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:30,960:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:30,979:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:32,040:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:38,283:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:38,319:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:40,594:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:40,606:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:40,649:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:41,397:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:42,995:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:43,058:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:43,157:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:45,313:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:45,626:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:45,628:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:46,177:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:47,611:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:48,029:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:50,393:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:50,440:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:50,934:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:52,265:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:49:53,129:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:12,422:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:12,575:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:13,900:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:14,272:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:14,606:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:15,263:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:15,361:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:15,840:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:16,704:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:16,973:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:50:16,988:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 17:50:16,989:INFO:Hyperparameter search completed
2024-06-10 17:50:16,990:INFO:SubProcess create_model() called ==================================
2024-06-10 17:50:16,991:INFO:Initializing create_model()
2024-06-10 17:50:16,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001660291BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-10 17:50:16,991:INFO:Checking exceptions
2024-06-10 17:50:16,992:INFO:Importing libraries
2024-06-10 17:50:16,992:INFO:Copying training dataset
2024-06-10 17:50:17,039:INFO:Defining folds
2024-06-10 17:50:17,040:INFO:Declaring metric variables
2024-06-10 17:50:17,048:INFO:Importing untrained model
2024-06-10 17:50:17,048:INFO:Declaring custom model
2024-06-10 17:50:17,059:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:50:17,071:INFO:Starting cross validation
2024-06-10 17:50:17,076:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:50:24,902:INFO:Calculating mean and std
2024-06-10 17:50:24,904:INFO:Creating metrics dataframe
2024-06-10 17:50:24,918:INFO:Finalizing model
2024-06-10 17:50:26,042:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:50:26,042:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:50:26,043:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:50:26,085:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 17:50:26,086:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:50:26,086:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 17:50:26,086:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:50:26,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002357 seconds.
2024-06-10 17:50:26,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:50:26,089:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:50:26,090:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:50:26,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:50:26,092:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:50:26,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 17:50:26,904:INFO:Uploading results into container
2024-06-10 17:50:26,906:INFO:Uploading model into container now
2024-06-10 17:50:26,908:INFO:_master_model_container: 2
2024-06-10 17:50:26,908:INFO:_display_container: 3
2024-06-10 17:50:26,910:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:50:26,910:INFO:create_model() successfully completed......................................
2024-06-10 17:50:27,027:INFO:SubProcess create_model() end ==================================
2024-06-10 17:50:27,028:INFO:choose_better activated
2024-06-10 17:50:27,032:INFO:SubProcess create_model() called ==================================
2024-06-10 17:50:27,033:INFO:Initializing create_model()
2024-06-10 17:50:27,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:50:27,033:INFO:Checking exceptions
2024-06-10 17:50:27,035:INFO:Importing libraries
2024-06-10 17:50:27,035:INFO:Copying training dataset
2024-06-10 17:50:27,062:INFO:Defining folds
2024-06-10 17:50:27,063:INFO:Declaring metric variables
2024-06-10 17:50:27,063:INFO:Importing untrained model
2024-06-10 17:50:27,063:INFO:Declaring custom model
2024-06-10 17:50:27,064:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:50:27,065:INFO:Starting cross validation
2024-06-10 17:50:27,067:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:50:30,828:INFO:Calculating mean and std
2024-06-10 17:50:30,829:INFO:Creating metrics dataframe
2024-06-10 17:50:30,834:INFO:Finalizing model
2024-06-10 17:50:32,029:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:50:32,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004156 seconds.
2024-06-10 17:50:32,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:50:32,034:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:50:32,035:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:50:32,035:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:50:32,036:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:50:32,301:INFO:Uploading results into container
2024-06-10 17:50:32,301:INFO:Uploading model into container now
2024-06-10 17:50:32,302:INFO:_master_model_container: 3
2024-06-10 17:50:32,302:INFO:_display_container: 4
2024-06-10 17:50:32,303:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:50:32,303:INFO:create_model() successfully completed......................................
2024-06-10 17:50:32,421:INFO:SubProcess create_model() end ==================================
2024-06-10 17:50:32,422:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2894
2024-06-10 17:50:32,423:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2407
2024-06-10 17:50:32,423:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 17:50:32,423:INFO:choose_better completed
2024-06-10 17:50:32,423:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-10 17:50:32,434:INFO:_master_model_container: 3
2024-06-10 17:50:32,434:INFO:_display_container: 3
2024-06-10 17:50:32,435:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:50:32,435:INFO:tune_model() successfully completed......................................
2024-06-10 17:50:32,583:INFO:Initializing plot_model()
2024-06-10 17:50:32,583:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:50:32,583:INFO:Checking exceptions
2024-06-10 17:50:32,595:INFO:Preloading libraries
2024-06-10 17:50:32,603:INFO:Copying training dataset
2024-06-10 17:50:32,603:INFO:Plot type: auc
2024-06-10 17:50:32,821:INFO:Fitting Model
2024-06-10 17:50:32,822:INFO:Scoring test/hold-out set
2024-06-10 17:50:33,132:INFO:Visual Rendered Successfully
2024-06-10 17:50:33,238:INFO:plot_model() successfully completed......................................
2024-06-10 17:50:33,264:INFO:Initializing finalize_model()
2024-06-10 17:50:33,265:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 17:50:33,265:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:50:33,275:INFO:Initializing create_model()
2024-06-10 17:50:33,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:50:33,276:INFO:Checking exceptions
2024-06-10 17:50:33,277:INFO:Importing libraries
2024-06-10 17:50:33,278:INFO:Copying training dataset
2024-06-10 17:50:33,279:INFO:Defining folds
2024-06-10 17:50:33,279:INFO:Declaring metric variables
2024-06-10 17:50:33,279:INFO:Importing untrained model
2024-06-10 17:50:33,279:INFO:Declaring custom model
2024-06-10 17:50:33,280:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:50:33,282:INFO:Cross validation set to False
2024-06-10 17:50:33,282:INFO:Fitting Model
2024-06-10 17:50:34,675:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 17:50:34,681:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.
2024-06-10 17:50:34,681:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:50:34,682:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:50:34,682:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 17:50:34,683:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 17:50:34,683:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 17:50:35,004:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:50:35,004:INFO:create_model() successfully completed......................................
2024-06-10 17:50:35,100:INFO:_master_model_container: 3
2024-06-10 17:50:35,100:INFO:_display_container: 3
2024-06-10 17:50:35,140:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:50:35,140:INFO:finalize_model() successfully completed......................................
2024-06-10 17:50:35,269:INFO:Initializing evaluate_model()
2024-06-10 17:50:35,269:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 17:50:35,322:INFO:Initializing plot_model()
2024-06-10 17:50:35,322:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:50:35,322:INFO:Checking exceptions
2024-06-10 17:50:35,330:INFO:Preloading libraries
2024-06-10 17:50:35,336:INFO:Copying training dataset
2024-06-10 17:50:35,336:INFO:Plot type: pipeline
2024-06-10 17:50:35,587:INFO:Visual Rendered Successfully
2024-06-10 17:50:35,665:INFO:plot_model() successfully completed......................................
2024-06-10 17:50:35,720:INFO:Initializing plot_model()
2024-06-10 17:50:35,721:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:50:35,721:INFO:Checking exceptions
2024-06-10 17:50:35,731:INFO:Preloading libraries
2024-06-10 17:50:35,738:INFO:Copying training dataset
2024-06-10 17:50:35,738:INFO:Plot type: confusion_matrix
2024-06-10 17:50:35,950:INFO:Fitting Model
2024-06-10 17:50:35,951:INFO:Scoring test/hold-out set
2024-06-10 17:50:36,143:INFO:Visual Rendered Successfully
2024-06-10 17:50:36,225:INFO:plot_model() successfully completed......................................
2024-06-10 17:50:40,099:INFO:Initializing plot_model()
2024-06-10 17:50:40,100:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:50:40,100:INFO:Checking exceptions
2024-06-10 17:50:40,108:INFO:Preloading libraries
2024-06-10 17:50:40,125:INFO:Copying training dataset
2024-06-10 17:50:40,125:INFO:Plot type: auc
2024-06-10 17:50:40,319:INFO:Fitting Model
2024-06-10 17:50:40,320:INFO:Scoring test/hold-out set
2024-06-10 17:50:40,596:INFO:Visual Rendered Successfully
2024-06-10 17:50:40,676:INFO:plot_model() successfully completed......................................
2024-06-10 17:50:43,182:INFO:Initializing plot_model()
2024-06-10 17:50:43,182:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:50:43,182:INFO:Checking exceptions
2024-06-10 17:50:43,188:INFO:Preloading libraries
2024-06-10 17:50:43,195:INFO:Copying training dataset
2024-06-10 17:50:43,196:INFO:Plot type: confusion_matrix
2024-06-10 17:50:43,397:INFO:Fitting Model
2024-06-10 17:50:43,397:INFO:Scoring test/hold-out set
2024-06-10 17:50:43,582:INFO:Visual Rendered Successfully
2024-06-10 17:50:43,665:INFO:plot_model() successfully completed......................................
2024-06-10 17:51:29,404:INFO:Initializing plot_model()
2024-06-10 17:51:29,404:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:51:29,404:INFO:Checking exceptions
2024-06-10 17:51:29,411:INFO:Preloading libraries
2024-06-10 17:51:29,416:INFO:Copying training dataset
2024-06-10 17:51:29,416:INFO:Plot type: auc
2024-06-10 17:51:29,595:INFO:Fitting Model
2024-06-10 17:51:29,596:INFO:Scoring test/hold-out set
2024-06-10 17:51:29,855:INFO:Visual Rendered Successfully
2024-06-10 17:51:29,944:INFO:plot_model() successfully completed......................................
2024-06-10 17:51:52,445:INFO:Initializing plot_model()
2024-06-10 17:51:52,445:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016602D409D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:51:52,445:INFO:Checking exceptions
2024-06-10 17:51:52,453:INFO:Preloading libraries
2024-06-10 17:51:52,459:INFO:Copying training dataset
2024-06-10 17:51:52,459:INFO:Plot type: confusion_matrix
2024-06-10 17:51:52,645:INFO:Fitting Model
2024-06-10 17:51:52,646:INFO:Scoring test/hold-out set
2024-06-10 17:51:52,823:INFO:Visual Rendered Successfully
2024-06-10 17:51:52,904:INFO:plot_model() successfully completed......................................
2024-06-10 17:53:33,293:INFO:PyCaret ClassificationExperiment
2024-06-10 17:53:33,293:INFO:Logging name: clf-default-name
2024-06-10 17:53:33,293:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 17:53:33,293:INFO:version 3.3.2
2024-06-10 17:53:33,293:INFO:Initializing setup()
2024-06-10 17:53:33,293:INFO:self.USI: ed0d
2024-06-10 17:53:33,293:INFO:self._variable_keys: {'USI', 'idx', '_available_plots', 'y_test', 'y_train', 'fold_groups_param', 'is_multiclass', 'memory', 'X_test', 'n_jobs_param', '_ml_usecase', 'X_train', 'logging_param', 'fix_imbalance', 'fold_generator', 'seed', 'X', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'data', 'exp_id', 'fold_shuffle_param', 'html_param', 'y', 'gpu_param', 'gpu_n_jobs_param'}
2024-06-10 17:53:33,293:INFO:Checking environment
2024-06-10 17:53:33,293:INFO:python_version: 3.11.9
2024-06-10 17:53:33,294:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 17:53:33,294:INFO:machine: AMD64
2024-06-10 17:53:33,294:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 17:53:33,294:INFO:Memory: svmem(total=34056318976, available=22456258560, percent=34.1, used=11600060416, free=22456258560)
2024-06-10 17:53:33,294:INFO:Physical Core: 6
2024-06-10 17:53:33,294:INFO:Logical Core: 12
2024-06-10 17:53:33,294:INFO:Checking libraries
2024-06-10 17:53:33,294:INFO:System:
2024-06-10 17:53:33,294:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 17:53:33,295:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 17:53:33,295:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 17:53:33,295:INFO:PyCaret required dependencies:
2024-06-10 17:53:33,295:INFO:                 pip: 24.0
2024-06-10 17:53:33,295:INFO:          setuptools: 69.5.1
2024-06-10 17:53:33,295:INFO:             pycaret: 3.3.2
2024-06-10 17:53:33,295:INFO:             IPython: 8.25.0
2024-06-10 17:53:33,295:INFO:          ipywidgets: 8.1.3
2024-06-10 17:53:33,295:INFO:                tqdm: 4.66.4
2024-06-10 17:53:33,295:INFO:               numpy: 1.26.4
2024-06-10 17:53:33,296:INFO:              pandas: 2.1.4
2024-06-10 17:53:33,296:INFO:              jinja2: 3.1.4
2024-06-10 17:53:33,296:INFO:               scipy: 1.11.4
2024-06-10 17:53:33,296:INFO:              joblib: 1.3.2
2024-06-10 17:53:33,296:INFO:             sklearn: 1.4.2
2024-06-10 17:53:33,296:INFO:                pyod: 2.0.0
2024-06-10 17:53:33,296:INFO:            imblearn: 0.12.3
2024-06-10 17:53:33,296:INFO:   category_encoders: 2.6.3
2024-06-10 17:53:33,297:INFO:            lightgbm: 4.3.0
2024-06-10 17:53:33,297:INFO:               numba: 0.59.1
2024-06-10 17:53:33,297:INFO:            requests: 2.32.3
2024-06-10 17:53:33,297:INFO:          matplotlib: 3.7.5
2024-06-10 17:53:33,297:INFO:          scikitplot: 0.3.7
2024-06-10 17:53:33,297:INFO:         yellowbrick: 1.5
2024-06-10 17:53:33,297:INFO:              plotly: 5.22.0
2024-06-10 17:53:33,297:INFO:    plotly-resampler: Not installed
2024-06-10 17:53:33,297:INFO:             kaleido: 0.2.1
2024-06-10 17:53:33,297:INFO:           schemdraw: 0.15
2024-06-10 17:53:33,298:INFO:         statsmodels: 0.14.2
2024-06-10 17:53:33,298:INFO:              sktime: 0.26.0
2024-06-10 17:53:33,298:INFO:               tbats: 1.1.3
2024-06-10 17:53:33,298:INFO:            pmdarima: 2.0.4
2024-06-10 17:53:33,298:INFO:              psutil: 5.9.8
2024-06-10 17:53:33,298:INFO:          markupsafe: 2.1.5
2024-06-10 17:53:33,298:INFO:             pickle5: Not installed
2024-06-10 17:53:33,298:INFO:         cloudpickle: 3.0.0
2024-06-10 17:53:33,298:INFO:         deprecation: 2.1.0
2024-06-10 17:53:33,298:INFO:              xxhash: 3.4.1
2024-06-10 17:53:33,299:INFO:           wurlitzer: Not installed
2024-06-10 17:53:33,299:INFO:PyCaret optional dependencies:
2024-06-10 17:53:33,299:INFO:                shap: Not installed
2024-06-10 17:53:33,299:INFO:           interpret: Not installed
2024-06-10 17:53:33,299:INFO:                umap: Not installed
2024-06-10 17:53:33,299:INFO:     ydata_profiling: Not installed
2024-06-10 17:53:33,299:INFO:  explainerdashboard: Not installed
2024-06-10 17:53:33,299:INFO:             autoviz: Not installed
2024-06-10 17:53:33,299:INFO:           fairlearn: Not installed
2024-06-10 17:53:33,299:INFO:          deepchecks: Not installed
2024-06-10 17:53:33,300:INFO:             xgboost: Not installed
2024-06-10 17:53:33,300:INFO:            catboost: Not installed
2024-06-10 17:53:33,300:INFO:              kmodes: Not installed
2024-06-10 17:53:33,300:INFO:             mlxtend: Not installed
2024-06-10 17:53:33,300:INFO:       statsforecast: Not installed
2024-06-10 17:53:33,300:INFO:        tune_sklearn: Not installed
2024-06-10 17:53:33,300:INFO:                 ray: Not installed
2024-06-10 17:53:33,300:INFO:            hyperopt: Not installed
2024-06-10 17:53:33,300:INFO:              optuna: Not installed
2024-06-10 17:53:33,300:INFO:               skopt: Not installed
2024-06-10 17:53:33,301:INFO:              mlflow: Not installed
2024-06-10 17:53:33,301:INFO:              gradio: Not installed
2024-06-10 17:53:33,301:INFO:             fastapi: Not installed
2024-06-10 17:53:33,301:INFO:             uvicorn: Not installed
2024-06-10 17:53:33,301:INFO:              m2cgen: Not installed
2024-06-10 17:53:33,301:INFO:           evidently: Not installed
2024-06-10 17:53:33,301:INFO:               fugue: Not installed
2024-06-10 17:53:33,301:INFO:           streamlit: 1.35.0
2024-06-10 17:53:33,301:INFO:             prophet: Not installed
2024-06-10 17:53:33,301:INFO:None
2024-06-10 17:53:33,301:INFO:Set up data.
2024-06-10 17:53:33,355:INFO:Set up folding strategy.
2024-06-10 17:53:33,355:INFO:Set up train/test split.
2024-06-10 17:53:33,382:INFO:Set up index.
2024-06-10 17:53:33,383:INFO:Assigning column types.
2024-06-10 17:53:33,394:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 17:53:33,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:53:33,440:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:53:33,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 17:53:33,526:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:53:33,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,558:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,558:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 17:53:33,612:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:53:33,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,687:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 17:53:33,714:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,715:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 17:53:33,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:33,948:INFO:Preparing preprocessing pipeline...
2024-06-10 17:53:33,952:INFO:Set up date feature engineering.
2024-06-10 17:53:33,952:INFO:Set up simple imputation.
2024-06-10 17:53:33,966:INFO:Set up encoding of ordinal features.
2024-06-10 17:53:33,986:INFO:Set up encoding of categorical features.
2024-06-10 17:53:33,987:INFO:Set up removing outliers.
2024-06-10 17:53:33,987:INFO:Set up feature normalization.
2024-06-10 17:53:33,987:INFO:Set up PCA.
2024-06-10 17:53:34,568:INFO:Finished creating preprocessing pipeline.
2024-06-10 17:53:34,599:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 17:53:34,599:INFO:Creating final display dataframe.
2024-06-10 17:53:35,307:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48250, 34)
5   Transformed train set shape       (33250, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            robust
21                          PCA              True
22                   PCA method       incremental
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              ed0d
2024-06-10 17:53:35,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:35,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:35,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:35,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 17:53:35,448:INFO:setup() successfully completed in 2.25s...............
2024-06-10 17:53:35,462:INFO:Initializing create_model()
2024-06-10 17:53:35,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:53:35,463:INFO:Checking exceptions
2024-06-10 17:53:35,478:INFO:Importing libraries
2024-06-10 17:53:35,478:INFO:Copying training dataset
2024-06-10 17:53:35,504:INFO:Defining folds
2024-06-10 17:53:35,504:INFO:Declaring metric variables
2024-06-10 17:53:35,506:INFO:Importing untrained model
2024-06-10 17:53:35,510:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:53:35,518:INFO:Starting cross validation
2024-06-10 17:53:35,521:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:53:38,371:INFO:Calculating mean and std
2024-06-10 17:53:38,372:INFO:Creating metrics dataframe
2024-06-10 17:53:38,379:INFO:Finalizing model
2024-06-10 17:53:39,470:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:53:39,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002552 seconds.
2024-06-10 17:53:39,473:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:53:39,474:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:53:39,474:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:53:39,475:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:53:39,475:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:53:39,631:INFO:Uploading results into container
2024-06-10 17:53:39,632:INFO:Uploading model into container now
2024-06-10 17:53:39,643:INFO:_master_model_container: 1
2024-06-10 17:53:39,643:INFO:_display_container: 2
2024-06-10 17:53:39,644:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:53:39,645:INFO:create_model() successfully completed......................................
2024-06-10 17:53:39,781:INFO:Initializing tune_model()
2024-06-10 17:53:39,781:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 17:53:39,782:INFO:Checking exceptions
2024-06-10 17:53:39,806:INFO:Copying training dataset
2024-06-10 17:53:39,819:INFO:Checking base model
2024-06-10 17:53:39,819:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 17:53:39,822:INFO:Declaring metric variables
2024-06-10 17:53:39,825:INFO:Defining Hyperparameters
2024-06-10 17:53:39,906:INFO:Tuning with n_jobs=-1
2024-06-10 17:53:39,906:INFO:Initializing RandomizedSearchCV
2024-06-10 17:53:50,165:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:50,334:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:51,110:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:52,075:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:52,497:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:53,780:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:54,969:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:55,557:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:55,571:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:56,047:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:58,009:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:58,375:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:53:58,761:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:00,285:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:00,566:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:02,825:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:02,838:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:02,974:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:03,815:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:05,610:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:20,323:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:21,400:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:21,575:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:21,848:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:22,035:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:22,142:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:22,622:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:23,041:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:23,338:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:23,585:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 17:54:23,594:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 17:54:23,596:INFO:Hyperparameter search completed
2024-06-10 17:54:23,596:INFO:SubProcess create_model() called ==================================
2024-06-10 17:54:23,597:INFO:Initializing create_model()
2024-06-10 17:54:23,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016603175050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2024-06-10 17:54:23,598:INFO:Checking exceptions
2024-06-10 17:54:23,598:INFO:Importing libraries
2024-06-10 17:54:23,598:INFO:Copying training dataset
2024-06-10 17:54:23,637:INFO:Defining folds
2024-06-10 17:54:23,637:INFO:Declaring metric variables
2024-06-10 17:54:23,642:INFO:Importing untrained model
2024-06-10 17:54:23,642:INFO:Declaring custom model
2024-06-10 17:54:23,649:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:54:23,662:INFO:Starting cross validation
2024-06-10 17:54:23,668:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:54:26,858:INFO:Calculating mean and std
2024-06-10 17:54:26,860:INFO:Creating metrics dataframe
2024-06-10 17:54:26,868:INFO:Finalizing model
2024-06-10 17:54:27,894:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:54:27,894:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:54:27,894:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:54:27,938:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:54:27,938:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:54:27,938:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:54:27,938:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:54:27,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003014 seconds.
2024-06-10 17:54:27,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:54:27,942:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:54:27,942:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:54:27,944:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:54:27,944:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:54:28,168:INFO:Uploading results into container
2024-06-10 17:54:28,169:INFO:Uploading model into container now
2024-06-10 17:54:28,170:INFO:_master_model_container: 2
2024-06-10 17:54:28,170:INFO:_display_container: 3
2024-06-10 17:54:28,171:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:54:28,171:INFO:create_model() successfully completed......................................
2024-06-10 17:54:28,283:INFO:SubProcess create_model() end ==================================
2024-06-10 17:54:28,284:INFO:choose_better activated
2024-06-10 17:54:28,288:INFO:SubProcess create_model() called ==================================
2024-06-10 17:54:28,288:INFO:Initializing create_model()
2024-06-10 17:54:28,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:54:28,288:INFO:Checking exceptions
2024-06-10 17:54:28,290:INFO:Importing libraries
2024-06-10 17:54:28,290:INFO:Copying training dataset
2024-06-10 17:54:28,307:INFO:Defining folds
2024-06-10 17:54:28,308:INFO:Declaring metric variables
2024-06-10 17:54:28,308:INFO:Importing untrained model
2024-06-10 17:54:28,308:INFO:Declaring custom model
2024-06-10 17:54:28,308:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:54:28,309:INFO:Starting cross validation
2024-06-10 17:54:28,311:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 17:54:31,137:INFO:Calculating mean and std
2024-06-10 17:54:31,138:INFO:Creating metrics dataframe
2024-06-10 17:54:31,140:INFO:Finalizing model
2024-06-10 17:54:32,190:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 17:54:32,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002742 seconds.
2024-06-10 17:54:32,193:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:54:32,194:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:54:32,194:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 17:54:32,195:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 17:54:32,195:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 17:54:32,374:INFO:Uploading results into container
2024-06-10 17:54:32,375:INFO:Uploading model into container now
2024-06-10 17:54:32,375:INFO:_master_model_container: 3
2024-06-10 17:54:32,375:INFO:_display_container: 4
2024-06-10 17:54:32,376:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:54:32,376:INFO:create_model() successfully completed......................................
2024-06-10 17:54:32,476:INFO:SubProcess create_model() end ==================================
2024-06-10 17:54:32,476:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.3619
2024-06-10 17:54:32,477:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.4102
2024-06-10 17:54:32,477:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 17:54:32,477:INFO:choose_better completed
2024-06-10 17:54:32,484:INFO:_master_model_container: 3
2024-06-10 17:54:32,485:INFO:_display_container: 3
2024-06-10 17:54:32,485:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:54:32,485:INFO:tune_model() successfully completed......................................
2024-06-10 17:54:32,587:INFO:Initializing plot_model()
2024-06-10 17:54:32,587:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:54:32,588:INFO:Checking exceptions
2024-06-10 17:54:32,598:INFO:Preloading libraries
2024-06-10 17:54:32,605:INFO:Copying training dataset
2024-06-10 17:54:32,605:INFO:Plot type: auc
2024-06-10 17:54:32,785:INFO:Fitting Model
2024-06-10 17:54:32,786:INFO:Scoring test/hold-out set
2024-06-10 17:54:32,788:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:54:32,788:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:54:32,788:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:54:32,819:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:54:32,820:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:54:32,820:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:54:33,062:INFO:Visual Rendered Successfully
2024-06-10 17:54:33,141:INFO:plot_model() successfully completed......................................
2024-06-10 17:54:33,169:INFO:Initializing finalize_model()
2024-06-10 17:54:33,169:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 17:54:33,170:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 17:54:33,180:INFO:Initializing create_model()
2024-06-10 17:54:33,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 17:54:33,180:INFO:Checking exceptions
2024-06-10 17:54:33,181:INFO:Importing libraries
2024-06-10 17:54:33,181:INFO:Copying training dataset
2024-06-10 17:54:33,182:INFO:Defining folds
2024-06-10 17:54:33,182:INFO:Declaring metric variables
2024-06-10 17:54:33,183:INFO:Importing untrained model
2024-06-10 17:54:33,183:INFO:Declaring custom model
2024-06-10 17:54:33,183:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 17:54:33,185:INFO:Cross validation set to False
2024-06-10 17:54:33,185:INFO:Fitting Model
2024-06-10 17:54:34,480:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:54:34,480:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:54:34,480:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:54:34,540:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:54:34,540:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:54:34,540:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:54:34,540:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 17:54:34,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004248 seconds.
2024-06-10 17:54:34,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 17:54:34,545:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 17:54:34,546:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 17:54:34,548:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 17:54:34,548:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 17:54:34,847:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:54:34,848:INFO:create_model() successfully completed......................................
2024-06-10 17:54:34,936:INFO:_master_model_container: 3
2024-06-10 17:54:34,936:INFO:_display_container: 3
2024-06-10 17:54:34,975:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 17:54:34,975:INFO:finalize_model() successfully completed......................................
2024-06-10 17:54:35,100:INFO:Initializing evaluate_model()
2024-06-10 17:54:35,100:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 17:54:35,156:INFO:Initializing plot_model()
2024-06-10 17:54:35,156:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 17:54:35,156:INFO:Checking exceptions
2024-06-10 17:54:35,162:INFO:Preloading libraries
2024-06-10 17:54:35,174:INFO:Copying training dataset
2024-06-10 17:54:35,175:INFO:Plot type: pipeline
2024-06-10 17:54:35,419:INFO:Visual Rendered Successfully
2024-06-10 17:54:35,499:INFO:plot_model() successfully completed......................................
2024-06-10 17:54:35,559:INFO:Initializing plot_model()
2024-06-10 17:54:35,559:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 17:54:35,559:INFO:Checking exceptions
2024-06-10 17:54:35,569:INFO:Preloading libraries
2024-06-10 17:54:35,578:INFO:Copying training dataset
2024-06-10 17:54:35,578:INFO:Plot type: confusion_matrix
2024-06-10 17:54:35,763:INFO:Fitting Model
2024-06-10 17:54:35,763:INFO:Scoring test/hold-out set
2024-06-10 17:54:35,765:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:54:35,765:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:54:35,766:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:54:35,787:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 17:54:35,787:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 17:54:35,787:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 17:54:35,945:INFO:Visual Rendered Successfully
2024-06-10 17:54:36,026:INFO:plot_model() successfully completed......................................
2024-06-10 18:01:34,769:INFO:Initializing plot_model()
2024-06-10 18:01:34,769:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:01:34,769:INFO:Checking exceptions
2024-06-10 18:01:34,777:INFO:Preloading libraries
2024-06-10 18:01:34,784:INFO:Copying training dataset
2024-06-10 18:01:34,784:INFO:Plot type: auc
2024-06-10 18:01:34,971:INFO:Fitting Model
2024-06-10 18:01:34,972:INFO:Scoring test/hold-out set
2024-06-10 18:01:34,974:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:01:34,974:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:01:34,974:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:01:34,996:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:01:34,996:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:01:34,996:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:01:35,254:INFO:Visual Rendered Successfully
2024-06-10 18:01:35,339:INFO:plot_model() successfully completed......................................
2024-06-10 18:01:36,754:INFO:Initializing plot_model()
2024-06-10 18:01:36,754:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:01:36,754:INFO:Checking exceptions
2024-06-10 18:01:36,761:INFO:Preloading libraries
2024-06-10 18:01:36,766:INFO:Copying training dataset
2024-06-10 18:01:36,766:INFO:Plot type: confusion_matrix
2024-06-10 18:01:36,946:INFO:Fitting Model
2024-06-10 18:01:36,947:INFO:Scoring test/hold-out set
2024-06-10 18:01:36,949:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:01:36,949:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:01:36,949:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:01:36,974:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:01:36,974:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:01:36,974:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:01:37,135:INFO:Visual Rendered Successfully
2024-06-10 18:01:37,220:INFO:plot_model() successfully completed......................................
2024-06-10 18:02:30,818:INFO:Initializing plot_model()
2024-06-10 18:02:30,818:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:02:30,818:INFO:Checking exceptions
2024-06-10 18:02:30,825:INFO:Preloading libraries
2024-06-10 18:02:30,831:INFO:Copying training dataset
2024-06-10 18:02:30,831:INFO:Plot type: auc
2024-06-10 18:02:31,010:INFO:Fitting Model
2024-06-10 18:02:31,011:INFO:Scoring test/hold-out set
2024-06-10 18:02:31,013:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:02:31,013:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:02:31,013:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:02:31,037:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:02:31,037:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:02:31,037:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:02:31,267:INFO:Visual Rendered Successfully
2024-06-10 18:02:31,349:INFO:plot_model() successfully completed......................................
2024-06-10 18:03:04,424:INFO:Initializing plot_model()
2024-06-10 18:03:04,424:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000166028A2E10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:03:04,424:INFO:Checking exceptions
2024-06-10 18:03:04,430:INFO:Preloading libraries
2024-06-10 18:03:04,438:INFO:Copying training dataset
2024-06-10 18:03:04,438:INFO:Plot type: confusion_matrix
2024-06-10 18:03:04,615:INFO:Fitting Model
2024-06-10 18:03:04,615:INFO:Scoring test/hold-out set
2024-06-10 18:03:04,618:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:03:04,618:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:03:04,618:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:03:04,647:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:03:04,647:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:03:04,647:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:03:04,797:INFO:Visual Rendered Successfully
2024-06-10 18:03:04,880:INFO:plot_model() successfully completed......................................
2024-06-10 18:04:45,391:INFO:PyCaret ClassificationExperiment
2024-06-10 18:04:45,392:INFO:Logging name: clf-default-name
2024-06-10 18:04:45,392:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 18:04:45,392:INFO:version 3.3.2
2024-06-10 18:04:45,392:INFO:Initializing setup()
2024-06-10 18:04:45,392:INFO:self.USI: 781d
2024-06-10 18:04:45,392:INFO:self._variable_keys: {'USI', 'idx', '_available_plots', 'y_test', 'y_train', 'fold_groups_param', 'is_multiclass', 'memory', 'X_test', 'n_jobs_param', '_ml_usecase', 'X_train', 'logging_param', 'fix_imbalance', 'fold_generator', 'seed', 'X', 'pipeline', 'target_param', 'exp_name_log', 'log_plots_param', 'data', 'exp_id', 'fold_shuffle_param', 'html_param', 'y', 'gpu_param', 'gpu_n_jobs_param'}
2024-06-10 18:04:45,392:INFO:Checking environment
2024-06-10 18:04:45,392:INFO:python_version: 3.11.9
2024-06-10 18:04:45,392:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 18:04:45,392:INFO:machine: AMD64
2024-06-10 18:04:45,392:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 18:04:45,392:INFO:Memory: svmem(total=34056318976, available=24214499328, percent=28.9, used=9841819648, free=24214499328)
2024-06-10 18:04:45,393:INFO:Physical Core: 6
2024-06-10 18:04:45,393:INFO:Logical Core: 12
2024-06-10 18:04:45,393:INFO:Checking libraries
2024-06-10 18:04:45,393:INFO:System:
2024-06-10 18:04:45,393:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 18:04:45,393:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 18:04:45,393:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 18:04:45,393:INFO:PyCaret required dependencies:
2024-06-10 18:04:45,393:INFO:                 pip: 24.0
2024-06-10 18:04:45,393:INFO:          setuptools: 69.5.1
2024-06-10 18:04:45,393:INFO:             pycaret: 3.3.2
2024-06-10 18:04:45,393:INFO:             IPython: 8.25.0
2024-06-10 18:04:45,393:INFO:          ipywidgets: 8.1.3
2024-06-10 18:04:45,393:INFO:                tqdm: 4.66.4
2024-06-10 18:04:45,393:INFO:               numpy: 1.26.4
2024-06-10 18:04:45,394:INFO:              pandas: 2.1.4
2024-06-10 18:04:45,394:INFO:              jinja2: 3.1.4
2024-06-10 18:04:45,394:INFO:               scipy: 1.11.4
2024-06-10 18:04:45,394:INFO:              joblib: 1.3.2
2024-06-10 18:04:45,394:INFO:             sklearn: 1.4.2
2024-06-10 18:04:45,394:INFO:                pyod: 2.0.0
2024-06-10 18:04:45,394:INFO:            imblearn: 0.12.3
2024-06-10 18:04:45,394:INFO:   category_encoders: 2.6.3
2024-06-10 18:04:45,394:INFO:            lightgbm: 4.3.0
2024-06-10 18:04:45,394:INFO:               numba: 0.59.1
2024-06-10 18:04:45,394:INFO:            requests: 2.32.3
2024-06-10 18:04:45,394:INFO:          matplotlib: 3.7.5
2024-06-10 18:04:45,394:INFO:          scikitplot: 0.3.7
2024-06-10 18:04:45,394:INFO:         yellowbrick: 1.5
2024-06-10 18:04:45,394:INFO:              plotly: 5.22.0
2024-06-10 18:04:45,394:INFO:    plotly-resampler: Not installed
2024-06-10 18:04:45,395:INFO:             kaleido: 0.2.1
2024-06-10 18:04:45,395:INFO:           schemdraw: 0.15
2024-06-10 18:04:45,395:INFO:         statsmodels: 0.14.2
2024-06-10 18:04:45,395:INFO:              sktime: 0.26.0
2024-06-10 18:04:45,395:INFO:               tbats: 1.1.3
2024-06-10 18:04:45,395:INFO:            pmdarima: 2.0.4
2024-06-10 18:04:45,395:INFO:              psutil: 5.9.8
2024-06-10 18:04:45,395:INFO:          markupsafe: 2.1.5
2024-06-10 18:04:45,395:INFO:             pickle5: Not installed
2024-06-10 18:04:45,395:INFO:         cloudpickle: 3.0.0
2024-06-10 18:04:45,395:INFO:         deprecation: 2.1.0
2024-06-10 18:04:45,395:INFO:              xxhash: 3.4.1
2024-06-10 18:04:45,395:INFO:           wurlitzer: Not installed
2024-06-10 18:04:45,396:INFO:PyCaret optional dependencies:
2024-06-10 18:04:45,396:INFO:                shap: Not installed
2024-06-10 18:04:45,396:INFO:           interpret: Not installed
2024-06-10 18:04:45,396:INFO:                umap: Not installed
2024-06-10 18:04:45,396:INFO:     ydata_profiling: Not installed
2024-06-10 18:04:45,396:INFO:  explainerdashboard: Not installed
2024-06-10 18:04:45,396:INFO:             autoviz: Not installed
2024-06-10 18:04:45,396:INFO:           fairlearn: Not installed
2024-06-10 18:04:45,396:INFO:          deepchecks: Not installed
2024-06-10 18:04:45,397:INFO:             xgboost: Not installed
2024-06-10 18:04:45,397:INFO:            catboost: Not installed
2024-06-10 18:04:45,397:INFO:              kmodes: Not installed
2024-06-10 18:04:45,397:INFO:             mlxtend: Not installed
2024-06-10 18:04:45,397:INFO:       statsforecast: Not installed
2024-06-10 18:04:45,397:INFO:        tune_sklearn: Not installed
2024-06-10 18:04:45,397:INFO:                 ray: Not installed
2024-06-10 18:04:45,397:INFO:            hyperopt: Not installed
2024-06-10 18:04:45,397:INFO:              optuna: Not installed
2024-06-10 18:04:45,397:INFO:               skopt: Not installed
2024-06-10 18:04:45,397:INFO:              mlflow: Not installed
2024-06-10 18:04:45,397:INFO:              gradio: Not installed
2024-06-10 18:04:45,397:INFO:             fastapi: Not installed
2024-06-10 18:04:45,397:INFO:             uvicorn: Not installed
2024-06-10 18:04:45,398:INFO:              m2cgen: Not installed
2024-06-10 18:04:45,398:INFO:           evidently: Not installed
2024-06-10 18:04:45,398:INFO:               fugue: Not installed
2024-06-10 18:04:45,398:INFO:           streamlit: 1.35.0
2024-06-10 18:04:45,398:INFO:             prophet: Not installed
2024-06-10 18:04:45,398:INFO:None
2024-06-10 18:04:45,398:INFO:Set up data.
2024-06-10 18:04:45,436:INFO:Set up folding strategy.
2024-06-10 18:04:45,437:INFO:Set up train/test split.
2024-06-10 18:04:45,460:INFO:Set up index.
2024-06-10 18:04:45,461:INFO:Assigning column types.
2024-06-10 18:04:45,472:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 18:04:45,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:04:45,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:04:45,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:04:45,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:04:45,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,611:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 18:04:45,651:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:04:45,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,716:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:04:45,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,741:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 18:04:45,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:45,879:INFO:Preparing preprocessing pipeline...
2024-06-10 18:04:45,882:INFO:Set up date feature engineering.
2024-06-10 18:04:45,882:INFO:Set up simple imputation.
2024-06-10 18:04:45,893:INFO:Set up encoding of ordinal features.
2024-06-10 18:04:45,904:INFO:Set up encoding of categorical features.
2024-06-10 18:04:45,904:INFO:Set up removing outliers.
2024-06-10 18:04:45,904:INFO:Set up feature normalization.
2024-06-10 18:04:45,904:INFO:Set up PCA.
2024-06-10 18:04:46,340:INFO:Finished creating preprocessing pipeline.
2024-06-10 18:04:46,372:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 18:04:46,373:INFO:Creating final display dataframe.
2024-06-10 18:04:46,515:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48250, 34)
5   Transformed train set shape       (33250, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            robust
21                          PCA              True
22                   PCA method       incremental
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              781d
2024-06-10 18:04:46,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:46,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:46,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:46,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:04:46,661:INFO:setup() successfully completed in 1.36s...............
2024-06-10 18:04:46,687:INFO:Initializing create_model()
2024-06-10 18:04:46,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:04:46,688:INFO:Checking exceptions
2024-06-10 18:04:46,702:INFO:Importing libraries
2024-06-10 18:04:46,702:INFO:Copying training dataset
2024-06-10 18:04:46,720:INFO:Defining folds
2024-06-10 18:04:46,720:INFO:Declaring metric variables
2024-06-10 18:04:46,724:INFO:Importing untrained model
2024-06-10 18:04:46,728:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:04:46,735:INFO:Starting cross validation
2024-06-10 18:04:46,737:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:04:53,512:INFO:Calculating mean and std
2024-06-10 18:04:53,514:INFO:Creating metrics dataframe
2024-06-10 18:04:53,525:INFO:Finalizing model
2024-06-10 18:04:54,640:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:04:54,644:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003416 seconds.
2024-06-10 18:04:54,644:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:04:54,644:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:04:54,645:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:04:54,646:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:04:54,646:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:04:54,861:INFO:Uploading results into container
2024-06-10 18:04:54,863:INFO:Uploading model into container now
2024-06-10 18:04:54,878:INFO:_master_model_container: 1
2024-06-10 18:04:54,878:INFO:_display_container: 2
2024-06-10 18:04:54,879:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:04:54,880:INFO:create_model() successfully completed......................................
2024-06-10 18:06:09,326:INFO:Initializing tune_model()
2024-06-10 18:06:09,326:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:06:09,326:INFO:Checking exceptions
2024-06-10 18:06:09,369:INFO:Copying training dataset
2024-06-10 18:06:09,393:INFO:Checking base model
2024-06-10 18:06:09,394:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:06:09,399:INFO:Declaring metric variables
2024-06-10 18:06:09,403:INFO:Defining Hyperparameters
2024-06-10 18:06:09,496:INFO:Tuning with n_jobs=-1
2024-06-10 18:06:09,496:INFO:Initializing RandomizedSearchCV
2024-06-10 18:07:07,380:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-10 18:07:07,382:INFO:Hyperparameter search completed
2024-06-10 18:07:07,382:INFO:SubProcess create_model() called ==================================
2024-06-10 18:07:07,383:INFO:Initializing create_model()
2024-06-10 18:07:07,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016604335050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-10 18:07:07,383:INFO:Checking exceptions
2024-06-10 18:07:07,384:INFO:Importing libraries
2024-06-10 18:07:07,384:INFO:Copying training dataset
2024-06-10 18:07:07,423:INFO:Defining folds
2024-06-10 18:07:07,423:INFO:Declaring metric variables
2024-06-10 18:07:07,429:INFO:Importing untrained model
2024-06-10 18:07:07,429:INFO:Declaring custom model
2024-06-10 18:07:07,437:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:07:07,455:INFO:Starting cross validation
2024-06-10 18:07:07,460:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:07:11,136:INFO:Calculating mean and std
2024-06-10 18:07:11,139:INFO:Creating metrics dataframe
2024-06-10 18:07:11,153:INFO:Finalizing model
2024-06-10 18:07:12,252:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:07:12,252:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:07:12,252:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:07:12,294:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:07:12,294:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:07:12,294:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:07:12,294:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:07:12,298:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002540 seconds.
2024-06-10 18:07:12,298:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:07:12,299:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:07:12,301:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:07:12,303:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:07:12,303:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:07:12,437:INFO:Uploading results into container
2024-06-10 18:07:12,439:INFO:Uploading model into container now
2024-06-10 18:07:12,440:INFO:_master_model_container: 2
2024-06-10 18:07:12,440:INFO:_display_container: 3
2024-06-10 18:07:12,442:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:07:12,442:INFO:create_model() successfully completed......................................
2024-06-10 18:07:12,558:INFO:SubProcess create_model() end ==================================
2024-06-10 18:07:12,558:INFO:choose_better activated
2024-06-10 18:07:12,562:INFO:SubProcess create_model() called ==================================
2024-06-10 18:07:12,563:INFO:Initializing create_model()
2024-06-10 18:07:12,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:07:12,563:INFO:Checking exceptions
2024-06-10 18:07:12,565:INFO:Importing libraries
2024-06-10 18:07:12,565:INFO:Copying training dataset
2024-06-10 18:07:12,589:INFO:Defining folds
2024-06-10 18:07:12,589:INFO:Declaring metric variables
2024-06-10 18:07:12,589:INFO:Importing untrained model
2024-06-10 18:07:12,589:INFO:Declaring custom model
2024-06-10 18:07:12,590:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:07:12,590:INFO:Starting cross validation
2024-06-10 18:07:12,593:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:07:16,369:INFO:Calculating mean and std
2024-06-10 18:07:16,370:INFO:Creating metrics dataframe
2024-06-10 18:07:16,373:INFO:Finalizing model
2024-06-10 18:07:17,532:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:07:17,535:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002868 seconds.
2024-06-10 18:07:17,535:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:07:17,536:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:07:17,536:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:07:17,537:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:07:17,537:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:07:17,711:INFO:Uploading results into container
2024-06-10 18:07:17,712:INFO:Uploading model into container now
2024-06-10 18:07:17,712:INFO:_master_model_container: 3
2024-06-10 18:07:17,712:INFO:_display_container: 4
2024-06-10 18:07:17,713:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:07:17,713:INFO:create_model() successfully completed......................................
2024-06-10 18:07:17,825:INFO:SubProcess create_model() end ==================================
2024-06-10 18:07:17,826:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.0365
2024-06-10 18:07:17,826:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.1188
2024-06-10 18:07:17,827:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:07:17,827:INFO:choose_better completed
2024-06-10 18:07:17,836:INFO:_master_model_container: 3
2024-06-10 18:07:17,836:INFO:_display_container: 3
2024-06-10 18:07:17,836:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:07:17,837:INFO:tune_model() successfully completed......................................
2024-06-10 18:07:18,037:INFO:Initializing plot_model()
2024-06-10 18:07:18,038:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:07:18,038:INFO:Checking exceptions
2024-06-10 18:07:18,049:INFO:Preloading libraries
2024-06-10 18:07:18,055:INFO:Copying training dataset
2024-06-10 18:07:18,055:INFO:Plot type: auc
2024-06-10 18:07:18,263:INFO:Fitting Model
2024-06-10 18:07:18,264:INFO:Scoring test/hold-out set
2024-06-10 18:07:18,267:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:07:18,267:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:07:18,267:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:07:18,277:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:07:18,277:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:07:18,277:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:07:18,559:INFO:Visual Rendered Successfully
2024-06-10 18:07:18,645:INFO:plot_model() successfully completed......................................
2024-06-10 18:07:18,731:INFO:Initializing plot_model()
2024-06-10 18:07:18,731:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:07:18,732:INFO:Checking exceptions
2024-06-10 18:07:18,740:INFO:Preloading libraries
2024-06-10 18:07:18,746:INFO:Copying training dataset
2024-06-10 18:07:18,746:INFO:Plot type: confusion_matrix
2024-06-10 18:07:18,946:INFO:Fitting Model
2024-06-10 18:07:18,947:INFO:Scoring test/hold-out set
2024-06-10 18:07:18,950:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:07:18,950:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:07:18,950:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:07:18,963:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:07:18,963:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:07:18,963:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:07:19,142:INFO:Visual Rendered Successfully
2024-06-10 18:07:19,228:INFO:plot_model() successfully completed......................................
2024-06-10 18:07:19,259:INFO:Initializing finalize_model()
2024-06-10 18:07:19,260:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:07:19,261:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:07:19,282:INFO:Initializing create_model()
2024-06-10 18:07:19,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:07:19,282:INFO:Checking exceptions
2024-06-10 18:07:19,285:INFO:Importing libraries
2024-06-10 18:07:19,285:INFO:Copying training dataset
2024-06-10 18:07:19,287:INFO:Defining folds
2024-06-10 18:07:19,287:INFO:Declaring metric variables
2024-06-10 18:07:19,287:INFO:Importing untrained model
2024-06-10 18:07:19,287:INFO:Declaring custom model
2024-06-10 18:07:19,288:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:07:19,291:INFO:Cross validation set to False
2024-06-10 18:07:19,291:INFO:Fitting Model
2024-06-10 18:07:20,702:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:07:20,702:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:07:20,702:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:07:20,763:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:07:20,763:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:07:20,763:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:07:20,763:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 18:07:20,768:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003551 seconds.
2024-06-10 18:07:20,768:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:07:20,769:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:07:20,771:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 18:07:20,773:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 18:07:20,773:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 18:07:21,003:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-10 18:07:21,004:INFO:create_model() successfully completed......................................
2024-06-10 18:07:21,104:INFO:_master_model_container: 3
2024-06-10 18:07:21,104:INFO:_display_container: 3
2024-06-10 18:07:21,144:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-10 18:07:21,144:INFO:finalize_model() successfully completed......................................
2024-06-10 18:07:21,334:INFO:Initializing evaluate_model()
2024-06-10 18:07:21,335:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:07:21,388:INFO:Initializing plot_model()
2024-06-10 18:07:21,388:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:07:21,388:INFO:Checking exceptions
2024-06-10 18:07:21,395:INFO:Preloading libraries
2024-06-10 18:07:21,400:INFO:Copying training dataset
2024-06-10 18:07:21,400:INFO:Plot type: pipeline
2024-06-10 18:07:21,658:INFO:Visual Rendered Successfully
2024-06-10 18:07:21,741:INFO:plot_model() successfully completed......................................
2024-06-10 18:09:29,355:INFO:Initializing plot_model()
2024-06-10 18:09:29,355:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:09:29,356:INFO:Checking exceptions
2024-06-10 18:09:29,369:INFO:Preloading libraries
2024-06-10 18:09:29,378:INFO:Copying training dataset
2024-06-10 18:09:29,378:INFO:Plot type: auc
2024-06-10 18:09:29,584:INFO:Fitting Model
2024-06-10 18:09:29,585:INFO:Scoring test/hold-out set
2024-06-10 18:09:29,587:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:09:29,587:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:09:29,587:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:09:29,601:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:09:29,601:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:09:29,601:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:09:29,861:INFO:Visual Rendered Successfully
2024-06-10 18:09:29,947:INFO:plot_model() successfully completed......................................
2024-06-10 18:09:31,620:INFO:Initializing plot_model()
2024-06-10 18:09:31,620:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:09:31,620:INFO:Checking exceptions
2024-06-10 18:09:31,627:INFO:Preloading libraries
2024-06-10 18:09:31,632:INFO:Copying training dataset
2024-06-10 18:09:31,632:INFO:Plot type: confusion_matrix
2024-06-10 18:09:31,848:INFO:Fitting Model
2024-06-10 18:09:31,848:INFO:Scoring test/hold-out set
2024-06-10 18:09:31,851:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:09:31,851:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:09:31,851:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:09:31,869:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:09:31,869:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:09:31,869:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:09:32,021:INFO:Visual Rendered Successfully
2024-06-10 18:09:32,109:INFO:plot_model() successfully completed......................................
2024-06-10 18:10:28,671:INFO:Initializing tune_model()
2024-06-10 18:10:28,671:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:10:28,672:INFO:Checking exceptions
2024-06-10 18:10:28,696:INFO:Copying training dataset
2024-06-10 18:10:28,716:INFO:Checking base model
2024-06-10 18:10:28,716:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:10:28,720:INFO:Declaring metric variables
2024-06-10 18:10:28,724:INFO:Defining Hyperparameters
2024-06-10 18:10:28,816:INFO:Tuning with n_jobs=-1
2024-06-10 18:10:28,816:INFO:Initializing RandomizedSearchCV
2024-06-10 18:11:09,200:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-10 18:11:09,201:INFO:Hyperparameter search completed
2024-06-10 18:11:09,202:INFO:SubProcess create_model() called ==================================
2024-06-10 18:11:09,203:INFO:Initializing create_model()
2024-06-10 18:11:09,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001664AE761D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-10 18:11:09,203:INFO:Checking exceptions
2024-06-10 18:11:09,203:INFO:Importing libraries
2024-06-10 18:11:09,203:INFO:Copying training dataset
2024-06-10 18:11:09,240:INFO:Defining folds
2024-06-10 18:11:09,241:INFO:Declaring metric variables
2024-06-10 18:11:09,246:INFO:Importing untrained model
2024-06-10 18:11:09,246:INFO:Declaring custom model
2024-06-10 18:11:09,252:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:11:09,264:INFO:Starting cross validation
2024-06-10 18:11:09,269:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:11:11,872:INFO:Calculating mean and std
2024-06-10 18:11:11,874:INFO:Creating metrics dataframe
2024-06-10 18:11:11,883:INFO:Finalizing model
2024-06-10 18:11:12,900:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:12,900:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:12,900:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:12,942:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:12,942:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:12,942:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:12,942:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:11:12,946:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003042 seconds.
2024-06-10 18:11:12,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:11:12,947:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:11:12,949:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:11:12,951:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:11:12,951:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:11:13,090:INFO:Uploading results into container
2024-06-10 18:11:13,092:INFO:Uploading model into container now
2024-06-10 18:11:13,093:INFO:_master_model_container: 4
2024-06-10 18:11:13,093:INFO:_display_container: 4
2024-06-10 18:11:13,094:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:11:13,094:INFO:create_model() successfully completed......................................
2024-06-10 18:11:13,200:INFO:SubProcess create_model() end ==================================
2024-06-10 18:11:13,200:INFO:choose_better activated
2024-06-10 18:11:13,203:INFO:SubProcess create_model() called ==================================
2024-06-10 18:11:13,204:INFO:Initializing create_model()
2024-06-10 18:11:13,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:11:13,204:INFO:Checking exceptions
2024-06-10 18:11:13,206:INFO:Importing libraries
2024-06-10 18:11:13,206:INFO:Copying training dataset
2024-06-10 18:11:13,226:INFO:Defining folds
2024-06-10 18:11:13,226:INFO:Declaring metric variables
2024-06-10 18:11:13,226:INFO:Importing untrained model
2024-06-10 18:11:13,226:INFO:Declaring custom model
2024-06-10 18:11:13,227:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:11:13,227:INFO:Starting cross validation
2024-06-10 18:11:13,229:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:11:15,997:INFO:Calculating mean and std
2024-06-10 18:11:15,997:INFO:Creating metrics dataframe
2024-06-10 18:11:16,000:INFO:Finalizing model
2024-06-10 18:11:17,103:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:11:17,106:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003096 seconds.
2024-06-10 18:11:17,107:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:11:17,107:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:11:17,108:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:11:17,108:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:11:17,108:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:11:17,286:INFO:Uploading results into container
2024-06-10 18:11:17,287:INFO:Uploading model into container now
2024-06-10 18:11:17,287:INFO:_master_model_container: 5
2024-06-10 18:11:17,287:INFO:_display_container: 5
2024-06-10 18:11:17,288:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:11:17,288:INFO:create_model() successfully completed......................................
2024-06-10 18:11:17,390:INFO:SubProcess create_model() end ==================================
2024-06-10 18:11:17,390:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.0663
2024-06-10 18:11:17,391:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.1435
2024-06-10 18:11:17,391:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:11:17,391:INFO:choose_better completed
2024-06-10 18:11:17,399:INFO:_master_model_container: 5
2024-06-10 18:11:17,399:INFO:_display_container: 4
2024-06-10 18:11:17,400:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:11:17,400:INFO:tune_model() successfully completed......................................
2024-06-10 18:11:17,506:INFO:Initializing plot_model()
2024-06-10 18:11:17,506:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:11:17,506:INFO:Checking exceptions
2024-06-10 18:11:17,517:INFO:Preloading libraries
2024-06-10 18:11:17,522:INFO:Copying training dataset
2024-06-10 18:11:17,522:INFO:Plot type: auc
2024-06-10 18:11:17,707:INFO:Fitting Model
2024-06-10 18:11:17,708:INFO:Scoring test/hold-out set
2024-06-10 18:11:17,710:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:17,711:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:17,711:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:17,720:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:17,720:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:17,720:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:17,951:INFO:Visual Rendered Successfully
2024-06-10 18:11:18,034:INFO:plot_model() successfully completed......................................
2024-06-10 18:11:18,065:INFO:Initializing plot_model()
2024-06-10 18:11:18,065:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:11:18,065:INFO:Checking exceptions
2024-06-10 18:11:18,081:INFO:Preloading libraries
2024-06-10 18:11:18,093:INFO:Copying training dataset
2024-06-10 18:11:18,093:INFO:Plot type: confusion_matrix
2024-06-10 18:11:18,286:INFO:Fitting Model
2024-06-10 18:11:18,286:INFO:Scoring test/hold-out set
2024-06-10 18:11:18,288:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:18,288:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:18,288:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:18,299:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:18,299:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:18,299:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:18,447:INFO:Visual Rendered Successfully
2024-06-10 18:11:18,529:INFO:plot_model() successfully completed......................................
2024-06-10 18:11:18,545:INFO:Initializing finalize_model()
2024-06-10 18:11:18,545:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:11:18,546:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:11:18,556:INFO:Initializing create_model()
2024-06-10 18:11:18,557:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:11:18,557:INFO:Checking exceptions
2024-06-10 18:11:18,558:INFO:Importing libraries
2024-06-10 18:11:18,558:INFO:Copying training dataset
2024-06-10 18:11:18,559:INFO:Defining folds
2024-06-10 18:11:18,559:INFO:Declaring metric variables
2024-06-10 18:11:18,559:INFO:Importing untrained model
2024-06-10 18:11:18,560:INFO:Declaring custom model
2024-06-10 18:11:18,560:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:11:18,562:INFO:Cross validation set to False
2024-06-10 18:11:18,562:INFO:Fitting Model
2024-06-10 18:11:19,968:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:19,968:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:19,968:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:20,031:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:20,031:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:20,032:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:20,032:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 18:11:20,037:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003489 seconds.
2024-06-10 18:11:20,037:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:11:20,037:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:11:20,039:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 18:11:20,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 18:11:20,042:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 18:11:20,255:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-10 18:11:20,255:INFO:create_model() successfully completed......................................
2024-06-10 18:11:20,348:INFO:_master_model_container: 5
2024-06-10 18:11:20,348:INFO:_display_container: 4
2024-06-10 18:11:20,385:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-10 18:11:20,385:INFO:finalize_model() successfully completed......................................
2024-06-10 18:11:20,547:INFO:Initializing evaluate_model()
2024-06-10 18:11:20,547:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:11:20,602:INFO:Initializing plot_model()
2024-06-10 18:11:20,602:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:11:20,602:INFO:Checking exceptions
2024-06-10 18:11:20,609:INFO:Preloading libraries
2024-06-10 18:11:20,614:INFO:Copying training dataset
2024-06-10 18:11:20,614:INFO:Plot type: pipeline
2024-06-10 18:11:20,856:INFO:Visual Rendered Successfully
2024-06-10 18:11:20,939:INFO:plot_model() successfully completed......................................
2024-06-10 18:11:23,305:INFO:Initializing plot_model()
2024-06-10 18:11:23,305:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:11:23,305:INFO:Checking exceptions
2024-06-10 18:11:23,312:INFO:Preloading libraries
2024-06-10 18:11:23,317:INFO:Copying training dataset
2024-06-10 18:11:23,317:INFO:Plot type: auc
2024-06-10 18:11:23,499:INFO:Fitting Model
2024-06-10 18:11:23,500:INFO:Scoring test/hold-out set
2024-06-10 18:11:23,502:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:23,502:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:23,503:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:23,513:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:23,513:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:23,513:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:23,768:INFO:Visual Rendered Successfully
2024-06-10 18:11:23,851:INFO:plot_model() successfully completed......................................
2024-06-10 18:11:25,711:INFO:Initializing plot_model()
2024-06-10 18:11:25,711:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:11:25,711:INFO:Checking exceptions
2024-06-10 18:11:25,717:INFO:Preloading libraries
2024-06-10 18:11:25,721:INFO:Copying training dataset
2024-06-10 18:11:25,721:INFO:Plot type: confusion_matrix
2024-06-10 18:11:25,903:INFO:Fitting Model
2024-06-10 18:11:25,903:INFO:Scoring test/hold-out set
2024-06-10 18:11:25,906:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:25,906:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:25,906:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:25,917:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:11:25,917:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:11:25,918:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:11:26,067:INFO:Visual Rendered Successfully
2024-06-10 18:11:26,154:INFO:plot_model() successfully completed......................................
2024-06-10 18:11:44,757:INFO:Initializing tune_model()
2024-06-10 18:11:44,757:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Kappa, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:11:44,758:INFO:Checking exceptions
2024-06-10 18:11:44,783:INFO:Copying training dataset
2024-06-10 18:11:44,796:INFO:Checking base model
2024-06-10 18:11:44,797:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:11:44,800:INFO:Declaring metric variables
2024-06-10 18:11:44,804:INFO:Defining Hyperparameters
2024-06-10 18:11:44,912:INFO:Tuning with n_jobs=-1
2024-06-10 18:11:44,913:INFO:Initializing RandomizedSearchCV
2024-06-10 18:12:25,752:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-10 18:12:25,754:INFO:Hyperparameter search completed
2024-06-10 18:12:25,754:INFO:SubProcess create_model() called ==================================
2024-06-10 18:12:25,755:INFO:Initializing create_model()
2024-06-10 18:12:25,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001660318EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-10 18:12:25,756:INFO:Checking exceptions
2024-06-10 18:12:25,756:INFO:Importing libraries
2024-06-10 18:12:25,756:INFO:Copying training dataset
2024-06-10 18:12:25,794:INFO:Defining folds
2024-06-10 18:12:25,794:INFO:Declaring metric variables
2024-06-10 18:12:25,800:INFO:Importing untrained model
2024-06-10 18:12:25,800:INFO:Declaring custom model
2024-06-10 18:12:25,808:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:12:25,822:INFO:Starting cross validation
2024-06-10 18:12:25,829:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:12:28,635:INFO:Calculating mean and std
2024-06-10 18:12:28,637:INFO:Creating metrics dataframe
2024-06-10 18:12:28,647:INFO:Finalizing model
2024-06-10 18:12:29,747:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:12:29,747:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:12:29,747:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:12:29,788:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:12:29,788:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:12:29,788:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:12:29,788:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:12:29,793:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003282 seconds.
2024-06-10 18:12:29,793:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:12:29,793:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:12:29,795:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:12:29,797:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:12:29,797:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:12:29,937:INFO:Uploading results into container
2024-06-10 18:12:29,939:INFO:Uploading model into container now
2024-06-10 18:12:29,940:INFO:_master_model_container: 6
2024-06-10 18:12:29,940:INFO:_display_container: 5
2024-06-10 18:12:29,942:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:12:29,942:INFO:create_model() successfully completed......................................
2024-06-10 18:12:30,064:INFO:SubProcess create_model() end ==================================
2024-06-10 18:12:30,064:INFO:choose_better activated
2024-06-10 18:12:30,067:INFO:SubProcess create_model() called ==================================
2024-06-10 18:12:30,068:INFO:Initializing create_model()
2024-06-10 18:12:30,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:12:30,068:INFO:Checking exceptions
2024-06-10 18:12:30,070:INFO:Importing libraries
2024-06-10 18:12:30,070:INFO:Copying training dataset
2024-06-10 18:12:30,094:INFO:Defining folds
2024-06-10 18:12:30,094:INFO:Declaring metric variables
2024-06-10 18:12:30,095:INFO:Importing untrained model
2024-06-10 18:12:30,095:INFO:Declaring custom model
2024-06-10 18:12:30,097:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:12:30,098:INFO:Starting cross validation
2024-06-10 18:12:30,100:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:12:34,068:INFO:Calculating mean and std
2024-06-10 18:12:34,069:INFO:Creating metrics dataframe
2024-06-10 18:12:34,072:INFO:Finalizing model
2024-06-10 18:12:35,193:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:12:35,196:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002726 seconds.
2024-06-10 18:12:35,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:12:35,196:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:12:35,197:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:12:35,197:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:12:35,197:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:12:35,358:INFO:Uploading results into container
2024-06-10 18:12:35,358:INFO:Uploading model into container now
2024-06-10 18:12:35,359:INFO:_master_model_container: 7
2024-06-10 18:12:35,359:INFO:_display_container: 6
2024-06-10 18:12:35,360:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:12:35,360:INFO:create_model() successfully completed......................................
2024-06-10 18:12:35,467:INFO:SubProcess create_model() end ==================================
2024-06-10 18:12:35,467:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Kappa is 0.0524
2024-06-10 18:12:35,468:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Kappa is 0.0857
2024-06-10 18:12:35,468:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:12:35,468:INFO:choose_better completed
2024-06-10 18:12:35,477:INFO:_master_model_container: 7
2024-06-10 18:12:35,477:INFO:_display_container: 5
2024-06-10 18:12:35,478:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:12:35,478:INFO:tune_model() successfully completed......................................
2024-06-10 18:12:35,585:INFO:Initializing plot_model()
2024-06-10 18:12:35,585:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:12:35,585:INFO:Checking exceptions
2024-06-10 18:12:35,596:INFO:Preloading libraries
2024-06-10 18:12:35,601:INFO:Copying training dataset
2024-06-10 18:12:35,602:INFO:Plot type: auc
2024-06-10 18:12:35,806:INFO:Fitting Model
2024-06-10 18:12:35,807:INFO:Scoring test/hold-out set
2024-06-10 18:12:35,810:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:12:35,810:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:12:35,810:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:12:35,820:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:12:35,820:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:12:35,820:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:12:36,084:INFO:Visual Rendered Successfully
2024-06-10 18:12:36,199:INFO:plot_model() successfully completed......................................
2024-06-10 18:12:36,219:INFO:Initializing plot_model()
2024-06-10 18:12:36,219:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:12:36,219:INFO:Checking exceptions
2024-06-10 18:12:36,229:INFO:Preloading libraries
2024-06-10 18:12:36,234:INFO:Copying training dataset
2024-06-10 18:12:36,235:INFO:Plot type: confusion_matrix
2024-06-10 18:12:36,442:INFO:Fitting Model
2024-06-10 18:12:36,443:INFO:Scoring test/hold-out set
2024-06-10 18:12:36,445:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:12:36,445:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:12:36,445:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:12:36,455:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:12:36,456:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:12:36,456:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:12:36,620:INFO:Visual Rendered Successfully
2024-06-10 18:12:36,710:INFO:plot_model() successfully completed......................................
2024-06-10 18:12:36,729:INFO:Initializing finalize_model()
2024-06-10 18:12:36,729:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:12:36,730:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:12:36,740:INFO:Initializing create_model()
2024-06-10 18:12:36,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:12:36,741:INFO:Checking exceptions
2024-06-10 18:12:36,742:INFO:Importing libraries
2024-06-10 18:12:36,742:INFO:Copying training dataset
2024-06-10 18:12:36,743:INFO:Defining folds
2024-06-10 18:12:36,743:INFO:Declaring metric variables
2024-06-10 18:12:36,744:INFO:Importing untrained model
2024-06-10 18:12:36,744:INFO:Declaring custom model
2024-06-10 18:12:36,744:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:12:36,747:INFO:Cross validation set to False
2024-06-10 18:12:36,747:INFO:Fitting Model
2024-06-10 18:12:38,116:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:12:38,116:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:12:38,116:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:12:38,176:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:12:38,176:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-10 18:12:38,176:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:12:38,177:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 18:12:38,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003781 seconds.
2024-06-10 18:12:38,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:12:38,182:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:12:38,185:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 18:12:38,187:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 18:12:38,187:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 18:12:38,407:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-10 18:12:38,407:INFO:create_model() successfully completed......................................
2024-06-10 18:12:38,507:INFO:_master_model_container: 7
2024-06-10 18:12:38,507:INFO:_display_container: 5
2024-06-10 18:12:38,548:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-10 18:12:38,549:INFO:finalize_model() successfully completed......................................
2024-06-10 18:12:38,723:INFO:Initializing evaluate_model()
2024-06-10 18:12:38,723:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:12:38,777:INFO:Initializing plot_model()
2024-06-10 18:12:38,778:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:12:38,778:INFO:Checking exceptions
2024-06-10 18:12:38,786:INFO:Preloading libraries
2024-06-10 18:12:38,790:INFO:Copying training dataset
2024-06-10 18:12:38,790:INFO:Plot type: pipeline
2024-06-10 18:12:39,088:INFO:Visual Rendered Successfully
2024-06-10 18:12:39,175:INFO:plot_model() successfully completed......................................
2024-06-10 18:12:55,956:INFO:Initializing tune_model()
2024-06-10 18:12:55,956:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:12:55,957:INFO:Checking exceptions
2024-06-10 18:12:55,986:INFO:Copying training dataset
2024-06-10 18:12:56,007:INFO:Checking base model
2024-06-10 18:12:56,007:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:12:56,012:INFO:Declaring metric variables
2024-06-10 18:12:56,017:INFO:Defining Hyperparameters
2024-06-10 18:12:56,126:INFO:Tuning with n_jobs=-1
2024-06-10 18:12:56,126:INFO:Initializing RandomizedSearchCV
2024-06-10 18:13:40,956:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 18:13:40,958:INFO:Hyperparameter search completed
2024-06-10 18:13:40,958:INFO:SubProcess create_model() called ==================================
2024-06-10 18:13:40,959:INFO:Initializing create_model()
2024-06-10 18:13:40,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016602C79790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-10 18:13:40,960:INFO:Checking exceptions
2024-06-10 18:13:40,960:INFO:Importing libraries
2024-06-10 18:13:40,961:INFO:Copying training dataset
2024-06-10 18:13:41,000:INFO:Defining folds
2024-06-10 18:13:41,001:INFO:Declaring metric variables
2024-06-10 18:13:41,007:INFO:Importing untrained model
2024-06-10 18:13:41,007:INFO:Declaring custom model
2024-06-10 18:13:41,015:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:13:41,030:INFO:Starting cross validation
2024-06-10 18:13:41,035:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:13:46,277:INFO:Calculating mean and std
2024-06-10 18:13:46,279:INFO:Creating metrics dataframe
2024-06-10 18:13:46,290:INFO:Finalizing model
2024-06-10 18:13:47,381:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:13:47,382:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:13:47,382:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:13:47,422:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:13:47,423:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:13:47,423:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:13:47,423:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:13:47,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002324 seconds.
2024-06-10 18:13:47,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:13:47,426:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:13:47,427:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:13:47,429:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:13:47,429:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:13:47,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:47,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:48,023:INFO:Uploading results into container
2024-06-10 18:13:48,024:INFO:Uploading model into container now
2024-06-10 18:13:48,025:INFO:_master_model_container: 8
2024-06-10 18:13:48,025:INFO:_display_container: 6
2024-06-10 18:13:48,026:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:13:48,026:INFO:create_model() successfully completed......................................
2024-06-10 18:13:48,146:INFO:SubProcess create_model() end ==================================
2024-06-10 18:13:48,146:INFO:choose_better activated
2024-06-10 18:13:48,150:INFO:SubProcess create_model() called ==================================
2024-06-10 18:13:48,150:INFO:Initializing create_model()
2024-06-10 18:13:48,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:13:48,151:INFO:Checking exceptions
2024-06-10 18:13:48,152:INFO:Importing libraries
2024-06-10 18:13:48,152:INFO:Copying training dataset
2024-06-10 18:13:48,174:INFO:Defining folds
2024-06-10 18:13:48,174:INFO:Declaring metric variables
2024-06-10 18:13:48,174:INFO:Importing untrained model
2024-06-10 18:13:48,174:INFO:Declaring custom model
2024-06-10 18:13:48,175:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:13:48,175:INFO:Starting cross validation
2024-06-10 18:13:48,177:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:13:51,198:INFO:Calculating mean and std
2024-06-10 18:13:51,199:INFO:Creating metrics dataframe
2024-06-10 18:13:51,202:INFO:Finalizing model
2024-06-10 18:13:52,306:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:13:52,309:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002712 seconds.
2024-06-10 18:13:52,309:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:13:52,309:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:13:52,310:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:13:52,310:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:13:52,310:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:13:52,472:INFO:Uploading results into container
2024-06-10 18:13:52,473:INFO:Uploading model into container now
2024-06-10 18:13:52,473:INFO:_master_model_container: 9
2024-06-10 18:13:52,473:INFO:_display_container: 7
2024-06-10 18:13:52,474:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:13:52,474:INFO:create_model() successfully completed......................................
2024-06-10 18:13:52,585:INFO:SubProcess create_model() end ==================================
2024-06-10 18:13:52,586:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0937
2024-06-10 18:13:52,586:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0963
2024-06-10 18:13:52,587:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:13:52,587:INFO:choose_better completed
2024-06-10 18:13:52,595:INFO:_master_model_container: 9
2024-06-10 18:13:52,595:INFO:_display_container: 6
2024-06-10 18:13:52,596:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:13:52,596:INFO:tune_model() successfully completed......................................
2024-06-10 18:13:52,765:INFO:Initializing plot_model()
2024-06-10 18:13:52,765:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:13:52,765:INFO:Checking exceptions
2024-06-10 18:13:52,774:INFO:Preloading libraries
2024-06-10 18:13:52,804:INFO:Copying training dataset
2024-06-10 18:13:52,804:INFO:Plot type: auc
2024-06-10 18:13:52,999:INFO:Fitting Model
2024-06-10 18:13:53,000:INFO:Scoring test/hold-out set
2024-06-10 18:13:53,002:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:13:53,003:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:13:53,003:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:13:53,076:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:13:53,077:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:13:53,077:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:13:53,394:INFO:Visual Rendered Successfully
2024-06-10 18:13:53,477:INFO:plot_model() successfully completed......................................
2024-06-10 18:13:53,506:INFO:Initializing plot_model()
2024-06-10 18:13:53,507:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:13:53,507:INFO:Checking exceptions
2024-06-10 18:13:53,519:INFO:Preloading libraries
2024-06-10 18:13:53,570:INFO:Copying training dataset
2024-06-10 18:13:53,570:INFO:Plot type: confusion_matrix
2024-06-10 18:13:53,763:INFO:Fitting Model
2024-06-10 18:13:53,764:INFO:Scoring test/hold-out set
2024-06-10 18:13:53,766:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:13:53,766:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:13:53,766:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:13:53,820:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:13:53,820:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:13:53,820:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:13:54,032:INFO:Visual Rendered Successfully
2024-06-10 18:13:54,123:INFO:plot_model() successfully completed......................................
2024-06-10 18:13:54,146:INFO:Initializing finalize_model()
2024-06-10 18:13:54,146:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:13:54,146:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:13:54,157:INFO:Initializing create_model()
2024-06-10 18:13:54,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:13:54,157:INFO:Checking exceptions
2024-06-10 18:13:54,158:INFO:Importing libraries
2024-06-10 18:13:54,158:INFO:Copying training dataset
2024-06-10 18:13:54,159:INFO:Defining folds
2024-06-10 18:13:54,159:INFO:Declaring metric variables
2024-06-10 18:13:54,159:INFO:Importing untrained model
2024-06-10 18:13:54,159:INFO:Declaring custom model
2024-06-10 18:13:54,160:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:13:54,162:INFO:Cross validation set to False
2024-06-10 18:13:54,162:INFO:Fitting Model
2024-06-10 18:13:55,465:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:13:55,465:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:13:55,465:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:13:55,522:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:13:55,522:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:13:55,522:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:13:55,522:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 18:13:55,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002989 seconds.
2024-06-10 18:13:55,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:13:55,527:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:13:55,528:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 18:13:55,530:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 18:13:55,530:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 18:13:55,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:55,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:13:56,370:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:13:56,370:INFO:create_model() successfully completed......................................
2024-06-10 18:13:56,464:INFO:_master_model_container: 9
2024-06-10 18:13:56,464:INFO:_display_container: 6
2024-06-10 18:13:56,503:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:13:56,503:INFO:finalize_model() successfully completed......................................
2024-06-10 18:13:56,696:INFO:Initializing evaluate_model()
2024-06-10 18:13:56,696:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:13:56,745:INFO:Initializing plot_model()
2024-06-10 18:13:56,745:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:13:56,746:INFO:Checking exceptions
2024-06-10 18:13:56,752:INFO:Preloading libraries
2024-06-10 18:13:56,786:INFO:Copying training dataset
2024-06-10 18:13:56,786:INFO:Plot type: pipeline
2024-06-10 18:13:57,038:INFO:Visual Rendered Successfully
2024-06-10 18:13:57,122:INFO:plot_model() successfully completed......................................
2024-06-10 18:15:05,327:INFO:Initializing plot_model()
2024-06-10 18:15:05,327:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:15:05,327:INFO:Checking exceptions
2024-06-10 18:15:05,334:INFO:Preloading libraries
2024-06-10 18:15:05,373:INFO:Copying training dataset
2024-06-10 18:15:05,373:INFO:Plot type: auc
2024-06-10 18:15:05,552:INFO:Fitting Model
2024-06-10 18:15:05,554:INFO:Scoring test/hold-out set
2024-06-10 18:15:05,556:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:15:05,556:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:15:05,556:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:15:05,622:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:15:05,622:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:15:05,622:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:15:05,896:INFO:Visual Rendered Successfully
2024-06-10 18:15:05,984:INFO:plot_model() successfully completed......................................
2024-06-10 18:15:07,575:INFO:Initializing plot_model()
2024-06-10 18:15:07,575:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:15:07,575:INFO:Checking exceptions
2024-06-10 18:15:07,581:INFO:Preloading libraries
2024-06-10 18:15:07,611:INFO:Copying training dataset
2024-06-10 18:15:07,611:INFO:Plot type: confusion_matrix
2024-06-10 18:15:07,799:INFO:Fitting Model
2024-06-10 18:15:07,800:INFO:Scoring test/hold-out set
2024-06-10 18:15:07,803:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:15:07,803:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:15:07,804:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:15:07,892:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:15:07,893:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:15:07,893:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:15:08,082:INFO:Visual Rendered Successfully
2024-06-10 18:15:08,167:INFO:plot_model() successfully completed......................................
2024-06-10 18:20:00,187:INFO:Initializing plot_model()
2024-06-10 18:20:00,187:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:20:00,187:INFO:Checking exceptions
2024-06-10 18:20:00,194:INFO:Preloading libraries
2024-06-10 18:20:00,228:INFO:Copying training dataset
2024-06-10 18:20:00,228:INFO:Plot type: auc
2024-06-10 18:20:00,407:INFO:Fitting Model
2024-06-10 18:20:00,408:INFO:Scoring test/hold-out set
2024-06-10 18:20:00,410:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:00,410:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:00,410:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:00,483:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:00,483:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:00,483:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:00,780:INFO:Visual Rendered Successfully
2024-06-10 18:20:00,872:INFO:plot_model() successfully completed......................................
2024-06-10 18:20:20,121:INFO:Initializing plot_model()
2024-06-10 18:20:20,122:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=error, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:20:20,122:INFO:Checking exceptions
2024-06-10 18:20:20,128:INFO:Preloading libraries
2024-06-10 18:20:20,168:INFO:Copying training dataset
2024-06-10 18:20:20,168:INFO:Plot type: error
2024-06-10 18:20:20,343:INFO:Fitting Model
2024-06-10 18:20:20,344:INFO:Scoring test/hold-out set
2024-06-10 18:20:20,346:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:20,346:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:20,346:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:20,404:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:20,404:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:20,404:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:20,655:INFO:Visual Rendered Successfully
2024-06-10 18:20:20,740:INFO:plot_model() successfully completed......................................
2024-06-10 18:20:20,869:INFO:Initializing plot_model()
2024-06-10 18:20:20,869:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:20:20,869:INFO:Checking exceptions
2024-06-10 18:20:20,876:INFO:Preloading libraries
2024-06-10 18:20:20,913:INFO:Copying training dataset
2024-06-10 18:20:20,913:INFO:Plot type: confusion_matrix
2024-06-10 18:20:21,091:INFO:Fitting Model
2024-06-10 18:20:21,091:INFO:Scoring test/hold-out set
2024-06-10 18:20:21,094:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:21,094:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:21,094:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:21,146:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:21,146:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:21,146:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:21,335:INFO:Visual Rendered Successfully
2024-06-10 18:20:21,420:INFO:plot_model() successfully completed......................................
2024-06-10 18:20:23,348:INFO:Initializing plot_model()
2024-06-10 18:20:23,348:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=error, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:20:23,348:INFO:Checking exceptions
2024-06-10 18:20:23,354:INFO:Preloading libraries
2024-06-10 18:20:23,393:INFO:Copying training dataset
2024-06-10 18:20:23,393:INFO:Plot type: error
2024-06-10 18:20:23,574:INFO:Fitting Model
2024-06-10 18:20:23,575:INFO:Scoring test/hold-out set
2024-06-10 18:20:23,577:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:23,577:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:23,577:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:23,653:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:23,653:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:23,653:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:23,903:INFO:Visual Rendered Successfully
2024-06-10 18:20:24,009:INFO:plot_model() successfully completed......................................
2024-06-10 18:20:28,919:INFO:Initializing plot_model()
2024-06-10 18:20:28,919:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:20:28,919:INFO:Checking exceptions
2024-06-10 18:20:28,925:INFO:Preloading libraries
2024-06-10 18:20:28,956:INFO:Copying training dataset
2024-06-10 18:20:28,957:INFO:Plot type: confusion_matrix
2024-06-10 18:20:29,135:INFO:Fitting Model
2024-06-10 18:20:29,135:INFO:Scoring test/hold-out set
2024-06-10 18:20:29,137:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:29,137:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:29,137:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:29,202:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:20:29,202:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:20:29,202:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:20:29,394:INFO:Visual Rendered Successfully
2024-06-10 18:20:29,478:INFO:plot_model() successfully completed......................................
2024-06-10 18:21:35,017:INFO:Initializing tune_model()
2024-06-10 18:21:35,017:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:21:35,017:INFO:Checking exceptions
2024-06-10 18:21:35,042:INFO:Copying training dataset
2024-06-10 18:21:35,054:INFO:Checking base model
2024-06-10 18:21:35,055:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:21:35,059:INFO:Declaring metric variables
2024-06-10 18:21:35,062:INFO:Defining Hyperparameters
2024-06-10 18:21:35,167:INFO:Tuning with n_jobs=-1
2024-06-10 18:21:35,167:INFO:Initializing RandomizedSearchCV
2024-06-10 18:22:22,950:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2024-06-10 18:22:22,951:INFO:Hyperparameter search completed
2024-06-10 18:22:22,952:INFO:SubProcess create_model() called ==================================
2024-06-10 18:22:22,953:INFO:Initializing create_model()
2024-06-10 18:22:22,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166044C9950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2024-06-10 18:22:22,953:INFO:Checking exceptions
2024-06-10 18:22:22,953:INFO:Importing libraries
2024-06-10 18:22:22,953:INFO:Copying training dataset
2024-06-10 18:22:22,988:INFO:Defining folds
2024-06-10 18:22:22,988:INFO:Declaring metric variables
2024-06-10 18:22:22,993:INFO:Importing untrained model
2024-06-10 18:22:22,994:INFO:Declaring custom model
2024-06-10 18:22:23,001:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:22:23,012:INFO:Starting cross validation
2024-06-10 18:22:23,018:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:22:26,514:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:22:26,519:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:22:26,540:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:22:26,645:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:22:26,776:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:22:26,799:INFO:Calculating mean and std
2024-06-10 18:22:26,801:INFO:Creating metrics dataframe
2024-06-10 18:22:26,810:INFO:Finalizing model
2024-06-10 18:22:27,841:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:22:27,841:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:22:27,841:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:22:27,886:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:22:27,886:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:22:27,886:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:22:27,886:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:22:27,890:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003024 seconds.
2024-06-10 18:22:27,890:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:22:27,890:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:22:27,891:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:22:27,892:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:22:27,892:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:22:27,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:27,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:22:28,412:INFO:Uploading results into container
2024-06-10 18:22:28,414:INFO:Uploading model into container now
2024-06-10 18:22:28,415:INFO:_master_model_container: 10
2024-06-10 18:22:28,416:INFO:_display_container: 7
2024-06-10 18:22:28,417:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:22:28,417:INFO:create_model() successfully completed......................................
2024-06-10 18:22:28,523:INFO:SubProcess create_model() end ==================================
2024-06-10 18:22:28,523:INFO:choose_better activated
2024-06-10 18:22:28,526:INFO:SubProcess create_model() called ==================================
2024-06-10 18:22:28,527:INFO:Initializing create_model()
2024-06-10 18:22:28,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:22:28,527:INFO:Checking exceptions
2024-06-10 18:22:28,529:INFO:Importing libraries
2024-06-10 18:22:28,529:INFO:Copying training dataset
2024-06-10 18:22:28,548:INFO:Defining folds
2024-06-10 18:22:28,548:INFO:Declaring metric variables
2024-06-10 18:22:28,549:INFO:Importing untrained model
2024-06-10 18:22:28,549:INFO:Declaring custom model
2024-06-10 18:22:28,550:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:22:28,550:INFO:Starting cross validation
2024-06-10 18:22:28,555:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:22:31,487:INFO:Calculating mean and std
2024-06-10 18:22:31,488:INFO:Creating metrics dataframe
2024-06-10 18:22:31,490:INFO:Finalizing model
2024-06-10 18:22:32,555:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:22:32,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002871 seconds.
2024-06-10 18:22:32,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:22:32,559:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:22:32,559:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:22:32,560:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:22:32,560:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:22:32,730:INFO:Uploading results into container
2024-06-10 18:22:32,731:INFO:Uploading model into container now
2024-06-10 18:22:32,731:INFO:_master_model_container: 11
2024-06-10 18:22:32,732:INFO:_display_container: 8
2024-06-10 18:22:32,732:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:22:32,732:INFO:create_model() successfully completed......................................
2024-06-10 18:22:32,836:INFO:SubProcess create_model() end ==================================
2024-06-10 18:22:32,837:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9179
2024-06-10 18:22:32,837:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9202
2024-06-10 18:22:32,838:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:22:32,838:INFO:choose_better completed
2024-06-10 18:22:32,845:INFO:_master_model_container: 11
2024-06-10 18:22:32,845:INFO:_display_container: 7
2024-06-10 18:22:32,845:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:22:32,846:INFO:tune_model() successfully completed......................................
2024-06-10 18:22:32,983:INFO:Initializing plot_model()
2024-06-10 18:22:32,983:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:22:32,983:INFO:Checking exceptions
2024-06-10 18:22:32,993:INFO:Preloading libraries
2024-06-10 18:22:33,010:INFO:Copying training dataset
2024-06-10 18:22:33,010:INFO:Plot type: auc
2024-06-10 18:22:33,198:INFO:Fitting Model
2024-06-10 18:22:33,200:INFO:Scoring test/hold-out set
2024-06-10 18:22:33,202:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:22:33,203:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:22:33,203:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:22:33,229:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:22:33,229:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:22:33,229:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:22:33,471:INFO:Visual Rendered Successfully
2024-06-10 18:22:33,557:INFO:plot_model() successfully completed......................................
2024-06-10 18:22:33,582:INFO:Initializing plot_model()
2024-06-10 18:22:33,582:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:22:33,582:INFO:Checking exceptions
2024-06-10 18:22:33,592:INFO:Preloading libraries
2024-06-10 18:22:33,609:INFO:Copying training dataset
2024-06-10 18:22:33,609:INFO:Plot type: confusion_matrix
2024-06-10 18:22:33,785:INFO:Fitting Model
2024-06-10 18:22:33,785:INFO:Scoring test/hold-out set
2024-06-10 18:22:33,787:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:22:33,787:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:22:33,788:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:22:33,815:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:22:33,815:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:22:33,816:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:22:33,981:INFO:Visual Rendered Successfully
2024-06-10 18:22:34,067:INFO:plot_model() successfully completed......................................
2024-06-10 18:22:34,084:INFO:Initializing finalize_model()
2024-06-10 18:22:34,084:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:22:34,084:INFO:Finalizing LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:22:34,095:INFO:Initializing create_model()
2024-06-10 18:22:34,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:22:34,095:INFO:Checking exceptions
2024-06-10 18:22:34,097:INFO:Importing libraries
2024-06-10 18:22:34,097:INFO:Copying training dataset
2024-06-10 18:22:34,098:INFO:Defining folds
2024-06-10 18:22:34,098:INFO:Declaring metric variables
2024-06-10 18:22:34,098:INFO:Importing untrained model
2024-06-10 18:22:34,098:INFO:Declaring custom model
2024-06-10 18:22:34,099:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:22:34,101:INFO:Cross validation set to False
2024-06-10 18:22:34,101:INFO:Fitting Model
2024-06-10 18:22:35,425:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:22:35,425:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:22:35,425:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:22:35,486:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:22:35,486:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:22:35,486:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:22:35,487:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 18:22:35,491:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003948 seconds.
2024-06-10 18:22:35,491:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:22:35,492:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:22:35,493:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 18:22:35,494:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 18:22:35,494:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 18:22:36,282:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:22:36,282:INFO:create_model() successfully completed......................................
2024-06-10 18:22:36,379:INFO:_master_model_container: 11
2024-06-10 18:22:36,379:INFO:_display_container: 7
2024-06-10 18:22:36,414:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:22:36,414:INFO:finalize_model() successfully completed......................................
2024-06-10 18:22:36,593:INFO:Initializing evaluate_model()
2024-06-10 18:22:36,593:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:22:36,639:INFO:Initializing plot_model()
2024-06-10 18:22:36,639:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:22:36,639:INFO:Checking exceptions
2024-06-10 18:22:36,646:INFO:Preloading libraries
2024-06-10 18:22:36,668:INFO:Copying training dataset
2024-06-10 18:22:36,668:INFO:Plot type: pipeline
2024-06-10 18:22:36,898:INFO:Visual Rendered Successfully
2024-06-10 18:22:37,000:INFO:plot_model() successfully completed......................................
2024-06-10 18:23:25,565:INFO:Initializing plot_model()
2024-06-10 18:23:25,566:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:23:25,566:INFO:Checking exceptions
2024-06-10 18:23:25,573:INFO:Preloading libraries
2024-06-10 18:23:25,599:INFO:Copying training dataset
2024-06-10 18:23:25,599:INFO:Plot type: auc
2024-06-10 18:23:25,780:INFO:Fitting Model
2024-06-10 18:23:25,781:INFO:Scoring test/hold-out set
2024-06-10 18:23:25,783:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:23:25,783:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:23:25,783:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:23:25,805:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:23:25,805:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:23:25,806:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:23:26,043:INFO:Visual Rendered Successfully
2024-06-10 18:23:26,131:INFO:plot_model() successfully completed......................................
2024-06-10 18:23:27,821:INFO:Initializing plot_model()
2024-06-10 18:23:27,821:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:23:27,821:INFO:Checking exceptions
2024-06-10 18:23:27,827:INFO:Preloading libraries
2024-06-10 18:23:27,846:INFO:Copying training dataset
2024-06-10 18:23:27,846:INFO:Plot type: confusion_matrix
2024-06-10 18:23:28,023:INFO:Fitting Model
2024-06-10 18:23:28,023:INFO:Scoring test/hold-out set
2024-06-10 18:23:28,026:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:23:28,026:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:23:28,026:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:23:28,053:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:23:28,053:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-10 18:23:28,053:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-10 18:23:28,205:INFO:Visual Rendered Successfully
2024-06-10 18:23:28,294:INFO:plot_model() successfully completed......................................
2024-06-10 18:23:56,014:INFO:Initializing tune_model()
2024-06-10 18:23:56,014:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:23:56,014:INFO:Checking exceptions
2024-06-10 18:23:56,040:INFO:Copying training dataset
2024-06-10 18:23:56,053:INFO:Checking base model
2024-06-10 18:23:56,053:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:23:56,057:INFO:Declaring metric variables
2024-06-10 18:23:56,061:INFO:Defining Hyperparameters
2024-06-10 18:23:56,153:INFO:Tuning with n_jobs=-1
2024-06-10 18:23:56,153:INFO:Initializing RandomizedSearchCV
2024-06-10 18:24:37,472:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 10, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 18:24:37,473:INFO:Hyperparameter search completed
2024-06-10 18:24:37,473:INFO:SubProcess create_model() called ==================================
2024-06-10 18:24:37,474:INFO:Initializing create_model()
2024-06-10 18:24:37,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166042D5C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 10, 'num_leaves': 10, 'n_estimators': 90, 'min_split_gain': 0.5, 'min_child_samples': 1, 'learning_rate': 1e-07, 'feature_fraction': 1.0, 'bagging_freq': 1, 'bagging_fraction': 0.6})
2024-06-10 18:24:37,475:INFO:Checking exceptions
2024-06-10 18:24:37,475:INFO:Importing libraries
2024-06-10 18:24:37,475:INFO:Copying training dataset
2024-06-10 18:24:37,513:INFO:Defining folds
2024-06-10 18:24:37,513:INFO:Declaring metric variables
2024-06-10 18:24:37,518:INFO:Importing untrained model
2024-06-10 18:24:37,519:INFO:Declaring custom model
2024-06-10 18:24:37,526:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:24:37,540:INFO:Starting cross validation
2024-06-10 18:24:37,547:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:24:39,834:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:24:39,870:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:24:39,903:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:24:39,920:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:24:39,921:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:24:39,948:INFO:Calculating mean and std
2024-06-10 18:24:39,950:INFO:Creating metrics dataframe
2024-06-10 18:24:39,958:INFO:Finalizing model
2024-06-10 18:24:41,018:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:41,018:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:41,018:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:41,059:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:41,060:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:41,060:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:41,060:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:24:41,063:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002863 seconds.
2024-06-10 18:24:41,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:24:41,064:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:24:41,064:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:24:41,064:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:24:41,065:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:24:41,173:INFO:Uploading results into container
2024-06-10 18:24:41,174:INFO:Uploading model into container now
2024-06-10 18:24:41,175:INFO:_master_model_container: 12
2024-06-10 18:24:41,176:INFO:_display_container: 8
2024-06-10 18:24:41,178:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:24:41,178:INFO:create_model() successfully completed......................................
2024-06-10 18:24:41,286:INFO:SubProcess create_model() end ==================================
2024-06-10 18:24:41,286:INFO:choose_better activated
2024-06-10 18:24:41,290:INFO:SubProcess create_model() called ==================================
2024-06-10 18:24:41,291:INFO:Initializing create_model()
2024-06-10 18:24:41,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:24:41,291:INFO:Checking exceptions
2024-06-10 18:24:41,292:INFO:Importing libraries
2024-06-10 18:24:41,292:INFO:Copying training dataset
2024-06-10 18:24:41,310:INFO:Defining folds
2024-06-10 18:24:41,310:INFO:Declaring metric variables
2024-06-10 18:24:41,311:INFO:Importing untrained model
2024-06-10 18:24:41,311:INFO:Declaring custom model
2024-06-10 18:24:41,311:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:24:41,311:INFO:Starting cross validation
2024-06-10 18:24:41,313:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:24:44,119:INFO:Calculating mean and std
2024-06-10 18:24:44,120:INFO:Creating metrics dataframe
2024-06-10 18:24:44,123:INFO:Finalizing model
2024-06-10 18:24:45,172:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:24:45,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002960 seconds.
2024-06-10 18:24:45,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:24:45,175:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:24:45,176:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:24:45,176:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:24:45,177:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:24:45,346:INFO:Uploading results into container
2024-06-10 18:24:45,347:INFO:Uploading model into container now
2024-06-10 18:24:45,347:INFO:_master_model_container: 13
2024-06-10 18:24:45,347:INFO:_display_container: 9
2024-06-10 18:24:45,348:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:24:45,348:INFO:create_model() successfully completed......................................
2024-06-10 18:24:45,451:INFO:SubProcess create_model() end ==================================
2024-06-10 18:24:45,451:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.7661
2024-06-10 18:24:45,452:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.781
2024-06-10 18:24:45,452:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:24:45,452:INFO:choose_better completed
2024-06-10 18:24:45,460:INFO:_master_model_container: 13
2024-06-10 18:24:45,460:INFO:_display_container: 8
2024-06-10 18:24:45,460:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:24:45,460:INFO:tune_model() successfully completed......................................
2024-06-10 18:24:45,603:INFO:Initializing plot_model()
2024-06-10 18:24:45,603:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:24:45,603:INFO:Checking exceptions
2024-06-10 18:24:45,614:INFO:Preloading libraries
2024-06-10 18:24:45,618:INFO:Copying training dataset
2024-06-10 18:24:45,618:INFO:Plot type: auc
2024-06-10 18:24:45,798:INFO:Fitting Model
2024-06-10 18:24:45,799:INFO:Scoring test/hold-out set
2024-06-10 18:24:45,801:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:45,801:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:45,801:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:45,813:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:45,813:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:45,813:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:46,047:INFO:Visual Rendered Successfully
2024-06-10 18:24:46,132:INFO:plot_model() successfully completed......................................
2024-06-10 18:24:46,167:INFO:Initializing plot_model()
2024-06-10 18:24:46,168:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:24:46,168:INFO:Checking exceptions
2024-06-10 18:24:46,181:INFO:Preloading libraries
2024-06-10 18:24:46,185:INFO:Copying training dataset
2024-06-10 18:24:46,185:INFO:Plot type: confusion_matrix
2024-06-10 18:24:46,377:INFO:Fitting Model
2024-06-10 18:24:46,378:INFO:Scoring test/hold-out set
2024-06-10 18:24:46,380:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:46,380:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:46,380:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:46,391:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:46,391:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:46,391:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:46,539:INFO:Visual Rendered Successfully
2024-06-10 18:24:46,623:INFO:plot_model() successfully completed......................................
2024-06-10 18:24:46,638:INFO:Initializing finalize_model()
2024-06-10 18:24:46,638:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:24:46,639:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:24:46,654:INFO:Initializing create_model()
2024-06-10 18:24:46,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:24:46,654:INFO:Checking exceptions
2024-06-10 18:24:46,657:INFO:Importing libraries
2024-06-10 18:24:46,657:INFO:Copying training dataset
2024-06-10 18:24:46,658:INFO:Defining folds
2024-06-10 18:24:46,658:INFO:Declaring metric variables
2024-06-10 18:24:46,659:INFO:Importing untrained model
2024-06-10 18:24:46,659:INFO:Declaring custom model
2024-06-10 18:24:46,660:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:24:46,665:INFO:Cross validation set to False
2024-06-10 18:24:46,665:INFO:Fitting Model
2024-06-10 18:24:48,000:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:48,000:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:48,000:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:48,064:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:48,064:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:48,064:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:48,064:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 18:24:48,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005819 seconds.
2024-06-10 18:24:48,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:24:48,071:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:24:48,071:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 18:24:48,072:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 18:24:48,072:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 18:24:48,268:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:24:48,268:INFO:create_model() successfully completed......................................
2024-06-10 18:24:48,364:INFO:_master_model_container: 13
2024-06-10 18:24:48,364:INFO:_display_container: 8
2024-06-10 18:24:48,399:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:24:48,399:INFO:finalize_model() successfully completed......................................
2024-06-10 18:24:48,579:INFO:Initializing evaluate_model()
2024-06-10 18:24:48,579:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:24:48,638:INFO:Initializing plot_model()
2024-06-10 18:24:48,638:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:24:48,638:INFO:Checking exceptions
2024-06-10 18:24:48,645:INFO:Preloading libraries
2024-06-10 18:24:48,649:INFO:Copying training dataset
2024-06-10 18:24:48,650:INFO:Plot type: pipeline
2024-06-10 18:24:48,905:INFO:Visual Rendered Successfully
2024-06-10 18:24:48,993:INFO:plot_model() successfully completed......................................
2024-06-10 18:24:50,299:INFO:Initializing plot_model()
2024-06-10 18:24:50,299:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:24:50,299:INFO:Checking exceptions
2024-06-10 18:24:50,306:INFO:Preloading libraries
2024-06-10 18:24:50,309:INFO:Copying training dataset
2024-06-10 18:24:50,310:INFO:Plot type: auc
2024-06-10 18:24:50,496:INFO:Fitting Model
2024-06-10 18:24:50,497:INFO:Scoring test/hold-out set
2024-06-10 18:24:50,499:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:50,499:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:50,499:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:50,516:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:50,516:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:50,516:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:50,756:INFO:Visual Rendered Successfully
2024-06-10 18:24:50,850:INFO:plot_model() successfully completed......................................
2024-06-10 18:24:52,912:INFO:Initializing plot_model()
2024-06-10 18:24:52,912:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:24:52,912:INFO:Checking exceptions
2024-06-10 18:24:52,918:INFO:Preloading libraries
2024-06-10 18:24:52,921:INFO:Copying training dataset
2024-06-10 18:24:52,921:INFO:Plot type: confusion_matrix
2024-06-10 18:24:53,104:INFO:Fitting Model
2024-06-10 18:24:53,104:INFO:Scoring test/hold-out set
2024-06-10 18:24:53,106:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:53,106:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:53,106:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:53,121:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:24:53,121:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:24:53,121:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-10 18:24:53,281:INFO:Visual Rendered Successfully
2024-06-10 18:24:53,368:INFO:plot_model() successfully completed......................................
2024-06-10 18:25:13,646:INFO:Initializing tune_model()
2024-06-10 18:25:13,646:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:25:13,647:INFO:Checking exceptions
2024-06-10 18:25:47,958:INFO:Initializing tune_model()
2024-06-10 18:25:47,958:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:25:47,958:INFO:Checking exceptions
2024-06-10 18:25:47,985:INFO:Copying training dataset
2024-06-10 18:25:47,997:INFO:Checking base model
2024-06-10 18:25:47,998:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:25:48,001:INFO:Declaring metric variables
2024-06-10 18:25:48,004:INFO:Defining Hyperparameters
2024-06-10 18:25:48,158:INFO:Tuning with n_jobs=-1
2024-06-10 18:25:48,158:INFO:Initializing RandomizedSearchCV
2024-06-10 18:26:00,841:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:01,090:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:01,215:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:01,409:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:03,753:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:03,878:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:06,269:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:07,544:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:07,732:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:08,980:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:09,035:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:10,613:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:11,441:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:11,944:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:16,161:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:16,444:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:17,405:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:17,471:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:19,056:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:19,699:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:38,619:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:38,928:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:39,485:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:39,720:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:40,030:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:40,720:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:40,971:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:41,127:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:41,851:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:42,180:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:26:42,191:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 18:26:42,192:INFO:Hyperparameter search completed
2024-06-10 18:26:42,193:INFO:SubProcess create_model() called ==================================
2024-06-10 18:26:42,194:INFO:Initializing create_model()
2024-06-10 18:26:42,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166043F25D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2024-06-10 18:26:42,195:INFO:Checking exceptions
2024-06-10 18:26:42,196:INFO:Importing libraries
2024-06-10 18:26:42,196:INFO:Copying training dataset
2024-06-10 18:26:42,239:INFO:Defining folds
2024-06-10 18:26:42,239:INFO:Declaring metric variables
2024-06-10 18:26:42,246:INFO:Importing untrained model
2024-06-10 18:26:42,246:INFO:Declaring custom model
2024-06-10 18:26:42,254:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:26:42,268:INFO:Starting cross validation
2024-06-10 18:26:42,272:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:26:45,883:INFO:Calculating mean and std
2024-06-10 18:26:45,884:INFO:Creating metrics dataframe
2024-06-10 18:26:45,895:INFO:Finalizing model
2024-06-10 18:26:47,022:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:26:47,022:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:26:47,022:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:26:47,063:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:26:47,063:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:26:47,063:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:26:47,064:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:26:47,067:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002740 seconds.
2024-06-10 18:26:47,067:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:26:47,067:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:26:47,067:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:26:47,069:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:26:47,069:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:26:47,271:INFO:Uploading results into container
2024-06-10 18:26:47,272:INFO:Uploading model into container now
2024-06-10 18:26:47,273:INFO:_master_model_container: 14
2024-06-10 18:26:47,274:INFO:_display_container: 9
2024-06-10 18:26:47,275:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:26:47,275:INFO:create_model() successfully completed......................................
2024-06-10 18:26:47,413:INFO:SubProcess create_model() end ==================================
2024-06-10 18:26:47,413:INFO:choose_better activated
2024-06-10 18:26:47,417:INFO:SubProcess create_model() called ==================================
2024-06-10 18:26:47,417:INFO:Initializing create_model()
2024-06-10 18:26:47,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:26:47,418:INFO:Checking exceptions
2024-06-10 18:26:47,419:INFO:Importing libraries
2024-06-10 18:26:47,419:INFO:Copying training dataset
2024-06-10 18:26:47,441:INFO:Defining folds
2024-06-10 18:26:47,441:INFO:Declaring metric variables
2024-06-10 18:26:47,441:INFO:Importing untrained model
2024-06-10 18:26:47,442:INFO:Declaring custom model
2024-06-10 18:26:47,442:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:26:47,442:INFO:Starting cross validation
2024-06-10 18:26:47,445:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:26:50,769:INFO:Calculating mean and std
2024-06-10 18:26:50,770:INFO:Creating metrics dataframe
2024-06-10 18:26:50,773:INFO:Finalizing model
2024-06-10 18:26:51,874:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:26:51,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003933 seconds.
2024-06-10 18:26:51,878:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:26:51,879:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:26:51,879:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:26:51,880:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:26:51,880:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:26:52,164:INFO:Uploading results into container
2024-06-10 18:26:52,165:INFO:Uploading model into container now
2024-06-10 18:26:52,166:INFO:_master_model_container: 15
2024-06-10 18:26:52,166:INFO:_display_container: 10
2024-06-10 18:26:52,167:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:26:52,167:INFO:create_model() successfully completed......................................
2024-06-10 18:26:52,302:INFO:SubProcess create_model() end ==================================
2024-06-10 18:26:52,302:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.3619
2024-06-10 18:26:52,303:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.4102
2024-06-10 18:26:52,303:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:26:52,303:INFO:choose_better completed
2024-06-10 18:26:52,312:INFO:_master_model_container: 15
2024-06-10 18:26:52,312:INFO:_display_container: 9
2024-06-10 18:26:52,312:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:26:52,313:INFO:tune_model() successfully completed......................................
2024-06-10 18:26:52,470:INFO:Initializing plot_model()
2024-06-10 18:26:52,471:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:26:52,471:INFO:Checking exceptions
2024-06-10 18:26:52,480:INFO:Preloading libraries
2024-06-10 18:26:52,486:INFO:Copying training dataset
2024-06-10 18:26:52,487:INFO:Plot type: auc
2024-06-10 18:26:52,685:INFO:Fitting Model
2024-06-10 18:26:52,686:INFO:Scoring test/hold-out set
2024-06-10 18:26:52,688:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:26:52,688:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:26:52,688:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:26:52,726:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:26:52,726:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:26:52,726:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:26:53,017:INFO:Visual Rendered Successfully
2024-06-10 18:26:53,123:INFO:plot_model() successfully completed......................................
2024-06-10 18:26:53,140:INFO:Initializing plot_model()
2024-06-10 18:26:53,141:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:26:53,141:INFO:Checking exceptions
2024-06-10 18:26:53,152:INFO:Preloading libraries
2024-06-10 18:26:53,159:INFO:Copying training dataset
2024-06-10 18:26:53,159:INFO:Plot type: confusion_matrix
2024-06-10 18:26:53,352:INFO:Fitting Model
2024-06-10 18:26:53,353:INFO:Scoring test/hold-out set
2024-06-10 18:26:53,355:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:26:53,355:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:26:53,355:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:26:53,394:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:26:53,394:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:26:53,394:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:26:53,585:INFO:Visual Rendered Successfully
2024-06-10 18:26:53,691:INFO:plot_model() successfully completed......................................
2024-06-10 18:26:53,707:INFO:Initializing finalize_model()
2024-06-10 18:26:53,708:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:26:53,708:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:26:53,718:INFO:Initializing create_model()
2024-06-10 18:26:53,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:26:53,718:INFO:Checking exceptions
2024-06-10 18:26:53,719:INFO:Importing libraries
2024-06-10 18:26:53,719:INFO:Copying training dataset
2024-06-10 18:26:53,720:INFO:Defining folds
2024-06-10 18:26:53,721:INFO:Declaring metric variables
2024-06-10 18:26:53,721:INFO:Importing untrained model
2024-06-10 18:26:53,721:INFO:Declaring custom model
2024-06-10 18:26:53,721:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:26:53,724:INFO:Cross validation set to False
2024-06-10 18:26:53,724:INFO:Fitting Model
2024-06-10 18:26:55,138:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:26:55,138:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:26:55,138:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:26:55,196:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:26:55,197:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:26:55,197:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:26:55,197:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 18:26:55,203:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005120 seconds.
2024-06-10 18:26:55,203:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:26:55,203:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:26:55,203:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 18:26:55,205:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 18:26:55,205:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 18:26:55,629:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:26:55,629:INFO:create_model() successfully completed......................................
2024-06-10 18:26:55,750:INFO:_master_model_container: 15
2024-06-10 18:26:55,750:INFO:_display_container: 9
2024-06-10 18:26:55,787:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:26:55,787:INFO:finalize_model() successfully completed......................................
2024-06-10 18:26:56,035:INFO:Initializing evaluate_model()
2024-06-10 18:26:56,035:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:26:56,085:INFO:Initializing plot_model()
2024-06-10 18:26:56,085:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:26:56,085:INFO:Checking exceptions
2024-06-10 18:26:56,092:INFO:Preloading libraries
2024-06-10 18:26:56,099:INFO:Copying training dataset
2024-06-10 18:26:56,099:INFO:Plot type: pipeline
2024-06-10 18:26:56,373:INFO:Visual Rendered Successfully
2024-06-10 18:26:56,488:INFO:plot_model() successfully completed......................................
2024-06-10 18:27:41,840:INFO:Initializing plot_model()
2024-06-10 18:27:41,840:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:27:41,840:INFO:Checking exceptions
2024-06-10 18:27:41,849:INFO:Preloading libraries
2024-06-10 18:27:41,855:INFO:Copying training dataset
2024-06-10 18:27:41,855:INFO:Plot type: auc
2024-06-10 18:27:42,037:INFO:Fitting Model
2024-06-10 18:27:42,038:INFO:Scoring test/hold-out set
2024-06-10 18:27:42,040:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:27:42,040:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:27:42,040:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:27:42,062:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:27:42,063:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:27:42,063:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:27:42,323:INFO:Visual Rendered Successfully
2024-06-10 18:27:42,448:INFO:plot_model() successfully completed......................................
2024-06-10 18:27:44,346:INFO:Initializing plot_model()
2024-06-10 18:27:44,346:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016603175950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:27:44,346:INFO:Checking exceptions
2024-06-10 18:27:44,353:INFO:Preloading libraries
2024-06-10 18:27:44,359:INFO:Copying training dataset
2024-06-10 18:27:44,359:INFO:Plot type: confusion_matrix
2024-06-10 18:27:44,532:INFO:Fitting Model
2024-06-10 18:27:44,533:INFO:Scoring test/hold-out set
2024-06-10 18:27:44,535:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:27:44,535:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:27:44,535:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:27:44,564:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:27:44,564:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:27:44,564:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:27:44,726:INFO:Visual Rendered Successfully
2024-06-10 18:27:44,827:INFO:plot_model() successfully completed......................................
2024-06-10 18:28:41,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:28:41,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:28:41,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:28:41,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:28:42,563:INFO:PyCaret ClassificationExperiment
2024-06-10 18:28:42,563:INFO:Logging name: clf-default-name
2024-06-10 18:28:42,563:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 18:28:42,563:INFO:version 3.3.2
2024-06-10 18:28:42,563:INFO:Initializing setup()
2024-06-10 18:28:42,563:INFO:self.USI: b25e
2024-06-10 18:28:42,563:INFO:self._variable_keys: {'X_train', 'data', '_available_plots', 'fold_groups_param', 'fix_imbalance', 'gpu_param', 'y', 'pipeline', 'fold_generator', 'exp_id', 'y_train', 'fold_shuffle_param', '_ml_usecase', 'exp_name_log', 'X_test', 'idx', 'logging_param', 'memory', 'log_plots_param', 'is_multiclass', 'gpu_n_jobs_param', 'target_param', 'y_test', 'n_jobs_param', 'seed', 'html_param', 'X', 'USI'}
2024-06-10 18:28:42,563:INFO:Checking environment
2024-06-10 18:28:42,563:INFO:python_version: 3.11.9
2024-06-10 18:28:42,563:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 18:28:42,564:INFO:machine: AMD64
2024-06-10 18:28:42,564:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 18:28:42,564:INFO:Memory: svmem(total=34056318976, available=23962587136, percent=29.6, used=10093731840, free=23962587136)
2024-06-10 18:28:42,564:INFO:Physical Core: 6
2024-06-10 18:28:42,564:INFO:Logical Core: 12
2024-06-10 18:28:42,564:INFO:Checking libraries
2024-06-10 18:28:42,564:INFO:System:
2024-06-10 18:28:42,564:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 18:28:42,564:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 18:28:42,564:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 18:28:42,564:INFO:PyCaret required dependencies:
2024-06-10 18:28:42,589:INFO:                 pip: 24.0
2024-06-10 18:28:42,589:INFO:          setuptools: 69.5.1
2024-06-10 18:28:42,589:INFO:             pycaret: 3.3.2
2024-06-10 18:28:42,589:INFO:             IPython: 8.25.0
2024-06-10 18:28:42,589:INFO:          ipywidgets: 8.1.3
2024-06-10 18:28:42,589:INFO:                tqdm: 4.66.4
2024-06-10 18:28:42,589:INFO:               numpy: 1.26.4
2024-06-10 18:28:42,589:INFO:              pandas: 2.1.4
2024-06-10 18:28:42,590:INFO:              jinja2: 3.1.4
2024-06-10 18:28:42,590:INFO:               scipy: 1.11.4
2024-06-10 18:28:42,590:INFO:              joblib: 1.3.2
2024-06-10 18:28:42,590:INFO:             sklearn: 1.4.2
2024-06-10 18:28:42,590:INFO:                pyod: 2.0.0
2024-06-10 18:28:42,590:INFO:            imblearn: 0.12.3
2024-06-10 18:28:42,590:INFO:   category_encoders: 2.6.3
2024-06-10 18:28:42,590:INFO:            lightgbm: 4.3.0
2024-06-10 18:28:42,590:INFO:               numba: 0.59.1
2024-06-10 18:28:42,590:INFO:            requests: 2.32.3
2024-06-10 18:28:42,590:INFO:          matplotlib: 3.7.5
2024-06-10 18:28:42,590:INFO:          scikitplot: 0.3.7
2024-06-10 18:28:42,590:INFO:         yellowbrick: 1.5
2024-06-10 18:28:42,590:INFO:              plotly: 5.22.0
2024-06-10 18:28:42,590:INFO:    plotly-resampler: Not installed
2024-06-10 18:28:42,590:INFO:             kaleido: 0.2.1
2024-06-10 18:28:42,590:INFO:           schemdraw: 0.15
2024-06-10 18:28:42,590:INFO:         statsmodels: 0.14.2
2024-06-10 18:28:42,590:INFO:              sktime: 0.26.0
2024-06-10 18:28:42,590:INFO:               tbats: 1.1.3
2024-06-10 18:28:42,590:INFO:            pmdarima: 2.0.4
2024-06-10 18:28:42,590:INFO:              psutil: 5.9.8
2024-06-10 18:28:42,590:INFO:          markupsafe: 2.1.5
2024-06-10 18:28:42,591:INFO:             pickle5: Not installed
2024-06-10 18:28:42,591:INFO:         cloudpickle: 3.0.0
2024-06-10 18:28:42,591:INFO:         deprecation: 2.1.0
2024-06-10 18:28:42,591:INFO:              xxhash: 3.4.1
2024-06-10 18:28:42,591:INFO:           wurlitzer: Not installed
2024-06-10 18:28:42,591:INFO:PyCaret optional dependencies:
2024-06-10 18:28:42,601:INFO:                shap: Not installed
2024-06-10 18:28:42,601:INFO:           interpret: Not installed
2024-06-10 18:28:42,601:INFO:                umap: Not installed
2024-06-10 18:28:42,601:INFO:     ydata_profiling: Not installed
2024-06-10 18:28:42,601:INFO:  explainerdashboard: Not installed
2024-06-10 18:28:42,601:INFO:             autoviz: Not installed
2024-06-10 18:28:42,601:INFO:           fairlearn: Not installed
2024-06-10 18:28:42,601:INFO:          deepchecks: Not installed
2024-06-10 18:28:42,601:INFO:             xgboost: Not installed
2024-06-10 18:28:42,601:INFO:            catboost: Not installed
2024-06-10 18:28:42,601:INFO:              kmodes: Not installed
2024-06-10 18:28:42,601:INFO:             mlxtend: Not installed
2024-06-10 18:28:42,601:INFO:       statsforecast: Not installed
2024-06-10 18:28:42,601:INFO:        tune_sklearn: Not installed
2024-06-10 18:28:42,601:INFO:                 ray: Not installed
2024-06-10 18:28:42,602:INFO:            hyperopt: Not installed
2024-06-10 18:28:42,602:INFO:              optuna: Not installed
2024-06-10 18:28:42,602:INFO:               skopt: Not installed
2024-06-10 18:28:42,602:INFO:              mlflow: Not installed
2024-06-10 18:28:42,602:INFO:              gradio: Not installed
2024-06-10 18:28:42,602:INFO:             fastapi: Not installed
2024-06-10 18:28:42,602:INFO:             uvicorn: Not installed
2024-06-10 18:28:42,602:INFO:              m2cgen: Not installed
2024-06-10 18:28:42,602:INFO:           evidently: Not installed
2024-06-10 18:28:42,602:INFO:               fugue: Not installed
2024-06-10 18:28:42,602:INFO:           streamlit: 1.35.0
2024-06-10 18:28:42,602:INFO:             prophet: Not installed
2024-06-10 18:28:42,602:INFO:None
2024-06-10 18:28:42,602:INFO:Set up data.
2024-06-10 18:28:42,639:INFO:Set up folding strategy.
2024-06-10 18:28:42,639:INFO:Set up train/test split.
2024-06-10 18:28:42,663:INFO:Set up index.
2024-06-10 18:28:42,665:INFO:Assigning column types.
2024-06-10 18:28:42,675:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 18:28:42,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:28:42,722:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:28:42,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:42,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:42,798:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:28:42,799:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:28:42,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:42,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:42,827:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 18:28:42,870:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:28:42,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:42,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:42,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:28:42,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:42,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:42,967:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 18:28:43,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:43,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:43,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:43,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:43,118:INFO:Preparing preprocessing pipeline...
2024-06-10 18:28:43,120:INFO:Set up date feature engineering.
2024-06-10 18:28:43,121:INFO:Set up simple imputation.
2024-06-10 18:28:43,131:INFO:Set up encoding of ordinal features.
2024-06-10 18:28:43,142:INFO:Set up encoding of categorical features.
2024-06-10 18:28:43,142:INFO:Set up removing outliers.
2024-06-10 18:28:43,142:INFO:Set up feature normalization.
2024-06-10 18:28:43,142:INFO:Set up PCA.
2024-06-10 18:28:43,572:INFO:Finished creating preprocessing pipeline.
2024-06-10 18:28:43,606:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-10 18:28:43,606:INFO:Creating final display dataframe.
2024-06-10 18:28:44,321:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48250, 34)
5   Transformed train set shape       (33250, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            robust
21                          PCA              True
22                   PCA method            linear
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              b25e
2024-06-10 18:28:44,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:44,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:44,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:44,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:28:44,477:INFO:setup() successfully completed in 2.02s...............
2024-06-10 18:28:44,493:INFO:Initializing create_model()
2024-06-10 18:28:44,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:28:44,494:INFO:Checking exceptions
2024-06-10 18:28:44,509:INFO:Importing libraries
2024-06-10 18:28:44,509:INFO:Copying training dataset
2024-06-10 18:28:44,527:INFO:Defining folds
2024-06-10 18:28:44,528:INFO:Declaring metric variables
2024-06-10 18:28:44,531:INFO:Importing untrained model
2024-06-10 18:28:44,534:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:28:44,540:INFO:Starting cross validation
2024-06-10 18:28:44,543:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:28:50,717:INFO:Calculating mean and std
2024-06-10 18:28:50,719:INFO:Creating metrics dataframe
2024-06-10 18:28:50,730:INFO:Finalizing model
2024-06-10 18:28:51,907:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:28:51,910:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002828 seconds.
2024-06-10 18:28:51,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:28:51,910:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:28:51,911:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:28:51,911:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:28:51,912:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:28:52,127:INFO:Uploading results into container
2024-06-10 18:28:52,129:INFO:Uploading model into container now
2024-06-10 18:28:52,141:INFO:_master_model_container: 1
2024-06-10 18:28:52,141:INFO:_display_container: 2
2024-06-10 18:28:52,142:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:28:52,142:INFO:create_model() successfully completed......................................
2024-06-10 18:28:52,246:INFO:Initializing tune_model()
2024-06-10 18:28:52,246:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:28:52,247:INFO:Checking exceptions
2024-06-10 18:28:52,272:INFO:Copying training dataset
2024-06-10 18:28:52,286:INFO:Checking base model
2024-06-10 18:28:52,287:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:28:52,290:INFO:Declaring metric variables
2024-06-10 18:28:52,294:INFO:Defining Hyperparameters
2024-06-10 18:28:52,367:INFO:Tuning with n_jobs=-1
2024-06-10 18:28:52,367:INFO:Initializing RandomizedSearchCV
2024-06-10 18:29:43,606:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 18:29:43,608:INFO:Hyperparameter search completed
2024-06-10 18:29:43,614:INFO:SubProcess create_model() called ==================================
2024-06-10 18:29:43,615:INFO:Initializing create_model()
2024-06-10 18:29:43,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000254FBC68A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-10 18:29:43,615:INFO:Checking exceptions
2024-06-10 18:29:43,615:INFO:Importing libraries
2024-06-10 18:29:43,616:INFO:Copying training dataset
2024-06-10 18:29:43,657:INFO:Defining folds
2024-06-10 18:29:43,657:INFO:Declaring metric variables
2024-06-10 18:29:43,665:INFO:Importing untrained model
2024-06-10 18:29:43,665:INFO:Declaring custom model
2024-06-10 18:29:43,673:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:29:43,688:INFO:Starting cross validation
2024-06-10 18:29:43,693:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:29:49,408:INFO:Calculating mean and std
2024-06-10 18:29:49,410:INFO:Creating metrics dataframe
2024-06-10 18:29:49,420:INFO:Finalizing model
2024-06-10 18:29:50,466:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:29:50,467:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:29:50,467:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:29:50,509:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:29:50,509:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:29:50,509:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:29:50,509:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:29:50,512:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002286 seconds.
2024-06-10 18:29:50,512:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:29:50,513:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:29:50,514:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:29:50,515:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:29:50,516:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:29:50,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:50,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:51,362:INFO:Uploading results into container
2024-06-10 18:29:51,363:INFO:Uploading model into container now
2024-06-10 18:29:51,364:INFO:_master_model_container: 2
2024-06-10 18:29:51,365:INFO:_display_container: 3
2024-06-10 18:29:51,366:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:29:51,367:INFO:create_model() successfully completed......................................
2024-06-10 18:29:51,478:INFO:SubProcess create_model() end ==================================
2024-06-10 18:29:51,478:INFO:choose_better activated
2024-06-10 18:29:51,482:INFO:SubProcess create_model() called ==================================
2024-06-10 18:29:51,482:INFO:Initializing create_model()
2024-06-10 18:29:51,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:29:51,483:INFO:Checking exceptions
2024-06-10 18:29:51,485:INFO:Importing libraries
2024-06-10 18:29:51,485:INFO:Copying training dataset
2024-06-10 18:29:51,510:INFO:Defining folds
2024-06-10 18:29:51,510:INFO:Declaring metric variables
2024-06-10 18:29:51,510:INFO:Importing untrained model
2024-06-10 18:29:51,510:INFO:Declaring custom model
2024-06-10 18:29:51,511:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:29:51,512:INFO:Starting cross validation
2024-06-10 18:29:51,514:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:29:55,080:INFO:Calculating mean and std
2024-06-10 18:29:55,080:INFO:Creating metrics dataframe
2024-06-10 18:29:55,083:INFO:Finalizing model
2024-06-10 18:29:56,178:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:29:56,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003411 seconds.
2024-06-10 18:29:56,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:29:56,182:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:29:56,183:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:29:56,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:29:56,184:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:29:56,413:INFO:Uploading results into container
2024-06-10 18:29:56,414:INFO:Uploading model into container now
2024-06-10 18:29:56,415:INFO:_master_model_container: 3
2024-06-10 18:29:56,415:INFO:_display_container: 4
2024-06-10 18:29:56,416:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:29:56,416:INFO:create_model() successfully completed......................................
2024-06-10 18:29:56,521:INFO:SubProcess create_model() end ==================================
2024-06-10 18:29:56,522:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0932
2024-06-10 18:29:56,522:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1021
2024-06-10 18:29:56,523:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:29:56,523:INFO:choose_better completed
2024-06-10 18:29:56,534:INFO:_master_model_container: 3
2024-06-10 18:29:56,534:INFO:_display_container: 3
2024-06-10 18:29:56,535:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:29:56,535:INFO:tune_model() successfully completed......................................
2024-06-10 18:29:56,666:INFO:Initializing plot_model()
2024-06-10 18:29:56,666:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:29:56,666:INFO:Checking exceptions
2024-06-10 18:29:56,678:INFO:Preloading libraries
2024-06-10 18:29:56,718:INFO:Copying training dataset
2024-06-10 18:29:56,718:INFO:Plot type: auc
2024-06-10 18:29:56,931:INFO:Fitting Model
2024-06-10 18:29:56,932:INFO:Scoring test/hold-out set
2024-06-10 18:29:56,935:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:29:56,935:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:29:56,935:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:29:56,996:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:29:56,997:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:29:56,997:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:29:57,377:INFO:Visual Rendered Successfully
2024-06-10 18:29:57,447:INFO:plot_model() successfully completed......................................
2024-06-10 18:29:57,468:INFO:Initializing plot_model()
2024-06-10 18:29:57,468:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:29:57,468:INFO:Checking exceptions
2024-06-10 18:29:57,477:INFO:Preloading libraries
2024-06-10 18:29:57,512:INFO:Copying training dataset
2024-06-10 18:29:57,512:INFO:Plot type: confusion_matrix
2024-06-10 18:29:57,716:INFO:Fitting Model
2024-06-10 18:29:57,717:INFO:Scoring test/hold-out set
2024-06-10 18:29:57,719:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:29:57,719:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:29:57,719:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:29:57,776:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:29:57,776:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:29:57,777:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:29:58,031:INFO:Visual Rendered Successfully
2024-06-10 18:29:58,103:INFO:plot_model() successfully completed......................................
2024-06-10 18:29:58,118:INFO:Initializing finalize_model()
2024-06-10 18:29:58,118:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:29:58,119:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:29:58,131:INFO:Initializing create_model()
2024-06-10 18:29:58,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:29:58,131:INFO:Checking exceptions
2024-06-10 18:29:58,133:INFO:Importing libraries
2024-06-10 18:29:58,133:INFO:Copying training dataset
2024-06-10 18:29:58,134:INFO:Defining folds
2024-06-10 18:29:58,134:INFO:Declaring metric variables
2024-06-10 18:29:58,134:INFO:Importing untrained model
2024-06-10 18:29:58,134:INFO:Declaring custom model
2024-06-10 18:29:58,135:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:29:58,137:INFO:Cross validation set to False
2024-06-10 18:29:58,137:INFO:Fitting Model
2024-06-10 18:29:59,392:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:29:59,392:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:29:59,392:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:29:59,456:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:29:59,456:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:29:59,456:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:29:59,456:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 18:29:59,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003689 seconds.
2024-06-10 18:29:59,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:29:59,462:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:29:59,463:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 18:29:59,465:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 18:29:59,465:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 18:29:59,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:29:59,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:30:00,567:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:30:00,568:INFO:create_model() successfully completed......................................
2024-06-10 18:30:00,647:INFO:_master_model_container: 3
2024-06-10 18:30:00,647:INFO:_display_container: 3
2024-06-10 18:30:00,692:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:30:00,692:INFO:finalize_model() successfully completed......................................
2024-06-10 18:30:00,875:INFO:Initializing evaluate_model()
2024-06-10 18:30:00,876:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:30:00,963:INFO:Initializing plot_model()
2024-06-10 18:30:00,963:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:30:00,963:INFO:Checking exceptions
2024-06-10 18:30:00,972:INFO:Preloading libraries
2024-06-10 18:30:01,030:INFO:Copying training dataset
2024-06-10 18:30:01,030:INFO:Plot type: pipeline
2024-06-10 18:30:01,356:INFO:Visual Rendered Successfully
2024-06-10 18:30:01,425:INFO:plot_model() successfully completed......................................
2024-06-10 18:33:02,314:INFO:Initializing plot_model()
2024-06-10 18:33:02,314:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:33:02,314:INFO:Checking exceptions
2024-06-10 18:33:02,322:INFO:Preloading libraries
2024-06-10 18:33:02,364:INFO:Copying training dataset
2024-06-10 18:33:02,364:INFO:Plot type: auc
2024-06-10 18:33:02,548:INFO:Fitting Model
2024-06-10 18:33:02,550:INFO:Scoring test/hold-out set
2024-06-10 18:33:02,552:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:33:02,552:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:33:02,552:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:33:02,616:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:33:02,616:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:33:02,616:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:33:02,894:INFO:Visual Rendered Successfully
2024-06-10 18:33:02,968:INFO:plot_model() successfully completed......................................
2024-06-10 18:33:04,866:INFO:Initializing plot_model()
2024-06-10 18:33:04,866:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:33:04,866:INFO:Checking exceptions
2024-06-10 18:33:04,873:INFO:Preloading libraries
2024-06-10 18:33:04,910:INFO:Copying training dataset
2024-06-10 18:33:04,910:INFO:Plot type: confusion_matrix
2024-06-10 18:33:05,086:INFO:Fitting Model
2024-06-10 18:33:05,086:INFO:Scoring test/hold-out set
2024-06-10 18:33:05,088:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:33:05,088:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:33:05,088:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:33:05,154:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:33:05,154:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:33:05,154:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:33:05,330:INFO:Visual Rendered Successfully
2024-06-10 18:33:05,405:INFO:plot_model() successfully completed......................................
2024-06-10 18:35:23,513:INFO:Initializing plot_model()
2024-06-10 18:35:23,513:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254C87826D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:35:23,513:INFO:Checking exceptions
2024-06-10 18:35:23,520:INFO:Preloading libraries
2024-06-10 18:35:23,563:INFO:Copying training dataset
2024-06-10 18:35:23,563:INFO:Plot type: auc
2024-06-10 18:35:23,748:INFO:Fitting Model
2024-06-10 18:35:23,749:INFO:Scoring test/hold-out set
2024-06-10 18:35:23,751:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:35:23,751:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:35:23,751:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:35:23,820:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:35:23,820:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:35:23,820:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:35:24,112:INFO:Visual Rendered Successfully
2024-06-10 18:35:24,183:INFO:plot_model() successfully completed......................................
2024-06-10 18:36:00,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:36:00,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:36:00,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:36:00,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:36:01,560:INFO:PyCaret ClassificationExperiment
2024-06-10 18:36:01,560:INFO:Logging name: clf-default-name
2024-06-10 18:36:01,560:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 18:36:01,560:INFO:version 3.3.2
2024-06-10 18:36:01,560:INFO:Initializing setup()
2024-06-10 18:36:01,560:INFO:self.USI: 0cba
2024-06-10 18:36:01,560:INFO:self._variable_keys: {'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y_train', 'X_train', 'idx', 'y', 'data', 'X_test', 'seed', 'pipeline', '_ml_usecase', 'log_plots_param', 'USI', 'exp_id', 'y_test', 'is_multiclass', 'fold_generator', 'fix_imbalance', 'exp_name_log', 'n_jobs_param', 'target_param', 'X', 'html_param', 'memory', 'fold_groups_param', 'logging_param'}
2024-06-10 18:36:01,560:INFO:Checking environment
2024-06-10 18:36:01,561:INFO:python_version: 3.11.9
2024-06-10 18:36:01,561:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 18:36:01,561:INFO:machine: AMD64
2024-06-10 18:36:01,561:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 18:36:01,561:INFO:Memory: svmem(total=34056318976, available=23967240192, percent=29.6, used=10089078784, free=23967240192)
2024-06-10 18:36:01,561:INFO:Physical Core: 6
2024-06-10 18:36:01,561:INFO:Logical Core: 12
2024-06-10 18:36:01,561:INFO:Checking libraries
2024-06-10 18:36:01,561:INFO:System:
2024-06-10 18:36:01,561:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 18:36:01,561:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 18:36:01,561:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 18:36:01,561:INFO:PyCaret required dependencies:
2024-06-10 18:36:01,590:INFO:                 pip: 24.0
2024-06-10 18:36:01,590:INFO:          setuptools: 69.5.1
2024-06-10 18:36:01,590:INFO:             pycaret: 3.3.2
2024-06-10 18:36:01,590:INFO:             IPython: 8.25.0
2024-06-10 18:36:01,590:INFO:          ipywidgets: 8.1.3
2024-06-10 18:36:01,590:INFO:                tqdm: 4.66.4
2024-06-10 18:36:01,590:INFO:               numpy: 1.26.4
2024-06-10 18:36:01,590:INFO:              pandas: 2.1.4
2024-06-10 18:36:01,590:INFO:              jinja2: 3.1.4
2024-06-10 18:36:01,590:INFO:               scipy: 1.11.4
2024-06-10 18:36:01,590:INFO:              joblib: 1.3.2
2024-06-10 18:36:01,590:INFO:             sklearn: 1.4.2
2024-06-10 18:36:01,590:INFO:                pyod: 2.0.0
2024-06-10 18:36:01,590:INFO:            imblearn: 0.12.3
2024-06-10 18:36:01,590:INFO:   category_encoders: 2.6.3
2024-06-10 18:36:01,590:INFO:            lightgbm: 4.3.0
2024-06-10 18:36:01,590:INFO:               numba: 0.59.1
2024-06-10 18:36:01,591:INFO:            requests: 2.32.3
2024-06-10 18:36:01,591:INFO:          matplotlib: 3.7.5
2024-06-10 18:36:01,591:INFO:          scikitplot: 0.3.7
2024-06-10 18:36:01,591:INFO:         yellowbrick: 1.5
2024-06-10 18:36:01,591:INFO:              plotly: 5.22.0
2024-06-10 18:36:01,591:INFO:    plotly-resampler: Not installed
2024-06-10 18:36:01,591:INFO:             kaleido: 0.2.1
2024-06-10 18:36:01,591:INFO:           schemdraw: 0.15
2024-06-10 18:36:01,591:INFO:         statsmodels: 0.14.2
2024-06-10 18:36:01,591:INFO:              sktime: 0.26.0
2024-06-10 18:36:01,591:INFO:               tbats: 1.1.3
2024-06-10 18:36:01,591:INFO:            pmdarima: 2.0.4
2024-06-10 18:36:01,591:INFO:              psutil: 5.9.8
2024-06-10 18:36:01,591:INFO:          markupsafe: 2.1.5
2024-06-10 18:36:01,591:INFO:             pickle5: Not installed
2024-06-10 18:36:01,591:INFO:         cloudpickle: 3.0.0
2024-06-10 18:36:01,591:INFO:         deprecation: 2.1.0
2024-06-10 18:36:01,591:INFO:              xxhash: 3.4.1
2024-06-10 18:36:01,591:INFO:           wurlitzer: Not installed
2024-06-10 18:36:01,591:INFO:PyCaret optional dependencies:
2024-06-10 18:36:01,607:INFO:                shap: Not installed
2024-06-10 18:36:01,607:INFO:           interpret: Not installed
2024-06-10 18:36:01,607:INFO:                umap: Not installed
2024-06-10 18:36:01,607:INFO:     ydata_profiling: Not installed
2024-06-10 18:36:01,607:INFO:  explainerdashboard: Not installed
2024-06-10 18:36:01,607:INFO:             autoviz: Not installed
2024-06-10 18:36:01,607:INFO:           fairlearn: Not installed
2024-06-10 18:36:01,607:INFO:          deepchecks: Not installed
2024-06-10 18:36:01,607:INFO:             xgboost: Not installed
2024-06-10 18:36:01,607:INFO:            catboost: Not installed
2024-06-10 18:36:01,607:INFO:              kmodes: Not installed
2024-06-10 18:36:01,608:INFO:             mlxtend: Not installed
2024-06-10 18:36:01,608:INFO:       statsforecast: Not installed
2024-06-10 18:36:01,608:INFO:        tune_sklearn: Not installed
2024-06-10 18:36:01,608:INFO:                 ray: Not installed
2024-06-10 18:36:01,608:INFO:            hyperopt: Not installed
2024-06-10 18:36:01,608:INFO:              optuna: Not installed
2024-06-10 18:36:01,608:INFO:               skopt: Not installed
2024-06-10 18:36:01,608:INFO:              mlflow: Not installed
2024-06-10 18:36:01,608:INFO:              gradio: Not installed
2024-06-10 18:36:01,608:INFO:             fastapi: Not installed
2024-06-10 18:36:01,608:INFO:             uvicorn: Not installed
2024-06-10 18:36:01,608:INFO:              m2cgen: Not installed
2024-06-10 18:36:01,609:INFO:           evidently: Not installed
2024-06-10 18:36:01,609:INFO:               fugue: Not installed
2024-06-10 18:36:01,609:INFO:           streamlit: 1.35.0
2024-06-10 18:36:01,609:INFO:             prophet: Not installed
2024-06-10 18:36:01,609:INFO:None
2024-06-10 18:36:01,609:INFO:Set up data.
2024-06-10 18:36:01,653:INFO:Set up folding strategy.
2024-06-10 18:36:01,653:INFO:Set up train/test split.
2024-06-10 18:36:01,678:INFO:Set up index.
2024-06-10 18:36:01,680:INFO:Assigning column types.
2024-06-10 18:36:01,689:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 18:36:01,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:36:01,732:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:36:01,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:01,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:01,805:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:36:01,806:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:36:01,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:01,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:01,833:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 18:36:01,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:36:01,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:01,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:01,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:36:01,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:01,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:01,971:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 18:36:02,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:02,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:02,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:02,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:36:02,108:INFO:Preparing preprocessing pipeline...
2024-06-10 18:36:02,110:INFO:Set up date feature engineering.
2024-06-10 18:36:02,110:INFO:Set up simple imputation.
2024-06-10 18:36:02,121:INFO:Set up encoding of ordinal features.
2024-06-10 18:36:02,131:INFO:Set up encoding of categorical features.
2024-06-10 18:36:02,131:INFO:Set up removing outliers.
2024-06-10 18:36:02,131:INFO:Set up feature normalization.
2024-06-10 18:36:02,131:INFO:Set up PCA.
2024-06-10 18:42:26,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:42:26,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:42:26,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:42:26,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:42:28,205:INFO:PyCaret ClassificationExperiment
2024-06-10 18:42:28,205:INFO:Logging name: clf-default-name
2024-06-10 18:42:28,205:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 18:42:28,205:INFO:version 3.3.2
2024-06-10 18:42:28,205:INFO:Initializing setup()
2024-06-10 18:42:28,205:INFO:self.USI: 5d7d
2024-06-10 18:42:28,206:INFO:self._variable_keys: {'idx', 'USI', 'exp_id', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'pipeline', 'html_param', 'y_train', 'target_param', '_ml_usecase', 'memory', 'is_multiclass', 'gpu_param', 'y_test', 'X', 'logging_param', 'data', 'seed', 'gpu_n_jobs_param', 'exp_name_log', 'X_train', 'X_test', 'log_plots_param', 'y', '_available_plots', 'fold_generator', 'fold_shuffle_param'}
2024-06-10 18:42:28,206:INFO:Checking environment
2024-06-10 18:42:28,206:INFO:python_version: 3.11.9
2024-06-10 18:42:28,206:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 18:42:28,206:INFO:machine: AMD64
2024-06-10 18:42:28,206:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 18:42:28,206:INFO:Memory: svmem(total=34056318976, available=27572404224, percent=19.0, used=6483914752, free=27572404224)
2024-06-10 18:42:28,206:INFO:Physical Core: 6
2024-06-10 18:42:28,206:INFO:Logical Core: 12
2024-06-10 18:42:28,206:INFO:Checking libraries
2024-06-10 18:42:28,206:INFO:System:
2024-06-10 18:42:28,206:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 18:42:28,206:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 18:42:28,206:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 18:42:28,206:INFO:PyCaret required dependencies:
2024-06-10 18:42:28,238:INFO:                 pip: 24.0
2024-06-10 18:42:28,239:INFO:          setuptools: 69.5.1
2024-06-10 18:42:28,239:INFO:             pycaret: 3.3.2
2024-06-10 18:42:28,239:INFO:             IPython: 8.25.0
2024-06-10 18:42:28,239:INFO:          ipywidgets: 8.1.3
2024-06-10 18:42:28,239:INFO:                tqdm: 4.66.4
2024-06-10 18:42:28,239:INFO:               numpy: 1.26.4
2024-06-10 18:42:28,239:INFO:              pandas: 2.1.4
2024-06-10 18:42:28,239:INFO:              jinja2: 3.1.4
2024-06-10 18:42:28,239:INFO:               scipy: 1.11.4
2024-06-10 18:42:28,239:INFO:              joblib: 1.3.2
2024-06-10 18:42:28,239:INFO:             sklearn: 1.4.2
2024-06-10 18:42:28,239:INFO:                pyod: 2.0.0
2024-06-10 18:42:28,239:INFO:            imblearn: 0.12.3
2024-06-10 18:42:28,239:INFO:   category_encoders: 2.6.3
2024-06-10 18:42:28,239:INFO:            lightgbm: 4.3.0
2024-06-10 18:42:28,239:INFO:               numba: 0.59.1
2024-06-10 18:42:28,239:INFO:            requests: 2.32.3
2024-06-10 18:42:28,239:INFO:          matplotlib: 3.7.5
2024-06-10 18:42:28,239:INFO:          scikitplot: 0.3.7
2024-06-10 18:42:28,239:INFO:         yellowbrick: 1.5
2024-06-10 18:42:28,239:INFO:              plotly: 5.22.0
2024-06-10 18:42:28,239:INFO:    plotly-resampler: Not installed
2024-06-10 18:42:28,240:INFO:             kaleido: 0.2.1
2024-06-10 18:42:28,240:INFO:           schemdraw: 0.15
2024-06-10 18:42:28,240:INFO:         statsmodels: 0.14.2
2024-06-10 18:42:28,240:INFO:              sktime: 0.26.0
2024-06-10 18:42:28,240:INFO:               tbats: 1.1.3
2024-06-10 18:42:28,240:INFO:            pmdarima: 2.0.4
2024-06-10 18:42:28,240:INFO:              psutil: 5.9.8
2024-06-10 18:42:28,240:INFO:          markupsafe: 2.1.5
2024-06-10 18:42:28,240:INFO:             pickle5: Not installed
2024-06-10 18:42:28,240:INFO:         cloudpickle: 3.0.0
2024-06-10 18:42:28,240:INFO:         deprecation: 2.1.0
2024-06-10 18:42:28,240:INFO:              xxhash: 3.4.1
2024-06-10 18:42:28,240:INFO:           wurlitzer: Not installed
2024-06-10 18:42:28,240:INFO:PyCaret optional dependencies:
2024-06-10 18:42:28,250:INFO:                shap: Not installed
2024-06-10 18:42:28,250:INFO:           interpret: Not installed
2024-06-10 18:42:28,251:INFO:                umap: Not installed
2024-06-10 18:42:28,251:INFO:     ydata_profiling: Not installed
2024-06-10 18:42:28,251:INFO:  explainerdashboard: Not installed
2024-06-10 18:42:28,251:INFO:             autoviz: Not installed
2024-06-10 18:42:28,251:INFO:           fairlearn: Not installed
2024-06-10 18:42:28,251:INFO:          deepchecks: Not installed
2024-06-10 18:42:28,251:INFO:             xgboost: Not installed
2024-06-10 18:42:28,251:INFO:            catboost: Not installed
2024-06-10 18:42:28,251:INFO:              kmodes: Not installed
2024-06-10 18:42:28,251:INFO:             mlxtend: Not installed
2024-06-10 18:42:28,251:INFO:       statsforecast: Not installed
2024-06-10 18:42:28,251:INFO:        tune_sklearn: Not installed
2024-06-10 18:42:28,251:INFO:                 ray: Not installed
2024-06-10 18:42:28,251:INFO:            hyperopt: Not installed
2024-06-10 18:42:28,251:INFO:              optuna: Not installed
2024-06-10 18:42:28,251:INFO:               skopt: Not installed
2024-06-10 18:42:28,251:INFO:              mlflow: Not installed
2024-06-10 18:42:28,251:INFO:              gradio: Not installed
2024-06-10 18:42:28,251:INFO:             fastapi: Not installed
2024-06-10 18:42:28,251:INFO:             uvicorn: Not installed
2024-06-10 18:42:28,251:INFO:              m2cgen: Not installed
2024-06-10 18:42:28,251:INFO:           evidently: Not installed
2024-06-10 18:42:28,251:INFO:               fugue: Not installed
2024-06-10 18:42:28,252:INFO:           streamlit: 1.35.0
2024-06-10 18:42:28,252:INFO:             prophet: Not installed
2024-06-10 18:42:28,252:INFO:None
2024-06-10 18:42:28,252:INFO:Set up data.
2024-06-10 18:42:28,293:INFO:Set up folding strategy.
2024-06-10 18:42:28,293:INFO:Set up train/test split.
2024-06-10 18:42:28,324:INFO:Set up index.
2024-06-10 18:42:28,325:INFO:Assigning column types.
2024-06-10 18:42:28,335:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 18:42:28,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:42:28,380:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:42:28,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:42:28,457:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:42:28,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,484:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 18:42:28,526:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:42:28,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,597:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:42:28,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,624:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 18:42:28,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:28,762:INFO:Preparing preprocessing pipeline...
2024-06-10 18:42:28,764:INFO:Set up date feature engineering.
2024-06-10 18:42:28,764:INFO:Set up simple imputation.
2024-06-10 18:42:28,775:INFO:Set up encoding of ordinal features.
2024-06-10 18:42:28,786:INFO:Set up encoding of categorical features.
2024-06-10 18:42:28,786:INFO:Set up removing outliers.
2024-06-10 18:42:28,786:INFO:Set up imbalanced handling.
2024-06-10 18:42:28,786:INFO:Set up feature normalization.
2024-06-10 18:42:28,786:INFO:Set up PCA.
2024-06-10 18:42:29,408:INFO:Finished creating preprocessing pipeline.
2024-06-10 18:42:29,444:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-10 18:42:29,444:INFO:Creating final display dataframe.
2024-06-10 18:42:30,270:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method            linear
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              5d7d
2024-06-10 18:42:30,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:30,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:30,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:30,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:42:30,433:INFO:setup() successfully completed in 2.38s...............
2024-06-10 18:42:30,445:INFO:Initializing create_model()
2024-06-10 18:42:30,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:42:30,445:INFO:Checking exceptions
2024-06-10 18:42:30,462:INFO:Importing libraries
2024-06-10 18:42:30,463:INFO:Copying training dataset
2024-06-10 18:42:30,482:INFO:Defining folds
2024-06-10 18:42:30,482:INFO:Declaring metric variables
2024-06-10 18:42:30,486:INFO:Importing untrained model
2024-06-10 18:42:30,489:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:42:30,495:INFO:Starting cross validation
2024-06-10 18:42:30,497:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:42:38,614:INFO:Calculating mean and std
2024-06-10 18:42:38,616:INFO:Creating metrics dataframe
2024-06-10 18:42:38,624:INFO:Finalizing model
2024-06-10 18:42:40,104:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 18:42:40,111:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006310 seconds.
2024-06-10 18:42:40,112:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:42:40,112:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:42:40,113:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 18:42:40,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:42:40,505:INFO:Uploading results into container
2024-06-10 18:42:40,506:INFO:Uploading model into container now
2024-06-10 18:42:40,518:INFO:_master_model_container: 1
2024-06-10 18:42:40,518:INFO:_display_container: 2
2024-06-10 18:42:40,519:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:42:40,520:INFO:create_model() successfully completed......................................
2024-06-10 18:42:40,650:INFO:Initializing tune_model()
2024-06-10 18:42:40,650:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:42:40,650:INFO:Checking exceptions
2024-06-10 18:42:40,675:INFO:Copying training dataset
2024-06-10 18:42:40,687:INFO:Checking base model
2024-06-10 18:42:40,687:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:42:40,691:INFO:Declaring metric variables
2024-06-10 18:42:40,697:INFO:Defining Hyperparameters
2024-06-10 18:42:40,773:INFO:Tuning with n_jobs=-1
2024-06-10 18:42:40,773:INFO:Initializing RandomizedSearchCV
2024-06-10 18:43:53,506:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 210, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.005, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2024-06-10 18:43:53,508:INFO:Hyperparameter search completed
2024-06-10 18:43:53,508:INFO:SubProcess create_model() called ==================================
2024-06-10 18:43:53,509:INFO:Initializing create_model()
2024-06-10 18:43:53,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB54DFB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 0.001, 'num_leaves': 80, 'n_estimators': 210, 'min_split_gain': 0.5, 'min_child_samples': 96, 'learning_rate': 0.005, 'feature_fraction': 1.0, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2024-06-10 18:43:53,510:INFO:Checking exceptions
2024-06-10 18:43:53,510:INFO:Importing libraries
2024-06-10 18:43:53,511:INFO:Copying training dataset
2024-06-10 18:43:53,551:INFO:Defining folds
2024-06-10 18:43:53,551:INFO:Declaring metric variables
2024-06-10 18:43:53,558:INFO:Importing untrained model
2024-06-10 18:43:53,558:INFO:Declaring custom model
2024-06-10 18:43:53,566:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:43:53,579:INFO:Starting cross validation
2024-06-10 18:43:53,587:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:44:06,112:INFO:Calculating mean and std
2024-06-10 18:44:06,114:INFO:Creating metrics dataframe
2024-06-10 18:44:06,123:INFO:Finalizing model
2024-06-10 18:44:07,440:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:44:07,440:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:44:07,441:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:44:07,528:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:44:07,528:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:44:07,528:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:44:07,529:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 18:44:07,535:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005979 seconds.
2024-06-10 18:44:07,535:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:44:07,536:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:44:07,538:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 18:44:07,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:44:09,552:INFO:Uploading results into container
2024-06-10 18:44:09,553:INFO:Uploading model into container now
2024-06-10 18:44:09,554:INFO:_master_model_container: 2
2024-06-10 18:44:09,555:INFO:_display_container: 3
2024-06-10 18:44:09,556:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:44:09,557:INFO:create_model() successfully completed......................................
2024-06-10 18:44:09,667:INFO:SubProcess create_model() end ==================================
2024-06-10 18:44:09,668:INFO:choose_better activated
2024-06-10 18:44:09,672:INFO:SubProcess create_model() called ==================================
2024-06-10 18:44:09,672:INFO:Initializing create_model()
2024-06-10 18:44:09,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:44:09,673:INFO:Checking exceptions
2024-06-10 18:44:09,675:INFO:Importing libraries
2024-06-10 18:44:09,675:INFO:Copying training dataset
2024-06-10 18:44:09,699:INFO:Defining folds
2024-06-10 18:44:09,699:INFO:Declaring metric variables
2024-06-10 18:44:09,699:INFO:Importing untrained model
2024-06-10 18:44:09,699:INFO:Declaring custom model
2024-06-10 18:44:09,700:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:44:09,701:INFO:Starting cross validation
2024-06-10 18:44:09,703:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:44:14,520:INFO:Calculating mean and std
2024-06-10 18:44:14,522:INFO:Creating metrics dataframe
2024-06-10 18:44:14,524:INFO:Finalizing model
2024-06-10 18:44:16,111:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 18:44:16,121:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009094 seconds.
2024-06-10 18:44:16,122:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:44:16,122:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:44:16,123:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 18:44:16,124:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:44:16,672:INFO:Uploading results into container
2024-06-10 18:44:16,676:INFO:Uploading model into container now
2024-06-10 18:44:16,677:INFO:_master_model_container: 3
2024-06-10 18:44:16,677:INFO:_display_container: 4
2024-06-10 18:44:16,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:44:16,678:INFO:create_model() successfully completed......................................
2024-06-10 18:44:16,785:INFO:SubProcess create_model() end ==================================
2024-06-10 18:44:16,785:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.166
2024-06-10 18:44:16,786:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.2196
2024-06-10 18:44:16,786:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:44:16,787:INFO:choose_better completed
2024-06-10 18:44:16,797:INFO:_master_model_container: 3
2024-06-10 18:44:16,797:INFO:_display_container: 3
2024-06-10 18:44:16,798:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:44:16,798:INFO:tune_model() successfully completed......................................
2024-06-10 18:44:16,934:INFO:Initializing plot_model()
2024-06-10 18:44:16,935:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:44:16,935:INFO:Checking exceptions
2024-06-10 18:44:16,946:INFO:Preloading libraries
2024-06-10 18:44:16,986:INFO:Copying training dataset
2024-06-10 18:44:16,986:INFO:Plot type: auc
2024-06-10 18:44:17,201:INFO:Fitting Model
2024-06-10 18:44:17,203:INFO:Scoring test/hold-out set
2024-06-10 18:44:17,205:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:44:17,205:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:44:17,205:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:44:17,250:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:44:17,250:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:44:17,251:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:44:17,621:INFO:Visual Rendered Successfully
2024-06-10 18:44:17,695:INFO:plot_model() successfully completed......................................
2024-06-10 18:44:17,737:INFO:Initializing plot_model()
2024-06-10 18:44:17,738:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:44:17,738:INFO:Checking exceptions
2024-06-10 18:44:17,752:INFO:Preloading libraries
2024-06-10 18:44:17,826:INFO:Copying training dataset
2024-06-10 18:44:17,826:INFO:Plot type: confusion_matrix
2024-06-10 18:44:18,074:INFO:Fitting Model
2024-06-10 18:44:18,075:INFO:Scoring test/hold-out set
2024-06-10 18:44:18,078:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:44:18,078:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:44:18,078:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:44:18,125:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:44:18,125:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:44:18,125:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:44:18,342:INFO:Visual Rendered Successfully
2024-06-10 18:44:18,419:INFO:plot_model() successfully completed......................................
2024-06-10 18:44:18,446:INFO:Initializing finalize_model()
2024-06-10 18:44:18,446:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:44:18,446:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:44:18,457:INFO:Initializing create_model()
2024-06-10 18:44:18,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:44:18,457:INFO:Checking exceptions
2024-06-10 18:44:18,459:INFO:Importing libraries
2024-06-10 18:44:18,459:INFO:Copying training dataset
2024-06-10 18:44:18,460:INFO:Defining folds
2024-06-10 18:44:18,460:INFO:Declaring metric variables
2024-06-10 18:44:18,461:INFO:Importing untrained model
2024-06-10 18:44:18,461:INFO:Declaring custom model
2024-06-10 18:44:18,461:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:44:18,464:INFO:Cross validation set to False
2024-06-10 18:44:18,464:INFO:Fitting Model
2024-06-10 18:44:20,004:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:44:20,004:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:44:20,004:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:44:20,123:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:44:20,123:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:44:20,123:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:44:20,123:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-10 18:44:20,131:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007066 seconds.
2024-06-10 18:44:20,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:44:20,132:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:44:20,133:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-10 18:44:20,136:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:44:22,552:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-10 18:44:22,552:INFO:create_model() successfully completed......................................
2024-06-10 18:44:22,633:INFO:_master_model_container: 3
2024-06-10 18:44:22,633:INFO:_display_container: 3
2024-06-10 18:44:22,680:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-10 18:44:22,680:INFO:finalize_model() successfully completed......................................
2024-06-10 18:44:22,847:INFO:Initializing evaluate_model()
2024-06-10 18:44:22,847:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:44:22,903:INFO:Initializing plot_model()
2024-06-10 18:44:22,903:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:44:22,903:INFO:Checking exceptions
2024-06-10 18:44:22,911:INFO:Preloading libraries
2024-06-10 18:44:22,952:INFO:Copying training dataset
2024-06-10 18:44:22,952:INFO:Plot type: pipeline
2024-06-10 18:44:23,280:INFO:Visual Rendered Successfully
2024-06-10 18:44:23,352:INFO:plot_model() successfully completed......................................
2024-06-10 18:46:01,730:INFO:Initializing plot_model()
2024-06-10 18:46:01,730:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:46:01,731:INFO:Checking exceptions
2024-06-10 18:46:01,737:INFO:Preloading libraries
2024-06-10 18:46:01,770:INFO:Copying training dataset
2024-06-10 18:46:01,770:INFO:Plot type: confusion_matrix
2024-06-10 18:46:01,961:INFO:Fitting Model
2024-06-10 18:46:01,962:INFO:Scoring test/hold-out set
2024-06-10 18:46:01,964:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:46:01,964:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:46:01,965:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:46:01,997:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:46:01,997:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:46:01,997:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:46:02,167:INFO:Visual Rendered Successfully
2024-06-10 18:46:02,242:INFO:plot_model() successfully completed......................................
2024-06-10 18:46:02,533:INFO:Initializing plot_model()
2024-06-10 18:46:02,533:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:46:02,533:INFO:Checking exceptions
2024-06-10 18:46:02,540:INFO:Preloading libraries
2024-06-10 18:46:02,574:INFO:Copying training dataset
2024-06-10 18:46:02,574:INFO:Plot type: auc
2024-06-10 18:46:02,758:INFO:Fitting Model
2024-06-10 18:46:02,760:INFO:Scoring test/hold-out set
2024-06-10 18:46:02,761:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:46:02,762:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:46:02,762:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:46:02,792:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:46:02,792:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:46:02,792:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:46:03,044:INFO:Visual Rendered Successfully
2024-06-10 18:46:03,117:INFO:plot_model() successfully completed......................................
2024-06-10 18:46:05,118:INFO:Initializing plot_model()
2024-06-10 18:46:05,118:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:46:05,118:INFO:Checking exceptions
2024-06-10 18:46:05,124:INFO:Preloading libraries
2024-06-10 18:46:05,158:INFO:Copying training dataset
2024-06-10 18:46:05,158:INFO:Plot type: confusion_matrix
2024-06-10 18:46:05,342:INFO:Fitting Model
2024-06-10 18:46:05,343:INFO:Scoring test/hold-out set
2024-06-10 18:46:05,345:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:46:05,345:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:46:05,345:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:46:05,372:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-10 18:46:05,372:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-10 18:46:05,372:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-10 18:46:05,529:INFO:Visual Rendered Successfully
2024-06-10 18:46:05,635:INFO:plot_model() successfully completed......................................
2024-06-10 18:46:24,421:INFO:Initializing tune_model()
2024-06-10 18:46:24,422:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:46:24,422:INFO:Checking exceptions
2024-06-10 18:46:24,461:INFO:Copying training dataset
2024-06-10 18:46:24,479:INFO:Checking base model
2024-06-10 18:46:24,479:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:46:24,485:INFO:Declaring metric variables
2024-06-10 18:46:24,489:INFO:Defining Hyperparameters
2024-06-10 18:46:24,576:INFO:Tuning with n_jobs=-1
2024-06-10 18:46:24,576:INFO:Initializing RandomizedSearchCV
2024-06-10 18:47:27,649:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 18:47:27,651:INFO:Hyperparameter search completed
2024-06-10 18:47:27,651:INFO:SubProcess create_model() called ==================================
2024-06-10 18:47:27,652:INFO:Initializing create_model()
2024-06-10 18:47:27,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EB58B44D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-10 18:47:27,653:INFO:Checking exceptions
2024-06-10 18:47:27,653:INFO:Importing libraries
2024-06-10 18:47:27,654:INFO:Copying training dataset
2024-06-10 18:47:27,694:INFO:Defining folds
2024-06-10 18:47:27,694:INFO:Declaring metric variables
2024-06-10 18:47:27,700:INFO:Importing untrained model
2024-06-10 18:47:27,701:INFO:Declaring custom model
2024-06-10 18:47:27,709:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:47:27,725:INFO:Starting cross validation
2024-06-10 18:47:27,732:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:47:36,735:INFO:Calculating mean and std
2024-06-10 18:47:36,737:INFO:Creating metrics dataframe
2024-06-10 18:47:36,750:INFO:Finalizing model
2024-06-10 18:47:38,224:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:38,224:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:38,224:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:38,315:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:38,315:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:38,315:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:38,315:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 18:47:38,323:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005681 seconds.
2024-06-10 18:47:38,323:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:47:38,323:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:47:38,325:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 18:47:38,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:47:39,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:39,809:INFO:Uploading results into container
2024-06-10 18:47:39,810:INFO:Uploading model into container now
2024-06-10 18:47:39,811:INFO:_master_model_container: 4
2024-06-10 18:47:39,811:INFO:_display_container: 4
2024-06-10 18:47:39,812:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:47:39,812:INFO:create_model() successfully completed......................................
2024-06-10 18:47:39,924:INFO:SubProcess create_model() end ==================================
2024-06-10 18:47:39,924:INFO:choose_better activated
2024-06-10 18:47:39,928:INFO:SubProcess create_model() called ==================================
2024-06-10 18:47:39,929:INFO:Initializing create_model()
2024-06-10 18:47:39,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:47:39,929:INFO:Checking exceptions
2024-06-10 18:47:39,931:INFO:Importing libraries
2024-06-10 18:47:39,931:INFO:Copying training dataset
2024-06-10 18:47:39,954:INFO:Defining folds
2024-06-10 18:47:39,954:INFO:Declaring metric variables
2024-06-10 18:47:39,954:INFO:Importing untrained model
2024-06-10 18:47:39,955:INFO:Declaring custom model
2024-06-10 18:47:39,955:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:47:39,956:INFO:Starting cross validation
2024-06-10 18:47:39,958:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:47:45,351:INFO:Calculating mean and std
2024-06-10 18:47:45,352:INFO:Creating metrics dataframe
2024-06-10 18:47:45,357:INFO:Finalizing model
2024-06-10 18:47:46,891:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 18:47:46,898:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006137 seconds.
2024-06-10 18:47:46,898:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:47:46,898:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:47:46,899:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 18:47:46,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:47:47,498:INFO:Uploading results into container
2024-06-10 18:47:47,499:INFO:Uploading model into container now
2024-06-10 18:47:47,500:INFO:_master_model_container: 5
2024-06-10 18:47:47,500:INFO:_display_container: 5
2024-06-10 18:47:47,501:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:47:47,501:INFO:create_model() successfully completed......................................
2024-06-10 18:47:47,608:INFO:SubProcess create_model() end ==================================
2024-06-10 18:47:47,609:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2649
2024-06-10 18:47:47,609:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2669
2024-06-10 18:47:47,610:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:47:47,610:INFO:choose_better completed
2024-06-10 18:47:47,620:INFO:_master_model_container: 5
2024-06-10 18:47:47,620:INFO:_display_container: 4
2024-06-10 18:47:47,621:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:47:47,621:INFO:tune_model() successfully completed......................................
2024-06-10 18:47:48,084:INFO:Initializing plot_model()
2024-06-10 18:47:48,084:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:47:48,085:INFO:Checking exceptions
2024-06-10 18:47:48,098:INFO:Preloading libraries
2024-06-10 18:47:48,160:INFO:Copying training dataset
2024-06-10 18:47:48,160:INFO:Plot type: auc
2024-06-10 18:47:48,381:INFO:Fitting Model
2024-06-10 18:47:48,383:INFO:Scoring test/hold-out set
2024-06-10 18:47:48,385:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:48,386:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:48,386:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:48,450:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:48,450:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:48,450:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:48,826:INFO:Visual Rendered Successfully
2024-06-10 18:47:48,909:INFO:plot_model() successfully completed......................................
2024-06-10 18:47:49,005:INFO:Initializing plot_model()
2024-06-10 18:47:49,005:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:47:49,006:INFO:Checking exceptions
2024-06-10 18:47:49,018:INFO:Preloading libraries
2024-06-10 18:47:49,076:INFO:Copying training dataset
2024-06-10 18:47:49,076:INFO:Plot type: confusion_matrix
2024-06-10 18:47:49,307:INFO:Fitting Model
2024-06-10 18:47:49,308:INFO:Scoring test/hold-out set
2024-06-10 18:47:49,310:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:49,310:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:49,310:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:49,382:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:49,382:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:49,382:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:49,632:INFO:Visual Rendered Successfully
2024-06-10 18:47:49,712:INFO:plot_model() successfully completed......................................
2024-06-10 18:47:49,732:INFO:Initializing finalize_model()
2024-06-10 18:47:49,733:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:47:49,734:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:47:49,745:INFO:Initializing create_model()
2024-06-10 18:47:49,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:47:49,745:INFO:Checking exceptions
2024-06-10 18:47:49,747:INFO:Importing libraries
2024-06-10 18:47:49,747:INFO:Copying training dataset
2024-06-10 18:47:49,748:INFO:Defining folds
2024-06-10 18:47:49,748:INFO:Declaring metric variables
2024-06-10 18:47:49,748:INFO:Importing untrained model
2024-06-10 18:47:49,748:INFO:Declaring custom model
2024-06-10 18:47:49,749:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:47:49,752:INFO:Cross validation set to False
2024-06-10 18:47:49,752:INFO:Fitting Model
2024-06-10 18:47:51,526:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:51,526:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:51,526:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:51,663:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:51,664:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:51,664:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:51,664:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-10 18:47:51,675:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008871 seconds.
2024-06-10 18:47:51,675:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:47:51,676:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:47:51,677:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-10 18:47:51,681:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:47:53,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:53,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:53,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:53,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:53,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:53,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-10 18:47:53,882:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:47:53,882:INFO:create_model() successfully completed......................................
2024-06-10 18:47:53,977:INFO:_master_model_container: 5
2024-06-10 18:47:53,977:INFO:_display_container: 4
2024-06-10 18:47:54,022:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:47:54,022:INFO:finalize_model() successfully completed......................................
2024-06-10 18:47:54,170:INFO:Initializing evaluate_model()
2024-06-10 18:47:54,170:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:47:54,229:INFO:Initializing plot_model()
2024-06-10 18:47:54,229:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:47:54,229:INFO:Checking exceptions
2024-06-10 18:47:54,236:INFO:Preloading libraries
2024-06-10 18:47:54,277:INFO:Copying training dataset
2024-06-10 18:47:54,277:INFO:Plot type: pipeline
2024-06-10 18:47:54,560:INFO:Visual Rendered Successfully
2024-06-10 18:47:54,636:INFO:plot_model() successfully completed......................................
2024-06-10 18:47:56,143:INFO:Initializing plot_model()
2024-06-10 18:47:56,143:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:47:56,143:INFO:Checking exceptions
2024-06-10 18:47:56,152:INFO:Preloading libraries
2024-06-10 18:47:56,209:INFO:Copying training dataset
2024-06-10 18:47:56,209:INFO:Plot type: confusion_matrix
2024-06-10 18:47:56,449:INFO:Fitting Model
2024-06-10 18:47:56,450:INFO:Scoring test/hold-out set
2024-06-10 18:47:56,452:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:56,452:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:56,452:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:56,547:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:56,547:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:56,547:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:56,769:INFO:Visual Rendered Successfully
2024-06-10 18:47:56,841:INFO:plot_model() successfully completed......................................
2024-06-10 18:47:58,751:INFO:Initializing plot_model()
2024-06-10 18:47:58,751:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EB5517E90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:47:58,751:INFO:Checking exceptions
2024-06-10 18:47:58,758:INFO:Preloading libraries
2024-06-10 18:47:58,798:INFO:Copying training dataset
2024-06-10 18:47:58,798:INFO:Plot type: auc
2024-06-10 18:47:59,002:INFO:Fitting Model
2024-06-10 18:47:59,004:INFO:Scoring test/hold-out set
2024-06-10 18:47:59,006:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:59,006:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:59,007:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:59,082:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-10 18:47:59,082:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:47:59,083:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-10 18:47:59,400:INFO:Visual Rendered Successfully
2024-06-10 18:47:59,491:INFO:plot_model() successfully completed......................................
2024-06-10 18:48:19,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:48:19,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:48:19,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:48:19,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:48:20,231:INFO:PyCaret ClassificationExperiment
2024-06-10 18:48:20,231:INFO:Logging name: clf-default-name
2024-06-10 18:48:20,231:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 18:48:20,231:INFO:version 3.3.2
2024-06-10 18:48:20,231:INFO:Initializing setup()
2024-06-10 18:48:20,231:INFO:self.USI: dc86
2024-06-10 18:48:20,231:INFO:self._variable_keys: {'_ml_usecase', 'X_test', 'seed', 'fold_generator', 'y_test', 'idx', 'n_jobs_param', 'is_multiclass', 'data', 'exp_name_log', 'X', 'exp_id', 'memory', 'y', 'X_train', 'y_train', 'target_param', 'pipeline', 'USI', '_available_plots', 'log_plots_param', 'gpu_param', 'fold_shuffle_param', 'logging_param', 'gpu_n_jobs_param', 'fold_groups_param', 'fix_imbalance', 'html_param'}
2024-06-10 18:48:20,231:INFO:Checking environment
2024-06-10 18:48:20,231:INFO:python_version: 3.11.9
2024-06-10 18:48:20,231:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 18:48:20,231:INFO:machine: AMD64
2024-06-10 18:48:20,231:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 18:48:20,231:INFO:Memory: svmem(total=34056318976, available=27232964608, percent=20.0, used=6823354368, free=27232964608)
2024-06-10 18:48:20,232:INFO:Physical Core: 6
2024-06-10 18:48:20,232:INFO:Logical Core: 12
2024-06-10 18:48:20,232:INFO:Checking libraries
2024-06-10 18:48:20,232:INFO:System:
2024-06-10 18:48:20,232:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 18:48:20,232:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 18:48:20,232:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 18:48:20,232:INFO:PyCaret required dependencies:
2024-06-10 18:48:20,253:INFO:                 pip: 24.0
2024-06-10 18:48:20,253:INFO:          setuptools: 69.5.1
2024-06-10 18:48:20,253:INFO:             pycaret: 3.3.2
2024-06-10 18:48:20,254:INFO:             IPython: 8.25.0
2024-06-10 18:48:20,254:INFO:          ipywidgets: 8.1.3
2024-06-10 18:48:20,254:INFO:                tqdm: 4.66.4
2024-06-10 18:48:20,254:INFO:               numpy: 1.26.4
2024-06-10 18:48:20,254:INFO:              pandas: 2.1.4
2024-06-10 18:48:20,254:INFO:              jinja2: 3.1.4
2024-06-10 18:48:20,254:INFO:               scipy: 1.11.4
2024-06-10 18:48:20,254:INFO:              joblib: 1.3.2
2024-06-10 18:48:20,254:INFO:             sklearn: 1.4.2
2024-06-10 18:48:20,254:INFO:                pyod: 2.0.0
2024-06-10 18:48:20,254:INFO:            imblearn: 0.12.3
2024-06-10 18:48:20,254:INFO:   category_encoders: 2.6.3
2024-06-10 18:48:20,254:INFO:            lightgbm: 4.3.0
2024-06-10 18:48:20,254:INFO:               numba: 0.59.1
2024-06-10 18:48:20,254:INFO:            requests: 2.32.3
2024-06-10 18:48:20,254:INFO:          matplotlib: 3.7.5
2024-06-10 18:48:20,254:INFO:          scikitplot: 0.3.7
2024-06-10 18:48:20,254:INFO:         yellowbrick: 1.5
2024-06-10 18:48:20,254:INFO:              plotly: 5.22.0
2024-06-10 18:48:20,254:INFO:    plotly-resampler: Not installed
2024-06-10 18:48:20,254:INFO:             kaleido: 0.2.1
2024-06-10 18:48:20,254:INFO:           schemdraw: 0.15
2024-06-10 18:48:20,254:INFO:         statsmodels: 0.14.2
2024-06-10 18:48:20,254:INFO:              sktime: 0.26.0
2024-06-10 18:48:20,254:INFO:               tbats: 1.1.3
2024-06-10 18:48:20,255:INFO:            pmdarima: 2.0.4
2024-06-10 18:48:20,255:INFO:              psutil: 5.9.8
2024-06-10 18:48:20,255:INFO:          markupsafe: 2.1.5
2024-06-10 18:48:20,255:INFO:             pickle5: Not installed
2024-06-10 18:48:20,255:INFO:         cloudpickle: 3.0.0
2024-06-10 18:48:20,255:INFO:         deprecation: 2.1.0
2024-06-10 18:48:20,255:INFO:              xxhash: 3.4.1
2024-06-10 18:48:20,255:INFO:           wurlitzer: Not installed
2024-06-10 18:48:20,255:INFO:PyCaret optional dependencies:
2024-06-10 18:48:20,265:INFO:                shap: Not installed
2024-06-10 18:48:20,265:INFO:           interpret: Not installed
2024-06-10 18:48:20,265:INFO:                umap: Not installed
2024-06-10 18:48:20,265:INFO:     ydata_profiling: Not installed
2024-06-10 18:48:20,265:INFO:  explainerdashboard: Not installed
2024-06-10 18:48:20,265:INFO:             autoviz: Not installed
2024-06-10 18:48:20,265:INFO:           fairlearn: Not installed
2024-06-10 18:48:20,265:INFO:          deepchecks: Not installed
2024-06-10 18:48:20,265:INFO:             xgboost: Not installed
2024-06-10 18:48:20,265:INFO:            catboost: Not installed
2024-06-10 18:48:20,265:INFO:              kmodes: Not installed
2024-06-10 18:48:20,265:INFO:             mlxtend: Not installed
2024-06-10 18:48:20,265:INFO:       statsforecast: Not installed
2024-06-10 18:48:20,265:INFO:        tune_sklearn: Not installed
2024-06-10 18:48:20,265:INFO:                 ray: Not installed
2024-06-10 18:48:20,265:INFO:            hyperopt: Not installed
2024-06-10 18:48:20,265:INFO:              optuna: Not installed
2024-06-10 18:48:20,265:INFO:               skopt: Not installed
2024-06-10 18:48:20,265:INFO:              mlflow: Not installed
2024-06-10 18:48:20,266:INFO:              gradio: Not installed
2024-06-10 18:48:20,266:INFO:             fastapi: Not installed
2024-06-10 18:48:20,266:INFO:             uvicorn: Not installed
2024-06-10 18:48:20,266:INFO:              m2cgen: Not installed
2024-06-10 18:48:20,266:INFO:           evidently: Not installed
2024-06-10 18:48:20,266:INFO:               fugue: Not installed
2024-06-10 18:48:20,266:INFO:           streamlit: 1.35.0
2024-06-10 18:48:20,266:INFO:             prophet: Not installed
2024-06-10 18:48:20,266:INFO:None
2024-06-10 18:48:20,266:INFO:Set up data.
2024-06-10 18:48:20,304:INFO:Set up folding strategy.
2024-06-10 18:48:20,304:INFO:Set up train/test split.
2024-06-10 18:48:20,329:INFO:Set up index.
2024-06-10 18:48:20,330:INFO:Assigning column types.
2024-06-10 18:48:20,339:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 18:48:20,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:48:20,385:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:48:20,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:48:20,459:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:48:20,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,485:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 18:48:20,527:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:48:20,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,595:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:48:20,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,622:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 18:48:20,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:20,760:INFO:Preparing preprocessing pipeline...
2024-06-10 18:48:20,762:INFO:Set up date feature engineering.
2024-06-10 18:48:20,763:INFO:Set up simple imputation.
2024-06-10 18:48:20,773:INFO:Set up encoding of ordinal features.
2024-06-10 18:48:20,783:INFO:Set up encoding of categorical features.
2024-06-10 18:48:20,784:INFO:Set up removing outliers.
2024-06-10 18:48:20,784:INFO:Set up feature normalization.
2024-06-10 18:48:20,784:INFO:Set up PCA.
2024-06-10 18:48:21,218:INFO:Finished creating preprocessing pipeline.
2024-06-10 18:48:21,251:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-10 18:48:21,251:INFO:Creating final display dataframe.
2024-06-10 18:48:21,407:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48250, 34)
5   Transformed train set shape       (33250, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            robust
21                          PCA              True
22                   PCA method            linear
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              dc86
2024-06-10 18:48:21,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:21,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:21,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:21,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:48:21,553:INFO:setup() successfully completed in 1.38s...............
2024-06-10 18:48:21,567:INFO:Initializing create_model()
2024-06-10 18:48:21,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:48:21,568:INFO:Checking exceptions
2024-06-10 18:48:21,583:INFO:Importing libraries
2024-06-10 18:48:21,583:INFO:Copying training dataset
2024-06-10 18:48:21,614:INFO:Defining folds
2024-06-10 18:48:21,614:INFO:Declaring metric variables
2024-06-10 18:48:21,618:INFO:Importing untrained model
2024-06-10 18:48:21,624:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:48:21,631:INFO:Starting cross validation
2024-06-10 18:48:21,635:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:48:27,723:INFO:Calculating mean and std
2024-06-10 18:48:27,724:INFO:Creating metrics dataframe
2024-06-10 18:48:27,732:INFO:Finalizing model
2024-06-10 18:48:28,742:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:48:28,746:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003440 seconds.
2024-06-10 18:48:28,746:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:48:28,746:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:48:28,747:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:48:28,748:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:48:28,748:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:48:28,940:INFO:Uploading results into container
2024-06-10 18:48:28,941:INFO:Uploading model into container now
2024-06-10 18:48:28,953:INFO:_master_model_container: 1
2024-06-10 18:48:28,953:INFO:_display_container: 2
2024-06-10 18:48:28,954:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:48:28,954:INFO:create_model() successfully completed......................................
2024-06-10 18:48:29,091:INFO:Initializing tune_model()
2024-06-10 18:48:29,091:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:48:29,091:INFO:Checking exceptions
2024-06-10 18:48:29,120:INFO:Copying training dataset
2024-06-10 18:48:29,132:INFO:Checking base model
2024-06-10 18:48:29,132:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:48:29,136:INFO:Declaring metric variables
2024-06-10 18:48:29,139:INFO:Defining Hyperparameters
2024-06-10 18:48:29,210:INFO:Tuning with n_jobs=-1
2024-06-10 18:48:29,211:INFO:Initializing RandomizedSearchCV
2024-06-10 18:48:47,698:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:47,838:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:48,493:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:48,602:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:50,798:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:51,193:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:51,923:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:53,208:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:53,566:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:55,650:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:55,949:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:56,541:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:56,740:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:48:57,972:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:00,453:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:00,458:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:00,549:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:00,922:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:01,586:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:04,191:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:19,961:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:20,496:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:20,936:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:21,038:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:21,286:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:21,289:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:21,686:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:22,509:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:22,697:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:23,158:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-10 18:49:23,165:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2024-06-10 18:49:23,166:INFO:Hyperparameter search completed
2024-06-10 18:49:23,166:INFO:SubProcess create_model() called ==================================
2024-06-10 18:49:23,168:INFO:Initializing create_model()
2024-06-10 18:49:23,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A9D0851590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2024-06-10 18:49:23,168:INFO:Checking exceptions
2024-06-10 18:49:23,169:INFO:Importing libraries
2024-06-10 18:49:23,169:INFO:Copying training dataset
2024-06-10 18:49:23,207:INFO:Defining folds
2024-06-10 18:49:23,208:INFO:Declaring metric variables
2024-06-10 18:49:23,213:INFO:Importing untrained model
2024-06-10 18:49:23,214:INFO:Declaring custom model
2024-06-10 18:49:23,221:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:49:23,233:INFO:Starting cross validation
2024-06-10 18:49:23,239:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:49:26,544:INFO:Calculating mean and std
2024-06-10 18:49:26,546:INFO:Creating metrics dataframe
2024-06-10 18:49:26,555:INFO:Finalizing model
2024-06-10 18:49:27,792:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:27,793:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:27,793:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:27,859:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:27,859:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:27,859:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:27,859:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:49:27,863:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003312 seconds.
2024-06-10 18:49:27,863:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:49:27,864:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:49:27,864:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:49:27,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:49:27,866:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:49:28,123:INFO:Uploading results into container
2024-06-10 18:49:28,124:INFO:Uploading model into container now
2024-06-10 18:49:28,125:INFO:_master_model_container: 2
2024-06-10 18:49:28,126:INFO:_display_container: 3
2024-06-10 18:49:28,127:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:49:28,127:INFO:create_model() successfully completed......................................
2024-06-10 18:49:28,228:INFO:SubProcess create_model() end ==================================
2024-06-10 18:49:28,228:INFO:choose_better activated
2024-06-10 18:49:28,232:INFO:SubProcess create_model() called ==================================
2024-06-10 18:49:28,232:INFO:Initializing create_model()
2024-06-10 18:49:28,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:49:28,233:INFO:Checking exceptions
2024-06-10 18:49:28,235:INFO:Importing libraries
2024-06-10 18:49:28,235:INFO:Copying training dataset
2024-06-10 18:49:28,257:INFO:Defining folds
2024-06-10 18:49:28,257:INFO:Declaring metric variables
2024-06-10 18:49:28,257:INFO:Importing untrained model
2024-06-10 18:49:28,258:INFO:Declaring custom model
2024-06-10 18:49:28,258:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:49:28,259:INFO:Starting cross validation
2024-06-10 18:49:28,261:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:49:31,365:INFO:Calculating mean and std
2024-06-10 18:49:31,366:INFO:Creating metrics dataframe
2024-06-10 18:49:31,368:INFO:Finalizing model
2024-06-10 18:49:32,398:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-10 18:49:32,401:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002638 seconds.
2024-06-10 18:49:32,401:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:49:32,401:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:49:32,402:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-10 18:49:32,403:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-10 18:49:32,403:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-10 18:49:32,581:INFO:Uploading results into container
2024-06-10 18:49:32,582:INFO:Uploading model into container now
2024-06-10 18:49:32,582:INFO:_master_model_container: 3
2024-06-10 18:49:32,582:INFO:_display_container: 4
2024-06-10 18:49:32,583:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:49:32,583:INFO:create_model() successfully completed......................................
2024-06-10 18:49:32,668:INFO:SubProcess create_model() end ==================================
2024-06-10 18:49:32,669:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.3575
2024-06-10 18:49:32,670:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.3634
2024-06-10 18:49:32,671:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:49:32,671:INFO:choose_better completed
2024-06-10 18:49:32,680:INFO:_master_model_container: 3
2024-06-10 18:49:32,680:INFO:_display_container: 3
2024-06-10 18:49:32,681:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:49:32,681:INFO:tune_model() successfully completed......................................
2024-06-10 18:49:32,792:INFO:Initializing plot_model()
2024-06-10 18:49:32,792:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:49:32,792:INFO:Checking exceptions
2024-06-10 18:49:32,802:INFO:Preloading libraries
2024-06-10 18:49:32,811:INFO:Copying training dataset
2024-06-10 18:49:32,811:INFO:Plot type: auc
2024-06-10 18:49:33,004:INFO:Fitting Model
2024-06-10 18:49:33,005:INFO:Scoring test/hold-out set
2024-06-10 18:49:33,008:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:33,008:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:33,008:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:33,035:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:33,035:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:33,035:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:33,333:INFO:Visual Rendered Successfully
2024-06-10 18:49:33,403:INFO:plot_model() successfully completed......................................
2024-06-10 18:49:33,426:INFO:Initializing plot_model()
2024-06-10 18:49:33,426:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:49:33,426:INFO:Checking exceptions
2024-06-10 18:49:33,435:INFO:Preloading libraries
2024-06-10 18:49:33,445:INFO:Copying training dataset
2024-06-10 18:49:33,445:INFO:Plot type: confusion_matrix
2024-06-10 18:49:33,639:INFO:Fitting Model
2024-06-10 18:49:33,639:INFO:Scoring test/hold-out set
2024-06-10 18:49:33,642:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:33,642:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:33,642:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:33,669:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:33,669:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:33,669:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:33,855:INFO:Visual Rendered Successfully
2024-06-10 18:49:33,924:INFO:plot_model() successfully completed......................................
2024-06-10 18:49:33,942:INFO:Initializing finalize_model()
2024-06-10 18:49:33,942:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:49:33,943:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:49:33,953:INFO:Initializing create_model()
2024-06-10 18:49:33,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:49:33,953:INFO:Checking exceptions
2024-06-10 18:49:33,955:INFO:Importing libraries
2024-06-10 18:49:33,955:INFO:Copying training dataset
2024-06-10 18:49:33,956:INFO:Defining folds
2024-06-10 18:49:33,956:INFO:Declaring metric variables
2024-06-10 18:49:33,956:INFO:Importing untrained model
2024-06-10 18:49:33,956:INFO:Declaring custom model
2024-06-10 18:49:33,957:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:49:33,959:INFO:Cross validation set to False
2024-06-10 18:49:33,959:INFO:Fitting Model
2024-06-10 18:49:35,169:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:35,169:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:35,169:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:35,232:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:35,233:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:35,233:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:35,233:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-10 18:49:35,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003669 seconds.
2024-06-10 18:49:35,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:49:35,237:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:49:35,238:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-10 18:49:35,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-10 18:49:35,240:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-10 18:49:35,562:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:49:35,563:INFO:create_model() successfully completed......................................
2024-06-10 18:49:35,642:INFO:_master_model_container: 3
2024-06-10 18:49:35,642:INFO:_display_container: 3
2024-06-10 18:49:35,681:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:49:35,681:INFO:finalize_model() successfully completed......................................
2024-06-10 18:49:35,915:INFO:Initializing evaluate_model()
2024-06-10 18:49:35,915:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:49:35,971:INFO:Initializing plot_model()
2024-06-10 18:49:35,971:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:49:35,971:INFO:Checking exceptions
2024-06-10 18:49:35,978:INFO:Preloading libraries
2024-06-10 18:49:35,985:INFO:Copying training dataset
2024-06-10 18:49:35,985:INFO:Plot type: pipeline
2024-06-10 18:49:36,291:INFO:Visual Rendered Successfully
2024-06-10 18:49:36,359:INFO:plot_model() successfully completed......................................
2024-06-10 18:49:49,422:INFO:Initializing plot_model()
2024-06-10 18:49:49,423:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:49:49,423:INFO:Checking exceptions
2024-06-10 18:49:49,429:INFO:Preloading libraries
2024-06-10 18:49:49,438:INFO:Copying training dataset
2024-06-10 18:49:49,438:INFO:Plot type: confusion_matrix
2024-06-10 18:49:49,613:INFO:Fitting Model
2024-06-10 18:49:49,613:INFO:Scoring test/hold-out set
2024-06-10 18:49:49,615:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:49,615:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:49,615:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:49,636:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:49,636:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:49,636:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:49,787:INFO:Visual Rendered Successfully
2024-06-10 18:49:49,856:INFO:plot_model() successfully completed......................................
2024-06-10 18:49:52,108:INFO:Initializing plot_model()
2024-06-10 18:49:52,108:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:49:52,108:INFO:Checking exceptions
2024-06-10 18:49:52,114:INFO:Preloading libraries
2024-06-10 18:49:52,122:INFO:Copying training dataset
2024-06-10 18:49:52,122:INFO:Plot type: auc
2024-06-10 18:49:52,295:INFO:Fitting Model
2024-06-10 18:49:52,296:INFO:Scoring test/hold-out set
2024-06-10 18:49:52,298:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:52,298:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:52,298:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:52,325:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:52,325:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:52,325:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:52,568:INFO:Visual Rendered Successfully
2024-06-10 18:49:52,639:INFO:plot_model() successfully completed......................................
2024-06-10 18:49:54,234:INFO:Initializing plot_model()
2024-06-10 18:49:54,234:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A984A78A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:49:54,234:INFO:Checking exceptions
2024-06-10 18:49:54,240:INFO:Preloading libraries
2024-06-10 18:49:54,246:INFO:Copying training dataset
2024-06-10 18:49:54,246:INFO:Plot type: confusion_matrix
2024-06-10 18:49:54,423:INFO:Fitting Model
2024-06-10 18:49:54,423:INFO:Scoring test/hold-out set
2024-06-10 18:49:54,425:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:54,425:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:54,425:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:54,447:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-10 18:49:54,448:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-10 18:49:54,448:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-10 18:49:54,603:INFO:Visual Rendered Successfully
2024-06-10 18:49:54,693:INFO:plot_model() successfully completed......................................
2024-06-10 18:51:46,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:51:46,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:51:46,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:51:46,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 18:51:47,692:INFO:PyCaret ClassificationExperiment
2024-06-10 18:51:47,692:INFO:Logging name: clf-default-name
2024-06-10 18:51:47,692:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 18:51:47,692:INFO:version 3.3.2
2024-06-10 18:51:47,692:INFO:Initializing setup()
2024-06-10 18:51:47,693:INFO:self.USI: 1363
2024-06-10 18:51:47,693:INFO:self._variable_keys: {'_ml_usecase', 'data', 'is_multiclass', 'y_test', 'USI', 'X', 'X_train', 'y_train', 'exp_name_log', 'logging_param', 'X_test', 'target_param', 'gpu_n_jobs_param', 'exp_id', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'memory', 'n_jobs_param', '_available_plots', 'idx', 'seed', 'fold_groups_param', 'fix_imbalance', 'gpu_param', 'pipeline', 'y', 'fold_generator'}
2024-06-10 18:51:47,693:INFO:Checking environment
2024-06-10 18:51:47,693:INFO:python_version: 3.11.9
2024-06-10 18:51:47,693:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 18:51:47,693:INFO:machine: AMD64
2024-06-10 18:51:47,693:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 18:51:47,693:INFO:Memory: svmem(total=34056318976, available=27167367168, percent=20.2, used=6888951808, free=27167367168)
2024-06-10 18:51:47,693:INFO:Physical Core: 6
2024-06-10 18:51:47,693:INFO:Logical Core: 12
2024-06-10 18:51:47,693:INFO:Checking libraries
2024-06-10 18:51:47,693:INFO:System:
2024-06-10 18:51:47,693:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 18:51:47,693:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 18:51:47,693:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 18:51:47,693:INFO:PyCaret required dependencies:
2024-06-10 18:51:47,717:INFO:                 pip: 24.0
2024-06-10 18:51:47,717:INFO:          setuptools: 69.5.1
2024-06-10 18:51:47,717:INFO:             pycaret: 3.3.2
2024-06-10 18:51:47,717:INFO:             IPython: 8.25.0
2024-06-10 18:51:47,717:INFO:          ipywidgets: 8.1.3
2024-06-10 18:51:47,717:INFO:                tqdm: 4.66.4
2024-06-10 18:51:47,717:INFO:               numpy: 1.26.4
2024-06-10 18:51:47,717:INFO:              pandas: 2.1.4
2024-06-10 18:51:47,717:INFO:              jinja2: 3.1.4
2024-06-10 18:51:47,717:INFO:               scipy: 1.11.4
2024-06-10 18:51:47,717:INFO:              joblib: 1.3.2
2024-06-10 18:51:47,717:INFO:             sklearn: 1.4.2
2024-06-10 18:51:47,717:INFO:                pyod: 2.0.0
2024-06-10 18:51:47,717:INFO:            imblearn: 0.12.3
2024-06-10 18:51:47,717:INFO:   category_encoders: 2.6.3
2024-06-10 18:51:47,717:INFO:            lightgbm: 4.3.0
2024-06-10 18:51:47,717:INFO:               numba: 0.59.1
2024-06-10 18:51:47,717:INFO:            requests: 2.32.3
2024-06-10 18:51:47,718:INFO:          matplotlib: 3.7.5
2024-06-10 18:51:47,718:INFO:          scikitplot: 0.3.7
2024-06-10 18:51:47,718:INFO:         yellowbrick: 1.5
2024-06-10 18:51:47,718:INFO:              plotly: 5.22.0
2024-06-10 18:51:47,718:INFO:    plotly-resampler: Not installed
2024-06-10 18:51:47,718:INFO:             kaleido: 0.2.1
2024-06-10 18:51:47,718:INFO:           schemdraw: 0.15
2024-06-10 18:51:47,718:INFO:         statsmodels: 0.14.2
2024-06-10 18:51:47,718:INFO:              sktime: 0.26.0
2024-06-10 18:51:47,718:INFO:               tbats: 1.1.3
2024-06-10 18:51:47,718:INFO:            pmdarima: 2.0.4
2024-06-10 18:51:47,718:INFO:              psutil: 5.9.8
2024-06-10 18:51:47,718:INFO:          markupsafe: 2.1.5
2024-06-10 18:51:47,718:INFO:             pickle5: Not installed
2024-06-10 18:51:47,718:INFO:         cloudpickle: 3.0.0
2024-06-10 18:51:47,718:INFO:         deprecation: 2.1.0
2024-06-10 18:51:47,718:INFO:              xxhash: 3.4.1
2024-06-10 18:51:47,718:INFO:           wurlitzer: Not installed
2024-06-10 18:51:47,718:INFO:PyCaret optional dependencies:
2024-06-10 18:51:47,728:INFO:                shap: Not installed
2024-06-10 18:51:47,728:INFO:           interpret: Not installed
2024-06-10 18:51:47,728:INFO:                umap: Not installed
2024-06-10 18:51:47,728:INFO:     ydata_profiling: Not installed
2024-06-10 18:51:47,728:INFO:  explainerdashboard: Not installed
2024-06-10 18:51:47,728:INFO:             autoviz: Not installed
2024-06-10 18:51:47,728:INFO:           fairlearn: Not installed
2024-06-10 18:51:47,729:INFO:          deepchecks: Not installed
2024-06-10 18:51:47,729:INFO:             xgboost: Not installed
2024-06-10 18:51:47,729:INFO:            catboost: Not installed
2024-06-10 18:51:47,729:INFO:              kmodes: Not installed
2024-06-10 18:51:47,729:INFO:             mlxtend: Not installed
2024-06-10 18:51:47,729:INFO:       statsforecast: Not installed
2024-06-10 18:51:47,729:INFO:        tune_sklearn: Not installed
2024-06-10 18:51:47,729:INFO:                 ray: Not installed
2024-06-10 18:51:47,729:INFO:            hyperopt: Not installed
2024-06-10 18:51:47,729:INFO:              optuna: Not installed
2024-06-10 18:51:47,729:INFO:               skopt: Not installed
2024-06-10 18:51:47,729:INFO:              mlflow: Not installed
2024-06-10 18:51:47,729:INFO:              gradio: Not installed
2024-06-10 18:51:47,729:INFO:             fastapi: Not installed
2024-06-10 18:51:47,729:INFO:             uvicorn: Not installed
2024-06-10 18:51:47,729:INFO:              m2cgen: Not installed
2024-06-10 18:51:47,729:INFO:           evidently: Not installed
2024-06-10 18:51:47,729:INFO:               fugue: Not installed
2024-06-10 18:51:47,729:INFO:           streamlit: 1.35.0
2024-06-10 18:51:47,729:INFO:             prophet: Not installed
2024-06-10 18:51:47,729:INFO:None
2024-06-10 18:51:47,729:INFO:Set up data.
2024-06-10 18:51:47,766:INFO:Set up folding strategy.
2024-06-10 18:51:47,766:INFO:Set up train/test split.
2024-06-10 18:51:47,791:INFO:Set up index.
2024-06-10 18:51:47,792:INFO:Assigning column types.
2024-06-10 18:51:47,801:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 18:51:47,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:51:47,848:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:51:47,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:47,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:47,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:51:47,924:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:51:47,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:47,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:47,951:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 18:51:47,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:51:48,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:48,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:48,064:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:51:48,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:48,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:48,090:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 18:51:48,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:48,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:48,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:48,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:48,231:INFO:Preparing preprocessing pipeline...
2024-06-10 18:51:48,233:INFO:Set up date feature engineering.
2024-06-10 18:51:48,233:INFO:Set up simple imputation.
2024-06-10 18:51:48,244:INFO:Set up encoding of ordinal features.
2024-06-10 18:51:48,254:INFO:Set up encoding of categorical features.
2024-06-10 18:51:48,254:INFO:Set up removing outliers.
2024-06-10 18:51:48,254:INFO:Set up imbalanced handling.
2024-06-10 18:51:48,254:INFO:Set up feature normalization.
2024-06-10 18:51:48,254:INFO:Set up PCA.
2024-06-10 18:51:48,966:INFO:Finished creating preprocessing pipeline.
2024-06-10 18:51:49,000:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 18:51:49,000:INFO:Creating final display dataframe.
2024-06-10 18:51:49,765:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              1363
2024-06-10 18:51:49,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:49,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:49,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:49,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:51:49,910:INFO:setup() successfully completed in 2.28s...............
2024-06-10 18:51:49,929:INFO:Initializing create_model()
2024-06-10 18:51:49,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:51:49,929:INFO:Checking exceptions
2024-06-10 18:51:49,944:INFO:Importing libraries
2024-06-10 18:51:49,944:INFO:Copying training dataset
2024-06-10 18:51:49,962:INFO:Defining folds
2024-06-10 18:51:49,962:INFO:Declaring metric variables
2024-06-10 18:51:49,965:INFO:Importing untrained model
2024-06-10 18:51:49,969:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:51:49,975:INFO:Starting cross validation
2024-06-10 18:51:49,978:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:51:57,214:INFO:Calculating mean and std
2024-06-10 18:51:57,217:INFO:Creating metrics dataframe
2024-06-10 18:51:57,229:INFO:Finalizing model
2024-06-10 18:51:58,754:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 18:51:58,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005155 seconds.
2024-06-10 18:51:58,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:51:58,760:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:51:58,761:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 18:51:58,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:51:59,134:INFO:Uploading results into container
2024-06-10 18:51:59,135:INFO:Uploading model into container now
2024-06-10 18:51:59,149:INFO:_master_model_container: 1
2024-06-10 18:51:59,149:INFO:_display_container: 2
2024-06-10 18:51:59,150:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:51:59,150:INFO:create_model() successfully completed......................................
2024-06-10 18:51:59,279:INFO:Initializing tune_model()
2024-06-10 18:51:59,279:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 18:51:59,286:INFO:Checking exceptions
2024-06-10 18:51:59,308:INFO:Copying training dataset
2024-06-10 18:51:59,322:INFO:Checking base model
2024-06-10 18:51:59,323:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 18:51:59,326:INFO:Declaring metric variables
2024-06-10 18:51:59,330:INFO:Defining Hyperparameters
2024-06-10 18:51:59,403:INFO:Tuning with n_jobs=-1
2024-06-10 18:51:59,403:INFO:Initializing RandomizedSearchCV
2024-06-10 18:53:11,339:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-10 18:53:11,340:INFO:Hyperparameter search completed
2024-06-10 18:53:11,341:INFO:SubProcess create_model() called ==================================
2024-06-10 18:53:11,342:INFO:Initializing create_model()
2024-06-10 18:53:11,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F805961B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-10 18:53:11,343:INFO:Checking exceptions
2024-06-10 18:53:11,343:INFO:Importing libraries
2024-06-10 18:53:11,343:INFO:Copying training dataset
2024-06-10 18:53:11,389:INFO:Defining folds
2024-06-10 18:53:11,389:INFO:Declaring metric variables
2024-06-10 18:53:11,398:INFO:Importing untrained model
2024-06-10 18:53:11,399:INFO:Declaring custom model
2024-06-10 18:53:11,408:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:53:11,425:INFO:Starting cross validation
2024-06-10 18:53:11,430:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:53:17,753:INFO:Calculating mean and std
2024-06-10 18:53:17,755:INFO:Creating metrics dataframe
2024-06-10 18:53:17,765:INFO:Finalizing model
2024-06-10 18:53:19,317:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:53:19,317:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 18:53:19,317:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 18:53:19,402:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-10 18:53:19,402:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-10 18:53:19,402:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-10 18:53:19,403:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 18:53:19,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005049 seconds.
2024-06-10 18:53:19,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:53:19,411:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:53:19,412:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 18:53:19,415:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:53:20,241:INFO:Uploading results into container
2024-06-10 18:53:20,244:INFO:Uploading model into container now
2024-06-10 18:53:20,246:INFO:_master_model_container: 2
2024-06-10 18:53:20,247:INFO:_display_container: 3
2024-06-10 18:53:20,249:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:53:20,250:INFO:create_model() successfully completed......................................
2024-06-10 18:53:20,378:INFO:SubProcess create_model() end ==================================
2024-06-10 18:53:20,378:INFO:choose_better activated
2024-06-10 18:53:20,387:INFO:SubProcess create_model() called ==================================
2024-06-10 18:53:20,388:INFO:Initializing create_model()
2024-06-10 18:53:20,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:53:20,389:INFO:Checking exceptions
2024-06-10 18:53:20,392:INFO:Importing libraries
2024-06-10 18:53:20,392:INFO:Copying training dataset
2024-06-10 18:53:20,440:INFO:Defining folds
2024-06-10 18:53:20,441:INFO:Declaring metric variables
2024-06-10 18:53:20,441:INFO:Importing untrained model
2024-06-10 18:53:20,441:INFO:Declaring custom model
2024-06-10 18:53:20,443:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:53:20,443:INFO:Starting cross validation
2024-06-10 18:53:20,449:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 18:53:26,272:INFO:Calculating mean and std
2024-06-10 18:53:26,273:INFO:Creating metrics dataframe
2024-06-10 18:53:26,277:INFO:Finalizing model
2024-06-10 18:53:27,986:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 18:53:27,996:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008833 seconds.
2024-06-10 18:53:27,996:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:53:27,997:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:53:27,998:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 18:53:27,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:53:28,587:INFO:Uploading results into container
2024-06-10 18:53:28,588:INFO:Uploading model into container now
2024-06-10 18:53:28,588:INFO:_master_model_container: 3
2024-06-10 18:53:28,588:INFO:_display_container: 4
2024-06-10 18:53:28,589:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:53:28,589:INFO:create_model() successfully completed......................................
2024-06-10 18:53:28,697:INFO:SubProcess create_model() end ==================================
2024-06-10 18:53:28,697:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2635
2024-06-10 18:53:28,698:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2617
2024-06-10 18:53:28,699:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-10 18:53:28,699:INFO:choose_better completed
2024-06-10 18:53:28,699:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-10 18:53:28,711:INFO:_master_model_container: 3
2024-06-10 18:53:28,711:INFO:_display_container: 3
2024-06-10 18:53:28,712:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:53:28,712:INFO:tune_model() successfully completed......................................
2024-06-10 18:53:28,925:INFO:Initializing plot_model()
2024-06-10 18:53:28,925:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:53:28,925:INFO:Checking exceptions
2024-06-10 18:53:28,938:INFO:Preloading libraries
2024-06-10 18:53:28,947:INFO:Copying training dataset
2024-06-10 18:53:28,947:INFO:Plot type: auc
2024-06-10 18:53:29,208:INFO:Fitting Model
2024-06-10 18:53:29,210:INFO:Scoring test/hold-out set
2024-06-10 18:53:29,615:INFO:Visual Rendered Successfully
2024-06-10 18:53:29,688:INFO:plot_model() successfully completed......................................
2024-06-10 18:53:29,743:INFO:Initializing plot_model()
2024-06-10 18:53:29,743:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-10 18:53:29,743:INFO:Checking exceptions
2024-06-10 18:53:29,753:INFO:Preloading libraries
2024-06-10 18:53:29,760:INFO:Copying training dataset
2024-06-10 18:53:29,760:INFO:Plot type: confusion_matrix
2024-06-10 18:53:29,977:INFO:Fitting Model
2024-06-10 18:53:29,978:INFO:Scoring test/hold-out set
2024-06-10 18:53:30,193:INFO:Visual Rendered Successfully
2024-06-10 18:53:30,265:INFO:plot_model() successfully completed......................................
2024-06-10 18:53:30,280:INFO:Initializing finalize_model()
2024-06-10 18:53:30,280:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 18:53:30,280:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 18:53:30,289:INFO:Initializing create_model()
2024-06-10 18:53:30,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:53:30,290:INFO:Checking exceptions
2024-06-10 18:53:30,291:INFO:Importing libraries
2024-06-10 18:53:30,291:INFO:Copying training dataset
2024-06-10 18:53:30,293:INFO:Defining folds
2024-06-10 18:53:30,293:INFO:Declaring metric variables
2024-06-10 18:53:30,293:INFO:Importing untrained model
2024-06-10 18:53:30,293:INFO:Declaring custom model
2024-06-10 18:53:30,294:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:53:30,296:INFO:Cross validation set to False
2024-06-10 18:53:30,296:INFO:Fitting Model
2024-06-10 18:53:32,283:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-10 18:53:32,292:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007552 seconds.
2024-06-10 18:53:32,292:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 18:53:32,292:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 18:53:32,293:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-10 18:53:32,294:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 18:53:32,915:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:53:32,915:INFO:create_model() successfully completed......................................
2024-06-10 18:53:32,995:INFO:_master_model_container: 3
2024-06-10 18:53:32,995:INFO:_display_container: 3
2024-06-10 18:53:33,040:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-10 18:53:33,040:INFO:finalize_model() successfully completed......................................
2024-06-10 18:53:33,270:INFO:Initializing evaluate_model()
2024-06-10 18:53:33,270:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-10 18:53:33,338:INFO:Initializing plot_model()
2024-06-10 18:53:33,339:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:53:33,339:INFO:Checking exceptions
2024-06-10 18:53:33,346:INFO:Preloading libraries
2024-06-10 18:53:33,354:INFO:Copying training dataset
2024-06-10 18:53:33,355:INFO:Plot type: pipeline
2024-06-10 18:53:33,673:INFO:Visual Rendered Successfully
2024-06-10 18:53:33,742:INFO:plot_model() successfully completed......................................
2024-06-10 18:55:36,601:INFO:Initializing plot_model()
2024-06-10 18:55:36,601:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:55:36,601:INFO:Checking exceptions
2024-06-10 18:55:36,619:INFO:Preloading libraries
2024-06-10 18:55:36,631:INFO:Copying training dataset
2024-06-10 18:55:36,631:INFO:Plot type: confusion_matrix
2024-06-10 18:55:36,866:INFO:Fitting Model
2024-06-10 18:55:36,867:INFO:Scoring test/hold-out set
2024-06-10 18:55:37,080:INFO:Visual Rendered Successfully
2024-06-10 18:55:37,157:INFO:plot_model() successfully completed......................................
2024-06-10 18:55:39,437:INFO:Initializing plot_model()
2024-06-10 18:55:39,437:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:55:39,437:INFO:Checking exceptions
2024-06-10 18:55:39,444:INFO:Preloading libraries
2024-06-10 18:55:39,450:INFO:Copying training dataset
2024-06-10 18:55:39,450:INFO:Plot type: auc
2024-06-10 18:55:39,634:INFO:Fitting Model
2024-06-10 18:55:39,642:INFO:Scoring test/hold-out set
2024-06-10 18:55:39,906:INFO:Visual Rendered Successfully
2024-06-10 18:55:39,975:INFO:plot_model() successfully completed......................................
2024-06-10 18:55:41,834:INFO:Initializing plot_model()
2024-06-10 18:55:41,834:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8059B7B90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-10 18:55:41,834:INFO:Checking exceptions
2024-06-10 18:55:41,840:INFO:Preloading libraries
2024-06-10 18:55:41,847:INFO:Copying training dataset
2024-06-10 18:55:41,847:INFO:Plot type: confusion_matrix
2024-06-10 18:55:42,037:INFO:Fitting Model
2024-06-10 18:55:42,038:INFO:Scoring test/hold-out set
2024-06-10 18:55:42,220:INFO:Visual Rendered Successfully
2024-06-10 18:55:42,291:INFO:plot_model() successfully completed......................................
2024-06-10 18:57:15,978:INFO:PyCaret ClassificationExperiment
2024-06-10 18:57:15,979:INFO:Logging name: clf-default-name
2024-06-10 18:57:15,979:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 18:57:15,979:INFO:version 3.3.2
2024-06-10 18:57:15,979:INFO:Initializing setup()
2024-06-10 18:57:15,979:INFO:self.USI: 1092
2024-06-10 18:57:15,979:INFO:self._variable_keys: {'_ml_usecase', 'data', 'is_multiclass', 'y_test', 'USI', 'X', 'X_train', 'y_train', 'exp_name_log', 'logging_param', 'X_test', 'target_param', 'gpu_n_jobs_param', 'exp_id', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'memory', 'n_jobs_param', '_available_plots', 'idx', 'seed', 'fold_groups_param', 'fix_imbalance', 'gpu_param', 'pipeline', 'y', 'fold_generator'}
2024-06-10 18:57:15,979:INFO:Checking environment
2024-06-10 18:57:15,979:INFO:python_version: 3.11.9
2024-06-10 18:57:15,979:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 18:57:15,979:INFO:machine: AMD64
2024-06-10 18:57:15,979:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 18:57:15,979:INFO:Memory: svmem(total=34056318976, available=25187229696, percent=26.0, used=8869089280, free=25187229696)
2024-06-10 18:57:15,979:INFO:Physical Core: 6
2024-06-10 18:57:15,979:INFO:Logical Core: 12
2024-06-10 18:57:15,979:INFO:Checking libraries
2024-06-10 18:57:15,979:INFO:System:
2024-06-10 18:57:15,980:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 18:57:15,980:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 18:57:15,980:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 18:57:15,980:INFO:PyCaret required dependencies:
2024-06-10 18:57:15,980:INFO:                 pip: 24.0
2024-06-10 18:57:15,980:INFO:          setuptools: 69.5.1
2024-06-10 18:57:15,980:INFO:             pycaret: 3.3.2
2024-06-10 18:57:15,980:INFO:             IPython: 8.25.0
2024-06-10 18:57:15,980:INFO:          ipywidgets: 8.1.3
2024-06-10 18:57:15,980:INFO:                tqdm: 4.66.4
2024-06-10 18:57:15,980:INFO:               numpy: 1.26.4
2024-06-10 18:57:15,980:INFO:              pandas: 2.1.4
2024-06-10 18:57:15,980:INFO:              jinja2: 3.1.4
2024-06-10 18:57:15,980:INFO:               scipy: 1.11.4
2024-06-10 18:57:15,980:INFO:              joblib: 1.3.2
2024-06-10 18:57:15,980:INFO:             sklearn: 1.4.2
2024-06-10 18:57:15,981:INFO:                pyod: 2.0.0
2024-06-10 18:57:15,981:INFO:            imblearn: 0.12.3
2024-06-10 18:57:15,981:INFO:   category_encoders: 2.6.3
2024-06-10 18:57:15,981:INFO:            lightgbm: 4.3.0
2024-06-10 18:57:15,981:INFO:               numba: 0.59.1
2024-06-10 18:57:15,981:INFO:            requests: 2.32.3
2024-06-10 18:57:15,981:INFO:          matplotlib: 3.7.5
2024-06-10 18:57:15,981:INFO:          scikitplot: 0.3.7
2024-06-10 18:57:15,981:INFO:         yellowbrick: 1.5
2024-06-10 18:57:15,981:INFO:              plotly: 5.22.0
2024-06-10 18:57:15,981:INFO:    plotly-resampler: Not installed
2024-06-10 18:57:15,981:INFO:             kaleido: 0.2.1
2024-06-10 18:57:15,981:INFO:           schemdraw: 0.15
2024-06-10 18:57:15,981:INFO:         statsmodels: 0.14.2
2024-06-10 18:57:15,981:INFO:              sktime: 0.26.0
2024-06-10 18:57:15,981:INFO:               tbats: 1.1.3
2024-06-10 18:57:15,981:INFO:            pmdarima: 2.0.4
2024-06-10 18:57:15,981:INFO:              psutil: 5.9.8
2024-06-10 18:57:15,981:INFO:          markupsafe: 2.1.5
2024-06-10 18:57:15,982:INFO:             pickle5: Not installed
2024-06-10 18:57:15,982:INFO:         cloudpickle: 3.0.0
2024-06-10 18:57:15,982:INFO:         deprecation: 2.1.0
2024-06-10 18:57:15,982:INFO:              xxhash: 3.4.1
2024-06-10 18:57:15,982:INFO:           wurlitzer: Not installed
2024-06-10 18:57:15,982:INFO:PyCaret optional dependencies:
2024-06-10 18:57:15,982:INFO:                shap: Not installed
2024-06-10 18:57:15,982:INFO:           interpret: Not installed
2024-06-10 18:57:15,982:INFO:                umap: Not installed
2024-06-10 18:57:15,982:INFO:     ydata_profiling: Not installed
2024-06-10 18:57:15,982:INFO:  explainerdashboard: Not installed
2024-06-10 18:57:15,982:INFO:             autoviz: Not installed
2024-06-10 18:57:15,982:INFO:           fairlearn: Not installed
2024-06-10 18:57:15,982:INFO:          deepchecks: Not installed
2024-06-10 18:57:15,982:INFO:             xgboost: Not installed
2024-06-10 18:57:15,982:INFO:            catboost: Not installed
2024-06-10 18:57:15,983:INFO:              kmodes: Not installed
2024-06-10 18:57:15,983:INFO:             mlxtend: Not installed
2024-06-10 18:57:15,983:INFO:       statsforecast: Not installed
2024-06-10 18:57:15,983:INFO:        tune_sklearn: Not installed
2024-06-10 18:57:15,983:INFO:                 ray: Not installed
2024-06-10 18:57:15,983:INFO:            hyperopt: Not installed
2024-06-10 18:57:15,983:INFO:              optuna: Not installed
2024-06-10 18:57:15,983:INFO:               skopt: Not installed
2024-06-10 18:57:15,983:INFO:              mlflow: Not installed
2024-06-10 18:57:15,983:INFO:              gradio: Not installed
2024-06-10 18:57:15,983:INFO:             fastapi: Not installed
2024-06-10 18:57:15,983:INFO:             uvicorn: Not installed
2024-06-10 18:57:15,983:INFO:              m2cgen: Not installed
2024-06-10 18:57:15,983:INFO:           evidently: Not installed
2024-06-10 18:57:15,983:INFO:               fugue: Not installed
2024-06-10 18:57:15,984:INFO:           streamlit: 1.35.0
2024-06-10 18:57:15,984:INFO:             prophet: Not installed
2024-06-10 18:57:15,984:INFO:None
2024-06-10 18:57:15,984:INFO:Set up data.
2024-06-10 18:57:16,019:INFO:Set up folding strategy.
2024-06-10 18:57:16,019:INFO:Set up train/test split.
2024-06-10 18:57:16,040:INFO:Set up index.
2024-06-10 18:57:16,041:INFO:Assigning column types.
2024-06-10 18:57:16,051:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 18:57:16,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:57:16,092:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:57:16,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:57:16,159:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:57:16,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,184:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 18:57:16,227:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:57:16,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,293:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:57:16,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,319:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 18:57:16,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:16,453:INFO:Preparing preprocessing pipeline...
2024-06-10 18:57:16,455:INFO:Set up date feature engineering.
2024-06-10 18:57:16,455:INFO:Set up simple imputation.
2024-06-10 18:57:16,465:INFO:Set up encoding of ordinal features.
2024-06-10 18:57:16,475:INFO:Set up encoding of categorical features.
2024-06-10 18:57:16,476:INFO:Set up removing outliers.
2024-06-10 18:57:16,476:INFO:Set up imbalanced handling.
2024-06-10 18:57:23,313:INFO:PyCaret ClassificationExperiment
2024-06-10 18:57:23,313:INFO:Logging name: clf-default-name
2024-06-10 18:57:23,313:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 18:57:23,314:INFO:version 3.3.2
2024-06-10 18:57:23,314:INFO:Initializing setup()
2024-06-10 18:57:23,314:INFO:self.USI: 3a56
2024-06-10 18:57:23,314:INFO:self._variable_keys: {'_ml_usecase', 'data', 'is_multiclass', 'y_test', 'USI', 'X', 'X_train', 'y_train', 'exp_name_log', 'logging_param', 'X_test', 'target_param', 'gpu_n_jobs_param', 'exp_id', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'memory', 'n_jobs_param', '_available_plots', 'idx', 'seed', 'fold_groups_param', 'fix_imbalance', 'gpu_param', 'pipeline', 'y', 'fold_generator'}
2024-06-10 18:57:23,314:INFO:Checking environment
2024-06-10 18:57:23,314:INFO:python_version: 3.11.9
2024-06-10 18:57:23,314:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-10 18:57:23,314:INFO:machine: AMD64
2024-06-10 18:57:23,314:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 18:57:23,314:INFO:Memory: svmem(total=34056318976, available=25193099264, percent=26.0, used=8863219712, free=25193099264)
2024-06-10 18:57:23,314:INFO:Physical Core: 6
2024-06-10 18:57:23,314:INFO:Logical Core: 12
2024-06-10 18:57:23,314:INFO:Checking libraries
2024-06-10 18:57:23,314:INFO:System:
2024-06-10 18:57:23,314:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-10 18:57:23,314:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-10 18:57:23,314:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 18:57:23,314:INFO:PyCaret required dependencies:
2024-06-10 18:57:23,314:INFO:                 pip: 24.0
2024-06-10 18:57:23,315:INFO:          setuptools: 69.5.1
2024-06-10 18:57:23,315:INFO:             pycaret: 3.3.2
2024-06-10 18:57:23,315:INFO:             IPython: 8.25.0
2024-06-10 18:57:23,315:INFO:          ipywidgets: 8.1.3
2024-06-10 18:57:23,315:INFO:                tqdm: 4.66.4
2024-06-10 18:57:23,315:INFO:               numpy: 1.26.4
2024-06-10 18:57:23,315:INFO:              pandas: 2.1.4
2024-06-10 18:57:23,315:INFO:              jinja2: 3.1.4
2024-06-10 18:57:23,315:INFO:               scipy: 1.11.4
2024-06-10 18:57:23,315:INFO:              joblib: 1.3.2
2024-06-10 18:57:23,315:INFO:             sklearn: 1.4.2
2024-06-10 18:57:23,315:INFO:                pyod: 2.0.0
2024-06-10 18:57:23,315:INFO:            imblearn: 0.12.3
2024-06-10 18:57:23,315:INFO:   category_encoders: 2.6.3
2024-06-10 18:57:23,315:INFO:            lightgbm: 4.3.0
2024-06-10 18:57:23,315:INFO:               numba: 0.59.1
2024-06-10 18:57:23,315:INFO:            requests: 2.32.3
2024-06-10 18:57:23,315:INFO:          matplotlib: 3.7.5
2024-06-10 18:57:23,315:INFO:          scikitplot: 0.3.7
2024-06-10 18:57:23,315:INFO:         yellowbrick: 1.5
2024-06-10 18:57:23,316:INFO:              plotly: 5.22.0
2024-06-10 18:57:23,316:INFO:    plotly-resampler: Not installed
2024-06-10 18:57:23,316:INFO:             kaleido: 0.2.1
2024-06-10 18:57:23,316:INFO:           schemdraw: 0.15
2024-06-10 18:57:23,316:INFO:         statsmodels: 0.14.2
2024-06-10 18:57:23,316:INFO:              sktime: 0.26.0
2024-06-10 18:57:23,316:INFO:               tbats: 1.1.3
2024-06-10 18:57:23,316:INFO:            pmdarima: 2.0.4
2024-06-10 18:57:23,316:INFO:              psutil: 5.9.8
2024-06-10 18:57:23,316:INFO:          markupsafe: 2.1.5
2024-06-10 18:57:23,316:INFO:             pickle5: Not installed
2024-06-10 18:57:23,316:INFO:         cloudpickle: 3.0.0
2024-06-10 18:57:23,316:INFO:         deprecation: 2.1.0
2024-06-10 18:57:23,316:INFO:              xxhash: 3.4.1
2024-06-10 18:57:23,316:INFO:           wurlitzer: Not installed
2024-06-10 18:57:23,316:INFO:PyCaret optional dependencies:
2024-06-10 18:57:23,316:INFO:                shap: Not installed
2024-06-10 18:57:23,316:INFO:           interpret: Not installed
2024-06-10 18:57:23,316:INFO:                umap: Not installed
2024-06-10 18:57:23,316:INFO:     ydata_profiling: Not installed
2024-06-10 18:57:23,317:INFO:  explainerdashboard: Not installed
2024-06-10 18:57:23,317:INFO:             autoviz: Not installed
2024-06-10 18:57:23,317:INFO:           fairlearn: Not installed
2024-06-10 18:57:23,317:INFO:          deepchecks: Not installed
2024-06-10 18:57:23,317:INFO:             xgboost: Not installed
2024-06-10 18:57:23,317:INFO:            catboost: Not installed
2024-06-10 18:57:23,317:INFO:              kmodes: Not installed
2024-06-10 18:57:23,317:INFO:             mlxtend: Not installed
2024-06-10 18:57:23,317:INFO:       statsforecast: Not installed
2024-06-10 18:57:23,317:INFO:        tune_sklearn: Not installed
2024-06-10 18:57:23,317:INFO:                 ray: Not installed
2024-06-10 18:57:23,317:INFO:            hyperopt: Not installed
2024-06-10 18:57:23,317:INFO:              optuna: Not installed
2024-06-10 18:57:23,317:INFO:               skopt: Not installed
2024-06-10 18:57:23,317:INFO:              mlflow: Not installed
2024-06-10 18:57:23,317:INFO:              gradio: Not installed
2024-06-10 18:57:23,317:INFO:             fastapi: Not installed
2024-06-10 18:57:23,317:INFO:             uvicorn: Not installed
2024-06-10 18:57:23,317:INFO:              m2cgen: Not installed
2024-06-10 18:57:23,317:INFO:           evidently: Not installed
2024-06-10 18:57:23,317:INFO:               fugue: Not installed
2024-06-10 18:57:23,318:INFO:           streamlit: 1.35.0
2024-06-10 18:57:23,318:INFO:             prophet: Not installed
2024-06-10 18:57:23,318:INFO:None
2024-06-10 18:57:23,318:INFO:Set up data.
2024-06-10 18:57:23,352:INFO:Set up folding strategy.
2024-06-10 18:57:23,352:INFO:Set up train/test split.
2024-06-10 18:57:23,373:INFO:Set up index.
2024-06-10 18:57:23,375:INFO:Assigning column types.
2024-06-10 18:57:23,384:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 18:57:23,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:57:23,425:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:57:23,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 18:57:23,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:57:23,518:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,519:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 18:57:23,562:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:57:23,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,628:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 18:57:23,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,653:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 18:57:23,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:57:23,796:INFO:Preparing preprocessing pipeline...
2024-06-10 18:57:23,798:INFO:Set up date feature engineering.
2024-06-10 18:57:23,799:INFO:Set up simple imputation.
2024-06-10 18:57:23,809:INFO:Set up encoding of ordinal features.
2024-06-10 18:57:23,820:INFO:Set up encoding of categorical features.
2024-06-10 18:57:23,820:INFO:Set up removing outliers.
2024-06-10 18:57:23,820:INFO:Set up imbalanced handling.
2024-06-10 18:57:23,820:INFO:Set up feature normalization.
2024-06-10 18:57:23,820:INFO:Set up PCA.
2024-06-10 18:58:08,961:INFO:Finished creating preprocessing pipeline.
2024-06-10 18:58:08,995:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                               sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-10 18:58:08,995:INFO:Creating final display dataframe.
2024-06-10 18:58:54,437:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method            SMOTEN
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              3a56
2024-06-10 18:58:54,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:58:54,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:58:54,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:58:54,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 18:58:54,769:INFO:setup() successfully completed in 91.52s...............
2024-06-10 18:59:28,068:INFO:Initializing create_model()
2024-06-10 18:59:28,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F851982910>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 18:59:28,068:INFO:Checking exceptions
2024-06-10 18:59:28,084:INFO:Importing libraries
2024-06-10 18:59:28,084:INFO:Copying training dataset
2024-06-10 18:59:28,103:INFO:Defining folds
2024-06-10 18:59:28,103:INFO:Declaring metric variables
2024-06-10 18:59:28,106:INFO:Importing untrained model
2024-06-10 18:59:28,111:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-10 18:59:28,118:INFO:Starting cross validation
2024-06-10 18:59:28,133:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 19:00:23,711:INFO:Calculating mean and std
2024-06-10 19:00:23,714:INFO:Creating metrics dataframe
2024-06-10 19:00:23,726:INFO:Finalizing model
2024-06-10 19:01:10,932:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-10 19:01:10,932:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004412 seconds.
2024-06-10 19:01:10,932:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-10 19:01:10,932:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-10 19:01:10,932:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-10 19:01:10,932:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-10 19:01:11,212:INFO:Uploading results into container
2024-06-10 19:01:11,214:INFO:Uploading model into container now
2024-06-10 19:01:11,215:INFO:_master_model_container: 1
2024-06-10 19:01:11,215:INFO:_display_container: 2
2024-06-10 19:01:11,215:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-10 19:01:11,215:INFO:create_model() successfully completed......................................
2024-06-10 19:01:11,433:INFO:Initializing tune_model()
2024-06-10 19:01:11,434:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F851982910>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-10 19:01:11,434:INFO:Checking exceptions
2024-06-10 19:01:11,457:INFO:Copying training dataset
2024-06-10 19:01:11,468:INFO:Checking base model
2024-06-10 19:01:11,468:INFO:Base model : Light Gradient Boosting Machine
2024-06-10 19:01:11,474:INFO:Declaring metric variables
2024-06-10 19:01:11,476:INFO:Defining Hyperparameters
2024-06-10 19:01:11,565:INFO:Tuning with n_jobs=-1
2024-06-10 19:01:11,565:INFO:Initializing RandomizedSearchCV
2024-06-11 21:07:02,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:07:02,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:07:02,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:07:02,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:07:03,826:INFO:PyCaret ClassificationExperiment
2024-06-11 21:07:03,826:INFO:Logging name: clf-default-name
2024-06-11 21:07:03,826:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:07:03,826:INFO:version 3.3.2
2024-06-11 21:07:03,827:INFO:Initializing setup()
2024-06-11 21:07:03,827:INFO:self.USI: 9165
2024-06-11 21:07:03,827:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', '_available_plots', 'memory', 'exp_id', 'gpu_param', 'X_test', 'y_train', 'USI', 'fold_groups_param', 'logging_param', 'log_plots_param', 'fold_shuffle_param', 'pipeline', '_ml_usecase', 'idx', 'seed', 'data', 'target_param', 'html_param', 'fix_imbalance', 'X', 'y', 'fold_generator', 'is_multiclass', 'n_jobs_param', 'X_train', 'exp_name_log'}
2024-06-11 21:07:03,827:INFO:Checking environment
2024-06-11 21:07:03,827:INFO:python_version: 3.11.9
2024-06-11 21:07:03,827:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:07:03,827:INFO:machine: AMD64
2024-06-11 21:07:03,827:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:07:03,827:INFO:Memory: svmem(total=34056318976, available=26279260160, percent=22.8, used=7777058816, free=26279260160)
2024-06-11 21:07:03,827:INFO:Physical Core: 6
2024-06-11 21:07:03,827:INFO:Logical Core: 12
2024-06-11 21:07:03,827:INFO:Checking libraries
2024-06-11 21:07:03,827:INFO:System:
2024-06-11 21:07:03,827:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:07:03,827:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:07:03,827:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:07:03,827:INFO:PyCaret required dependencies:
2024-06-11 21:07:03,857:INFO:                 pip: 24.0
2024-06-11 21:07:03,857:INFO:          setuptools: 69.5.1
2024-06-11 21:07:03,857:INFO:             pycaret: 3.3.2
2024-06-11 21:07:03,857:INFO:             IPython: 8.25.0
2024-06-11 21:07:03,857:INFO:          ipywidgets: 8.1.3
2024-06-11 21:07:03,857:INFO:                tqdm: 4.66.4
2024-06-11 21:07:03,857:INFO:               numpy: 1.26.4
2024-06-11 21:07:03,857:INFO:              pandas: 2.1.4
2024-06-11 21:07:03,857:INFO:              jinja2: 3.1.4
2024-06-11 21:07:03,857:INFO:               scipy: 1.11.4
2024-06-11 21:07:03,857:INFO:              joblib: 1.3.2
2024-06-11 21:07:03,857:INFO:             sklearn: 1.4.2
2024-06-11 21:07:03,857:INFO:                pyod: 2.0.0
2024-06-11 21:07:03,857:INFO:            imblearn: 0.12.3
2024-06-11 21:07:03,857:INFO:   category_encoders: 2.6.3
2024-06-11 21:07:03,857:INFO:            lightgbm: 4.3.0
2024-06-11 21:07:03,857:INFO:               numba: 0.59.1
2024-06-11 21:07:03,857:INFO:            requests: 2.32.3
2024-06-11 21:07:03,857:INFO:          matplotlib: 3.7.5
2024-06-11 21:07:03,858:INFO:          scikitplot: 0.3.7
2024-06-11 21:07:03,858:INFO:         yellowbrick: 1.5
2024-06-11 21:07:03,858:INFO:              plotly: 5.22.0
2024-06-11 21:07:03,858:INFO:    plotly-resampler: Not installed
2024-06-11 21:07:03,858:INFO:             kaleido: 0.2.1
2024-06-11 21:07:03,858:INFO:           schemdraw: 0.15
2024-06-11 21:07:03,858:INFO:         statsmodels: 0.14.2
2024-06-11 21:07:03,858:INFO:              sktime: 0.26.0
2024-06-11 21:07:03,858:INFO:               tbats: 1.1.3
2024-06-11 21:07:03,858:INFO:            pmdarima: 2.0.4
2024-06-11 21:07:03,858:INFO:              psutil: 5.9.8
2024-06-11 21:07:03,858:INFO:          markupsafe: 2.1.5
2024-06-11 21:07:03,858:INFO:             pickle5: Not installed
2024-06-11 21:07:03,858:INFO:         cloudpickle: 3.0.0
2024-06-11 21:07:03,858:INFO:         deprecation: 2.1.0
2024-06-11 21:07:03,858:INFO:              xxhash: 3.4.1
2024-06-11 21:07:03,858:INFO:           wurlitzer: Not installed
2024-06-11 21:07:03,858:INFO:PyCaret optional dependencies:
2024-06-11 21:07:03,868:INFO:                shap: Not installed
2024-06-11 21:07:03,868:INFO:           interpret: Not installed
2024-06-11 21:07:03,868:INFO:                umap: Not installed
2024-06-11 21:07:03,868:INFO:     ydata_profiling: Not installed
2024-06-11 21:07:03,868:INFO:  explainerdashboard: Not installed
2024-06-11 21:07:03,868:INFO:             autoviz: Not installed
2024-06-11 21:07:03,869:INFO:           fairlearn: Not installed
2024-06-11 21:07:03,869:INFO:          deepchecks: Not installed
2024-06-11 21:07:03,869:INFO:             xgboost: Not installed
2024-06-11 21:07:03,869:INFO:            catboost: Not installed
2024-06-11 21:07:03,869:INFO:              kmodes: Not installed
2024-06-11 21:07:03,869:INFO:             mlxtend: Not installed
2024-06-11 21:07:03,869:INFO:       statsforecast: Not installed
2024-06-11 21:07:03,869:INFO:        tune_sklearn: Not installed
2024-06-11 21:07:03,869:INFO:                 ray: Not installed
2024-06-11 21:07:03,869:INFO:            hyperopt: Not installed
2024-06-11 21:07:03,869:INFO:              optuna: Not installed
2024-06-11 21:07:03,869:INFO:               skopt: Not installed
2024-06-11 21:07:03,869:INFO:              mlflow: Not installed
2024-06-11 21:07:03,869:INFO:              gradio: Not installed
2024-06-11 21:07:03,869:INFO:             fastapi: Not installed
2024-06-11 21:07:03,869:INFO:             uvicorn: Not installed
2024-06-11 21:07:03,869:INFO:              m2cgen: Not installed
2024-06-11 21:07:03,869:INFO:           evidently: Not installed
2024-06-11 21:07:03,869:INFO:               fugue: Not installed
2024-06-11 21:07:03,869:INFO:           streamlit: 1.35.0
2024-06-11 21:07:03,869:INFO:             prophet: Not installed
2024-06-11 21:07:03,869:INFO:None
2024-06-11 21:07:03,869:INFO:Set up data.
2024-06-11 21:07:03,909:INFO:Set up folding strategy.
2024-06-11 21:07:03,909:INFO:Set up train/test split.
2024-06-11 21:07:03,939:INFO:Set up index.
2024-06-11 21:07:03,940:INFO:Assigning column types.
2024-06-11 21:07:03,950:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:07:03,989:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:07:03,992:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:07:04,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:07:04,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:07:04,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,089:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:07:04,130:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:07:04,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,195:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:07:04,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,221:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:07:04,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:04,355:INFO:Preparing preprocessing pipeline...
2024-06-11 21:07:04,358:INFO:Set up date feature engineering.
2024-06-11 21:07:04,358:INFO:Set up simple imputation.
2024-06-11 21:07:04,369:INFO:Set up encoding of ordinal features.
2024-06-11 21:07:04,379:INFO:Set up encoding of categorical features.
2024-06-11 21:07:04,379:INFO:Set up removing outliers.
2024-06-11 21:07:04,379:INFO:Set up imbalanced handling.
2024-06-11 21:07:04,379:INFO:Set up feature normalization.
2024-06-11 21:07:04,379:INFO:Set up PCA.
2024-06-11 21:07:04,873:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:07:04,907:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                               sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-11 21:07:04,907:INFO:Creating final display dataframe.
2024-06-11 21:07:05,650:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method            SMOTEN
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              9165
2024-06-11 21:07:05,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:05,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:05,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:05,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:07:05,806:INFO:setup() successfully completed in 2.14s...............
2024-06-11 21:07:05,822:INFO:Initializing create_model()
2024-06-11 21:07:05,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CF0234910>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:07:05,822:INFO:Checking exceptions
2024-06-11 21:07:05,851:INFO:Importing libraries
2024-06-11 21:07:05,851:INFO:Copying training dataset
2024-06-11 21:07:05,871:INFO:Defining folds
2024-06-11 21:07:05,872:INFO:Declaring metric variables
2024-06-11 21:07:05,875:INFO:Importing untrained model
2024-06-11 21:07:05,878:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:07:05,885:INFO:Starting cross validation
2024-06-11 21:07:05,887:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:08:08,147:INFO:Calculating mean and std
2024-06-11 21:08:08,148:INFO:Creating metrics dataframe
2024-06-11 21:08:08,157:INFO:Finalizing model
2024-06-11 21:08:55,680:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:08:55,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005225 seconds.
2024-06-11 21:08:55,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:08:55,686:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:08:55,687:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:08:55,687:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:08:56,001:INFO:Uploading results into container
2024-06-11 21:08:56,002:INFO:Uploading model into container now
2024-06-11 21:08:56,013:INFO:_master_model_container: 1
2024-06-11 21:08:56,014:INFO:_display_container: 2
2024-06-11 21:08:56,015:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:08:56,015:INFO:create_model() successfully completed......................................
2024-06-11 21:08:56,129:INFO:Initializing tune_model()
2024-06-11 21:08:56,129:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012CF0234910>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:08:56,129:INFO:Checking exceptions
2024-06-11 21:08:56,159:INFO:Copying training dataset
2024-06-11 21:08:56,173:INFO:Checking base model
2024-06-11 21:08:56,173:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:08:56,177:INFO:Declaring metric variables
2024-06-11 21:08:56,181:INFO:Defining Hyperparameters
2024-06-11 21:08:56,251:INFO:Tuning with n_jobs=-1
2024-06-11 21:08:56,251:INFO:Initializing RandomizedSearchCV
2024-06-11 21:12:57,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:12:57,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:12:57,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:12:57,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:12:58,418:INFO:PyCaret ClassificationExperiment
2024-06-11 21:12:58,419:INFO:Logging name: clf-default-name
2024-06-11 21:12:58,419:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:12:58,419:INFO:version 3.3.2
2024-06-11 21:12:58,419:INFO:Initializing setup()
2024-06-11 21:12:58,419:INFO:self.USI: 3e7c
2024-06-11 21:12:58,419:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:12:58,419:INFO:Checking environment
2024-06-11 21:12:58,419:INFO:python_version: 3.11.9
2024-06-11 21:12:58,419:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:12:58,419:INFO:machine: AMD64
2024-06-11 21:12:58,419:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:12:58,419:INFO:Memory: svmem(total=34056318976, available=25795862528, percent=24.3, used=8260456448, free=25795862528)
2024-06-11 21:12:58,419:INFO:Physical Core: 6
2024-06-11 21:12:58,419:INFO:Logical Core: 12
2024-06-11 21:12:58,419:INFO:Checking libraries
2024-06-11 21:12:58,420:INFO:System:
2024-06-11 21:12:58,420:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:12:58,420:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:12:58,420:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:12:58,420:INFO:PyCaret required dependencies:
2024-06-11 21:12:58,449:INFO:                 pip: 24.0
2024-06-11 21:12:58,449:INFO:          setuptools: 69.5.1
2024-06-11 21:12:58,449:INFO:             pycaret: 3.3.2
2024-06-11 21:12:58,449:INFO:             IPython: 8.25.0
2024-06-11 21:12:58,449:INFO:          ipywidgets: 8.1.3
2024-06-11 21:12:58,449:INFO:                tqdm: 4.66.4
2024-06-11 21:12:58,449:INFO:               numpy: 1.26.4
2024-06-11 21:12:58,449:INFO:              pandas: 2.1.4
2024-06-11 21:12:58,449:INFO:              jinja2: 3.1.4
2024-06-11 21:12:58,449:INFO:               scipy: 1.11.4
2024-06-11 21:12:58,449:INFO:              joblib: 1.3.2
2024-06-11 21:12:58,450:INFO:             sklearn: 1.4.2
2024-06-11 21:12:58,450:INFO:                pyod: 2.0.0
2024-06-11 21:12:58,450:INFO:            imblearn: 0.12.3
2024-06-11 21:12:58,450:INFO:   category_encoders: 2.6.3
2024-06-11 21:12:58,450:INFO:            lightgbm: 4.3.0
2024-06-11 21:12:58,450:INFO:               numba: 0.59.1
2024-06-11 21:12:58,450:INFO:            requests: 2.32.3
2024-06-11 21:12:58,450:INFO:          matplotlib: 3.7.5
2024-06-11 21:12:58,450:INFO:          scikitplot: 0.3.7
2024-06-11 21:12:58,450:INFO:         yellowbrick: 1.5
2024-06-11 21:12:58,450:INFO:              plotly: 5.22.0
2024-06-11 21:12:58,450:INFO:    plotly-resampler: Not installed
2024-06-11 21:12:58,450:INFO:             kaleido: 0.2.1
2024-06-11 21:12:58,450:INFO:           schemdraw: 0.15
2024-06-11 21:12:58,450:INFO:         statsmodels: 0.14.2
2024-06-11 21:12:58,450:INFO:              sktime: 0.26.0
2024-06-11 21:12:58,450:INFO:               tbats: 1.1.3
2024-06-11 21:12:58,450:INFO:            pmdarima: 2.0.4
2024-06-11 21:12:58,450:INFO:              psutil: 5.9.8
2024-06-11 21:12:58,450:INFO:          markupsafe: 2.1.5
2024-06-11 21:12:58,450:INFO:             pickle5: Not installed
2024-06-11 21:12:58,451:INFO:         cloudpickle: 3.0.0
2024-06-11 21:12:58,451:INFO:         deprecation: 2.1.0
2024-06-11 21:12:58,451:INFO:              xxhash: 3.4.1
2024-06-11 21:12:58,451:INFO:           wurlitzer: Not installed
2024-06-11 21:12:58,451:INFO:PyCaret optional dependencies:
2024-06-11 21:12:58,462:INFO:                shap: Not installed
2024-06-11 21:12:58,462:INFO:           interpret: Not installed
2024-06-11 21:12:58,462:INFO:                umap: Not installed
2024-06-11 21:12:58,462:INFO:     ydata_profiling: Not installed
2024-06-11 21:12:58,462:INFO:  explainerdashboard: Not installed
2024-06-11 21:12:58,462:INFO:             autoviz: Not installed
2024-06-11 21:12:58,462:INFO:           fairlearn: Not installed
2024-06-11 21:12:58,462:INFO:          deepchecks: Not installed
2024-06-11 21:12:58,462:INFO:             xgboost: Not installed
2024-06-11 21:12:58,462:INFO:            catboost: Not installed
2024-06-11 21:12:58,462:INFO:              kmodes: Not installed
2024-06-11 21:12:58,462:INFO:             mlxtend: Not installed
2024-06-11 21:12:58,462:INFO:       statsforecast: Not installed
2024-06-11 21:12:58,462:INFO:        tune_sklearn: Not installed
2024-06-11 21:12:58,462:INFO:                 ray: Not installed
2024-06-11 21:12:58,462:INFO:            hyperopt: Not installed
2024-06-11 21:12:58,462:INFO:              optuna: Not installed
2024-06-11 21:12:58,463:INFO:               skopt: Not installed
2024-06-11 21:12:58,463:INFO:              mlflow: Not installed
2024-06-11 21:12:58,463:INFO:              gradio: Not installed
2024-06-11 21:12:58,463:INFO:             fastapi: Not installed
2024-06-11 21:12:58,463:INFO:             uvicorn: Not installed
2024-06-11 21:12:58,463:INFO:              m2cgen: Not installed
2024-06-11 21:12:58,463:INFO:           evidently: Not installed
2024-06-11 21:12:58,463:INFO:               fugue: Not installed
2024-06-11 21:12:58,463:INFO:           streamlit: 1.35.0
2024-06-11 21:12:58,463:INFO:             prophet: Not installed
2024-06-11 21:12:58,463:INFO:None
2024-06-11 21:12:58,463:INFO:Set up data.
2024-06-11 21:12:58,504:INFO:Set up folding strategy.
2024-06-11 21:12:58,504:INFO:Set up train/test split.
2024-06-11 21:12:58,532:INFO:Set up index.
2024-06-11 21:12:58,533:INFO:Assigning column types.
2024-06-11 21:12:58,544:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:12:58,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:12:58,597:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:12:58,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:58,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:58,682:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:12:58,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:12:58,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:58,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:58,711:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:12:58,760:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:12:58,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:58,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:58,833:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:12:58,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:58,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:58,860:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:12:58,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:58,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:59,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:59,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:12:59,012:INFO:Preparing preprocessing pipeline...
2024-06-11 21:12:59,014:INFO:Set up date feature engineering.
2024-06-11 21:12:59,014:INFO:Set up simple imputation.
2024-06-11 21:12:59,025:INFO:Set up encoding of ordinal features.
2024-06-11 21:12:59,035:INFO:Set up encoding of categorical features.
2024-06-11 21:12:59,035:INFO:Set up removing outliers.
2024-06-11 21:12:59,035:INFO:Set up imbalanced handling.
2024-06-11 21:12:59,035:INFO:Set up feature normalization.
2024-06-11 21:12:59,035:INFO:Set up PCA.
2024-06-11 21:12:59,844:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:12:59,879:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                                          shrinkage=None)))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-11 21:12:59,879:INFO:Creating final display dataframe.
2024-06-11 21:13:00,713:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target                mau
2                   Target type             Binary
3           Original data shape        (50000, 15)
4        Transformed data shape        (76226, 34)
5   Transformed train set shape        (61226, 34)
6    Transformed test set shape        (15000, 34)
7              Numeric features                  6
8                 Date features                  1
9          Categorical features                  7
10     Rows with missing values              17.1%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation                 -1
14       Categorical imputation               mode
15     Maximum one-hot encoding                 25
16              Encoding method               None
17              Remove outliers               True
18           Outliers threshold               0.05
19                Fix imbalance               True
20         Fix imbalance method  RandomOverSampler
21                    Normalize               True
22             Normalize method             robust
23                          PCA               True
24                   PCA method        incremental
25               PCA components               None
26               Fold Generator    StratifiedKFold
27                  Fold Number                 10
28                     CPU Jobs                 -1
29                      Use GPU              False
30               Log Experiment              False
31              Experiment Name   clf-default-name
32                          USI               3e7c
2024-06-11 21:13:00,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:13:00,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:13:00,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:13:00,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:13:00,864:INFO:setup() successfully completed in 2.51s...............
2024-06-11 21:13:00,879:INFO:Initializing create_model()
2024-06-11 21:13:00,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:13:00,880:INFO:Checking exceptions
2024-06-11 21:13:00,897:INFO:Importing libraries
2024-06-11 21:13:00,897:INFO:Copying training dataset
2024-06-11 21:13:00,918:INFO:Defining folds
2024-06-11 21:13:00,919:INFO:Declaring metric variables
2024-06-11 21:13:00,922:INFO:Importing untrained model
2024-06-11 21:13:00,925:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:13:00,932:INFO:Starting cross validation
2024-06-11 21:13:00,934:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:13:08,406:INFO:Calculating mean and std
2024-06-11 21:13:08,407:INFO:Creating metrics dataframe
2024-06-11 21:13:08,417:INFO:Finalizing model
2024-06-11 21:13:09,845:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:13:09,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005207 seconds.
2024-06-11 21:13:09,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:13:09,852:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:13:09,852:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:13:09,853:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:13:10,121:INFO:Uploading results into container
2024-06-11 21:13:10,122:INFO:Uploading model into container now
2024-06-11 21:13:10,133:INFO:_master_model_container: 1
2024-06-11 21:13:10,134:INFO:_display_container: 2
2024-06-11 21:13:10,135:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:13:10,135:INFO:create_model() successfully completed......................................
2024-06-11 21:13:10,263:INFO:Initializing tune_model()
2024-06-11 21:13:10,263:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:13:10,263:INFO:Checking exceptions
2024-06-11 21:13:10,290:INFO:Copying training dataset
2024-06-11 21:13:10,304:INFO:Checking base model
2024-06-11 21:13:10,304:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:13:10,307:INFO:Declaring metric variables
2024-06-11 21:13:10,311:INFO:Defining Hyperparameters
2024-06-11 21:13:10,391:INFO:Tuning with n_jobs=-1
2024-06-11 21:13:10,391:INFO:Initializing RandomizedSearchCV
2024-06-11 21:14:21,342:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 21:14:21,343:INFO:Hyperparameter search completed
2024-06-11 21:14:21,344:INFO:SubProcess create_model() called ==================================
2024-06-11 21:14:21,345:INFO:Initializing create_model()
2024-06-11 21:14:21,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC04400C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 21:14:21,346:INFO:Checking exceptions
2024-06-11 21:14:21,346:INFO:Importing libraries
2024-06-11 21:14:21,346:INFO:Copying training dataset
2024-06-11 21:14:21,389:INFO:Defining folds
2024-06-11 21:14:21,389:INFO:Declaring metric variables
2024-06-11 21:14:21,396:INFO:Importing untrained model
2024-06-11 21:14:21,396:INFO:Declaring custom model
2024-06-11 21:14:21,403:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:14:21,418:INFO:Starting cross validation
2024-06-11 21:14:21,423:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:14:30,598:INFO:Calculating mean and std
2024-06-11 21:14:30,600:INFO:Creating metrics dataframe
2024-06-11 21:14:30,610:INFO:Finalizing model
2024-06-11 21:14:32,026:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:14:32,026:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:14:32,026:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:14:32,132:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:14:32,132:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:14:32,132:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:14:32,132:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:14:32,141:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006982 seconds.
2024-06-11 21:14:32,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:14:32,142:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:14:32,143:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:14:32,146:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:14:33,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:14:33,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:14:33,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:14:33,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:14:33,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:14:33,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:14:33,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:14:33,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:14:33,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:14:33,730:INFO:Uploading results into container
2024-06-11 21:14:33,732:INFO:Uploading model into container now
2024-06-11 21:14:33,733:INFO:_master_model_container: 2
2024-06-11 21:14:33,733:INFO:_display_container: 3
2024-06-11 21:14:33,734:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:14:33,734:INFO:create_model() successfully completed......................................
2024-06-11 21:14:33,852:INFO:SubProcess create_model() end ==================================
2024-06-11 21:14:33,853:INFO:choose_better activated
2024-06-11 21:14:33,856:INFO:SubProcess create_model() called ==================================
2024-06-11 21:14:33,857:INFO:Initializing create_model()
2024-06-11 21:14:33,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:14:33,857:INFO:Checking exceptions
2024-06-11 21:14:33,860:INFO:Importing libraries
2024-06-11 21:14:33,860:INFO:Copying training dataset
2024-06-11 21:14:33,884:INFO:Defining folds
2024-06-11 21:14:33,884:INFO:Declaring metric variables
2024-06-11 21:14:33,885:INFO:Importing untrained model
2024-06-11 21:14:33,885:INFO:Declaring custom model
2024-06-11 21:14:33,885:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:14:33,886:INFO:Starting cross validation
2024-06-11 21:14:33,888:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:14:38,549:INFO:Calculating mean and std
2024-06-11 21:14:38,549:INFO:Creating metrics dataframe
2024-06-11 21:14:38,552:INFO:Finalizing model
2024-06-11 21:14:40,495:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:14:40,503:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008020 seconds.
2024-06-11 21:14:40,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:14:40,504:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:14:40,505:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:14:40,506:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:14:40,961:INFO:Uploading results into container
2024-06-11 21:14:40,962:INFO:Uploading model into container now
2024-06-11 21:14:40,962:INFO:_master_model_container: 3
2024-06-11 21:14:40,962:INFO:_display_container: 4
2024-06-11 21:14:40,963:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:14:40,963:INFO:create_model() successfully completed......................................
2024-06-11 21:14:41,069:INFO:SubProcess create_model() end ==================================
2024-06-11 21:14:41,070:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.1942
2024-06-11 21:14:41,070:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2299
2024-06-11 21:14:41,071:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:14:41,071:INFO:choose_better completed
2024-06-11 21:14:41,081:INFO:_master_model_container: 3
2024-06-11 21:14:41,081:INFO:_display_container: 3
2024-06-11 21:14:41,082:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:14:41,082:INFO:tune_model() successfully completed......................................
2024-06-11 21:14:41,270:INFO:Initializing plot_model()
2024-06-11 21:14:41,270:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:14:41,270:INFO:Checking exceptions
2024-06-11 21:14:41,283:INFO:Preloading libraries
2024-06-11 21:14:41,336:INFO:Copying training dataset
2024-06-11 21:14:41,336:INFO:Plot type: auc
2024-06-11 21:14:41,579:INFO:Fitting Model
2024-06-11 21:14:41,581:INFO:Scoring test/hold-out set
2024-06-11 21:14:41,583:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:14:41,584:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:14:41,584:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:14:41,652:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:14:41,652:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:14:41,652:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:14:42,019:INFO:Visual Rendered Successfully
2024-06-11 21:14:42,098:INFO:plot_model() successfully completed......................................
2024-06-11 21:14:42,136:INFO:Initializing plot_model()
2024-06-11 21:14:42,136:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:14:42,136:INFO:Checking exceptions
2024-06-11 21:14:42,154:INFO:Preloading libraries
2024-06-11 21:14:42,215:INFO:Copying training dataset
2024-06-11 21:14:42,216:INFO:Plot type: confusion_matrix
2024-06-11 21:14:42,442:INFO:Fitting Model
2024-06-11 21:14:42,443:INFO:Scoring test/hold-out set
2024-06-11 21:14:42,445:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:14:42,445:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:14:42,445:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:14:42,525:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:14:42,525:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:14:42,525:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:14:42,767:INFO:Visual Rendered Successfully
2024-06-11 21:14:42,845:INFO:plot_model() successfully completed......................................
2024-06-11 21:14:42,868:INFO:Initializing finalize_model()
2024-06-11 21:14:42,869:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:14:42,871:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:14:42,888:INFO:Initializing create_model()
2024-06-11 21:14:42,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:14:42,890:INFO:Checking exceptions
2024-06-11 21:14:42,891:INFO:Importing libraries
2024-06-11 21:14:42,891:INFO:Copying training dataset
2024-06-11 21:14:42,893:INFO:Defining folds
2024-06-11 21:14:42,893:INFO:Declaring metric variables
2024-06-11 21:14:42,893:INFO:Importing untrained model
2024-06-11 21:14:42,893:INFO:Declaring custom model
2024-06-11 21:14:42,894:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:14:42,898:INFO:Cross validation set to False
2024-06-11 21:14:42,898:INFO:Fitting Model
2024-06-11 21:14:44,682:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:14:44,682:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:14:44,682:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:14:44,809:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:14:44,809:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:14:44,810:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:14:44,810:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-11 21:14:44,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007450 seconds.
2024-06-11 21:14:44,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:14:44,821:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:14:44,822:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-11 21:14:44,825:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:14:46,507:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:14:46,507:INFO:create_model() successfully completed......................................
2024-06-11 21:14:46,587:INFO:_master_model_container: 3
2024-06-11 21:14:46,587:INFO:_display_container: 3
2024-06-11 21:14:46,624:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:14:46,624:INFO:finalize_model() successfully completed......................................
2024-06-11 21:14:46,813:INFO:Initializing evaluate_model()
2024-06-11 21:14:46,814:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:14:46,872:INFO:Initializing plot_model()
2024-06-11 21:14:46,872:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:14:46,872:INFO:Checking exceptions
2024-06-11 21:14:46,878:INFO:Preloading libraries
2024-06-11 21:14:46,929:INFO:Copying training dataset
2024-06-11 21:14:46,929:INFO:Plot type: pipeline
2024-06-11 21:14:47,236:INFO:Visual Rendered Successfully
2024-06-11 21:14:47,308:INFO:plot_model() successfully completed......................................
2024-06-11 21:15:14,313:INFO:Initializing plot_model()
2024-06-11 21:15:14,313:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:15:14,313:INFO:Checking exceptions
2024-06-11 21:15:14,322:INFO:Preloading libraries
2024-06-11 21:15:14,371:INFO:Copying training dataset
2024-06-11 21:15:14,371:INFO:Plot type: auc
2024-06-11 21:15:14,561:INFO:Fitting Model
2024-06-11 21:15:14,563:INFO:Scoring test/hold-out set
2024-06-11 21:15:14,565:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:15:14,565:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:15:14,565:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:15:14,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:15:14,612:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:15:14,612:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:15:14,874:INFO:Visual Rendered Successfully
2024-06-11 21:15:14,958:INFO:plot_model() successfully completed......................................
2024-06-11 21:15:17,026:INFO:Initializing plot_model()
2024-06-11 21:15:17,026:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:15:17,026:INFO:Checking exceptions
2024-06-11 21:15:17,033:INFO:Preloading libraries
2024-06-11 21:15:17,069:INFO:Copying training dataset
2024-06-11 21:15:17,069:INFO:Plot type: confusion_matrix
2024-06-11 21:15:17,260:INFO:Fitting Model
2024-06-11 21:15:17,261:INFO:Scoring test/hold-out set
2024-06-11 21:15:17,263:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:15:17,263:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:15:17,263:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:15:17,311:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:15:17,311:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:15:17,311:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:15:17,503:INFO:Visual Rendered Successfully
2024-06-11 21:15:17,579:INFO:plot_model() successfully completed......................................
2024-06-11 21:15:39,972:INFO:Initializing tune_model()
2024-06-11 21:15:39,972:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:15:39,972:INFO:Checking exceptions
2024-06-11 21:15:39,997:INFO:Copying training dataset
2024-06-11 21:15:40,010:INFO:Checking base model
2024-06-11 21:15:40,010:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:15:40,015:INFO:Declaring metric variables
2024-06-11 21:15:40,019:INFO:Defining Hyperparameters
2024-06-11 21:15:40,104:INFO:Tuning with n_jobs=-1
2024-06-11 21:15:40,104:INFO:Initializing RandomizedSearchCV
2024-06-11 21:16:37,063:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 21:16:37,064:INFO:Hyperparameter search completed
2024-06-11 21:16:37,065:INFO:SubProcess create_model() called ==================================
2024-06-11 21:16:37,066:INFO:Initializing create_model()
2024-06-11 21:16:37,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC3881EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 21:16:37,067:INFO:Checking exceptions
2024-06-11 21:16:37,067:INFO:Importing libraries
2024-06-11 21:16:37,067:INFO:Copying training dataset
2024-06-11 21:16:37,103:INFO:Defining folds
2024-06-11 21:16:37,104:INFO:Declaring metric variables
2024-06-11 21:16:37,108:INFO:Importing untrained model
2024-06-11 21:16:37,108:INFO:Declaring custom model
2024-06-11 21:16:37,115:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:16:37,126:INFO:Starting cross validation
2024-06-11 21:16:37,133:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:16:46,643:INFO:Calculating mean and std
2024-06-11 21:16:46,645:INFO:Creating metrics dataframe
2024-06-11 21:16:46,652:INFO:Finalizing model
2024-06-11 21:16:47,936:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:16:47,936:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:16:47,936:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:16:48,007:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:16:48,007:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:16:48,007:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:16:48,007:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:16:48,012:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003698 seconds.
2024-06-11 21:16:48,012:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:16:48,012:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:16:48,013:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:16:48,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:16:48,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:16:48,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:16:48,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:16:48,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:16:48,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:16:48,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:16:48,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:16:48,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:16:48,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:16:49,052:INFO:Uploading results into container
2024-06-11 21:16:49,054:INFO:Uploading model into container now
2024-06-11 21:16:49,055:INFO:_master_model_container: 4
2024-06-11 21:16:49,055:INFO:_display_container: 4
2024-06-11 21:16:49,057:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:16:49,057:INFO:create_model() successfully completed......................................
2024-06-11 21:16:49,153:INFO:SubProcess create_model() end ==================================
2024-06-11 21:16:49,153:INFO:choose_better activated
2024-06-11 21:16:49,157:INFO:SubProcess create_model() called ==================================
2024-06-11 21:16:49,157:INFO:Initializing create_model()
2024-06-11 21:16:49,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:16:49,158:INFO:Checking exceptions
2024-06-11 21:16:49,159:INFO:Importing libraries
2024-06-11 21:16:49,160:INFO:Copying training dataset
2024-06-11 21:16:49,180:INFO:Defining folds
2024-06-11 21:16:49,180:INFO:Declaring metric variables
2024-06-11 21:16:49,180:INFO:Importing untrained model
2024-06-11 21:16:49,180:INFO:Declaring custom model
2024-06-11 21:16:49,181:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:16:49,181:INFO:Starting cross validation
2024-06-11 21:16:49,184:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:16:52,812:INFO:Calculating mean and std
2024-06-11 21:16:52,812:INFO:Creating metrics dataframe
2024-06-11 21:16:52,815:INFO:Finalizing model
2024-06-11 21:16:54,179:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:16:54,185:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005856 seconds.
2024-06-11 21:16:54,185:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:16:54,186:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:16:54,186:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:16:54,187:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:16:54,422:INFO:Uploading results into container
2024-06-11 21:16:54,422:INFO:Uploading model into container now
2024-06-11 21:16:54,423:INFO:_master_model_container: 5
2024-06-11 21:16:54,423:INFO:_display_container: 5
2024-06-11 21:16:54,424:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:16:54,424:INFO:create_model() successfully completed......................................
2024-06-11 21:16:54,511:INFO:SubProcess create_model() end ==================================
2024-06-11 21:16:54,512:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7797
2024-06-11 21:16:54,512:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8594
2024-06-11 21:16:54,513:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:16:54,513:INFO:choose_better completed
2024-06-11 21:16:54,522:INFO:_master_model_container: 5
2024-06-11 21:16:54,522:INFO:_display_container: 4
2024-06-11 21:16:54,523:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:16:54,523:INFO:tune_model() successfully completed......................................
2024-06-11 21:16:54,641:INFO:Initializing plot_model()
2024-06-11 21:16:54,641:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:16:54,641:INFO:Checking exceptions
2024-06-11 21:16:54,652:INFO:Preloading libraries
2024-06-11 21:16:54,697:INFO:Copying training dataset
2024-06-11 21:16:54,698:INFO:Plot type: auc
2024-06-11 21:16:54,888:INFO:Fitting Model
2024-06-11 21:16:54,890:INFO:Scoring test/hold-out set
2024-06-11 21:16:54,892:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:16:54,892:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:16:54,892:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:16:54,977:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:16:54,977:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:16:54,977:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:16:55,273:INFO:Visual Rendered Successfully
2024-06-11 21:16:55,354:INFO:plot_model() successfully completed......................................
2024-06-11 21:16:55,370:INFO:Initializing plot_model()
2024-06-11 21:16:55,371:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:16:55,371:INFO:Checking exceptions
2024-06-11 21:16:55,381:INFO:Preloading libraries
2024-06-11 21:16:55,422:INFO:Copying training dataset
2024-06-11 21:16:55,423:INFO:Plot type: confusion_matrix
2024-06-11 21:16:55,607:INFO:Fitting Model
2024-06-11 21:16:55,608:INFO:Scoring test/hold-out set
2024-06-11 21:16:55,610:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:16:55,610:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:16:55,610:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:16:55,684:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:16:55,684:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:16:55,684:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:16:55,885:INFO:Visual Rendered Successfully
2024-06-11 21:16:55,961:INFO:plot_model() successfully completed......................................
2024-06-11 21:16:55,974:INFO:Initializing finalize_model()
2024-06-11 21:16:55,974:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:16:55,975:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:16:55,986:INFO:Initializing create_model()
2024-06-11 21:16:55,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:16:55,986:INFO:Checking exceptions
2024-06-11 21:16:55,987:INFO:Importing libraries
2024-06-11 21:16:55,987:INFO:Copying training dataset
2024-06-11 21:16:55,988:INFO:Defining folds
2024-06-11 21:16:55,988:INFO:Declaring metric variables
2024-06-11 21:16:55,989:INFO:Importing untrained model
2024-06-11 21:16:55,989:INFO:Declaring custom model
2024-06-11 21:16:55,989:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:16:55,992:INFO:Cross validation set to False
2024-06-11 21:16:55,992:INFO:Fitting Model
2024-06-11 21:16:57,792:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:16:57,792:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:16:57,793:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:16:57,911:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:16:57,911:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:16:57,911:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:16:57,911:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-11 21:16:57,921:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007641 seconds.
2024-06-11 21:16:57,921:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:16:57,921:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:16:57,923:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-11 21:16:57,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:16:59,632:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:16:59,632:INFO:create_model() successfully completed......................................
2024-06-11 21:16:59,714:INFO:_master_model_container: 5
2024-06-11 21:16:59,714:INFO:_display_container: 4
2024-06-11 21:16:59,753:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:16:59,754:INFO:finalize_model() successfully completed......................................
2024-06-11 21:16:59,941:INFO:Initializing evaluate_model()
2024-06-11 21:16:59,941:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:17:00,001:INFO:Initializing plot_model()
2024-06-11 21:17:00,001:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:17:00,001:INFO:Checking exceptions
2024-06-11 21:17:00,008:INFO:Preloading libraries
2024-06-11 21:17:00,063:INFO:Copying training dataset
2024-06-11 21:17:00,063:INFO:Plot type: pipeline
2024-06-11 21:17:00,332:INFO:Visual Rendered Successfully
2024-06-11 21:17:00,417:INFO:plot_model() successfully completed......................................
2024-06-11 21:17:03,843:INFO:Initializing plot_model()
2024-06-11 21:17:03,843:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:17:03,843:INFO:Checking exceptions
2024-06-11 21:17:03,852:INFO:Preloading libraries
2024-06-11 21:17:03,907:INFO:Copying training dataset
2024-06-11 21:17:03,907:INFO:Plot type: auc
2024-06-11 21:17:04,106:INFO:Fitting Model
2024-06-11 21:17:04,107:INFO:Scoring test/hold-out set
2024-06-11 21:17:04,109:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:17:04,110:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:17:04,110:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:17:04,176:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:17:04,176:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:17:04,176:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:17:04,457:INFO:Visual Rendered Successfully
2024-06-11 21:17:04,537:INFO:plot_model() successfully completed......................................
2024-06-11 21:17:06,421:INFO:Initializing plot_model()
2024-06-11 21:17:06,421:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC385074D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:17:06,421:INFO:Checking exceptions
2024-06-11 21:17:06,427:INFO:Preloading libraries
2024-06-11 21:17:06,470:INFO:Copying training dataset
2024-06-11 21:17:06,470:INFO:Plot type: confusion_matrix
2024-06-11 21:17:06,662:INFO:Fitting Model
2024-06-11 21:17:06,663:INFO:Scoring test/hold-out set
2024-06-11 21:17:06,665:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:17:06,665:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:17:06,665:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:17:06,722:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:17:06,722:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:17:06,722:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:17:06,908:INFO:Visual Rendered Successfully
2024-06-11 21:17:07,014:INFO:plot_model() successfully completed......................................
2024-06-11 21:17:44,416:INFO:PyCaret ClassificationExperiment
2024-06-11 21:17:44,416:INFO:Logging name: clf-default-name
2024-06-11 21:17:44,416:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:17:44,416:INFO:version 3.3.2
2024-06-11 21:17:44,416:INFO:Initializing setup()
2024-06-11 21:17:44,417:INFO:self.USI: be73
2024-06-11 21:17:44,417:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:17:44,417:INFO:Checking environment
2024-06-11 21:17:44,417:INFO:python_version: 3.11.9
2024-06-11 21:17:44,417:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:17:44,417:INFO:machine: AMD64
2024-06-11 21:17:44,417:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:17:44,417:INFO:Memory: svmem(total=34056318976, available=23775526912, percent=30.2, used=10280792064, free=23775526912)
2024-06-11 21:17:44,417:INFO:Physical Core: 6
2024-06-11 21:17:44,417:INFO:Logical Core: 12
2024-06-11 21:17:44,417:INFO:Checking libraries
2024-06-11 21:17:44,417:INFO:System:
2024-06-11 21:17:44,417:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:17:44,417:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:17:44,417:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:17:44,417:INFO:PyCaret required dependencies:
2024-06-11 21:17:44,418:INFO:                 pip: 24.0
2024-06-11 21:17:44,418:INFO:          setuptools: 69.5.1
2024-06-11 21:17:44,418:INFO:             pycaret: 3.3.2
2024-06-11 21:17:44,418:INFO:             IPython: 8.25.0
2024-06-11 21:17:44,418:INFO:          ipywidgets: 8.1.3
2024-06-11 21:17:44,418:INFO:                tqdm: 4.66.4
2024-06-11 21:17:44,418:INFO:               numpy: 1.26.4
2024-06-11 21:17:44,418:INFO:              pandas: 2.1.4
2024-06-11 21:17:44,418:INFO:              jinja2: 3.1.4
2024-06-11 21:17:44,418:INFO:               scipy: 1.11.4
2024-06-11 21:17:44,418:INFO:              joblib: 1.3.2
2024-06-11 21:17:44,418:INFO:             sklearn: 1.4.2
2024-06-11 21:17:44,418:INFO:                pyod: 2.0.0
2024-06-11 21:17:44,418:INFO:            imblearn: 0.12.3
2024-06-11 21:17:44,418:INFO:   category_encoders: 2.6.3
2024-06-11 21:17:44,418:INFO:            lightgbm: 4.3.0
2024-06-11 21:17:44,418:INFO:               numba: 0.59.1
2024-06-11 21:17:44,418:INFO:            requests: 2.32.3
2024-06-11 21:17:44,418:INFO:          matplotlib: 3.7.5
2024-06-11 21:17:44,418:INFO:          scikitplot: 0.3.7
2024-06-11 21:17:44,419:INFO:         yellowbrick: 1.5
2024-06-11 21:17:44,419:INFO:              plotly: 5.22.0
2024-06-11 21:17:44,419:INFO:    plotly-resampler: Not installed
2024-06-11 21:17:44,419:INFO:             kaleido: 0.2.1
2024-06-11 21:17:44,419:INFO:           schemdraw: 0.15
2024-06-11 21:17:44,419:INFO:         statsmodels: 0.14.2
2024-06-11 21:17:44,419:INFO:              sktime: 0.26.0
2024-06-11 21:17:44,419:INFO:               tbats: 1.1.3
2024-06-11 21:17:44,419:INFO:            pmdarima: 2.0.4
2024-06-11 21:17:44,419:INFO:              psutil: 5.9.8
2024-06-11 21:17:44,419:INFO:          markupsafe: 2.1.5
2024-06-11 21:17:44,419:INFO:             pickle5: Not installed
2024-06-11 21:17:44,419:INFO:         cloudpickle: 3.0.0
2024-06-11 21:17:44,419:INFO:         deprecation: 2.1.0
2024-06-11 21:17:44,419:INFO:              xxhash: 3.4.1
2024-06-11 21:17:44,419:INFO:           wurlitzer: Not installed
2024-06-11 21:17:44,419:INFO:PyCaret optional dependencies:
2024-06-11 21:17:44,419:INFO:                shap: Not installed
2024-06-11 21:17:44,419:INFO:           interpret: Not installed
2024-06-11 21:17:44,419:INFO:                umap: Not installed
2024-06-11 21:17:44,420:INFO:     ydata_profiling: Not installed
2024-06-11 21:17:44,420:INFO:  explainerdashboard: Not installed
2024-06-11 21:17:44,420:INFO:             autoviz: Not installed
2024-06-11 21:17:44,420:INFO:           fairlearn: Not installed
2024-06-11 21:17:44,420:INFO:          deepchecks: Not installed
2024-06-11 21:17:44,420:INFO:             xgboost: Not installed
2024-06-11 21:17:44,420:INFO:            catboost: Not installed
2024-06-11 21:17:44,420:INFO:              kmodes: Not installed
2024-06-11 21:17:44,420:INFO:             mlxtend: Not installed
2024-06-11 21:17:44,420:INFO:       statsforecast: Not installed
2024-06-11 21:17:44,420:INFO:        tune_sklearn: Not installed
2024-06-11 21:17:44,420:INFO:                 ray: Not installed
2024-06-11 21:17:44,420:INFO:            hyperopt: Not installed
2024-06-11 21:17:44,420:INFO:              optuna: Not installed
2024-06-11 21:17:44,420:INFO:               skopt: Not installed
2024-06-11 21:17:44,420:INFO:              mlflow: Not installed
2024-06-11 21:17:44,420:INFO:              gradio: Not installed
2024-06-11 21:17:44,420:INFO:             fastapi: Not installed
2024-06-11 21:17:44,420:INFO:             uvicorn: Not installed
2024-06-11 21:17:44,420:INFO:              m2cgen: Not installed
2024-06-11 21:17:44,420:INFO:           evidently: Not installed
2024-06-11 21:17:44,421:INFO:               fugue: Not installed
2024-06-11 21:17:44,421:INFO:           streamlit: 1.35.0
2024-06-11 21:17:44,421:INFO:             prophet: Not installed
2024-06-11 21:17:44,421:INFO:None
2024-06-11 21:17:44,421:INFO:Set up data.
2024-06-11 21:17:44,459:INFO:Set up folding strategy.
2024-06-11 21:17:44,459:INFO:Set up train/test split.
2024-06-11 21:17:44,495:INFO:Set up index.
2024-06-11 21:17:44,496:INFO:Assigning column types.
2024-06-11 21:17:44,507:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:17:44,549:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:17:44,549:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:17:44,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:17:44,625:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:17:44,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,665:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:17:44,709:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:17:44,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,790:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:17:44,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,824:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:17:44,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:44,990:INFO:Preparing preprocessing pipeline...
2024-06-11 21:17:44,993:INFO:Set up date feature engineering.
2024-06-11 21:17:44,993:INFO:Set up simple imputation.
2024-06-11 21:17:45,004:INFO:Set up encoding of ordinal features.
2024-06-11 21:17:45,014:INFO:Set up encoding of categorical features.
2024-06-11 21:17:45,015:INFO:Set up removing outliers.
2024-06-11 21:17:45,015:INFO:Set up imbalanced handling.
2024-06-11 21:17:45,015:INFO:Set up feature normalization.
2024-06-11 21:17:45,015:INFO:Set up PCA.
2024-06-11 21:17:46,266:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:17:46,300:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                               sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-11 21:17:46,300:INFO:Creating final display dataframe.
2024-06-11 21:17:47,366:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76025, 34)
5   Transformed train set shape       (61025, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method            ADASYN
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              be73
2024-06-11 21:17:47,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:47,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:47,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:47,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:17:47,515:INFO:setup() successfully completed in 3.19s...............
2024-06-11 21:17:47,528:INFO:Initializing create_model()
2024-06-11 21:17:47,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:17:47,528:INFO:Checking exceptions
2024-06-11 21:17:47,542:INFO:Importing libraries
2024-06-11 21:17:47,542:INFO:Copying training dataset
2024-06-11 21:17:47,562:INFO:Defining folds
2024-06-11 21:17:47,563:INFO:Declaring metric variables
2024-06-11 21:17:47,565:INFO:Importing untrained model
2024-06-11 21:17:47,569:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:17:47,576:INFO:Starting cross validation
2024-06-11 21:17:47,581:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:17:51,946:INFO:Calculating mean and std
2024-06-11 21:17:51,948:INFO:Creating metrics dataframe
2024-06-11 21:17:51,954:INFO:Finalizing model
2024-06-11 21:17:53,461:INFO:[LightGBM] [Info] Number of positive: 30412, number of negative: 30613
2024-06-11 21:17:53,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004646 seconds.
2024-06-11 21:17:53,466:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:17:53,467:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:17:53,468:INFO:[LightGBM] [Info] Number of data points in the train set: 61025, number of used features: 33
2024-06-11 21:17:53,468:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498353 -> initscore=-0.006587
2024-06-11 21:17:53,468:INFO:[LightGBM] [Info] Start training from score -0.006587
2024-06-11 21:17:53,813:INFO:Uploading results into container
2024-06-11 21:17:53,814:INFO:Uploading model into container now
2024-06-11 21:17:53,826:INFO:_master_model_container: 1
2024-06-11 21:17:53,826:INFO:_display_container: 2
2024-06-11 21:17:53,827:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:17:53,827:INFO:create_model() successfully completed......................................
2024-06-11 21:17:53,938:INFO:Initializing tune_model()
2024-06-11 21:17:53,938:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:17:53,939:INFO:Checking exceptions
2024-06-11 21:17:53,965:INFO:Copying training dataset
2024-06-11 21:17:53,980:INFO:Checking base model
2024-06-11 21:17:53,980:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:17:53,984:INFO:Declaring metric variables
2024-06-11 21:17:53,988:INFO:Defining Hyperparameters
2024-06-11 21:17:54,067:INFO:Tuning with n_jobs=-1
2024-06-11 21:17:54,067:INFO:Initializing RandomizedSearchCV
2024-06-11 21:18:16,092:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:16,560:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:17,090:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:20,604:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:23,905:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:24,392:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:24,545:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:25,722:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:28,636:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:29,554:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:30,715:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:32,418:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:33,284:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:18:34,853:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-11 21:19:03,763:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 21:19:03,764:INFO:Hyperparameter search completed
2024-06-11 21:19:03,764:INFO:SubProcess create_model() called ==================================
2024-06-11 21:19:03,766:INFO:Initializing create_model()
2024-06-11 21:19:03,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC3881EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 21:19:03,766:INFO:Checking exceptions
2024-06-11 21:19:03,766:INFO:Importing libraries
2024-06-11 21:19:03,767:INFO:Copying training dataset
2024-06-11 21:19:03,801:INFO:Defining folds
2024-06-11 21:19:03,801:INFO:Declaring metric variables
2024-06-11 21:19:03,806:INFO:Importing untrained model
2024-06-11 21:19:03,806:INFO:Declaring custom model
2024-06-11 21:19:03,813:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:19:03,825:INFO:Starting cross validation
2024-06-11 21:19:03,830:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:19:11,720:INFO:Calculating mean and std
2024-06-11 21:19:11,722:INFO:Creating metrics dataframe
2024-06-11 21:19:11,729:INFO:Finalizing model
2024-06-11 21:19:13,179:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:13,179:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:13,179:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:13,258:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:13,258:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:13,258:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:13,258:INFO:[LightGBM] [Info] Number of positive: 30412, number of negative: 30613
2024-06-11 21:19:13,264:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004366 seconds.
2024-06-11 21:19:13,264:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:19:13,264:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:19:13,265:INFO:[LightGBM] [Info] Number of data points in the train set: 61025, number of used features: 33
2024-06-11 21:19:13,268:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498353 -> initscore=-0.006587
2024-06-11 21:19:13,268:INFO:[LightGBM] [Info] Start training from score -0.006587
2024-06-11 21:19:14,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:14,370:INFO:Uploading results into container
2024-06-11 21:19:14,372:INFO:Uploading model into container now
2024-06-11 21:19:14,373:INFO:_master_model_container: 2
2024-06-11 21:19:14,373:INFO:_display_container: 3
2024-06-11 21:19:14,374:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:19:14,375:INFO:create_model() successfully completed......................................
2024-06-11 21:19:14,481:INFO:SubProcess create_model() end ==================================
2024-06-11 21:19:14,481:INFO:choose_better activated
2024-06-11 21:19:14,484:INFO:SubProcess create_model() called ==================================
2024-06-11 21:19:14,485:INFO:Initializing create_model()
2024-06-11 21:19:14,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:19:14,485:INFO:Checking exceptions
2024-06-11 21:19:14,487:INFO:Importing libraries
2024-06-11 21:19:14,487:INFO:Copying training dataset
2024-06-11 21:19:14,508:INFO:Defining folds
2024-06-11 21:19:14,508:INFO:Declaring metric variables
2024-06-11 21:19:14,508:INFO:Importing untrained model
2024-06-11 21:19:14,508:INFO:Declaring custom model
2024-06-11 21:19:14,509:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:19:14,509:INFO:Starting cross validation
2024-06-11 21:19:14,512:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:19:19,019:INFO:Calculating mean and std
2024-06-11 21:19:19,020:INFO:Creating metrics dataframe
2024-06-11 21:19:19,023:INFO:Finalizing model
2024-06-11 21:19:20,570:INFO:[LightGBM] [Info] Number of positive: 30412, number of negative: 30613
2024-06-11 21:19:20,575:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004263 seconds.
2024-06-11 21:19:20,575:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:19:20,576:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:19:20,577:INFO:[LightGBM] [Info] Number of data points in the train set: 61025, number of used features: 33
2024-06-11 21:19:20,577:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498353 -> initscore=-0.006587
2024-06-11 21:19:20,577:INFO:[LightGBM] [Info] Start training from score -0.006587
2024-06-11 21:19:21,009:INFO:Uploading results into container
2024-06-11 21:19:21,010:INFO:Uploading model into container now
2024-06-11 21:19:21,011:INFO:_master_model_container: 3
2024-06-11 21:19:21,011:INFO:_display_container: 4
2024-06-11 21:19:21,011:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:19:21,012:INFO:create_model() successfully completed......................................
2024-06-11 21:19:21,112:INFO:SubProcess create_model() end ==================================
2024-06-11 21:19:21,112:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.249
2024-06-11 21:19:21,113:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2586
2024-06-11 21:19:21,113:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:19:21,114:INFO:choose_better completed
2024-06-11 21:19:21,123:INFO:_master_model_container: 3
2024-06-11 21:19:21,123:INFO:_display_container: 3
2024-06-11 21:19:21,124:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:19:21,124:INFO:tune_model() successfully completed......................................
2024-06-11 21:19:21,248:INFO:Initializing plot_model()
2024-06-11 21:19:21,248:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:19:21,249:INFO:Checking exceptions
2024-06-11 21:19:21,259:INFO:Preloading libraries
2024-06-11 21:19:21,306:INFO:Copying training dataset
2024-06-11 21:19:21,306:INFO:Plot type: auc
2024-06-11 21:19:21,510:INFO:Fitting Model
2024-06-11 21:19:21,512:INFO:Scoring test/hold-out set
2024-06-11 21:19:21,514:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:21,514:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:21,514:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:21,573:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:21,574:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:21,574:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:21,874:INFO:Visual Rendered Successfully
2024-06-11 21:19:21,951:INFO:plot_model() successfully completed......................................
2024-06-11 21:19:21,966:INFO:Initializing plot_model()
2024-06-11 21:19:21,966:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:19:21,967:INFO:Checking exceptions
2024-06-11 21:19:21,977:INFO:Preloading libraries
2024-06-11 21:19:22,014:INFO:Copying training dataset
2024-06-11 21:19:22,014:INFO:Plot type: confusion_matrix
2024-06-11 21:19:22,200:INFO:Fitting Model
2024-06-11 21:19:22,200:INFO:Scoring test/hold-out set
2024-06-11 21:19:22,202:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:22,202:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:22,202:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:22,268:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:22,268:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:22,268:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:22,475:INFO:Visual Rendered Successfully
2024-06-11 21:19:22,551:INFO:plot_model() successfully completed......................................
2024-06-11 21:19:22,569:INFO:Initializing finalize_model()
2024-06-11 21:19:22,570:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:19:22,571:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:19:22,588:INFO:Initializing create_model()
2024-06-11 21:19:22,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:19:22,588:INFO:Checking exceptions
2024-06-11 21:19:22,589:INFO:Importing libraries
2024-06-11 21:19:22,589:INFO:Copying training dataset
2024-06-11 21:19:22,591:INFO:Defining folds
2024-06-11 21:19:22,592:INFO:Declaring metric variables
2024-06-11 21:19:22,592:INFO:Importing untrained model
2024-06-11 21:19:22,592:INFO:Declaring custom model
2024-06-11 21:19:22,592:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:19:22,595:INFO:Cross validation set to False
2024-06-11 21:19:22,595:INFO:Fitting Model
2024-06-11 21:19:24,532:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:24,532:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:24,532:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:24,673:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:24,674:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:24,674:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:24,674:INFO:[LightGBM] [Info] Number of positive: 44126, number of negative: 43748
2024-06-11 21:19:24,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008586 seconds.
2024-06-11 21:19:24,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:19:24,686:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:19:24,687:INFO:[LightGBM] [Info] Number of data points in the train set: 87874, number of used features: 33
2024-06-11 21:19:24,690:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502151 -> initscore=0.008603
2024-06-11 21:19:24,690:INFO:[LightGBM] [Info] Start training from score 0.008603
2024-06-11 21:19:26,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:26,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:19:26,279:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:19:26,279:INFO:create_model() successfully completed......................................
2024-06-11 21:19:26,364:INFO:_master_model_container: 3
2024-06-11 21:19:26,364:INFO:_display_container: 3
2024-06-11 21:19:26,402:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:19:26,402:INFO:finalize_model() successfully completed......................................
2024-06-11 21:19:26,608:INFO:Initializing evaluate_model()
2024-06-11 21:19:26,608:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:19:26,659:INFO:Initializing plot_model()
2024-06-11 21:19:26,659:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:19:26,659:INFO:Checking exceptions
2024-06-11 21:19:26,665:INFO:Preloading libraries
2024-06-11 21:19:26,706:INFO:Copying training dataset
2024-06-11 21:19:26,707:INFO:Plot type: pipeline
2024-06-11 21:19:26,970:INFO:Visual Rendered Successfully
2024-06-11 21:19:27,045:INFO:plot_model() successfully completed......................................
2024-06-11 21:19:30,964:INFO:Initializing plot_model()
2024-06-11 21:19:30,964:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:19:30,964:INFO:Checking exceptions
2024-06-11 21:19:30,972:INFO:Preloading libraries
2024-06-11 21:19:31,018:INFO:Copying training dataset
2024-06-11 21:19:31,018:INFO:Plot type: confusion_matrix
2024-06-11 21:19:31,202:INFO:Fitting Model
2024-06-11 21:19:31,202:INFO:Scoring test/hold-out set
2024-06-11 21:19:31,204:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:31,204:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:31,205:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:31,264:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:31,265:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:31,265:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:31,448:INFO:Visual Rendered Successfully
2024-06-11 21:19:31,528:INFO:plot_model() successfully completed......................................
2024-06-11 21:19:33,350:INFO:Initializing plot_model()
2024-06-11 21:19:33,350:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B792950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:19:33,350:INFO:Checking exceptions
2024-06-11 21:19:33,356:INFO:Preloading libraries
2024-06-11 21:19:33,392:INFO:Copying training dataset
2024-06-11 21:19:33,393:INFO:Plot type: auc
2024-06-11 21:19:33,580:INFO:Fitting Model
2024-06-11 21:19:33,582:INFO:Scoring test/hold-out set
2024-06-11 21:19:33,584:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:33,584:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:33,584:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:33,656:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:19:33,657:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:19:33,657:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:19:33,940:INFO:Visual Rendered Successfully
2024-06-11 21:19:34,013:INFO:plot_model() successfully completed......................................
2024-06-11 21:20:00,745:INFO:PyCaret ClassificationExperiment
2024-06-11 21:20:00,745:INFO:Logging name: clf-default-name
2024-06-11 21:20:00,746:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:20:00,746:INFO:version 3.3.2
2024-06-11 21:20:00,746:INFO:Initializing setup()
2024-06-11 21:20:00,746:INFO:self.USI: 7890
2024-06-11 21:20:00,746:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:20:00,746:INFO:Checking environment
2024-06-11 21:20:00,746:INFO:python_version: 3.11.9
2024-06-11 21:20:00,746:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:20:00,747:INFO:machine: AMD64
2024-06-11 21:20:00,747:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:20:00,747:INFO:Memory: svmem(total=34056318976, available=23727579136, percent=30.3, used=10328739840, free=23727579136)
2024-06-11 21:20:00,747:INFO:Physical Core: 6
2024-06-11 21:20:00,747:INFO:Logical Core: 12
2024-06-11 21:20:00,747:INFO:Checking libraries
2024-06-11 21:20:00,747:INFO:System:
2024-06-11 21:20:00,747:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:20:00,747:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:20:00,747:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:20:00,747:INFO:PyCaret required dependencies:
2024-06-11 21:20:00,748:INFO:                 pip: 24.0
2024-06-11 21:20:00,748:INFO:          setuptools: 69.5.1
2024-06-11 21:20:00,748:INFO:             pycaret: 3.3.2
2024-06-11 21:20:00,748:INFO:             IPython: 8.25.0
2024-06-11 21:20:00,748:INFO:          ipywidgets: 8.1.3
2024-06-11 21:20:00,748:INFO:                tqdm: 4.66.4
2024-06-11 21:20:00,748:INFO:               numpy: 1.26.4
2024-06-11 21:20:00,748:INFO:              pandas: 2.1.4
2024-06-11 21:20:00,748:INFO:              jinja2: 3.1.4
2024-06-11 21:20:00,748:INFO:               scipy: 1.11.4
2024-06-11 21:20:00,748:INFO:              joblib: 1.3.2
2024-06-11 21:20:00,748:INFO:             sklearn: 1.4.2
2024-06-11 21:20:00,748:INFO:                pyod: 2.0.0
2024-06-11 21:20:00,748:INFO:            imblearn: 0.12.3
2024-06-11 21:20:00,749:INFO:   category_encoders: 2.6.3
2024-06-11 21:20:00,749:INFO:            lightgbm: 4.3.0
2024-06-11 21:20:00,749:INFO:               numba: 0.59.1
2024-06-11 21:20:00,749:INFO:            requests: 2.32.3
2024-06-11 21:20:00,749:INFO:          matplotlib: 3.7.5
2024-06-11 21:20:00,749:INFO:          scikitplot: 0.3.7
2024-06-11 21:20:00,749:INFO:         yellowbrick: 1.5
2024-06-11 21:20:00,749:INFO:              plotly: 5.22.0
2024-06-11 21:20:00,749:INFO:    plotly-resampler: Not installed
2024-06-11 21:20:00,749:INFO:             kaleido: 0.2.1
2024-06-11 21:20:00,749:INFO:           schemdraw: 0.15
2024-06-11 21:20:00,749:INFO:         statsmodels: 0.14.2
2024-06-11 21:20:00,749:INFO:              sktime: 0.26.0
2024-06-11 21:20:00,750:INFO:               tbats: 1.1.3
2024-06-11 21:20:00,750:INFO:            pmdarima: 2.0.4
2024-06-11 21:20:00,750:INFO:              psutil: 5.9.8
2024-06-11 21:20:00,750:INFO:          markupsafe: 2.1.5
2024-06-11 21:20:00,750:INFO:             pickle5: Not installed
2024-06-11 21:20:00,750:INFO:         cloudpickle: 3.0.0
2024-06-11 21:20:00,750:INFO:         deprecation: 2.1.0
2024-06-11 21:20:00,750:INFO:              xxhash: 3.4.1
2024-06-11 21:20:00,750:INFO:           wurlitzer: Not installed
2024-06-11 21:20:00,750:INFO:PyCaret optional dependencies:
2024-06-11 21:20:00,750:INFO:                shap: Not installed
2024-06-11 21:20:00,750:INFO:           interpret: Not installed
2024-06-11 21:20:00,751:INFO:                umap: Not installed
2024-06-11 21:20:00,751:INFO:     ydata_profiling: Not installed
2024-06-11 21:20:00,751:INFO:  explainerdashboard: Not installed
2024-06-11 21:20:00,751:INFO:             autoviz: Not installed
2024-06-11 21:20:00,751:INFO:           fairlearn: Not installed
2024-06-11 21:20:00,751:INFO:          deepchecks: Not installed
2024-06-11 21:20:00,751:INFO:             xgboost: Not installed
2024-06-11 21:20:00,751:INFO:            catboost: Not installed
2024-06-11 21:20:00,751:INFO:              kmodes: Not installed
2024-06-11 21:20:00,751:INFO:             mlxtend: Not installed
2024-06-11 21:20:00,751:INFO:       statsforecast: Not installed
2024-06-11 21:20:00,751:INFO:        tune_sklearn: Not installed
2024-06-11 21:20:00,751:INFO:                 ray: Not installed
2024-06-11 21:20:00,751:INFO:            hyperopt: Not installed
2024-06-11 21:20:00,752:INFO:              optuna: Not installed
2024-06-11 21:20:00,752:INFO:               skopt: Not installed
2024-06-11 21:20:00,752:INFO:              mlflow: Not installed
2024-06-11 21:20:00,752:INFO:              gradio: Not installed
2024-06-11 21:20:00,752:INFO:             fastapi: Not installed
2024-06-11 21:20:00,752:INFO:             uvicorn: Not installed
2024-06-11 21:20:00,752:INFO:              m2cgen: Not installed
2024-06-11 21:20:00,752:INFO:           evidently: Not installed
2024-06-11 21:20:00,752:INFO:               fugue: Not installed
2024-06-11 21:20:00,752:INFO:           streamlit: 1.35.0
2024-06-11 21:20:00,752:INFO:             prophet: Not installed
2024-06-11 21:20:00,752:INFO:None
2024-06-11 21:20:00,752:INFO:Set up data.
2024-06-11 21:20:00,803:INFO:Set up folding strategy.
2024-06-11 21:20:00,803:INFO:Set up train/test split.
2024-06-11 21:20:00,839:INFO:Set up index.
2024-06-11 21:20:00,840:INFO:Assigning column types.
2024-06-11 21:20:00,851:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:20:00,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:20:00,896:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:20:00,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:00,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:00,974:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:20:00,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:20:01,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,003:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:20:01,052:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:20:01,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,122:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:20:01,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,149:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:20:01,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:01,293:INFO:Preparing preprocessing pipeline...
2024-06-11 21:20:01,295:INFO:Set up date feature engineering.
2024-06-11 21:20:01,295:INFO:Set up simple imputation.
2024-06-11 21:20:01,306:INFO:Set up encoding of ordinal features.
2024-06-11 21:20:01,317:INFO:Set up encoding of categorical features.
2024-06-11 21:20:01,317:INFO:Set up removing outliers.
2024-06-11 21:20:01,317:INFO:Set up imbalanced handling.
2024-06-11 21:20:01,317:INFO:Set up feature normalization.
2024-06-11 21:20:01,317:INFO:Set up PCA.
2024-06-11 21:20:02,357:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:20:02,390:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                                        sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-11 21:20:02,390:INFO:Creating final display dataframe.
2024-06-11 21:20:03,468:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method   BorderlineSMOTE
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              7890
2024-06-11 21:20:03,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:03,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:03,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:03,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:20:03,609:INFO:setup() successfully completed in 2.98s...............
2024-06-11 21:20:03,630:INFO:Initializing create_model()
2024-06-11 21:20:03,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:20:03,630:INFO:Checking exceptions
2024-06-11 21:20:03,645:INFO:Importing libraries
2024-06-11 21:20:03,645:INFO:Copying training dataset
2024-06-11 21:20:03,663:INFO:Defining folds
2024-06-11 21:20:03,663:INFO:Declaring metric variables
2024-06-11 21:20:03,666:INFO:Importing untrained model
2024-06-11 21:20:03,669:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:20:03,675:INFO:Starting cross validation
2024-06-11 21:20:03,679:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:20:07,549:INFO:Calculating mean and std
2024-06-11 21:20:07,550:INFO:Creating metrics dataframe
2024-06-11 21:20:07,557:INFO:Finalizing model
2024-06-11 21:20:09,041:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:20:09,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004575 seconds.
2024-06-11 21:20:09,046:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:20:09,047:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:20:09,047:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:20:09,048:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:20:09,405:INFO:Uploading results into container
2024-06-11 21:20:09,406:INFO:Uploading model into container now
2024-06-11 21:20:09,417:INFO:_master_model_container: 1
2024-06-11 21:20:09,417:INFO:_display_container: 2
2024-06-11 21:20:09,418:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:20:09,418:INFO:create_model() successfully completed......................................
2024-06-11 21:20:09,543:INFO:Initializing tune_model()
2024-06-11 21:20:09,543:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:20:09,543:INFO:Checking exceptions
2024-06-11 21:20:09,567:INFO:Copying training dataset
2024-06-11 21:20:09,578:INFO:Checking base model
2024-06-11 21:20:09,579:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:20:09,582:INFO:Declaring metric variables
2024-06-11 21:20:09,587:INFO:Defining Hyperparameters
2024-06-11 21:20:09,678:INFO:Tuning with n_jobs=-1
2024-06-11 21:20:09,678:INFO:Initializing RandomizedSearchCV
2024-06-11 21:21:13,494:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 21:21:13,496:INFO:Hyperparameter search completed
2024-06-11 21:21:13,496:INFO:SubProcess create_model() called ==================================
2024-06-11 21:21:13,498:INFO:Initializing create_model()
2024-06-11 21:21:13,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC3881EF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 21:21:13,498:INFO:Checking exceptions
2024-06-11 21:21:13,498:INFO:Importing libraries
2024-06-11 21:21:13,499:INFO:Copying training dataset
2024-06-11 21:21:13,540:INFO:Defining folds
2024-06-11 21:21:13,540:INFO:Declaring metric variables
2024-06-11 21:21:13,546:INFO:Importing untrained model
2024-06-11 21:21:13,546:INFO:Declaring custom model
2024-06-11 21:21:13,556:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:21:13,573:INFO:Starting cross validation
2024-06-11 21:21:13,588:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:21:22,638:INFO:Calculating mean and std
2024-06-11 21:21:22,640:INFO:Creating metrics dataframe
2024-06-11 21:21:22,649:INFO:Finalizing model
2024-06-11 21:21:24,151:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:21:24,152:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:21:24,152:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:21:24,252:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:21:24,252:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:21:24,252:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:21:24,252:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:21:24,257:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004027 seconds.
2024-06-11 21:21:24,258:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:21:24,258:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:21:24,259:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:21:24,261:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:21:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:25,477:INFO:Uploading results into container
2024-06-11 21:21:25,479:INFO:Uploading model into container now
2024-06-11 21:21:25,480:INFO:_master_model_container: 2
2024-06-11 21:21:25,480:INFO:_display_container: 3
2024-06-11 21:21:25,482:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:21:25,482:INFO:create_model() successfully completed......................................
2024-06-11 21:21:25,594:INFO:SubProcess create_model() end ==================================
2024-06-11 21:21:25,594:INFO:choose_better activated
2024-06-11 21:21:25,597:INFO:SubProcess create_model() called ==================================
2024-06-11 21:21:25,598:INFO:Initializing create_model()
2024-06-11 21:21:25,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:21:25,598:INFO:Checking exceptions
2024-06-11 21:21:25,600:INFO:Importing libraries
2024-06-11 21:21:25,600:INFO:Copying training dataset
2024-06-11 21:21:25,622:INFO:Defining folds
2024-06-11 21:21:25,622:INFO:Declaring metric variables
2024-06-11 21:21:25,622:INFO:Importing untrained model
2024-06-11 21:21:25,622:INFO:Declaring custom model
2024-06-11 21:21:25,623:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:21:25,623:INFO:Starting cross validation
2024-06-11 21:21:25,627:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:21:30,702:INFO:Calculating mean and std
2024-06-11 21:21:30,703:INFO:Creating metrics dataframe
2024-06-11 21:21:30,706:INFO:Finalizing model
2024-06-11 21:21:32,379:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:21:32,386:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006148 seconds.
2024-06-11 21:21:32,386:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:21:32,387:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:21:32,387:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:21:32,388:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:21:32,749:INFO:Uploading results into container
2024-06-11 21:21:32,750:INFO:Uploading model into container now
2024-06-11 21:21:32,750:INFO:_master_model_container: 3
2024-06-11 21:21:32,750:INFO:_display_container: 4
2024-06-11 21:21:32,751:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:21:32,751:INFO:create_model() successfully completed......................................
2024-06-11 21:21:32,863:INFO:SubProcess create_model() end ==================================
2024-06-11 21:21:32,863:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2644
2024-06-11 21:21:32,864:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.2696
2024-06-11 21:21:32,865:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:21:32,865:INFO:choose_better completed
2024-06-11 21:21:32,874:INFO:_master_model_container: 3
2024-06-11 21:21:32,874:INFO:_display_container: 3
2024-06-11 21:21:32,875:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:21:32,875:INFO:tune_model() successfully completed......................................
2024-06-11 21:21:32,975:INFO:Initializing plot_model()
2024-06-11 21:21:32,975:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:21:32,975:INFO:Checking exceptions
2024-06-11 21:21:32,987:INFO:Preloading libraries
2024-06-11 21:21:33,058:INFO:Copying training dataset
2024-06-11 21:21:33,058:INFO:Plot type: auc
2024-06-11 21:21:33,281:INFO:Fitting Model
2024-06-11 21:21:33,283:INFO:Scoring test/hold-out set
2024-06-11 21:21:33,285:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:21:33,285:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:21:33,285:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:21:33,359:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:21:33,359:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:21:33,359:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:21:33,699:INFO:Visual Rendered Successfully
2024-06-11 21:21:33,777:INFO:plot_model() successfully completed......................................
2024-06-11 21:21:33,807:INFO:Initializing plot_model()
2024-06-11 21:21:33,808:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:21:33,808:INFO:Checking exceptions
2024-06-11 21:21:33,819:INFO:Preloading libraries
2024-06-11 21:21:33,857:INFO:Copying training dataset
2024-06-11 21:21:33,857:INFO:Plot type: confusion_matrix
2024-06-11 21:21:34,062:INFO:Fitting Model
2024-06-11 21:21:34,063:INFO:Scoring test/hold-out set
2024-06-11 21:21:34,065:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:21:34,066:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:21:34,066:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:21:34,123:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:21:34,123:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:21:34,124:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:21:34,346:INFO:Visual Rendered Successfully
2024-06-11 21:21:34,423:INFO:plot_model() successfully completed......................................
2024-06-11 21:21:34,438:INFO:Initializing finalize_model()
2024-06-11 21:21:34,438:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:21:34,438:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:21:34,450:INFO:Initializing create_model()
2024-06-11 21:21:34,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:21:34,450:INFO:Checking exceptions
2024-06-11 21:21:34,451:INFO:Importing libraries
2024-06-11 21:21:34,451:INFO:Copying training dataset
2024-06-11 21:21:34,452:INFO:Defining folds
2024-06-11 21:21:34,452:INFO:Declaring metric variables
2024-06-11 21:21:34,453:INFO:Importing untrained model
2024-06-11 21:21:34,453:INFO:Declaring custom model
2024-06-11 21:21:34,453:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:21:34,457:INFO:Cross validation set to False
2024-06-11 21:21:34,457:INFO:Fitting Model
2024-06-11 21:21:36,389:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:21:36,389:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:21:36,389:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:21:36,528:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:21:36,528:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:21:36,528:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:21:36,528:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-11 21:21:36,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005415 seconds.
2024-06-11 21:21:36,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:21:36,536:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:21:36,537:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-11 21:21:36,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:21:38,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:38,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:38,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:38,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:38,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:38,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:38,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:38,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:38,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:21:38,459:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:21:38,459:INFO:create_model() successfully completed......................................
2024-06-11 21:21:38,552:INFO:_master_model_container: 3
2024-06-11 21:21:38,553:INFO:_display_container: 3
2024-06-11 21:21:38,594:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:21:38,594:INFO:finalize_model() successfully completed......................................
2024-06-11 21:21:38,844:INFO:Initializing evaluate_model()
2024-06-11 21:21:38,844:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:21:38,907:INFO:Initializing plot_model()
2024-06-11 21:21:38,908:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:21:38,908:INFO:Checking exceptions
2024-06-11 21:21:38,916:INFO:Preloading libraries
2024-06-11 21:21:38,962:INFO:Copying training dataset
2024-06-11 21:21:38,962:INFO:Plot type: pipeline
2024-06-11 21:21:39,272:INFO:Visual Rendered Successfully
2024-06-11 21:21:39,351:INFO:plot_model() successfully completed......................................
2024-06-11 21:22:18,813:INFO:Initializing plot_model()
2024-06-11 21:22:18,813:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:22:18,813:INFO:Checking exceptions
2024-06-11 21:22:18,821:INFO:Preloading libraries
2024-06-11 21:22:18,868:INFO:Copying training dataset
2024-06-11 21:22:18,868:INFO:Plot type: auc
2024-06-11 21:22:19,069:INFO:Fitting Model
2024-06-11 21:22:19,071:INFO:Scoring test/hold-out set
2024-06-11 21:22:19,073:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:22:19,073:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:22:19,073:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:22:19,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:22:19,135:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:22:19,136:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:22:19,416:INFO:Visual Rendered Successfully
2024-06-11 21:22:19,524:INFO:plot_model() successfully completed......................................
2024-06-11 21:22:21,010:INFO:Initializing plot_model()
2024-06-11 21:22:21,010:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A8950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:22:21,010:INFO:Checking exceptions
2024-06-11 21:22:21,016:INFO:Preloading libraries
2024-06-11 21:22:21,051:INFO:Copying training dataset
2024-06-11 21:22:21,052:INFO:Plot type: confusion_matrix
2024-06-11 21:22:21,242:INFO:Fitting Model
2024-06-11 21:22:21,243:INFO:Scoring test/hold-out set
2024-06-11 21:22:21,245:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:22:21,245:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:22:21,245:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:22:21,310:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:22:21,310:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:22:21,310:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:22:21,519:INFO:Visual Rendered Successfully
2024-06-11 21:22:21,595:INFO:plot_model() successfully completed......................................
2024-06-11 21:22:33,040:INFO:PyCaret ClassificationExperiment
2024-06-11 21:22:33,040:INFO:Logging name: clf-default-name
2024-06-11 21:22:33,040:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:22:33,040:INFO:version 3.3.2
2024-06-11 21:22:33,040:INFO:Initializing setup()
2024-06-11 21:22:33,040:INFO:self.USI: 4d71
2024-06-11 21:22:33,040:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:22:33,041:INFO:Checking environment
2024-06-11 21:22:33,041:INFO:python_version: 3.11.9
2024-06-11 21:22:33,041:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:22:33,041:INFO:machine: AMD64
2024-06-11 21:22:33,041:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:22:33,041:INFO:Memory: svmem(total=34056318976, available=23596359680, percent=30.7, used=10459959296, free=23596359680)
2024-06-11 21:22:33,041:INFO:Physical Core: 6
2024-06-11 21:22:33,041:INFO:Logical Core: 12
2024-06-11 21:22:33,041:INFO:Checking libraries
2024-06-11 21:22:33,041:INFO:System:
2024-06-11 21:22:33,041:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:22:33,041:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:22:33,041:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:22:33,041:INFO:PyCaret required dependencies:
2024-06-11 21:22:33,041:INFO:                 pip: 24.0
2024-06-11 21:22:33,042:INFO:          setuptools: 69.5.1
2024-06-11 21:22:33,042:INFO:             pycaret: 3.3.2
2024-06-11 21:22:33,042:INFO:             IPython: 8.25.0
2024-06-11 21:22:33,042:INFO:          ipywidgets: 8.1.3
2024-06-11 21:22:33,042:INFO:                tqdm: 4.66.4
2024-06-11 21:22:33,042:INFO:               numpy: 1.26.4
2024-06-11 21:22:33,042:INFO:              pandas: 2.1.4
2024-06-11 21:22:33,042:INFO:              jinja2: 3.1.4
2024-06-11 21:22:33,042:INFO:               scipy: 1.11.4
2024-06-11 21:22:33,042:INFO:              joblib: 1.3.2
2024-06-11 21:22:33,042:INFO:             sklearn: 1.4.2
2024-06-11 21:22:33,042:INFO:                pyod: 2.0.0
2024-06-11 21:22:33,042:INFO:            imblearn: 0.12.3
2024-06-11 21:22:33,042:INFO:   category_encoders: 2.6.3
2024-06-11 21:22:33,042:INFO:            lightgbm: 4.3.0
2024-06-11 21:22:33,042:INFO:               numba: 0.59.1
2024-06-11 21:22:33,043:INFO:            requests: 2.32.3
2024-06-11 21:22:33,043:INFO:          matplotlib: 3.7.5
2024-06-11 21:22:33,043:INFO:          scikitplot: 0.3.7
2024-06-11 21:22:33,043:INFO:         yellowbrick: 1.5
2024-06-11 21:22:33,043:INFO:              plotly: 5.22.0
2024-06-11 21:22:33,043:INFO:    plotly-resampler: Not installed
2024-06-11 21:22:33,043:INFO:             kaleido: 0.2.1
2024-06-11 21:22:33,043:INFO:           schemdraw: 0.15
2024-06-11 21:22:33,043:INFO:         statsmodels: 0.14.2
2024-06-11 21:22:33,043:INFO:              sktime: 0.26.0
2024-06-11 21:22:33,043:INFO:               tbats: 1.1.3
2024-06-11 21:22:33,043:INFO:            pmdarima: 2.0.4
2024-06-11 21:22:33,043:INFO:              psutil: 5.9.8
2024-06-11 21:22:33,043:INFO:          markupsafe: 2.1.5
2024-06-11 21:22:33,043:INFO:             pickle5: Not installed
2024-06-11 21:22:33,043:INFO:         cloudpickle: 3.0.0
2024-06-11 21:22:33,043:INFO:         deprecation: 2.1.0
2024-06-11 21:22:33,043:INFO:              xxhash: 3.4.1
2024-06-11 21:22:33,043:INFO:           wurlitzer: Not installed
2024-06-11 21:22:33,044:INFO:PyCaret optional dependencies:
2024-06-11 21:22:33,044:INFO:                shap: Not installed
2024-06-11 21:22:33,044:INFO:           interpret: Not installed
2024-06-11 21:22:33,044:INFO:                umap: Not installed
2024-06-11 21:22:33,044:INFO:     ydata_profiling: Not installed
2024-06-11 21:22:33,044:INFO:  explainerdashboard: Not installed
2024-06-11 21:22:33,044:INFO:             autoviz: Not installed
2024-06-11 21:22:33,044:INFO:           fairlearn: Not installed
2024-06-11 21:22:33,044:INFO:          deepchecks: Not installed
2024-06-11 21:22:33,044:INFO:             xgboost: Not installed
2024-06-11 21:22:33,044:INFO:            catboost: Not installed
2024-06-11 21:22:33,044:INFO:              kmodes: Not installed
2024-06-11 21:22:33,044:INFO:             mlxtend: Not installed
2024-06-11 21:22:33,044:INFO:       statsforecast: Not installed
2024-06-11 21:22:33,044:INFO:        tune_sklearn: Not installed
2024-06-11 21:22:33,044:INFO:                 ray: Not installed
2024-06-11 21:22:33,044:INFO:            hyperopt: Not installed
2024-06-11 21:22:33,044:INFO:              optuna: Not installed
2024-06-11 21:22:33,045:INFO:               skopt: Not installed
2024-06-11 21:22:33,045:INFO:              mlflow: Not installed
2024-06-11 21:22:33,045:INFO:              gradio: Not installed
2024-06-11 21:22:33,045:INFO:             fastapi: Not installed
2024-06-11 21:22:33,045:INFO:             uvicorn: Not installed
2024-06-11 21:22:33,045:INFO:              m2cgen: Not installed
2024-06-11 21:22:33,045:INFO:           evidently: Not installed
2024-06-11 21:22:33,045:INFO:               fugue: Not installed
2024-06-11 21:22:33,045:INFO:           streamlit: 1.35.0
2024-06-11 21:22:33,045:INFO:             prophet: Not installed
2024-06-11 21:22:33,045:INFO:None
2024-06-11 21:22:33,045:INFO:Set up data.
2024-06-11 21:22:33,092:INFO:Set up folding strategy.
2024-06-11 21:22:33,092:INFO:Set up train/test split.
2024-06-11 21:22:33,119:INFO:Set up index.
2024-06-11 21:22:33,121:INFO:Assigning column types.
2024-06-11 21:22:33,130:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:22:33,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:22:33,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:22:33,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:22:33,243:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:22:33,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,272:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:22:33,318:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:22:33,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,388:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:22:33,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,415:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:22:33,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:33,591:INFO:Preparing preprocessing pipeline...
2024-06-11 21:22:33,593:INFO:Set up date feature engineering.
2024-06-11 21:22:33,593:INFO:Set up simple imputation.
2024-06-11 21:22:33,604:INFO:Set up encoding of ordinal features.
2024-06-11 21:22:33,615:INFO:Set up encoding of categorical features.
2024-06-11 21:22:33,615:INFO:Set up removing outliers.
2024-06-11 21:22:33,615:INFO:Set up imbalanced handling.
2024-06-11 21:22:33,615:INFO:Set up feature normalization.
2024-06-11 21:22:33,615:INFO:Set up PCA.
2024-06-11 21:22:34,102:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:22:34,138:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                                        sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-11 21:22:34,138:INFO:Creating final display dataframe.
2024-06-11 21:22:34,924:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method   BorderlineSMOTE
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              4d71
2024-06-11 21:22:34,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:34,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:35,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:35,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:22:35,065:INFO:setup() successfully completed in 2.12s...............
2024-06-11 21:22:35,082:INFO:Initializing create_model()
2024-06-11 21:22:35,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:22:35,082:INFO:Checking exceptions
2024-06-11 21:22:35,096:INFO:Importing libraries
2024-06-11 21:22:35,096:INFO:Copying training dataset
2024-06-11 21:22:35,114:INFO:Defining folds
2024-06-11 21:22:35,114:INFO:Declaring metric variables
2024-06-11 21:22:35,117:INFO:Importing untrained model
2024-06-11 21:22:35,120:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:22:35,126:INFO:Starting cross validation
2024-06-11 21:22:35,129:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:22:39,712:INFO:Calculating mean and std
2024-06-11 21:22:39,713:INFO:Creating metrics dataframe
2024-06-11 21:22:39,720:INFO:Finalizing model
2024-06-11 21:22:41,223:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:22:41,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004894 seconds.
2024-06-11 21:22:41,229:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:22:41,229:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:22:41,230:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:22:41,230:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:22:41,657:INFO:Uploading results into container
2024-06-11 21:22:41,658:INFO:Uploading model into container now
2024-06-11 21:22:41,670:INFO:_master_model_container: 1
2024-06-11 21:22:41,670:INFO:_display_container: 2
2024-06-11 21:22:41,671:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:22:41,671:INFO:create_model() successfully completed......................................
2024-06-11 21:22:41,790:INFO:Initializing tune_model()
2024-06-11 21:22:41,790:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:22:41,790:INFO:Checking exceptions
2024-06-11 21:22:41,816:INFO:Copying training dataset
2024-06-11 21:22:41,829:INFO:Checking base model
2024-06-11 21:22:41,829:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:22:41,833:INFO:Declaring metric variables
2024-06-11 21:22:41,838:INFO:Defining Hyperparameters
2024-06-11 21:22:41,949:INFO:Tuning with n_jobs=-1
2024-06-11 21:22:41,950:INFO:Initializing RandomizedSearchCV
2024-06-11 21:23:43,077:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 10, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 21:23:43,078:INFO:Hyperparameter search completed
2024-06-11 21:23:43,078:INFO:SubProcess create_model() called ==================================
2024-06-11 21:23:43,079:INFO:Initializing create_model()
2024-06-11 21:23:43,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC3BAC3450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 10, 'num_leaves': 10, 'n_estimators': 90, 'min_split_gain': 0.5, 'min_child_samples': 1, 'learning_rate': 1e-07, 'feature_fraction': 1.0, 'bagging_freq': 1, 'bagging_fraction': 0.6})
2024-06-11 21:23:43,079:INFO:Checking exceptions
2024-06-11 21:23:43,079:INFO:Importing libraries
2024-06-11 21:23:43,080:INFO:Copying training dataset
2024-06-11 21:23:43,111:INFO:Defining folds
2024-06-11 21:23:43,111:INFO:Declaring metric variables
2024-06-11 21:23:43,116:INFO:Importing untrained model
2024-06-11 21:23:43,116:INFO:Declaring custom model
2024-06-11 21:23:43,123:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:23:43,133:INFO:Starting cross validation
2024-06-11 21:23:43,140:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:23:46,621:INFO:Calculating mean and std
2024-06-11 21:23:46,623:INFO:Creating metrics dataframe
2024-06-11 21:23:46,630:INFO:Finalizing model
2024-06-11 21:23:48,030:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:23:48,030:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:23:48,030:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:23:48,125:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:23:48,125:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:23:48,125:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:23:48,126:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:23:48,131:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004598 seconds.
2024-06-11 21:23:48,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:23:48,131:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:23:48,131:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:23:48,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:23:48,303:INFO:Uploading results into container
2024-06-11 21:23:48,304:INFO:Uploading model into container now
2024-06-11 21:23:48,305:INFO:_master_model_container: 2
2024-06-11 21:23:48,305:INFO:_display_container: 3
2024-06-11 21:23:48,306:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:23:48,306:INFO:create_model() successfully completed......................................
2024-06-11 21:23:48,405:INFO:SubProcess create_model() end ==================================
2024-06-11 21:23:48,406:INFO:choose_better activated
2024-06-11 21:23:48,409:INFO:SubProcess create_model() called ==================================
2024-06-11 21:23:48,409:INFO:Initializing create_model()
2024-06-11 21:23:48,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:23:48,410:INFO:Checking exceptions
2024-06-11 21:23:48,411:INFO:Importing libraries
2024-06-11 21:23:48,411:INFO:Copying training dataset
2024-06-11 21:23:48,430:INFO:Defining folds
2024-06-11 21:23:48,431:INFO:Declaring metric variables
2024-06-11 21:23:48,431:INFO:Importing untrained model
2024-06-11 21:23:48,431:INFO:Declaring custom model
2024-06-11 21:23:48,431:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:23:48,432:INFO:Starting cross validation
2024-06-11 21:23:48,434:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:23:52,785:INFO:Calculating mean and std
2024-06-11 21:23:52,786:INFO:Creating metrics dataframe
2024-06-11 21:23:52,789:INFO:Finalizing model
2024-06-11 21:23:54,272:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:23:54,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004510 seconds.
2024-06-11 21:23:54,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:23:54,278:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:23:54,279:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:23:54,279:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:23:54,567:INFO:Uploading results into container
2024-06-11 21:23:54,568:INFO:Uploading model into container now
2024-06-11 21:23:54,569:INFO:_master_model_container: 3
2024-06-11 21:23:54,569:INFO:_display_container: 4
2024-06-11 21:23:54,569:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:23:54,570:INFO:create_model() successfully completed......................................
2024-06-11 21:23:54,664:INFO:SubProcess create_model() end ==================================
2024-06-11 21:23:54,665:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1759
2024-06-11 21:23:54,666:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.2405
2024-06-11 21:23:54,666:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:23:54,666:INFO:choose_better completed
2024-06-11 21:23:54,675:INFO:_master_model_container: 3
2024-06-11 21:23:54,675:INFO:_display_container: 3
2024-06-11 21:23:54,676:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:23:54,676:INFO:tune_model() successfully completed......................................
2024-06-11 21:23:54,819:INFO:Initializing plot_model()
2024-06-11 21:23:54,819:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:23:54,819:INFO:Checking exceptions
2024-06-11 21:23:54,830:INFO:Preloading libraries
2024-06-11 21:23:54,835:INFO:Copying training dataset
2024-06-11 21:23:54,835:INFO:Plot type: auc
2024-06-11 21:23:55,056:INFO:Fitting Model
2024-06-11 21:23:55,058:INFO:Scoring test/hold-out set
2024-06-11 21:23:55,060:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:23:55,060:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:23:55,060:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:23:55,076:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:23:55,076:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:23:55,076:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:23:55,330:INFO:Visual Rendered Successfully
2024-06-11 21:23:55,408:INFO:plot_model() successfully completed......................................
2024-06-11 21:23:55,432:INFO:Initializing plot_model()
2024-06-11 21:23:55,433:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:23:55,433:INFO:Checking exceptions
2024-06-11 21:23:55,443:INFO:Preloading libraries
2024-06-11 21:23:55,446:INFO:Copying training dataset
2024-06-11 21:23:55,446:INFO:Plot type: confusion_matrix
2024-06-11 21:23:55,647:INFO:Fitting Model
2024-06-11 21:23:55,647:INFO:Scoring test/hold-out set
2024-06-11 21:23:55,650:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:23:55,650:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:23:55,650:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:23:55,665:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:23:55,665:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:23:55,665:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:23:55,828:INFO:Visual Rendered Successfully
2024-06-11 21:23:55,908:INFO:plot_model() successfully completed......................................
2024-06-11 21:23:55,924:INFO:Initializing finalize_model()
2024-06-11 21:23:55,924:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:23:55,924:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:23:55,935:INFO:Initializing create_model()
2024-06-11 21:23:55,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:23:55,935:INFO:Checking exceptions
2024-06-11 21:23:55,937:INFO:Importing libraries
2024-06-11 21:23:55,937:INFO:Copying training dataset
2024-06-11 21:23:55,938:INFO:Defining folds
2024-06-11 21:23:55,938:INFO:Declaring metric variables
2024-06-11 21:23:55,938:INFO:Importing untrained model
2024-06-11 21:23:55,938:INFO:Declaring custom model
2024-06-11 21:23:55,939:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:23:55,941:INFO:Cross validation set to False
2024-06-11 21:23:55,941:INFO:Fitting Model
2024-06-11 21:23:57,939:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:23:57,939:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:23:57,939:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:23:58,085:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:23:58,085:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:23:58,085:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:23:58,085:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-11 21:23:58,093:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006878 seconds.
2024-06-11 21:23:58,093:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:23:58,094:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:23:58,094:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-11 21:23:58,095:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:23:58,431:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:23:58,431:INFO:create_model() successfully completed......................................
2024-06-11 21:23:58,519:INFO:_master_model_container: 3
2024-06-11 21:23:58,519:INFO:_display_container: 3
2024-06-11 21:23:58,563:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:23:58,564:INFO:finalize_model() successfully completed......................................
2024-06-11 21:23:58,729:INFO:Initializing evaluate_model()
2024-06-11 21:23:58,729:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:23:58,786:INFO:Initializing plot_model()
2024-06-11 21:23:58,786:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:23:58,786:INFO:Checking exceptions
2024-06-11 21:23:58,794:INFO:Preloading libraries
2024-06-11 21:23:58,798:INFO:Copying training dataset
2024-06-11 21:23:58,798:INFO:Plot type: pipeline
2024-06-11 21:23:59,090:INFO:Visual Rendered Successfully
2024-06-11 21:23:59,170:INFO:plot_model() successfully completed......................................
2024-06-11 21:24:22,419:INFO:Initializing plot_model()
2024-06-11 21:24:22,419:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B708B10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:24:22,419:INFO:Checking exceptions
2024-06-11 21:24:22,426:INFO:Preloading libraries
2024-06-11 21:24:22,429:INFO:Copying training dataset
2024-06-11 21:24:22,429:INFO:Plot type: confusion_matrix
2024-06-11 21:24:22,620:INFO:Fitting Model
2024-06-11 21:24:22,621:INFO:Scoring test/hold-out set
2024-06-11 21:24:22,623:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:24:22,623:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:24:22,623:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:24:22,642:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:24:22,642:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:24:22,642:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:24:22,787:INFO:Visual Rendered Successfully
2024-06-11 21:24:22,881:INFO:plot_model() successfully completed......................................
2024-06-11 21:24:37,375:INFO:PyCaret ClassificationExperiment
2024-06-11 21:24:37,375:INFO:Logging name: clf-default-name
2024-06-11 21:24:37,375:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:24:37,375:INFO:version 3.3.2
2024-06-11 21:24:37,375:INFO:Initializing setup()
2024-06-11 21:24:37,375:INFO:self.USI: 5e8e
2024-06-11 21:24:37,375:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:24:37,375:INFO:Checking environment
2024-06-11 21:24:37,375:INFO:python_version: 3.11.9
2024-06-11 21:24:37,375:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:24:37,375:INFO:machine: AMD64
2024-06-11 21:24:37,375:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:24:37,376:INFO:Memory: svmem(total=34056318976, available=23436886016, percent=31.2, used=10619432960, free=23436886016)
2024-06-11 21:24:37,376:INFO:Physical Core: 6
2024-06-11 21:24:37,376:INFO:Logical Core: 12
2024-06-11 21:24:37,376:INFO:Checking libraries
2024-06-11 21:24:37,376:INFO:System:
2024-06-11 21:24:37,376:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:24:37,376:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:24:37,376:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:24:37,376:INFO:PyCaret required dependencies:
2024-06-11 21:24:37,376:INFO:                 pip: 24.0
2024-06-11 21:24:37,376:INFO:          setuptools: 69.5.1
2024-06-11 21:24:37,376:INFO:             pycaret: 3.3.2
2024-06-11 21:24:37,376:INFO:             IPython: 8.25.0
2024-06-11 21:24:37,376:INFO:          ipywidgets: 8.1.3
2024-06-11 21:24:37,376:INFO:                tqdm: 4.66.4
2024-06-11 21:24:37,376:INFO:               numpy: 1.26.4
2024-06-11 21:24:37,376:INFO:              pandas: 2.1.4
2024-06-11 21:24:37,376:INFO:              jinja2: 3.1.4
2024-06-11 21:24:37,377:INFO:               scipy: 1.11.4
2024-06-11 21:24:37,377:INFO:              joblib: 1.3.2
2024-06-11 21:24:37,377:INFO:             sklearn: 1.4.2
2024-06-11 21:24:37,377:INFO:                pyod: 2.0.0
2024-06-11 21:24:37,377:INFO:            imblearn: 0.12.3
2024-06-11 21:24:37,377:INFO:   category_encoders: 2.6.3
2024-06-11 21:24:37,377:INFO:            lightgbm: 4.3.0
2024-06-11 21:24:37,377:INFO:               numba: 0.59.1
2024-06-11 21:24:37,377:INFO:            requests: 2.32.3
2024-06-11 21:24:37,377:INFO:          matplotlib: 3.7.5
2024-06-11 21:24:37,377:INFO:          scikitplot: 0.3.7
2024-06-11 21:24:37,377:INFO:         yellowbrick: 1.5
2024-06-11 21:24:37,377:INFO:              plotly: 5.22.0
2024-06-11 21:24:37,377:INFO:    plotly-resampler: Not installed
2024-06-11 21:24:37,377:INFO:             kaleido: 0.2.1
2024-06-11 21:24:37,377:INFO:           schemdraw: 0.15
2024-06-11 21:24:37,377:INFO:         statsmodels: 0.14.2
2024-06-11 21:24:37,378:INFO:              sktime: 0.26.0
2024-06-11 21:24:37,378:INFO:               tbats: 1.1.3
2024-06-11 21:24:37,378:INFO:            pmdarima: 2.0.4
2024-06-11 21:24:37,378:INFO:              psutil: 5.9.8
2024-06-11 21:24:37,378:INFO:          markupsafe: 2.1.5
2024-06-11 21:24:37,378:INFO:             pickle5: Not installed
2024-06-11 21:24:37,378:INFO:         cloudpickle: 3.0.0
2024-06-11 21:24:37,378:INFO:         deprecation: 2.1.0
2024-06-11 21:24:37,378:INFO:              xxhash: 3.4.1
2024-06-11 21:24:37,378:INFO:           wurlitzer: Not installed
2024-06-11 21:24:37,378:INFO:PyCaret optional dependencies:
2024-06-11 21:24:37,378:INFO:                shap: Not installed
2024-06-11 21:24:37,378:INFO:           interpret: Not installed
2024-06-11 21:24:37,378:INFO:                umap: Not installed
2024-06-11 21:24:37,379:INFO:     ydata_profiling: Not installed
2024-06-11 21:24:37,379:INFO:  explainerdashboard: Not installed
2024-06-11 21:24:37,379:INFO:             autoviz: Not installed
2024-06-11 21:24:37,379:INFO:           fairlearn: Not installed
2024-06-11 21:24:37,379:INFO:          deepchecks: Not installed
2024-06-11 21:24:37,379:INFO:             xgboost: Not installed
2024-06-11 21:24:37,379:INFO:            catboost: Not installed
2024-06-11 21:24:37,379:INFO:              kmodes: Not installed
2024-06-11 21:24:37,379:INFO:             mlxtend: Not installed
2024-06-11 21:24:37,379:INFO:       statsforecast: Not installed
2024-06-11 21:24:37,379:INFO:        tune_sklearn: Not installed
2024-06-11 21:24:37,379:INFO:                 ray: Not installed
2024-06-11 21:24:37,379:INFO:            hyperopt: Not installed
2024-06-11 21:24:37,379:INFO:              optuna: Not installed
2024-06-11 21:24:37,379:INFO:               skopt: Not installed
2024-06-11 21:24:37,379:INFO:              mlflow: Not installed
2024-06-11 21:24:37,379:INFO:              gradio: Not installed
2024-06-11 21:24:37,379:INFO:             fastapi: Not installed
2024-06-11 21:24:37,379:INFO:             uvicorn: Not installed
2024-06-11 21:24:37,379:INFO:              m2cgen: Not installed
2024-06-11 21:24:37,380:INFO:           evidently: Not installed
2024-06-11 21:24:37,380:INFO:               fugue: Not installed
2024-06-11 21:24:37,380:INFO:           streamlit: 1.35.0
2024-06-11 21:24:37,380:INFO:             prophet: Not installed
2024-06-11 21:24:37,380:INFO:None
2024-06-11 21:24:37,380:INFO:Set up data.
2024-06-11 21:24:37,427:INFO:Set up folding strategy.
2024-06-11 21:24:37,427:INFO:Set up train/test split.
2024-06-11 21:24:37,451:INFO:Set up index.
2024-06-11 21:24:37,452:INFO:Assigning column types.
2024-06-11 21:24:37,462:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:24:37,503:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:24:37,504:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:24:37,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:24:37,579:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:24:37,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,606:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:24:37,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:24:37,674:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:24:37,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,757:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:24:37,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:24:37,907:INFO:Preparing preprocessing pipeline...
2024-06-11 21:24:37,909:INFO:Set up date feature engineering.
2024-06-11 21:24:37,909:INFO:Set up simple imputation.
2024-06-11 21:24:37,922:INFO:Set up encoding of ordinal features.
2024-06-11 21:24:37,932:INFO:Set up encoding of categorical features.
2024-06-11 21:24:37,932:INFO:Set up removing outliers.
2024-06-11 21:24:37,932:INFO:Set up imbalanced handling.
2024-06-11 21:24:37,932:INFO:Set up feature normalization.
2024-06-11 21:24:37,932:INFO:Set up PCA.
2024-06-11 21:25:39,580:INFO:PyCaret ClassificationExperiment
2024-06-11 21:25:39,580:INFO:Logging name: clf-default-name
2024-06-11 21:25:39,580:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:25:39,580:INFO:version 3.3.2
2024-06-11 21:25:39,580:INFO:Initializing setup()
2024-06-11 21:25:39,580:INFO:self.USI: f23c
2024-06-11 21:25:39,580:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:25:39,580:INFO:Checking environment
2024-06-11 21:25:39,580:INFO:python_version: 3.11.9
2024-06-11 21:25:39,580:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:25:39,581:INFO:machine: AMD64
2024-06-11 21:25:39,581:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:25:39,581:INFO:Memory: svmem(total=34056318976, available=23336644608, percent=31.5, used=10719674368, free=23336644608)
2024-06-11 21:25:39,581:INFO:Physical Core: 6
2024-06-11 21:25:39,581:INFO:Logical Core: 12
2024-06-11 21:25:39,581:INFO:Checking libraries
2024-06-11 21:25:39,581:INFO:System:
2024-06-11 21:25:39,581:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:25:39,581:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:25:39,581:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:25:39,581:INFO:PyCaret required dependencies:
2024-06-11 21:25:39,581:INFO:                 pip: 24.0
2024-06-11 21:25:39,581:INFO:          setuptools: 69.5.1
2024-06-11 21:25:39,581:INFO:             pycaret: 3.3.2
2024-06-11 21:25:39,581:INFO:             IPython: 8.25.0
2024-06-11 21:25:39,581:INFO:          ipywidgets: 8.1.3
2024-06-11 21:25:39,581:INFO:                tqdm: 4.66.4
2024-06-11 21:25:39,582:INFO:               numpy: 1.26.4
2024-06-11 21:25:39,582:INFO:              pandas: 2.1.4
2024-06-11 21:25:39,582:INFO:              jinja2: 3.1.4
2024-06-11 21:25:39,582:INFO:               scipy: 1.11.4
2024-06-11 21:25:39,582:INFO:              joblib: 1.3.2
2024-06-11 21:25:39,582:INFO:             sklearn: 1.4.2
2024-06-11 21:25:39,582:INFO:                pyod: 2.0.0
2024-06-11 21:25:39,582:INFO:            imblearn: 0.12.3
2024-06-11 21:25:39,582:INFO:   category_encoders: 2.6.3
2024-06-11 21:25:39,582:INFO:            lightgbm: 4.3.0
2024-06-11 21:25:39,582:INFO:               numba: 0.59.1
2024-06-11 21:25:39,582:INFO:            requests: 2.32.3
2024-06-11 21:25:39,582:INFO:          matplotlib: 3.7.5
2024-06-11 21:25:39,582:INFO:          scikitplot: 0.3.7
2024-06-11 21:25:39,582:INFO:         yellowbrick: 1.5
2024-06-11 21:25:39,582:INFO:              plotly: 5.22.0
2024-06-11 21:25:39,582:INFO:    plotly-resampler: Not installed
2024-06-11 21:25:39,582:INFO:             kaleido: 0.2.1
2024-06-11 21:25:39,582:INFO:           schemdraw: 0.15
2024-06-11 21:25:39,582:INFO:         statsmodels: 0.14.2
2024-06-11 21:25:39,582:INFO:              sktime: 0.26.0
2024-06-11 21:25:39,583:INFO:               tbats: 1.1.3
2024-06-11 21:25:39,583:INFO:            pmdarima: 2.0.4
2024-06-11 21:25:39,583:INFO:              psutil: 5.9.8
2024-06-11 21:25:39,583:INFO:          markupsafe: 2.1.5
2024-06-11 21:25:39,583:INFO:             pickle5: Not installed
2024-06-11 21:25:39,583:INFO:         cloudpickle: 3.0.0
2024-06-11 21:25:39,583:INFO:         deprecation: 2.1.0
2024-06-11 21:25:39,583:INFO:              xxhash: 3.4.1
2024-06-11 21:25:39,583:INFO:           wurlitzer: Not installed
2024-06-11 21:25:39,583:INFO:PyCaret optional dependencies:
2024-06-11 21:25:39,583:INFO:                shap: Not installed
2024-06-11 21:25:39,583:INFO:           interpret: Not installed
2024-06-11 21:25:39,583:INFO:                umap: Not installed
2024-06-11 21:25:39,583:INFO:     ydata_profiling: Not installed
2024-06-11 21:25:39,583:INFO:  explainerdashboard: Not installed
2024-06-11 21:25:39,584:INFO:             autoviz: Not installed
2024-06-11 21:25:39,584:INFO:           fairlearn: Not installed
2024-06-11 21:25:39,584:INFO:          deepchecks: Not installed
2024-06-11 21:25:39,584:INFO:             xgboost: Not installed
2024-06-11 21:25:39,584:INFO:            catboost: Not installed
2024-06-11 21:25:39,584:INFO:              kmodes: Not installed
2024-06-11 21:25:39,584:INFO:             mlxtend: Not installed
2024-06-11 21:25:39,584:INFO:       statsforecast: Not installed
2024-06-11 21:25:39,584:INFO:        tune_sklearn: Not installed
2024-06-11 21:25:39,584:INFO:                 ray: Not installed
2024-06-11 21:25:39,584:INFO:            hyperopt: Not installed
2024-06-11 21:25:39,584:INFO:              optuna: Not installed
2024-06-11 21:25:39,585:INFO:               skopt: Not installed
2024-06-11 21:25:39,585:INFO:              mlflow: Not installed
2024-06-11 21:25:39,585:INFO:              gradio: Not installed
2024-06-11 21:25:39,585:INFO:             fastapi: Not installed
2024-06-11 21:25:39,585:INFO:             uvicorn: Not installed
2024-06-11 21:25:39,585:INFO:              m2cgen: Not installed
2024-06-11 21:25:39,585:INFO:           evidently: Not installed
2024-06-11 21:25:39,585:INFO:               fugue: Not installed
2024-06-11 21:25:39,585:INFO:           streamlit: 1.35.0
2024-06-11 21:25:39,585:INFO:             prophet: Not installed
2024-06-11 21:25:39,585:INFO:None
2024-06-11 21:25:39,585:INFO:Set up data.
2024-06-11 21:25:39,636:INFO:Set up folding strategy.
2024-06-11 21:25:39,636:INFO:Set up train/test split.
2024-06-11 21:25:39,670:INFO:Set up index.
2024-06-11 21:25:39,671:INFO:Assigning column types.
2024-06-11 21:25:39,682:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:25:39,725:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:25:39,726:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:25:39,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:39,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:39,809:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:25:39,809:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:25:39,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:39,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:39,847:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:25:39,909:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:25:39,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:39,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:39,986:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:25:40,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:40,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:40,015:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:25:40,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:40,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:40,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:40,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:40,172:INFO:Preparing preprocessing pipeline...
2024-06-11 21:25:40,174:INFO:Set up date feature engineering.
2024-06-11 21:25:40,174:INFO:Set up simple imputation.
2024-06-11 21:25:40,186:INFO:Set up encoding of ordinal features.
2024-06-11 21:25:40,198:INFO:Set up encoding of categorical features.
2024-06-11 21:25:40,199:INFO:Set up removing outliers.
2024-06-11 21:25:40,199:INFO:Set up imbalanced handling.
2024-06-11 21:25:40,199:INFO:Set up feature normalization.
2024-06-11 21:25:40,199:INFO:Set up PCA.
2024-06-11 21:25:40,616:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:25:40,650:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                                           sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-11 21:25:40,650:INFO:Creating final display dataframe.
2024-06-11 21:25:41,364:INFO:Setup _display_container:                     Description               Value
0                    Session id                 123
1                        Target                 mau
2                   Target type              Binary
3           Original data shape         (50000, 15)
4        Transformed data shape         (20274, 34)
5   Transformed train set shape          (5274, 34)
6    Transformed test set shape         (15000, 34)
7              Numeric features                   6
8                 Date features                   1
9          Categorical features                   7
10     Rows with missing values               17.1%
11                   Preprocess                True
12              Imputation type              simple
13           Numeric imputation                  -1
14       Categorical imputation                mode
15     Maximum one-hot encoding                  25
16              Encoding method                None
17              Remove outliers                True
18           Outliers threshold                0.05
19                Fix imbalance                True
20         Fix imbalance method  RandomUnderSampler
21                    Normalize                True
22             Normalize method              robust
23                          PCA                True
24                   PCA method         incremental
25               PCA components                None
26               Fold Generator     StratifiedKFold
27                  Fold Number                  10
28                     CPU Jobs                  -1
29                      Use GPU               False
30               Log Experiment               False
31              Experiment Name    clf-default-name
32                          USI                f23c
2024-06-11 21:25:41,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:41,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:41,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:41,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:25:41,572:INFO:setup() successfully completed in 2.09s...............
2024-06-11 21:25:41,587:INFO:Initializing create_model()
2024-06-11 21:25:41,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:25:41,588:INFO:Checking exceptions
2024-06-11 21:25:41,603:INFO:Importing libraries
2024-06-11 21:25:41,603:INFO:Copying training dataset
2024-06-11 21:25:41,624:INFO:Defining folds
2024-06-11 21:25:41,625:INFO:Declaring metric variables
2024-06-11 21:25:41,628:INFO:Importing untrained model
2024-06-11 21:25:41,632:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:25:41,639:INFO:Starting cross validation
2024-06-11 21:25:41,642:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:25:43,869:INFO:Calculating mean and std
2024-06-11 21:25:43,870:INFO:Creating metrics dataframe
2024-06-11 21:25:43,877:INFO:Finalizing model
2024-06-11 21:25:44,779:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 2637
2024-06-11 21:25:44,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.
2024-06-11 21:25:44,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:25:44,780:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:25:44,781:INFO:[LightGBM] [Info] Number of data points in the train set: 5274, number of used features: 33
2024-06-11 21:25:44,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:25:44,895:INFO:Uploading results into container
2024-06-11 21:25:44,897:INFO:Uploading model into container now
2024-06-11 21:25:44,909:INFO:_master_model_container: 1
2024-06-11 21:25:44,909:INFO:_display_container: 2
2024-06-11 21:25:44,910:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:25:44,910:INFO:create_model() successfully completed......................................
2024-06-11 21:25:45,053:INFO:Initializing tune_model()
2024-06-11 21:25:45,053:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:25:45,053:INFO:Checking exceptions
2024-06-11 21:25:45,080:INFO:Copying training dataset
2024-06-11 21:25:45,094:INFO:Checking base model
2024-06-11 21:25:45,094:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:25:45,098:INFO:Declaring metric variables
2024-06-11 21:25:45,102:INFO:Defining Hyperparameters
2024-06-11 21:25:45,199:INFO:Tuning with n_jobs=-1
2024-06-11 21:25:45,199:INFO:Initializing RandomizedSearchCV
2024-06-11 21:26:13,559:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 10, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 21:26:13,560:INFO:Hyperparameter search completed
2024-06-11 21:26:13,560:INFO:SubProcess create_model() called ==================================
2024-06-11 21:26:13,561:INFO:Initializing create_model()
2024-06-11 21:26:13,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC3B801090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 10, 'num_leaves': 10, 'n_estimators': 90, 'min_split_gain': 0.5, 'min_child_samples': 1, 'learning_rate': 1e-07, 'feature_fraction': 1.0, 'bagging_freq': 1, 'bagging_fraction': 0.6})
2024-06-11 21:26:13,562:INFO:Checking exceptions
2024-06-11 21:26:13,562:INFO:Importing libraries
2024-06-11 21:26:13,562:INFO:Copying training dataset
2024-06-11 21:26:13,599:INFO:Defining folds
2024-06-11 21:26:13,599:INFO:Declaring metric variables
2024-06-11 21:26:13,603:INFO:Importing untrained model
2024-06-11 21:26:13,604:INFO:Declaring custom model
2024-06-11 21:26:13,610:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:26:13,621:INFO:Starting cross validation
2024-06-11 21:26:13,627:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:26:15,941:INFO:Calculating mean and std
2024-06-11 21:26:15,943:INFO:Creating metrics dataframe
2024-06-11 21:26:15,951:INFO:Finalizing model
2024-06-11 21:26:17,017:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:26:17,018:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:26:17,018:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:26:17,027:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:26:17,027:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:26:17,027:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:26:17,027:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 2637
2024-06-11 21:26:17,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.
2024-06-11 21:26:17,028:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:26:17,028:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:26:17,029:INFO:[LightGBM] [Info] Number of data points in the train set: 5274, number of used features: 33
2024-06-11 21:26:17,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:26:17,099:INFO:Uploading results into container
2024-06-11 21:26:17,100:INFO:Uploading model into container now
2024-06-11 21:26:17,101:INFO:_master_model_container: 2
2024-06-11 21:26:17,101:INFO:_display_container: 3
2024-06-11 21:26:17,102:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:26:17,103:INFO:create_model() successfully completed......................................
2024-06-11 21:26:17,225:INFO:SubProcess create_model() end ==================================
2024-06-11 21:26:17,225:INFO:choose_better activated
2024-06-11 21:26:17,228:INFO:SubProcess create_model() called ==================================
2024-06-11 21:26:17,229:INFO:Initializing create_model()
2024-06-11 21:26:17,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:26:17,229:INFO:Checking exceptions
2024-06-11 21:26:17,231:INFO:Importing libraries
2024-06-11 21:26:17,231:INFO:Copying training dataset
2024-06-11 21:26:17,249:INFO:Defining folds
2024-06-11 21:26:17,249:INFO:Declaring metric variables
2024-06-11 21:26:17,249:INFO:Importing untrained model
2024-06-11 21:26:17,249:INFO:Declaring custom model
2024-06-11 21:26:17,250:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:26:17,250:INFO:Starting cross validation
2024-06-11 21:26:17,252:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:26:19,653:INFO:Calculating mean and std
2024-06-11 21:26:19,654:INFO:Creating metrics dataframe
2024-06-11 21:26:19,657:INFO:Finalizing model
2024-06-11 21:26:20,597:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 2637
2024-06-11 21:26:20,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001006 seconds.
2024-06-11 21:26:20,599:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:26:20,599:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:26:20,599:INFO:[LightGBM] [Info] Number of data points in the train set: 5274, number of used features: 33
2024-06-11 21:26:20,600:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:26:20,770:INFO:Uploading results into container
2024-06-11 21:26:20,771:INFO:Uploading model into container now
2024-06-11 21:26:20,771:INFO:_master_model_container: 3
2024-06-11 21:26:20,772:INFO:_display_container: 4
2024-06-11 21:26:20,772:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:26:20,772:INFO:create_model() successfully completed......................................
2024-06-11 21:26:20,892:INFO:SubProcess create_model() end ==================================
2024-06-11 21:26:20,893:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.2109
2024-06-11 21:26:20,893:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.2416
2024-06-11 21:26:20,894:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:26:20,894:INFO:choose_better completed
2024-06-11 21:26:20,901:INFO:_master_model_container: 3
2024-06-11 21:26:20,901:INFO:_display_container: 3
2024-06-11 21:26:20,902:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:26:20,902:INFO:tune_model() successfully completed......................................
2024-06-11 21:26:21,056:INFO:Initializing plot_model()
2024-06-11 21:26:21,057:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:26:21,057:INFO:Checking exceptions
2024-06-11 21:26:21,067:INFO:Preloading libraries
2024-06-11 21:26:21,071:INFO:Copying training dataset
2024-06-11 21:26:21,071:INFO:Plot type: auc
2024-06-11 21:26:21,240:INFO:Fitting Model
2024-06-11 21:26:21,241:INFO:Scoring test/hold-out set
2024-06-11 21:26:21,243:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:26:21,243:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:26:21,243:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:26:21,260:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:26:21,260:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:26:21,260:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:26:21,507:INFO:Visual Rendered Successfully
2024-06-11 21:26:21,602:INFO:plot_model() successfully completed......................................
2024-06-11 21:26:21,631:INFO:Initializing plot_model()
2024-06-11 21:26:21,631:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:26:21,631:INFO:Checking exceptions
2024-06-11 21:26:21,645:INFO:Preloading libraries
2024-06-11 21:26:21,656:INFO:Copying training dataset
2024-06-11 21:26:21,656:INFO:Plot type: confusion_matrix
2024-06-11 21:26:21,832:INFO:Fitting Model
2024-06-11 21:26:21,832:INFO:Scoring test/hold-out set
2024-06-11 21:26:21,834:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:26:21,834:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:26:21,834:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:26:21,854:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:26:21,854:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:26:21,854:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:26:22,013:INFO:Visual Rendered Successfully
2024-06-11 21:26:22,101:INFO:plot_model() successfully completed......................................
2024-06-11 21:26:22,115:INFO:Initializing finalize_model()
2024-06-11 21:26:22,115:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:26:22,115:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:26:22,125:INFO:Initializing create_model()
2024-06-11 21:26:22,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=90, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=10, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:26:22,125:INFO:Checking exceptions
2024-06-11 21:26:22,126:INFO:Importing libraries
2024-06-11 21:26:22,126:INFO:Copying training dataset
2024-06-11 21:26:22,127:INFO:Defining folds
2024-06-11 21:26:22,127:INFO:Declaring metric variables
2024-06-11 21:26:22,127:INFO:Importing untrained model
2024-06-11 21:26:22,127:INFO:Declaring custom model
2024-06-11 21:26:22,128:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:26:22,130:INFO:Cross validation set to False
2024-06-11 21:26:22,130:INFO:Fitting Model
2024-06-11 21:26:23,270:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:26:23,271:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:26:23,271:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:26:23,282:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:26:23,282:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:26:23,282:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-06-11 21:26:23,282:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 3752
2024-06-11 21:26:23,284:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001173 seconds.
2024-06-11 21:26:23,284:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:26:23,284:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:26:23,284:INFO:[LightGBM] [Info] Number of data points in the train set: 7504, number of used features: 33
2024-06-11 21:26:23,285:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:26:23,436:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:26:23,437:INFO:create_model() successfully completed......................................
2024-06-11 21:26:23,545:INFO:_master_model_container: 3
2024-06-11 21:26:23,545:INFO:_display_container: 3
2024-06-11 21:26:23,581:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:26:23,581:INFO:finalize_model() successfully completed......................................
2024-06-11 21:26:23,734:INFO:Initializing evaluate_model()
2024-06-11 21:26:23,734:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:26:23,783:INFO:Initializing plot_model()
2024-06-11 21:26:23,783:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=1,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=90, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123, reg_alpha=10,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:26:23,783:INFO:Checking exceptions
2024-06-11 21:26:23,789:INFO:Preloading libraries
2024-06-11 21:26:23,794:INFO:Copying training dataset
2024-06-11 21:26:23,794:INFO:Plot type: pipeline
2024-06-11 21:26:24,094:INFO:Visual Rendered Successfully
2024-06-11 21:26:24,190:INFO:plot_model() successfully completed......................................
2024-06-11 21:26:29,607:INFO:Initializing tune_model()
2024-06-11 21:26:29,607:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:26:29,607:INFO:Checking exceptions
2024-06-11 21:26:29,640:INFO:Copying training dataset
2024-06-11 21:26:29,659:INFO:Checking base model
2024-06-11 21:26:29,660:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:26:29,663:INFO:Declaring metric variables
2024-06-11 21:26:29,667:INFO:Defining Hyperparameters
2024-06-11 21:26:29,812:INFO:Tuning with n_jobs=-1
2024-06-11 21:26:29,812:INFO:Initializing RandomizedSearchCV
2024-06-11 21:26:56,817:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2024-06-11 21:26:56,818:INFO:Hyperparameter search completed
2024-06-11 21:26:56,819:INFO:SubProcess create_model() called ==================================
2024-06-11 21:26:56,820:INFO:Initializing create_model()
2024-06-11 21:26:56,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC468C1A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2024-06-11 21:26:56,820:INFO:Checking exceptions
2024-06-11 21:26:56,820:INFO:Importing libraries
2024-06-11 21:26:56,820:INFO:Copying training dataset
2024-06-11 21:26:56,860:INFO:Defining folds
2024-06-11 21:26:56,860:INFO:Declaring metric variables
2024-06-11 21:26:56,867:INFO:Importing untrained model
2024-06-11 21:26:56,867:INFO:Declaring custom model
2024-06-11 21:26:56,876:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:26:56,890:INFO:Starting cross validation
2024-06-11 21:26:56,895:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:26:59,282:INFO:Calculating mean and std
2024-06-11 21:26:59,284:INFO:Creating metrics dataframe
2024-06-11 21:26:59,293:INFO:Finalizing model
2024-06-11 21:27:00,217:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:00,217:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:00,217:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:00,226:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:00,226:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:00,227:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:00,227:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 2637
2024-06-11 21:27:00,228:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.
2024-06-11 21:27:00,228:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:27:00,228:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:27:00,229:INFO:[LightGBM] [Info] Number of data points in the train set: 5274, number of used features: 33
2024-06-11 21:27:00,229:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:27:00,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:00,313:INFO:Uploading results into container
2024-06-11 21:27:00,315:INFO:Uploading model into container now
2024-06-11 21:27:00,315:INFO:_master_model_container: 4
2024-06-11 21:27:00,316:INFO:_display_container: 4
2024-06-11 21:27:00,317:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:27:00,317:INFO:create_model() successfully completed......................................
2024-06-11 21:27:00,435:INFO:SubProcess create_model() end ==================================
2024-06-11 21:27:00,435:INFO:choose_better activated
2024-06-11 21:27:00,439:INFO:SubProcess create_model() called ==================================
2024-06-11 21:27:00,440:INFO:Initializing create_model()
2024-06-11 21:27:00,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:27:00,440:INFO:Checking exceptions
2024-06-11 21:27:00,441:INFO:Importing libraries
2024-06-11 21:27:00,442:INFO:Copying training dataset
2024-06-11 21:27:00,461:INFO:Defining folds
2024-06-11 21:27:00,461:INFO:Declaring metric variables
2024-06-11 21:27:00,462:INFO:Importing untrained model
2024-06-11 21:27:00,462:INFO:Declaring custom model
2024-06-11 21:27:00,462:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:27:00,463:INFO:Starting cross validation
2024-06-11 21:27:00,465:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:27:02,577:INFO:Calculating mean and std
2024-06-11 21:27:02,577:INFO:Creating metrics dataframe
2024-06-11 21:27:02,580:INFO:Finalizing model
2024-06-11 21:27:03,503:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 2637
2024-06-11 21:27:03,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.
2024-06-11 21:27:03,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:27:03,505:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:27:03,505:INFO:[LightGBM] [Info] Number of data points in the train set: 5274, number of used features: 33
2024-06-11 21:27:03,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:27:03,592:INFO:Uploading results into container
2024-06-11 21:27:03,593:INFO:Uploading model into container now
2024-06-11 21:27:03,593:INFO:_master_model_container: 5
2024-06-11 21:27:03,593:INFO:_display_container: 5
2024-06-11 21:27:03,594:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:27:03,594:INFO:create_model() successfully completed......................................
2024-06-11 21:27:03,703:INFO:SubProcess create_model() end ==================================
2024-06-11 21:27:03,703:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6798
2024-06-11 21:27:03,704:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7042
2024-06-11 21:27:03,704:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:27:03,704:INFO:choose_better completed
2024-06-11 21:27:03,712:INFO:_master_model_container: 5
2024-06-11 21:27:03,712:INFO:_display_container: 4
2024-06-11 21:27:03,712:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:27:03,712:INFO:tune_model() successfully completed......................................
2024-06-11 21:27:03,830:INFO:Initializing plot_model()
2024-06-11 21:27:03,830:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:27:03,830:INFO:Checking exceptions
2024-06-11 21:27:03,841:INFO:Preloading libraries
2024-06-11 21:27:03,848:INFO:Copying training dataset
2024-06-11 21:27:03,848:INFO:Plot type: auc
2024-06-11 21:27:04,021:INFO:Fitting Model
2024-06-11 21:27:04,021:INFO:Scoring test/hold-out set
2024-06-11 21:27:04,023:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:04,023:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:04,023:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:04,044:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:04,044:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:04,044:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:04,273:INFO:Visual Rendered Successfully
2024-06-11 21:27:04,367:INFO:plot_model() successfully completed......................................
2024-06-11 21:27:04,385:INFO:Initializing plot_model()
2024-06-11 21:27:04,386:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:27:04,386:INFO:Checking exceptions
2024-06-11 21:27:04,396:INFO:Preloading libraries
2024-06-11 21:27:04,402:INFO:Copying training dataset
2024-06-11 21:27:04,402:INFO:Plot type: confusion_matrix
2024-06-11 21:27:04,565:INFO:Fitting Model
2024-06-11 21:27:04,565:INFO:Scoring test/hold-out set
2024-06-11 21:27:04,567:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:04,567:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:04,567:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:04,588:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:04,589:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:04,589:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:04,743:INFO:Visual Rendered Successfully
2024-06-11 21:27:04,834:INFO:plot_model() successfully completed......................................
2024-06-11 21:27:04,850:INFO:Initializing finalize_model()
2024-06-11 21:27:04,850:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:27:04,850:INFO:Finalizing LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:27:04,861:INFO:Initializing create_model()
2024-06-11 21:27:04,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:27:04,862:INFO:Checking exceptions
2024-06-11 21:27:04,863:INFO:Importing libraries
2024-06-11 21:27:04,863:INFO:Copying training dataset
2024-06-11 21:27:04,864:INFO:Defining folds
2024-06-11 21:27:04,864:INFO:Declaring metric variables
2024-06-11 21:27:04,864:INFO:Importing untrained model
2024-06-11 21:27:04,864:INFO:Declaring custom model
2024-06-11 21:27:04,865:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:27:04,867:INFO:Cross validation set to False
2024-06-11 21:27:04,867:INFO:Fitting Model
2024-06-11 21:27:05,993:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:05,993:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:05,993:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:06,004:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:06,004:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:06,004:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:06,005:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 3752
2024-06-11 21:27:06,006:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001012 seconds.
2024-06-11 21:27:06,006:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:27:06,006:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:27:06,007:INFO:[LightGBM] [Info] Number of data points in the train set: 7504, number of used features: 33
2024-06-11 21:27:06,007:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:27:06,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:27:06,163:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:27:06,163:INFO:create_model() successfully completed......................................
2024-06-11 21:27:06,269:INFO:_master_model_container: 5
2024-06-11 21:27:06,270:INFO:_display_container: 4
2024-06-11 21:27:06,307:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:27:06,307:INFO:finalize_model() successfully completed......................................
2024-06-11 21:27:06,499:INFO:Initializing evaluate_model()
2024-06-11 21:27:06,499:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:27:06,549:INFO:Initializing plot_model()
2024-06-11 21:27:06,549:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:27:06,549:INFO:Checking exceptions
2024-06-11 21:27:06,555:INFO:Preloading libraries
2024-06-11 21:27:06,562:INFO:Copying training dataset
2024-06-11 21:27:06,562:INFO:Plot type: pipeline
2024-06-11 21:27:06,803:INFO:Visual Rendered Successfully
2024-06-11 21:27:06,898:INFO:plot_model() successfully completed......................................
2024-06-11 21:27:54,730:INFO:Initializing plot_model()
2024-06-11 21:27:54,731:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3B8A4A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:27:54,731:INFO:Checking exceptions
2024-06-11 21:27:54,737:INFO:Preloading libraries
2024-06-11 21:27:54,744:INFO:Copying training dataset
2024-06-11 21:27:54,745:INFO:Plot type: confusion_matrix
2024-06-11 21:27:54,925:INFO:Fitting Model
2024-06-11 21:27:54,925:INFO:Scoring test/hold-out set
2024-06-11 21:27:54,927:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:54,927:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:54,927:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:54,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-11 21:27:54,951:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2024-06-11 21:27:54,951:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-06-11 21:27:55,104:INFO:Visual Rendered Successfully
2024-06-11 21:27:55,201:INFO:plot_model() successfully completed......................................
2024-06-11 21:28:10,405:INFO:PyCaret ClassificationExperiment
2024-06-11 21:28:10,405:INFO:Logging name: clf-default-name
2024-06-11 21:28:10,405:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:28:10,405:INFO:version 3.3.2
2024-06-11 21:28:10,405:INFO:Initializing setup()
2024-06-11 21:28:10,405:INFO:self.USI: 0eef
2024-06-11 21:28:10,405:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:28:10,405:INFO:Checking environment
2024-06-11 21:28:10,405:INFO:python_version: 3.11.9
2024-06-11 21:28:10,405:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:28:10,406:INFO:machine: AMD64
2024-06-11 21:28:10,406:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:28:10,406:INFO:Memory: svmem(total=34056318976, available=23328747520, percent=31.5, used=10727571456, free=23328747520)
2024-06-11 21:28:10,406:INFO:Physical Core: 6
2024-06-11 21:28:10,406:INFO:Logical Core: 12
2024-06-11 21:28:10,406:INFO:Checking libraries
2024-06-11 21:28:10,406:INFO:System:
2024-06-11 21:28:10,406:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:28:10,406:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:28:10,406:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:28:10,406:INFO:PyCaret required dependencies:
2024-06-11 21:28:10,406:INFO:                 pip: 24.0
2024-06-11 21:28:10,406:INFO:          setuptools: 69.5.1
2024-06-11 21:28:10,406:INFO:             pycaret: 3.3.2
2024-06-11 21:28:10,407:INFO:             IPython: 8.25.0
2024-06-11 21:28:10,407:INFO:          ipywidgets: 8.1.3
2024-06-11 21:28:10,407:INFO:                tqdm: 4.66.4
2024-06-11 21:28:10,407:INFO:               numpy: 1.26.4
2024-06-11 21:28:10,407:INFO:              pandas: 2.1.4
2024-06-11 21:28:10,407:INFO:              jinja2: 3.1.4
2024-06-11 21:28:10,407:INFO:               scipy: 1.11.4
2024-06-11 21:28:10,407:INFO:              joblib: 1.3.2
2024-06-11 21:28:10,407:INFO:             sklearn: 1.4.2
2024-06-11 21:28:10,407:INFO:                pyod: 2.0.0
2024-06-11 21:28:10,407:INFO:            imblearn: 0.12.3
2024-06-11 21:28:10,407:INFO:   category_encoders: 2.6.3
2024-06-11 21:28:10,407:INFO:            lightgbm: 4.3.0
2024-06-11 21:28:10,407:INFO:               numba: 0.59.1
2024-06-11 21:28:10,407:INFO:            requests: 2.32.3
2024-06-11 21:28:10,407:INFO:          matplotlib: 3.7.5
2024-06-11 21:28:10,408:INFO:          scikitplot: 0.3.7
2024-06-11 21:28:10,408:INFO:         yellowbrick: 1.5
2024-06-11 21:28:10,408:INFO:              plotly: 5.22.0
2024-06-11 21:28:10,408:INFO:    plotly-resampler: Not installed
2024-06-11 21:28:10,408:INFO:             kaleido: 0.2.1
2024-06-11 21:28:10,408:INFO:           schemdraw: 0.15
2024-06-11 21:28:10,408:INFO:         statsmodels: 0.14.2
2024-06-11 21:28:10,408:INFO:              sktime: 0.26.0
2024-06-11 21:28:10,408:INFO:               tbats: 1.1.3
2024-06-11 21:28:10,408:INFO:            pmdarima: 2.0.4
2024-06-11 21:28:10,408:INFO:              psutil: 5.9.8
2024-06-11 21:28:10,408:INFO:          markupsafe: 2.1.5
2024-06-11 21:28:10,408:INFO:             pickle5: Not installed
2024-06-11 21:28:10,408:INFO:         cloudpickle: 3.0.0
2024-06-11 21:28:10,408:INFO:         deprecation: 2.1.0
2024-06-11 21:28:10,408:INFO:              xxhash: 3.4.1
2024-06-11 21:28:10,408:INFO:           wurlitzer: Not installed
2024-06-11 21:28:10,408:INFO:PyCaret optional dependencies:
2024-06-11 21:28:10,408:INFO:                shap: Not installed
2024-06-11 21:28:10,408:INFO:           interpret: Not installed
2024-06-11 21:28:10,409:INFO:                umap: Not installed
2024-06-11 21:28:10,409:INFO:     ydata_profiling: Not installed
2024-06-11 21:28:10,409:INFO:  explainerdashboard: Not installed
2024-06-11 21:28:10,409:INFO:             autoviz: Not installed
2024-06-11 21:28:10,409:INFO:           fairlearn: Not installed
2024-06-11 21:28:10,409:INFO:          deepchecks: Not installed
2024-06-11 21:28:10,409:INFO:             xgboost: Not installed
2024-06-11 21:28:10,409:INFO:            catboost: Not installed
2024-06-11 21:28:10,409:INFO:              kmodes: Not installed
2024-06-11 21:28:10,409:INFO:             mlxtend: Not installed
2024-06-11 21:28:10,409:INFO:       statsforecast: Not installed
2024-06-11 21:28:10,409:INFO:        tune_sklearn: Not installed
2024-06-11 21:28:10,409:INFO:                 ray: Not installed
2024-06-11 21:28:10,409:INFO:            hyperopt: Not installed
2024-06-11 21:28:10,409:INFO:              optuna: Not installed
2024-06-11 21:28:10,409:INFO:               skopt: Not installed
2024-06-11 21:28:10,409:INFO:              mlflow: Not installed
2024-06-11 21:28:10,409:INFO:              gradio: Not installed
2024-06-11 21:28:10,409:INFO:             fastapi: Not installed
2024-06-11 21:28:10,409:INFO:             uvicorn: Not installed
2024-06-11 21:28:10,409:INFO:              m2cgen: Not installed
2024-06-11 21:28:10,409:INFO:           evidently: Not installed
2024-06-11 21:28:10,410:INFO:               fugue: Not installed
2024-06-11 21:28:10,410:INFO:           streamlit: 1.35.0
2024-06-11 21:28:10,410:INFO:             prophet: Not installed
2024-06-11 21:28:10,410:INFO:None
2024-06-11 21:28:10,410:INFO:Set up data.
2024-06-11 21:28:10,453:INFO:Set up folding strategy.
2024-06-11 21:28:10,453:INFO:Set up train/test split.
2024-06-11 21:28:10,481:INFO:Set up index.
2024-06-11 21:28:10,482:INFO:Assigning column types.
2024-06-11 21:28:10,493:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:28:10,534:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:28:10,535:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:28:10,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:10,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:10,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:28:10,610:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:28:10,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:10,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:10,642:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:28:10,690:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:28:10,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:10,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:10,774:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:28:10,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:10,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:10,804:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:28:10,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:10,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:11,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:11,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:11,016:INFO:Preparing preprocessing pipeline...
2024-06-11 21:28:11,019:INFO:Set up date feature engineering.
2024-06-11 21:28:11,019:INFO:Set up simple imputation.
2024-06-11 21:28:11,033:INFO:Set up encoding of ordinal features.
2024-06-11 21:28:11,049:INFO:Set up encoding of categorical features.
2024-06-11 21:28:11,049:INFO:Set up removing outliers.
2024-06-11 21:28:11,050:INFO:Set up imbalanced handling.
2024-06-11 21:28:11,050:INFO:Set up feature normalization.
2024-06-11 21:28:11,050:INFO:Set up PCA.
2024-06-11 21:28:13,225:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:28:13,257:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                                   sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-11 21:28:13,257:INFO:Creating final display dataframe.
2024-06-11 21:28:15,197:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (47137, 34)
5   Transformed train set shape       (32137, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method        TomekLinks
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              0eef
2024-06-11 21:28:15,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:15,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:15,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:15,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:28:15,339:INFO:setup() successfully completed in 5.02s...............
2024-06-11 21:28:15,352:INFO:Initializing create_model()
2024-06-11 21:28:15,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:28:15,352:INFO:Checking exceptions
2024-06-11 21:28:15,366:INFO:Importing libraries
2024-06-11 21:28:15,366:INFO:Copying training dataset
2024-06-11 21:28:15,384:INFO:Defining folds
2024-06-11 21:28:15,384:INFO:Declaring metric variables
2024-06-11 21:28:15,387:INFO:Importing untrained model
2024-06-11 21:28:15,391:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:28:15,397:INFO:Starting cross validation
2024-06-11 21:28:15,400:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:28:22,043:INFO:Calculating mean and std
2024-06-11 21:28:22,044:INFO:Creating metrics dataframe
2024-06-11 21:28:22,051:INFO:Finalizing model
2024-06-11 21:28:24,409:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-11 21:28:24,412:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002475 seconds.
2024-06-11 21:28:24,412:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:28:24,413:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:28:24,413:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-11 21:28:24,414:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-11 21:28:24,414:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-11 21:28:24,570:INFO:Uploading results into container
2024-06-11 21:28:24,571:INFO:Uploading model into container now
2024-06-11 21:28:24,583:INFO:_master_model_container: 1
2024-06-11 21:28:24,583:INFO:_display_container: 2
2024-06-11 21:28:24,584:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:28:24,584:INFO:create_model() successfully completed......................................
2024-06-11 21:28:24,719:INFO:Initializing tune_model()
2024-06-11 21:28:24,720:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:28:24,720:INFO:Checking exceptions
2024-06-11 21:28:24,747:INFO:Copying training dataset
2024-06-11 21:28:24,769:INFO:Checking base model
2024-06-11 21:28:24,769:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:28:24,774:INFO:Declaring metric variables
2024-06-11 21:28:24,780:INFO:Defining Hyperparameters
2024-06-11 21:28:24,904:INFO:Tuning with n_jobs=-1
2024-06-11 21:28:24,904:INFO:Initializing RandomizedSearchCV
2024-06-11 21:30:28,526:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 21:30:28,528:INFO:Hyperparameter search completed
2024-06-11 21:30:28,528:INFO:SubProcess create_model() called ==================================
2024-06-11 21:30:28,529:INFO:Initializing create_model()
2024-06-11 21:30:28,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC3BA8F5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 21:30:28,530:INFO:Checking exceptions
2024-06-11 21:30:28,530:INFO:Importing libraries
2024-06-11 21:30:28,530:INFO:Copying training dataset
2024-06-11 21:30:28,571:INFO:Defining folds
2024-06-11 21:30:28,571:INFO:Declaring metric variables
2024-06-11 21:30:28,577:INFO:Importing untrained model
2024-06-11 21:30:28,577:INFO:Declaring custom model
2024-06-11 21:30:28,585:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:30:28,599:INFO:Starting cross validation
2024-06-11 21:30:28,605:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:30:38,879:INFO:Calculating mean and std
2024-06-11 21:30:38,881:INFO:Creating metrics dataframe
2024-06-11 21:30:38,891:INFO:Finalizing model
2024-06-11 21:30:41,790:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:30:41,790:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:30:41,790:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:30:41,851:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:30:41,851:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:30:41,851:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:30:41,851:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-11 21:30:41,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004202 seconds.
2024-06-11 21:30:41,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:30:41,858:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:30:41,860:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-11 21:30:41,862:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-11 21:30:41,862:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-11 21:30:41,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:41,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:41,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:41,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:41,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:30:42,760:INFO:Uploading results into container
2024-06-11 21:30:42,761:INFO:Uploading model into container now
2024-06-11 21:30:42,762:INFO:_master_model_container: 2
2024-06-11 21:30:42,762:INFO:_display_container: 3
2024-06-11 21:30:42,763:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:30:42,763:INFO:create_model() successfully completed......................................
2024-06-11 21:30:42,916:INFO:SubProcess create_model() end ==================================
2024-06-11 21:30:42,916:INFO:choose_better activated
2024-06-11 21:30:42,919:INFO:SubProcess create_model() called ==================================
2024-06-11 21:30:42,920:INFO:Initializing create_model()
2024-06-11 21:30:42,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:30:42,920:INFO:Checking exceptions
2024-06-11 21:30:42,922:INFO:Importing libraries
2024-06-11 21:30:42,922:INFO:Copying training dataset
2024-06-11 21:30:42,946:INFO:Defining folds
2024-06-11 21:30:42,946:INFO:Declaring metric variables
2024-06-11 21:30:42,946:INFO:Importing untrained model
2024-06-11 21:30:42,946:INFO:Declaring custom model
2024-06-11 21:30:42,947:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:30:42,947:INFO:Starting cross validation
2024-06-11 21:30:42,950:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:30:51,039:INFO:Calculating mean and std
2024-06-11 21:30:51,040:INFO:Creating metrics dataframe
2024-06-11 21:30:51,043:INFO:Finalizing model
2024-06-11 21:30:53,813:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-11 21:30:53,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003573 seconds.
2024-06-11 21:30:53,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:30:53,818:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:30:53,818:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-11 21:30:53,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-11 21:30:53,819:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-11 21:30:54,092:INFO:Uploading results into container
2024-06-11 21:30:54,093:INFO:Uploading model into container now
2024-06-11 21:30:54,093:INFO:_master_model_container: 3
2024-06-11 21:30:54,093:INFO:_display_container: 4
2024-06-11 21:30:54,094:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:30:54,094:INFO:create_model() successfully completed......................................
2024-06-11 21:30:54,226:INFO:SubProcess create_model() end ==================================
2024-06-11 21:30:54,227:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1269
2024-06-11 21:30:54,227:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.119
2024-06-11 21:30:54,228:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:30:54,228:INFO:choose_better completed
2024-06-11 21:30:54,228:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-11 21:30:54,237:INFO:_master_model_container: 3
2024-06-11 21:30:54,238:INFO:_display_container: 3
2024-06-11 21:30:54,238:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:30:54,238:INFO:tune_model() successfully completed......................................
2024-06-11 21:30:54,356:INFO:Initializing plot_model()
2024-06-11 21:30:54,356:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:30:54,356:INFO:Checking exceptions
2024-06-11 21:30:54,368:INFO:Preloading libraries
2024-06-11 21:30:54,375:INFO:Copying training dataset
2024-06-11 21:30:54,375:INFO:Plot type: auc
2024-06-11 21:30:54,569:INFO:Fitting Model
2024-06-11 21:30:54,570:INFO:Scoring test/hold-out set
2024-06-11 21:30:54,852:INFO:Visual Rendered Successfully
2024-06-11 21:30:54,948:INFO:plot_model() successfully completed......................................
2024-06-11 21:30:54,972:INFO:Initializing plot_model()
2024-06-11 21:30:54,973:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:30:54,973:INFO:Checking exceptions
2024-06-11 21:30:54,988:INFO:Preloading libraries
2024-06-11 21:30:55,002:INFO:Copying training dataset
2024-06-11 21:30:55,002:INFO:Plot type: confusion_matrix
2024-06-11 21:30:55,198:INFO:Fitting Model
2024-06-11 21:30:55,199:INFO:Scoring test/hold-out set
2024-06-11 21:30:55,373:INFO:Visual Rendered Successfully
2024-06-11 21:30:55,468:INFO:plot_model() successfully completed......................................
2024-06-11 21:30:55,484:INFO:Initializing finalize_model()
2024-06-11 21:30:55,484:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:30:55,484:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:30:55,496:INFO:Initializing create_model()
2024-06-11 21:30:55,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:30:55,496:INFO:Checking exceptions
2024-06-11 21:30:55,498:INFO:Importing libraries
2024-06-11 21:30:55,498:INFO:Copying training dataset
2024-06-11 21:30:55,499:INFO:Defining folds
2024-06-11 21:30:55,500:INFO:Declaring metric variables
2024-06-11 21:30:55,500:INFO:Importing untrained model
2024-06-11 21:30:55,500:INFO:Declaring custom model
2024-06-11 21:30:55,500:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:30:55,503:INFO:Cross validation set to False
2024-06-11 21:30:55,503:INFO:Fitting Model
2024-06-11 21:30:59,875:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 42323
2024-06-11 21:30:59,879:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003764 seconds.
2024-06-11 21:30:59,879:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:30:59,880:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:30:59,880:INFO:[LightGBM] [Info] Number of data points in the train set: 46075, number of used features: 33
2024-06-11 21:30:59,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081432 -> initscore=-2.423042
2024-06-11 21:30:59,881:INFO:[LightGBM] [Info] Start training from score -2.423042
2024-06-11 21:31:00,198:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:31:00,198:INFO:create_model() successfully completed......................................
2024-06-11 21:31:00,307:INFO:_master_model_container: 3
2024-06-11 21:31:00,307:INFO:_display_container: 3
2024-06-11 21:31:00,346:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:31:00,346:INFO:finalize_model() successfully completed......................................
2024-06-11 21:31:00,552:INFO:Initializing evaluate_model()
2024-06-11 21:31:00,553:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:31:00,605:INFO:Initializing plot_model()
2024-06-11 21:31:00,605:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:31:00,605:INFO:Checking exceptions
2024-06-11 21:31:00,612:INFO:Preloading libraries
2024-06-11 21:31:00,618:INFO:Copying training dataset
2024-06-11 21:31:00,619:INFO:Plot type: pipeline
2024-06-11 21:31:00,889:INFO:Visual Rendered Successfully
2024-06-11 21:31:00,982:INFO:plot_model() successfully completed......................................
2024-06-11 21:34:21,057:INFO:Initializing plot_model()
2024-06-11 21:34:21,057:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:34:21,057:INFO:Checking exceptions
2024-06-11 21:34:21,068:INFO:Preloading libraries
2024-06-11 21:34:21,097:INFO:Copying training dataset
2024-06-11 21:34:21,097:INFO:Plot type: confusion_matrix
2024-06-11 21:34:21,302:INFO:Fitting Model
2024-06-11 21:34:21,302:INFO:Scoring test/hold-out set
2024-06-11 21:34:21,465:INFO:Visual Rendered Successfully
2024-06-11 21:34:21,567:INFO:plot_model() successfully completed......................................
2024-06-11 21:36:25,548:INFO:Initializing plot_model()
2024-06-11 21:36:25,548:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:36:25,548:INFO:Checking exceptions
2024-06-11 21:36:25,554:INFO:Preloading libraries
2024-06-11 21:36:25,560:INFO:Copying training dataset
2024-06-11 21:36:25,560:INFO:Plot type: auc
2024-06-11 21:36:25,742:INFO:Fitting Model
2024-06-11 21:36:25,743:INFO:Scoring test/hold-out set
2024-06-11 21:36:25,995:INFO:Visual Rendered Successfully
2024-06-11 21:36:26,092:INFO:plot_model() successfully completed......................................
2024-06-11 21:37:04,799:INFO:Initializing plot_model()
2024-06-11 21:37:04,799:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA27350>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:37:04,799:INFO:Checking exceptions
2024-06-11 21:37:04,806:INFO:Preloading libraries
2024-06-11 21:37:04,812:INFO:Copying training dataset
2024-06-11 21:37:04,812:INFO:Plot type: confusion_matrix
2024-06-11 21:37:04,997:INFO:Fitting Model
2024-06-11 21:37:04,998:INFO:Scoring test/hold-out set
2024-06-11 21:37:05,157:INFO:Visual Rendered Successfully
2024-06-11 21:37:05,251:INFO:plot_model() successfully completed......................................
2024-06-11 21:37:37,235:INFO:PyCaret ClassificationExperiment
2024-06-11 21:37:37,235:INFO:Logging name: clf-default-name
2024-06-11 21:37:37,235:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:37:37,235:INFO:version 3.3.2
2024-06-11 21:37:37,235:INFO:Initializing setup()
2024-06-11 21:37:37,235:INFO:self.USI: e2f7
2024-06-11 21:37:37,235:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:37:37,235:INFO:Checking environment
2024-06-11 21:37:37,235:INFO:python_version: 3.11.9
2024-06-11 21:37:37,235:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:37:37,235:INFO:machine: AMD64
2024-06-11 21:37:37,235:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:37:37,236:INFO:Memory: svmem(total=34056318976, available=25267351552, percent=25.8, used=8788967424, free=25267351552)
2024-06-11 21:37:37,236:INFO:Physical Core: 6
2024-06-11 21:37:37,236:INFO:Logical Core: 12
2024-06-11 21:37:37,236:INFO:Checking libraries
2024-06-11 21:37:37,236:INFO:System:
2024-06-11 21:37:37,236:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:37:37,236:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:37:37,236:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:37:37,236:INFO:PyCaret required dependencies:
2024-06-11 21:37:37,236:INFO:                 pip: 24.0
2024-06-11 21:37:37,236:INFO:          setuptools: 69.5.1
2024-06-11 21:37:37,236:INFO:             pycaret: 3.3.2
2024-06-11 21:37:37,236:INFO:             IPython: 8.25.0
2024-06-11 21:37:37,236:INFO:          ipywidgets: 8.1.3
2024-06-11 21:37:37,236:INFO:                tqdm: 4.66.4
2024-06-11 21:37:37,237:INFO:               numpy: 1.26.4
2024-06-11 21:37:37,237:INFO:              pandas: 2.1.4
2024-06-11 21:37:37,237:INFO:              jinja2: 3.1.4
2024-06-11 21:37:37,237:INFO:               scipy: 1.11.4
2024-06-11 21:37:37,237:INFO:              joblib: 1.3.2
2024-06-11 21:37:37,237:INFO:             sklearn: 1.4.2
2024-06-11 21:37:37,237:INFO:                pyod: 2.0.0
2024-06-11 21:37:37,237:INFO:            imblearn: 0.12.3
2024-06-11 21:37:37,237:INFO:   category_encoders: 2.6.3
2024-06-11 21:37:37,237:INFO:            lightgbm: 4.3.0
2024-06-11 21:37:37,237:INFO:               numba: 0.59.1
2024-06-11 21:37:37,237:INFO:            requests: 2.32.3
2024-06-11 21:37:37,237:INFO:          matplotlib: 3.7.5
2024-06-11 21:37:37,237:INFO:          scikitplot: 0.3.7
2024-06-11 21:37:37,237:INFO:         yellowbrick: 1.5
2024-06-11 21:37:37,237:INFO:              plotly: 5.22.0
2024-06-11 21:37:37,237:INFO:    plotly-resampler: Not installed
2024-06-11 21:37:37,237:INFO:             kaleido: 0.2.1
2024-06-11 21:37:37,237:INFO:           schemdraw: 0.15
2024-06-11 21:37:37,238:INFO:         statsmodels: 0.14.2
2024-06-11 21:37:37,238:INFO:              sktime: 0.26.0
2024-06-11 21:37:37,238:INFO:               tbats: 1.1.3
2024-06-11 21:37:37,238:INFO:            pmdarima: 2.0.4
2024-06-11 21:37:37,238:INFO:              psutil: 5.9.8
2024-06-11 21:37:37,238:INFO:          markupsafe: 2.1.5
2024-06-11 21:37:37,238:INFO:             pickle5: Not installed
2024-06-11 21:37:37,238:INFO:         cloudpickle: 3.0.0
2024-06-11 21:37:37,238:INFO:         deprecation: 2.1.0
2024-06-11 21:37:37,238:INFO:              xxhash: 3.4.1
2024-06-11 21:37:37,238:INFO:           wurlitzer: Not installed
2024-06-11 21:37:37,238:INFO:PyCaret optional dependencies:
2024-06-11 21:37:37,238:INFO:                shap: Not installed
2024-06-11 21:37:37,238:INFO:           interpret: Not installed
2024-06-11 21:37:37,238:INFO:                umap: Not installed
2024-06-11 21:37:37,238:INFO:     ydata_profiling: Not installed
2024-06-11 21:37:37,238:INFO:  explainerdashboard: Not installed
2024-06-11 21:37:37,238:INFO:             autoviz: Not installed
2024-06-11 21:37:37,239:INFO:           fairlearn: Not installed
2024-06-11 21:37:37,239:INFO:          deepchecks: Not installed
2024-06-11 21:37:37,239:INFO:             xgboost: Not installed
2024-06-11 21:37:37,239:INFO:            catboost: Not installed
2024-06-11 21:37:37,239:INFO:              kmodes: Not installed
2024-06-11 21:37:37,239:INFO:             mlxtend: Not installed
2024-06-11 21:37:37,239:INFO:       statsforecast: Not installed
2024-06-11 21:37:37,239:INFO:        tune_sklearn: Not installed
2024-06-11 21:37:37,239:INFO:                 ray: Not installed
2024-06-11 21:37:37,239:INFO:            hyperopt: Not installed
2024-06-11 21:37:37,239:INFO:              optuna: Not installed
2024-06-11 21:37:37,240:INFO:               skopt: Not installed
2024-06-11 21:37:37,240:INFO:              mlflow: Not installed
2024-06-11 21:37:37,240:INFO:              gradio: Not installed
2024-06-11 21:37:37,240:INFO:             fastapi: Not installed
2024-06-11 21:37:37,240:INFO:             uvicorn: Not installed
2024-06-11 21:37:37,240:INFO:              m2cgen: Not installed
2024-06-11 21:37:37,240:INFO:           evidently: Not installed
2024-06-11 21:37:37,240:INFO:               fugue: Not installed
2024-06-11 21:37:37,240:INFO:           streamlit: 1.35.0
2024-06-11 21:37:37,240:INFO:             prophet: Not installed
2024-06-11 21:37:37,241:INFO:None
2024-06-11 21:37:37,241:INFO:Set up data.
2024-06-11 21:37:37,296:INFO:Set up folding strategy.
2024-06-11 21:37:37,296:INFO:Set up train/test split.
2024-06-11 21:37:37,336:INFO:Set up index.
2024-06-11 21:37:37,338:INFO:Assigning column types.
2024-06-11 21:37:37,350:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:37:37,393:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:37:37,394:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:37:37,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:37:37,470:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:37:37,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,498:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:37:37,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:37:37,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,627:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:37:37,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,664:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:37:37,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:37,849:INFO:Preparing preprocessing pipeline...
2024-06-11 21:37:37,852:INFO:Set up date feature engineering.
2024-06-11 21:37:37,852:INFO:Set up simple imputation.
2024-06-11 21:37:37,865:INFO:Set up encoding of ordinal features.
2024-06-11 21:37:37,884:INFO:Set up encoding of categorical features.
2024-06-11 21:37:37,884:INFO:Set up removing outliers.
2024-06-11 21:37:37,884:INFO:Set up imbalanced handling.
2024-06-11 21:37:53,805:INFO:PyCaret ClassificationExperiment
2024-06-11 21:37:53,805:INFO:Logging name: clf-default-name
2024-06-11 21:37:53,805:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:37:53,805:INFO:version 3.3.2
2024-06-11 21:37:53,805:INFO:Initializing setup()
2024-06-11 21:37:53,805:INFO:self.USI: 2a43
2024-06-11 21:37:53,806:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:37:53,806:INFO:Checking environment
2024-06-11 21:37:53,806:INFO:python_version: 3.11.9
2024-06-11 21:37:53,806:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:37:53,806:INFO:machine: AMD64
2024-06-11 21:37:53,806:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:37:53,806:INFO:Memory: svmem(total=34056318976, available=25275617280, percent=25.8, used=8780701696, free=25275617280)
2024-06-11 21:37:53,806:INFO:Physical Core: 6
2024-06-11 21:37:53,806:INFO:Logical Core: 12
2024-06-11 21:37:53,807:INFO:Checking libraries
2024-06-11 21:37:53,807:INFO:System:
2024-06-11 21:37:53,807:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:37:53,807:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:37:53,807:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:37:53,807:INFO:PyCaret required dependencies:
2024-06-11 21:37:53,807:INFO:                 pip: 24.0
2024-06-11 21:37:53,807:INFO:          setuptools: 69.5.1
2024-06-11 21:37:53,807:INFO:             pycaret: 3.3.2
2024-06-11 21:37:53,807:INFO:             IPython: 8.25.0
2024-06-11 21:37:53,807:INFO:          ipywidgets: 8.1.3
2024-06-11 21:37:53,807:INFO:                tqdm: 4.66.4
2024-06-11 21:37:53,808:INFO:               numpy: 1.26.4
2024-06-11 21:37:53,808:INFO:              pandas: 2.1.4
2024-06-11 21:37:53,808:INFO:              jinja2: 3.1.4
2024-06-11 21:37:53,808:INFO:               scipy: 1.11.4
2024-06-11 21:37:53,808:INFO:              joblib: 1.3.2
2024-06-11 21:37:53,808:INFO:             sklearn: 1.4.2
2024-06-11 21:37:53,808:INFO:                pyod: 2.0.0
2024-06-11 21:37:53,808:INFO:            imblearn: 0.12.3
2024-06-11 21:37:53,808:INFO:   category_encoders: 2.6.3
2024-06-11 21:37:53,808:INFO:            lightgbm: 4.3.0
2024-06-11 21:37:53,808:INFO:               numba: 0.59.1
2024-06-11 21:37:53,808:INFO:            requests: 2.32.3
2024-06-11 21:37:53,808:INFO:          matplotlib: 3.7.5
2024-06-11 21:37:53,808:INFO:          scikitplot: 0.3.7
2024-06-11 21:37:53,808:INFO:         yellowbrick: 1.5
2024-06-11 21:37:53,809:INFO:              plotly: 5.22.0
2024-06-11 21:37:53,809:INFO:    plotly-resampler: Not installed
2024-06-11 21:37:53,809:INFO:             kaleido: 0.2.1
2024-06-11 21:37:53,809:INFO:           schemdraw: 0.15
2024-06-11 21:37:53,809:INFO:         statsmodels: 0.14.2
2024-06-11 21:37:53,809:INFO:              sktime: 0.26.0
2024-06-11 21:37:53,809:INFO:               tbats: 1.1.3
2024-06-11 21:37:53,809:INFO:            pmdarima: 2.0.4
2024-06-11 21:37:53,809:INFO:              psutil: 5.9.8
2024-06-11 21:37:53,809:INFO:          markupsafe: 2.1.5
2024-06-11 21:37:53,809:INFO:             pickle5: Not installed
2024-06-11 21:37:53,809:INFO:         cloudpickle: 3.0.0
2024-06-11 21:37:53,809:INFO:         deprecation: 2.1.0
2024-06-11 21:37:53,809:INFO:              xxhash: 3.4.1
2024-06-11 21:37:53,809:INFO:           wurlitzer: Not installed
2024-06-11 21:37:53,809:INFO:PyCaret optional dependencies:
2024-06-11 21:37:53,809:INFO:                shap: Not installed
2024-06-11 21:37:53,810:INFO:           interpret: Not installed
2024-06-11 21:37:53,810:INFO:                umap: Not installed
2024-06-11 21:37:53,810:INFO:     ydata_profiling: Not installed
2024-06-11 21:37:53,810:INFO:  explainerdashboard: Not installed
2024-06-11 21:37:53,810:INFO:             autoviz: Not installed
2024-06-11 21:37:53,810:INFO:           fairlearn: Not installed
2024-06-11 21:37:53,810:INFO:          deepchecks: Not installed
2024-06-11 21:37:53,810:INFO:             xgboost: Not installed
2024-06-11 21:37:53,810:INFO:            catboost: Not installed
2024-06-11 21:37:53,810:INFO:              kmodes: Not installed
2024-06-11 21:37:53,810:INFO:             mlxtend: Not installed
2024-06-11 21:37:53,810:INFO:       statsforecast: Not installed
2024-06-11 21:37:53,810:INFO:        tune_sklearn: Not installed
2024-06-11 21:37:53,810:INFO:                 ray: Not installed
2024-06-11 21:37:53,810:INFO:            hyperopt: Not installed
2024-06-11 21:37:53,811:INFO:              optuna: Not installed
2024-06-11 21:37:53,811:INFO:               skopt: Not installed
2024-06-11 21:37:53,811:INFO:              mlflow: Not installed
2024-06-11 21:37:53,811:INFO:              gradio: Not installed
2024-06-11 21:37:53,811:INFO:             fastapi: Not installed
2024-06-11 21:37:53,811:INFO:             uvicorn: Not installed
2024-06-11 21:37:53,811:INFO:              m2cgen: Not installed
2024-06-11 21:37:53,811:INFO:           evidently: Not installed
2024-06-11 21:37:53,811:INFO:               fugue: Not installed
2024-06-11 21:37:53,811:INFO:           streamlit: 1.35.0
2024-06-11 21:37:53,811:INFO:             prophet: Not installed
2024-06-11 21:37:53,811:INFO:None
2024-06-11 21:37:53,811:INFO:Set up data.
2024-06-11 21:37:53,852:INFO:Set up folding strategy.
2024-06-11 21:37:53,853:INFO:Set up train/test split.
2024-06-11 21:37:53,876:INFO:Set up index.
2024-06-11 21:37:53,877:INFO:Assigning column types.
2024-06-11 21:37:53,887:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:37:53,929:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:37:53,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:37:53,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:53,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,000:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:37:54,001:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:37:54,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,031:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:37:54,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:37:54,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,151:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:37:54,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,177:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:37:54,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:54,321:INFO:Preparing preprocessing pipeline...
2024-06-11 21:37:54,326:INFO:Set up date feature engineering.
2024-06-11 21:37:54,326:INFO:Set up simple imputation.
2024-06-11 21:37:54,344:INFO:Set up encoding of ordinal features.
2024-06-11 21:37:54,356:INFO:Set up encoding of categorical features.
2024-06-11 21:37:54,357:INFO:Set up removing outliers.
2024-06-11 21:37:54,357:INFO:Set up imbalanced handling.
2024-06-11 21:37:54,357:INFO:Set up feature normalization.
2024-06-11 21:37:54,357:INFO:Set up PCA.
2024-06-11 21:37:54,913:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:37:54,946:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-11 21:37:54,947:INFO:Creating final display dataframe.
2024-06-11 21:37:55,129:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (76226, 34)
5   Transformed train set shape       (61226, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method       incremental
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              2a43
2024-06-11 21:37:55,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:55,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:55,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:55,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:37:55,292:INFO:setup() successfully completed in 1.58s...............
2024-06-11 21:37:55,309:INFO:Initializing create_model()
2024-06-11 21:37:55,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:37:55,309:INFO:Checking exceptions
2024-06-11 21:37:55,323:INFO:Importing libraries
2024-06-11 21:37:55,323:INFO:Copying training dataset
2024-06-11 21:37:55,342:INFO:Defining folds
2024-06-11 21:37:55,342:INFO:Declaring metric variables
2024-06-11 21:37:55,344:INFO:Importing untrained model
2024-06-11 21:37:55,348:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:37:55,354:INFO:Starting cross validation
2024-06-11 21:37:55,356:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:38:02,463:INFO:Calculating mean and std
2024-06-11 21:38:02,465:INFO:Creating metrics dataframe
2024-06-11 21:38:02,471:INFO:Finalizing model
2024-06-11 21:38:03,817:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:38:03,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004963 seconds.
2024-06-11 21:38:03,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:38:03,823:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:38:03,823:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:38:03,824:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:38:04,114:INFO:Uploading results into container
2024-06-11 21:38:04,115:INFO:Uploading model into container now
2024-06-11 21:38:04,126:INFO:_master_model_container: 1
2024-06-11 21:38:04,126:INFO:_display_container: 2
2024-06-11 21:38:04,127:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:38:04,127:INFO:create_model() successfully completed......................................
2024-06-11 21:38:04,328:INFO:Initializing tune_model()
2024-06-11 21:38:04,328:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:38:04,329:INFO:Checking exceptions
2024-06-11 21:38:04,357:INFO:Copying training dataset
2024-06-11 21:38:04,369:INFO:Checking base model
2024-06-11 21:38:04,369:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:38:04,373:INFO:Declaring metric variables
2024-06-11 21:38:04,376:INFO:Defining Hyperparameters
2024-06-11 21:38:04,494:INFO:Tuning with n_jobs=-1
2024-06-11 21:38:04,494:INFO:Initializing RandomizedSearchCV
2024-06-11 21:39:11,956:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 210, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.005, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2024-06-11 21:39:11,957:INFO:Hyperparameter search completed
2024-06-11 21:39:11,957:INFO:SubProcess create_model() called ==================================
2024-06-11 21:39:11,959:INFO:Initializing create_model()
2024-06-11 21:39:11,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC56563E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 0.001, 'num_leaves': 80, 'n_estimators': 210, 'min_split_gain': 0.5, 'min_child_samples': 96, 'learning_rate': 0.005, 'feature_fraction': 1.0, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2024-06-11 21:39:11,959:INFO:Checking exceptions
2024-06-11 21:39:11,959:INFO:Importing libraries
2024-06-11 21:39:11,960:INFO:Copying training dataset
2024-06-11 21:39:11,994:INFO:Defining folds
2024-06-11 21:39:11,994:INFO:Declaring metric variables
2024-06-11 21:39:11,999:INFO:Importing untrained model
2024-06-11 21:39:11,999:INFO:Declaring custom model
2024-06-11 21:39:12,006:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:39:12,018:INFO:Starting cross validation
2024-06-11 21:39:12,022:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:39:22,879:INFO:Calculating mean and std
2024-06-11 21:39:22,881:INFO:Creating metrics dataframe
2024-06-11 21:39:22,889:INFO:Finalizing model
2024-06-11 21:39:24,204:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:39:24,205:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-11 21:39:24,205:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-11 21:39:24,286:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:39:24,286:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-11 21:39:24,286:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-11 21:39:24,286:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:39:24,293:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005832 seconds.
2024-06-11 21:39:24,293:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:39:24,294:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:39:24,295:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:39:24,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:39:25,712:INFO:Uploading results into container
2024-06-11 21:39:25,713:INFO:Uploading model into container now
2024-06-11 21:39:25,714:INFO:_master_model_container: 2
2024-06-11 21:39:25,715:INFO:_display_container: 3
2024-06-11 21:39:25,716:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:39:25,716:INFO:create_model() successfully completed......................................
2024-06-11 21:39:25,849:INFO:SubProcess create_model() end ==================================
2024-06-11 21:39:25,849:INFO:choose_better activated
2024-06-11 21:39:25,853:INFO:SubProcess create_model() called ==================================
2024-06-11 21:39:25,853:INFO:Initializing create_model()
2024-06-11 21:39:25,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:39:25,854:INFO:Checking exceptions
2024-06-11 21:39:25,856:INFO:Importing libraries
2024-06-11 21:39:25,856:INFO:Copying training dataset
2024-06-11 21:39:25,878:INFO:Defining folds
2024-06-11 21:39:25,878:INFO:Declaring metric variables
2024-06-11 21:39:25,878:INFO:Importing untrained model
2024-06-11 21:39:25,878:INFO:Declaring custom model
2024-06-11 21:39:25,879:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:39:25,879:INFO:Starting cross validation
2024-06-11 21:39:25,883:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:39:30,254:INFO:Calculating mean and std
2024-06-11 21:39:30,255:INFO:Creating metrics dataframe
2024-06-11 21:39:30,258:INFO:Finalizing model
2024-06-11 21:39:31,640:INFO:[LightGBM] [Info] Number of positive: 30613, number of negative: 30613
2024-06-11 21:39:31,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004423 seconds.
2024-06-11 21:39:31,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:39:31,646:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:39:31,646:INFO:[LightGBM] [Info] Number of data points in the train set: 61226, number of used features: 33
2024-06-11 21:39:31,647:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:39:31,972:INFO:Uploading results into container
2024-06-11 21:39:31,973:INFO:Uploading model into container now
2024-06-11 21:39:31,973:INFO:_master_model_container: 3
2024-06-11 21:39:31,973:INFO:_display_container: 4
2024-06-11 21:39:31,974:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:39:31,974:INFO:create_model() successfully completed......................................
2024-06-11 21:39:32,091:INFO:SubProcess create_model() end ==================================
2024-06-11 21:39:32,092:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1646
2024-06-11 21:39:32,092:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.2221
2024-06-11 21:39:32,093:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:39:32,093:INFO:choose_better completed
2024-06-11 21:39:32,100:INFO:_master_model_container: 3
2024-06-11 21:39:32,100:INFO:_display_container: 3
2024-06-11 21:39:32,101:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:39:32,101:INFO:tune_model() successfully completed......................................
2024-06-11 21:39:32,251:INFO:Initializing plot_model()
2024-06-11 21:39:32,251:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:39:32,251:INFO:Checking exceptions
2024-06-11 21:39:32,260:INFO:Preloading libraries
2024-06-11 21:39:32,299:INFO:Copying training dataset
2024-06-11 21:39:32,300:INFO:Plot type: auc
2024-06-11 21:39:32,485:INFO:Fitting Model
2024-06-11 21:39:32,487:INFO:Scoring test/hold-out set
2024-06-11 21:39:32,489:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:39:32,489:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-11 21:39:32,489:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-11 21:39:32,526:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:39:32,527:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-11 21:39:32,527:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-11 21:39:32,780:INFO:Visual Rendered Successfully
2024-06-11 21:39:32,880:INFO:plot_model() successfully completed......................................
2024-06-11 21:39:32,899:INFO:Initializing plot_model()
2024-06-11 21:39:32,900:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:39:32,900:INFO:Checking exceptions
2024-06-11 21:39:32,915:INFO:Preloading libraries
2024-06-11 21:39:32,964:INFO:Copying training dataset
2024-06-11 21:39:32,964:INFO:Plot type: confusion_matrix
2024-06-11 21:39:33,147:INFO:Fitting Model
2024-06-11 21:39:33,148:INFO:Scoring test/hold-out set
2024-06-11 21:39:33,150:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:39:33,151:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-11 21:39:33,151:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-11 21:39:33,193:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:39:33,194:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-11 21:39:33,194:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-11 21:39:33,360:INFO:Visual Rendered Successfully
2024-06-11 21:39:33,458:INFO:plot_model() successfully completed......................................
2024-06-11 21:39:33,473:INFO:Initializing finalize_model()
2024-06-11 21:39:33,473:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:39:33,474:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:39:33,484:INFO:Initializing create_model()
2024-06-11 21:39:33,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:39:33,484:INFO:Checking exceptions
2024-06-11 21:39:33,486:INFO:Importing libraries
2024-06-11 21:39:33,486:INFO:Copying training dataset
2024-06-11 21:39:33,488:INFO:Defining folds
2024-06-11 21:39:33,488:INFO:Declaring metric variables
2024-06-11 21:39:33,488:INFO:Importing untrained model
2024-06-11 21:39:33,488:INFO:Declaring custom model
2024-06-11 21:39:33,489:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:39:33,491:INFO:Cross validation set to False
2024-06-11 21:39:33,491:INFO:Fitting Model
2024-06-11 21:39:35,168:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:39:35,168:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-11 21:39:35,168:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-11 21:39:35,282:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-06-11 21:39:35,282:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-06-11 21:39:35,282:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-11 21:39:35,282:INFO:[LightGBM] [Info] Number of positive: 43748, number of negative: 43748
2024-06-11 21:39:35,289:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006146 seconds.
2024-06-11 21:39:35,289:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:39:35,290:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:39:35,291:INFO:[LightGBM] [Info] Number of data points in the train set: 87496, number of used features: 33
2024-06-11 21:39:35,294:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-11 21:39:36,877:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-11 21:39:36,877:INFO:create_model() successfully completed......................................
2024-06-11 21:39:36,986:INFO:_master_model_container: 3
2024-06-11 21:39:36,986:INFO:_display_container: 3
2024-06-11 21:39:37,024:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-11 21:39:37,024:INFO:finalize_model() successfully completed......................................
2024-06-11 21:39:37,245:INFO:Initializing evaluate_model()
2024-06-11 21:39:37,245:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:39:37,294:INFO:Initializing plot_model()
2024-06-11 21:39:37,294:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BAB1AD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.005,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=210, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123,
                                reg_alpha=0.001, reg_lambda=1e-06,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:39:37,295:INFO:Checking exceptions
2024-06-11 21:39:37,301:INFO:Preloading libraries
2024-06-11 21:39:37,335:INFO:Copying training dataset
2024-06-11 21:39:37,335:INFO:Plot type: pipeline
2024-06-11 21:39:37,596:INFO:Visual Rendered Successfully
2024-06-11 21:39:37,695:INFO:plot_model() successfully completed......................................
2024-06-11 21:40:23,668:INFO:PyCaret ClassificationExperiment
2024-06-11 21:40:23,668:INFO:Logging name: clf-default-name
2024-06-11 21:40:23,668:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:40:23,668:INFO:version 3.3.2
2024-06-11 21:40:23,668:INFO:Initializing setup()
2024-06-11 21:40:23,668:INFO:self.USI: a79e
2024-06-11 21:40:23,668:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:40:23,668:INFO:Checking environment
2024-06-11 21:40:23,668:INFO:python_version: 3.11.9
2024-06-11 21:40:23,668:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:40:23,668:INFO:machine: AMD64
2024-06-11 21:40:23,668:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:40:23,668:INFO:Memory: svmem(total=34056318976, available=23332323328, percent=31.5, used=10723995648, free=23332323328)
2024-06-11 21:40:23,669:INFO:Physical Core: 6
2024-06-11 21:40:23,669:INFO:Logical Core: 12
2024-06-11 21:40:23,669:INFO:Checking libraries
2024-06-11 21:40:23,669:INFO:System:
2024-06-11 21:40:23,669:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:40:23,669:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:40:23,669:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:40:23,669:INFO:PyCaret required dependencies:
2024-06-11 21:40:23,669:INFO:                 pip: 24.0
2024-06-11 21:40:23,669:INFO:          setuptools: 69.5.1
2024-06-11 21:40:23,669:INFO:             pycaret: 3.3.2
2024-06-11 21:40:23,670:INFO:             IPython: 8.25.0
2024-06-11 21:40:23,670:INFO:          ipywidgets: 8.1.3
2024-06-11 21:40:23,670:INFO:                tqdm: 4.66.4
2024-06-11 21:40:23,670:INFO:               numpy: 1.26.4
2024-06-11 21:40:23,670:INFO:              pandas: 2.1.4
2024-06-11 21:40:23,670:INFO:              jinja2: 3.1.4
2024-06-11 21:40:23,670:INFO:               scipy: 1.11.4
2024-06-11 21:40:23,670:INFO:              joblib: 1.3.2
2024-06-11 21:40:23,670:INFO:             sklearn: 1.4.2
2024-06-11 21:40:23,670:INFO:                pyod: 2.0.0
2024-06-11 21:40:23,670:INFO:            imblearn: 0.12.3
2024-06-11 21:40:23,670:INFO:   category_encoders: 2.6.3
2024-06-11 21:40:23,670:INFO:            lightgbm: 4.3.0
2024-06-11 21:40:23,670:INFO:               numba: 0.59.1
2024-06-11 21:40:23,670:INFO:            requests: 2.32.3
2024-06-11 21:40:23,670:INFO:          matplotlib: 3.7.5
2024-06-11 21:40:23,670:INFO:          scikitplot: 0.3.7
2024-06-11 21:40:23,670:INFO:         yellowbrick: 1.5
2024-06-11 21:40:23,671:INFO:              plotly: 5.22.0
2024-06-11 21:40:23,671:INFO:    plotly-resampler: Not installed
2024-06-11 21:40:23,671:INFO:             kaleido: 0.2.1
2024-06-11 21:40:23,671:INFO:           schemdraw: 0.15
2024-06-11 21:40:23,671:INFO:         statsmodels: 0.14.2
2024-06-11 21:40:23,671:INFO:              sktime: 0.26.0
2024-06-11 21:40:23,671:INFO:               tbats: 1.1.3
2024-06-11 21:40:23,671:INFO:            pmdarima: 2.0.4
2024-06-11 21:40:23,671:INFO:              psutil: 5.9.8
2024-06-11 21:40:23,671:INFO:          markupsafe: 2.1.5
2024-06-11 21:40:23,671:INFO:             pickle5: Not installed
2024-06-11 21:40:23,671:INFO:         cloudpickle: 3.0.0
2024-06-11 21:40:23,671:INFO:         deprecation: 2.1.0
2024-06-11 21:40:23,671:INFO:              xxhash: 3.4.1
2024-06-11 21:40:23,671:INFO:           wurlitzer: Not installed
2024-06-11 21:40:23,671:INFO:PyCaret optional dependencies:
2024-06-11 21:40:23,671:INFO:                shap: Not installed
2024-06-11 21:40:23,671:INFO:           interpret: Not installed
2024-06-11 21:40:23,671:INFO:                umap: Not installed
2024-06-11 21:40:23,672:INFO:     ydata_profiling: Not installed
2024-06-11 21:40:23,672:INFO:  explainerdashboard: Not installed
2024-06-11 21:40:23,672:INFO:             autoviz: Not installed
2024-06-11 21:40:23,672:INFO:           fairlearn: Not installed
2024-06-11 21:40:23,672:INFO:          deepchecks: Not installed
2024-06-11 21:40:23,672:INFO:             xgboost: Not installed
2024-06-11 21:40:23,672:INFO:            catboost: Not installed
2024-06-11 21:40:23,672:INFO:              kmodes: Not installed
2024-06-11 21:40:23,672:INFO:             mlxtend: Not installed
2024-06-11 21:40:23,672:INFO:       statsforecast: Not installed
2024-06-11 21:40:23,672:INFO:        tune_sklearn: Not installed
2024-06-11 21:40:23,672:INFO:                 ray: Not installed
2024-06-11 21:40:23,672:INFO:            hyperopt: Not installed
2024-06-11 21:40:23,672:INFO:              optuna: Not installed
2024-06-11 21:40:23,672:INFO:               skopt: Not installed
2024-06-11 21:40:23,672:INFO:              mlflow: Not installed
2024-06-11 21:40:23,672:INFO:              gradio: Not installed
2024-06-11 21:40:23,672:INFO:             fastapi: Not installed
2024-06-11 21:40:23,672:INFO:             uvicorn: Not installed
2024-06-11 21:40:23,672:INFO:              m2cgen: Not installed
2024-06-11 21:40:23,672:INFO:           evidently: Not installed
2024-06-11 21:40:23,673:INFO:               fugue: Not installed
2024-06-11 21:40:23,673:INFO:           streamlit: 1.35.0
2024-06-11 21:40:23,673:INFO:             prophet: Not installed
2024-06-11 21:40:23,673:INFO:None
2024-06-11 21:40:23,673:INFO:Set up data.
2024-06-11 21:40:23,709:INFO:Set up folding strategy.
2024-06-11 21:40:23,709:INFO:Set up train/test split.
2024-06-11 21:40:23,732:INFO:Set up index.
2024-06-11 21:40:23,733:INFO:Assigning column types.
2024-06-11 21:40:23,743:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:40:23,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:40:23,787:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:40:23,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:23,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:23,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:40:23,857:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:40:23,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:23,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:23,883:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:40:23,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:40:23,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:23,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:40:24,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,029:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:40:24,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,171:INFO:Preparing preprocessing pipeline...
2024-06-11 21:40:24,175:INFO:Set up date feature engineering.
2024-06-11 21:40:24,175:INFO:Set up simple imputation.
2024-06-11 21:40:24,189:INFO:Set up encoding of ordinal features.
2024-06-11 21:40:24,200:INFO:Set up encoding of categorical features.
2024-06-11 21:40:24,200:INFO:Set up removing outliers.
2024-06-11 21:40:24,200:INFO:Set up feature normalization.
2024-06-11 21:40:24,200:INFO:Set up PCA.
2024-06-11 21:40:24,594:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:40:24,626:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=IncrementalPCA(batch_size=None,
                                                               copy=True,
                                                               n_components=None,
                                                               whiten=False)))],
         verbose=False)
2024-06-11 21:40:24,626:INFO:Creating final display dataframe.
2024-06-11 21:40:24,783:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48250, 34)
5   Transformed train set shape       (33250, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            robust
21                          PCA              True
22                   PCA method       incremental
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              a79e
2024-06-11 21:40:24,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:40:24,929:INFO:setup() successfully completed in 1.33s...............
2024-06-11 21:40:24,940:INFO:Initializing create_model()
2024-06-11 21:40:24,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:40:24,940:INFO:Checking exceptions
2024-06-11 21:40:24,954:INFO:Importing libraries
2024-06-11 21:40:24,954:INFO:Copying training dataset
2024-06-11 21:40:24,980:INFO:Defining folds
2024-06-11 21:40:24,980:INFO:Declaring metric variables
2024-06-11 21:40:24,983:INFO:Importing untrained model
2024-06-11 21:40:24,986:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:40:24,992:INFO:Starting cross validation
2024-06-11 21:40:24,994:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:40:27,785:INFO:Calculating mean and std
2024-06-11 21:40:27,786:INFO:Creating metrics dataframe
2024-06-11 21:40:27,792:INFO:Finalizing model
2024-06-11 21:40:28,903:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-11 21:40:28,906:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002817 seconds.
2024-06-11 21:40:28,906:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:40:28,906:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:40:28,907:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-11 21:40:28,908:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-11 21:40:28,908:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-11 21:40:29,098:INFO:Uploading results into container
2024-06-11 21:40:29,099:INFO:Uploading model into container now
2024-06-11 21:40:29,109:INFO:_master_model_container: 1
2024-06-11 21:40:29,109:INFO:_display_container: 2
2024-06-11 21:40:29,110:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:40:29,110:INFO:create_model() successfully completed......................................
2024-06-11 21:40:29,278:INFO:Initializing tune_model()
2024-06-11 21:40:29,278:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:40:29,278:INFO:Checking exceptions
2024-06-11 21:40:29,314:INFO:Copying training dataset
2024-06-11 21:40:29,326:INFO:Checking base model
2024-06-11 21:40:29,326:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:40:29,329:INFO:Declaring metric variables
2024-06-11 21:40:29,333:INFO:Defining Hyperparameters
2024-06-11 21:40:29,431:INFO:Tuning with n_jobs=-1
2024-06-11 21:40:29,431:INFO:Initializing RandomizedSearchCV
2024-06-11 21:41:08,254:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 21:41:08,255:INFO:Hyperparameter search completed
2024-06-11 21:41:08,255:INFO:SubProcess create_model() called ==================================
2024-06-11 21:41:08,256:INFO:Initializing create_model()
2024-06-11 21:41:08,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AC3BC42490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 21:41:08,257:INFO:Checking exceptions
2024-06-11 21:41:08,257:INFO:Importing libraries
2024-06-11 21:41:08,257:INFO:Copying training dataset
2024-06-11 21:41:08,294:INFO:Defining folds
2024-06-11 21:41:08,294:INFO:Declaring metric variables
2024-06-11 21:41:08,299:INFO:Importing untrained model
2024-06-11 21:41:08,299:INFO:Declaring custom model
2024-06-11 21:41:08,306:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:41:08,317:INFO:Starting cross validation
2024-06-11 21:41:08,321:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:41:12,746:INFO:Calculating mean and std
2024-06-11 21:41:12,747:INFO:Creating metrics dataframe
2024-06-11 21:41:12,754:INFO:Finalizing model
2024-06-11 21:41:13,799:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:41:13,799:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:41:13,799:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:41:13,838:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:41:13,839:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:41:13,839:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:41:13,839:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-11 21:41:13,843:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003017 seconds.
2024-06-11 21:41:13,843:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:41:13,843:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:41:13,844:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-11 21:41:13,846:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-11 21:41:13,846:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-11 21:41:13,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:13,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:13,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:13,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:13,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:13,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:13,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:14,421:INFO:Uploading results into container
2024-06-11 21:41:14,423:INFO:Uploading model into container now
2024-06-11 21:41:14,423:INFO:_master_model_container: 2
2024-06-11 21:41:14,424:INFO:_display_container: 3
2024-06-11 21:41:14,425:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:41:14,425:INFO:create_model() successfully completed......................................
2024-06-11 21:41:14,550:INFO:SubProcess create_model() end ==================================
2024-06-11 21:41:14,550:INFO:choose_better activated
2024-06-11 21:41:14,554:INFO:SubProcess create_model() called ==================================
2024-06-11 21:41:14,555:INFO:Initializing create_model()
2024-06-11 21:41:14,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:41:14,555:INFO:Checking exceptions
2024-06-11 21:41:14,557:INFO:Importing libraries
2024-06-11 21:41:14,557:INFO:Copying training dataset
2024-06-11 21:41:14,577:INFO:Defining folds
2024-06-11 21:41:14,577:INFO:Declaring metric variables
2024-06-11 21:41:14,578:INFO:Importing untrained model
2024-06-11 21:41:14,578:INFO:Declaring custom model
2024-06-11 21:41:14,578:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:41:14,579:INFO:Starting cross validation
2024-06-11 21:41:14,581:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:41:17,204:INFO:Calculating mean and std
2024-06-11 21:41:17,206:INFO:Creating metrics dataframe
2024-06-11 21:41:17,208:INFO:Finalizing model
2024-06-11 21:41:18,285:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-11 21:41:18,288:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002526 seconds.
2024-06-11 21:41:18,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:41:18,289:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:41:18,290:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-11 21:41:18,290:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-11 21:41:18,290:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-11 21:41:18,452:INFO:Uploading results into container
2024-06-11 21:41:18,452:INFO:Uploading model into container now
2024-06-11 21:41:18,453:INFO:_master_model_container: 3
2024-06-11 21:41:18,453:INFO:_display_container: 4
2024-06-11 21:41:18,453:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:41:18,453:INFO:create_model() successfully completed......................................
2024-06-11 21:41:18,569:INFO:SubProcess create_model() end ==================================
2024-06-11 21:41:18,570:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0937
2024-06-11 21:41:18,571:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0963
2024-06-11 21:41:18,571:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:41:18,571:INFO:choose_better completed
2024-06-11 21:41:18,580:INFO:_master_model_container: 3
2024-06-11 21:41:18,580:INFO:_display_container: 3
2024-06-11 21:41:18,581:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:41:18,581:INFO:tune_model() successfully completed......................................
2024-06-11 21:41:18,705:INFO:Initializing plot_model()
2024-06-11 21:41:18,706:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:41:18,706:INFO:Checking exceptions
2024-06-11 21:41:18,718:INFO:Preloading libraries
2024-06-11 21:41:18,750:INFO:Copying training dataset
2024-06-11 21:41:18,750:INFO:Plot type: auc
2024-06-11 21:41:18,922:INFO:Fitting Model
2024-06-11 21:41:18,923:INFO:Scoring test/hold-out set
2024-06-11 21:41:18,925:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:41:18,925:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:41:18,925:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:41:18,992:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:41:18,992:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:41:18,992:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:41:19,266:INFO:Visual Rendered Successfully
2024-06-11 21:41:19,388:INFO:plot_model() successfully completed......................................
2024-06-11 21:41:19,405:INFO:Initializing plot_model()
2024-06-11 21:41:19,405:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:41:19,405:INFO:Checking exceptions
2024-06-11 21:41:19,416:INFO:Preloading libraries
2024-06-11 21:41:19,446:INFO:Copying training dataset
2024-06-11 21:41:19,446:INFO:Plot type: confusion_matrix
2024-06-11 21:41:19,622:INFO:Fitting Model
2024-06-11 21:41:19,623:INFO:Scoring test/hold-out set
2024-06-11 21:41:19,625:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:41:19,625:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:41:19,625:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:41:19,691:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:41:19,691:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:41:19,691:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:41:19,873:INFO:Visual Rendered Successfully
2024-06-11 21:41:19,977:INFO:plot_model() successfully completed......................................
2024-06-11 21:41:19,990:INFO:Initializing finalize_model()
2024-06-11 21:41:19,990:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:41:19,991:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:41:20,001:INFO:Initializing create_model()
2024-06-11 21:41:20,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:41:20,001:INFO:Checking exceptions
2024-06-11 21:41:20,003:INFO:Importing libraries
2024-06-11 21:41:20,003:INFO:Copying training dataset
2024-06-11 21:41:20,004:INFO:Defining folds
2024-06-11 21:41:20,004:INFO:Declaring metric variables
2024-06-11 21:41:20,004:INFO:Importing untrained model
2024-06-11 21:41:20,004:INFO:Declaring custom model
2024-06-11 21:41:20,005:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:41:20,007:INFO:Cross validation set to False
2024-06-11 21:41:20,007:INFO:Fitting Model
2024-06-11 21:41:21,315:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:41:21,315:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:41:21,315:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:41:21,375:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:41:21,375:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:41:21,375:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:41:21,375:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 43748
2024-06-11 21:41:21,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003063 seconds.
2024-06-11 21:41:21,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:41:21,380:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:41:21,380:INFO:[LightGBM] [Info] Number of data points in the train set: 47500, number of used features: 33
2024-06-11 21:41:21,382:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078989 -> initscore=-2.456157
2024-06-11 21:41:21,382:INFO:[LightGBM] [Info] Start training from score -2.456157
2024-06-11 21:41:21,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:21,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:41:22,115:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:41:22,115:INFO:create_model() successfully completed......................................
2024-06-11 21:41:22,217:INFO:_master_model_container: 3
2024-06-11 21:41:22,218:INFO:_display_container: 3
2024-06-11 21:41:22,254:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:41:22,254:INFO:finalize_model() successfully completed......................................
2024-06-11 21:41:22,438:INFO:Initializing evaluate_model()
2024-06-11 21:41:22,438:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:41:22,485:INFO:Initializing plot_model()
2024-06-11 21:41:22,485:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC5656CB90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:41:22,485:INFO:Checking exceptions
2024-06-11 21:41:22,492:INFO:Preloading libraries
2024-06-11 21:41:22,528:INFO:Copying training dataset
2024-06-11 21:41:22,528:INFO:Plot type: pipeline
2024-06-11 21:41:22,767:INFO:Visual Rendered Successfully
2024-06-11 21:41:22,866:INFO:plot_model() successfully completed......................................
2024-06-11 21:42:42,943:INFO:PyCaret ClassificationExperiment
2024-06-11 21:42:42,944:INFO:Logging name: clf-default-name
2024-06-11 21:42:42,944:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:42:42,944:INFO:version 3.3.2
2024-06-11 21:42:42,944:INFO:Initializing setup()
2024-06-11 21:42:42,944:INFO:self.USI: 5417
2024-06-11 21:42:42,944:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'gpu_param', 'n_jobs_param', 'html_param', 'USI', 'memory', 'pipeline', 'data', 'logging_param', 'y_train', 'fold_groups_param', 'exp_name_log', 'X_test', 'fold_generator', 'X', 'is_multiclass', 'idx', 'fold_shuffle_param', 'log_plots_param', 'exp_id', 'y', 'X_train', 'y_test', '_ml_usecase', 'target_param', 'seed', 'gpu_n_jobs_param'}
2024-06-11 21:42:42,944:INFO:Checking environment
2024-06-11 21:42:42,944:INFO:python_version: 3.11.9
2024-06-11 21:42:42,944:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:42:42,944:INFO:machine: AMD64
2024-06-11 21:42:42,944:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:42:42,944:INFO:Memory: svmem(total=34056318976, available=23356735488, percent=31.4, used=10699583488, free=23356735488)
2024-06-11 21:42:42,944:INFO:Physical Core: 6
2024-06-11 21:42:42,944:INFO:Logical Core: 12
2024-06-11 21:42:42,944:INFO:Checking libraries
2024-06-11 21:42:42,945:INFO:System:
2024-06-11 21:42:42,945:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:42:42,945:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:42:42,945:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:42:42,945:INFO:PyCaret required dependencies:
2024-06-11 21:42:42,945:INFO:                 pip: 24.0
2024-06-11 21:42:42,945:INFO:          setuptools: 69.5.1
2024-06-11 21:42:42,945:INFO:             pycaret: 3.3.2
2024-06-11 21:42:42,945:INFO:             IPython: 8.25.0
2024-06-11 21:42:42,945:INFO:          ipywidgets: 8.1.3
2024-06-11 21:42:42,945:INFO:                tqdm: 4.66.4
2024-06-11 21:42:42,945:INFO:               numpy: 1.26.4
2024-06-11 21:42:42,945:INFO:              pandas: 2.1.4
2024-06-11 21:42:42,945:INFO:              jinja2: 3.1.4
2024-06-11 21:42:42,945:INFO:               scipy: 1.11.4
2024-06-11 21:42:42,945:INFO:              joblib: 1.3.2
2024-06-11 21:42:42,946:INFO:             sklearn: 1.4.2
2024-06-11 21:42:42,946:INFO:                pyod: 2.0.0
2024-06-11 21:42:42,946:INFO:            imblearn: 0.12.3
2024-06-11 21:42:42,946:INFO:   category_encoders: 2.6.3
2024-06-11 21:42:42,946:INFO:            lightgbm: 4.3.0
2024-06-11 21:42:42,946:INFO:               numba: 0.59.1
2024-06-11 21:42:42,946:INFO:            requests: 2.32.3
2024-06-11 21:42:42,946:INFO:          matplotlib: 3.7.5
2024-06-11 21:42:42,946:INFO:          scikitplot: 0.3.7
2024-06-11 21:42:42,946:INFO:         yellowbrick: 1.5
2024-06-11 21:42:42,946:INFO:              plotly: 5.22.0
2024-06-11 21:42:42,946:INFO:    plotly-resampler: Not installed
2024-06-11 21:42:42,946:INFO:             kaleido: 0.2.1
2024-06-11 21:42:42,946:INFO:           schemdraw: 0.15
2024-06-11 21:42:42,947:INFO:         statsmodels: 0.14.2
2024-06-11 21:42:42,947:INFO:              sktime: 0.26.0
2024-06-11 21:42:42,947:INFO:               tbats: 1.1.3
2024-06-11 21:42:42,947:INFO:            pmdarima: 2.0.4
2024-06-11 21:42:42,947:INFO:              psutil: 5.9.8
2024-06-11 21:42:42,947:INFO:          markupsafe: 2.1.5
2024-06-11 21:42:42,947:INFO:             pickle5: Not installed
2024-06-11 21:42:42,947:INFO:         cloudpickle: 3.0.0
2024-06-11 21:42:42,947:INFO:         deprecation: 2.1.0
2024-06-11 21:42:42,947:INFO:              xxhash: 3.4.1
2024-06-11 21:42:42,947:INFO:           wurlitzer: Not installed
2024-06-11 21:42:42,947:INFO:PyCaret optional dependencies:
2024-06-11 21:42:42,947:INFO:                shap: Not installed
2024-06-11 21:42:42,948:INFO:           interpret: Not installed
2024-06-11 21:42:42,948:INFO:                umap: Not installed
2024-06-11 21:42:42,948:INFO:     ydata_profiling: Not installed
2024-06-11 21:42:42,948:INFO:  explainerdashboard: Not installed
2024-06-11 21:42:42,948:INFO:             autoviz: Not installed
2024-06-11 21:42:42,948:INFO:           fairlearn: Not installed
2024-06-11 21:42:42,948:INFO:          deepchecks: Not installed
2024-06-11 21:42:42,948:INFO:             xgboost: Not installed
2024-06-11 21:42:42,948:INFO:            catboost: Not installed
2024-06-11 21:42:42,948:INFO:              kmodes: Not installed
2024-06-11 21:42:42,948:INFO:             mlxtend: Not installed
2024-06-11 21:42:42,948:INFO:       statsforecast: Not installed
2024-06-11 21:42:42,948:INFO:        tune_sklearn: Not installed
2024-06-11 21:42:42,948:INFO:                 ray: Not installed
2024-06-11 21:42:42,948:INFO:            hyperopt: Not installed
2024-06-11 21:42:42,948:INFO:              optuna: Not installed
2024-06-11 21:42:42,948:INFO:               skopt: Not installed
2024-06-11 21:42:42,949:INFO:              mlflow: Not installed
2024-06-11 21:42:42,949:INFO:              gradio: Not installed
2024-06-11 21:42:42,949:INFO:             fastapi: Not installed
2024-06-11 21:42:42,949:INFO:             uvicorn: Not installed
2024-06-11 21:42:42,949:INFO:              m2cgen: Not installed
2024-06-11 21:42:42,949:INFO:           evidently: Not installed
2024-06-11 21:42:42,949:INFO:               fugue: Not installed
2024-06-11 21:42:42,949:INFO:           streamlit: 1.35.0
2024-06-11 21:42:42,949:INFO:             prophet: Not installed
2024-06-11 21:42:42,949:INFO:None
2024-06-11 21:42:42,949:INFO:Set up data.
2024-06-11 21:42:43,024:INFO:Set up folding strategy.
2024-06-11 21:42:43,025:INFO:Set up train/test split.
2024-06-11 21:42:43,066:INFO:Set up index.
2024-06-11 21:42:43,068:INFO:Assigning column types.
2024-06-11 21:42:43,084:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:42:43,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:42:43,129:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:42:43,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:42:43,229:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:42:43,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,258:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:42:43,313:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:42:43,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,402:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:42:43,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,433:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:42:43,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:43,578:INFO:Preparing preprocessing pipeline...
2024-06-11 21:42:43,582:INFO:Set up date feature engineering.
2024-06-11 21:42:43,582:INFO:Set up simple imputation.
2024-06-11 21:42:43,596:INFO:Set up encoding of ordinal features.
2024-06-11 21:42:43,610:INFO:Set up encoding of categorical features.
2024-06-11 21:42:43,610:INFO:Set up removing outliers.
2024-06-11 21:42:43,610:INFO:Set up feature normalization.
2024-06-11 21:42:43,610:INFO:Set up PCA.
2024-06-11 21:42:44,050:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:42:44,082:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-11 21:42:44,082:INFO:Creating final display dataframe.
2024-06-11 21:42:44,238:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48250, 34)
5   Transformed train set shape       (33250, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            robust
21                          PCA              True
22                   PCA method            linear
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              5417
2024-06-11 21:42:44,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:44,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:44,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:44,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:42:44,390:INFO:setup() successfully completed in 1.52s...............
2024-06-11 21:42:44,411:INFO:Initializing create_model()
2024-06-11 21:42:44,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA1AFD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:42:44,411:INFO:Checking exceptions
2024-06-11 21:42:44,432:INFO:Importing libraries
2024-06-11 21:42:44,432:INFO:Copying training dataset
2024-06-11 21:42:44,463:INFO:Defining folds
2024-06-11 21:42:44,463:INFO:Declaring metric variables
2024-06-11 21:42:44,469:INFO:Importing untrained model
2024-06-11 21:42:44,474:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:42:44,481:INFO:Starting cross validation
2024-06-11 21:42:44,484:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:42:47,607:INFO:Calculating mean and std
2024-06-11 21:42:47,609:INFO:Creating metrics dataframe
2024-06-11 21:42:47,617:INFO:Finalizing model
2024-06-11 21:42:48,638:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 30613
2024-06-11 21:42:48,642:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003630 seconds.
2024-06-11 21:42:48,642:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:42:48,642:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:42:48,643:INFO:[LightGBM] [Info] Number of data points in the train set: 33250, number of used features: 33
2024-06-11 21:42:48,644:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079308 -> initscore=-2.451783
2024-06-11 21:42:48,644:INFO:[LightGBM] [Info] Start training from score -2.451783
2024-06-11 21:42:48,967:INFO:Uploading results into container
2024-06-11 21:42:48,968:INFO:Uploading model into container now
2024-06-11 21:42:48,983:INFO:_master_model_container: 1
2024-06-11 21:42:48,983:INFO:_display_container: 2
2024-06-11 21:42:48,984:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:42:48,984:INFO:create_model() successfully completed......................................
2024-06-11 21:42:49,156:INFO:Initializing tune_model()
2024-06-11 21:42:49,157:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002AC3BA1AFD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:42:49,157:INFO:Checking exceptions
2024-06-11 21:42:49,182:INFO:Copying training dataset
2024-06-11 21:42:49,195:INFO:Checking base model
2024-06-11 21:42:49,195:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:42:49,199:INFO:Declaring metric variables
2024-06-11 21:42:49,202:INFO:Defining Hyperparameters
2024-06-11 21:42:49,311:INFO:Tuning with n_jobs=-1
2024-06-11 21:42:49,311:INFO:Initializing RandomizedSearchCV
2024-06-11 21:43:43,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:43:43,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:43:43,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:43:43,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 21:43:44,478:INFO:PyCaret ClassificationExperiment
2024-06-11 21:43:44,478:INFO:Logging name: clf-default-name
2024-06-11 21:43:44,478:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:43:44,478:INFO:version 3.3.2
2024-06-11 21:43:44,478:INFO:Initializing setup()
2024-06-11 21:43:44,478:INFO:self.USI: d8e2
2024-06-11 21:43:44,478:INFO:self._variable_keys: {'idx', 'gpu_param', 'y_train', 'data', 'exp_name_log', 'seed', '_available_plots', 'fix_imbalance', 'is_multiclass', '_ml_usecase', 'html_param', 'n_jobs_param', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_n_jobs_param', 'log_plots_param', 'pipeline', 'USI', 'memory', 'logging_param', 'fold_generator', 'X', 'y_test', 'y', 'fold_shuffle_param', 'X_train', 'X_test'}
2024-06-11 21:43:44,478:INFO:Checking environment
2024-06-11 21:43:44,478:INFO:python_version: 3.11.9
2024-06-11 21:43:44,478:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:43:44,478:INFO:machine: AMD64
2024-06-11 21:43:44,478:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:43:44,478:INFO:Memory: svmem(total=34056318976, available=25267875840, percent=25.8, used=8788443136, free=25267875840)
2024-06-11 21:43:44,479:INFO:Physical Core: 6
2024-06-11 21:43:44,479:INFO:Logical Core: 12
2024-06-11 21:43:44,479:INFO:Checking libraries
2024-06-11 21:43:44,479:INFO:System:
2024-06-11 21:43:44,479:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:43:44,479:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:43:44,479:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:43:44,479:INFO:PyCaret required dependencies:
2024-06-11 21:43:44,501:INFO:                 pip: 24.0
2024-06-11 21:43:44,501:INFO:          setuptools: 69.5.1
2024-06-11 21:43:44,501:INFO:             pycaret: 3.3.2
2024-06-11 21:43:44,502:INFO:             IPython: 8.25.0
2024-06-11 21:43:44,502:INFO:          ipywidgets: 8.1.3
2024-06-11 21:43:44,502:INFO:                tqdm: 4.66.4
2024-06-11 21:43:44,502:INFO:               numpy: 1.26.4
2024-06-11 21:43:44,502:INFO:              pandas: 2.1.4
2024-06-11 21:43:44,502:INFO:              jinja2: 3.1.4
2024-06-11 21:43:44,502:INFO:               scipy: 1.11.4
2024-06-11 21:43:44,502:INFO:              joblib: 1.3.2
2024-06-11 21:43:44,502:INFO:             sklearn: 1.4.2
2024-06-11 21:43:44,502:INFO:                pyod: 2.0.0
2024-06-11 21:43:44,502:INFO:            imblearn: 0.12.3
2024-06-11 21:43:44,502:INFO:   category_encoders: 2.6.3
2024-06-11 21:43:44,502:INFO:            lightgbm: 4.3.0
2024-06-11 21:43:44,502:INFO:               numba: 0.59.1
2024-06-11 21:43:44,502:INFO:            requests: 2.32.3
2024-06-11 21:43:44,502:INFO:          matplotlib: 3.7.5
2024-06-11 21:43:44,502:INFO:          scikitplot: 0.3.7
2024-06-11 21:43:44,502:INFO:         yellowbrick: 1.5
2024-06-11 21:43:44,502:INFO:              plotly: 5.22.0
2024-06-11 21:43:44,502:INFO:    plotly-resampler: Not installed
2024-06-11 21:43:44,502:INFO:             kaleido: 0.2.1
2024-06-11 21:43:44,502:INFO:           schemdraw: 0.15
2024-06-11 21:43:44,502:INFO:         statsmodels: 0.14.2
2024-06-11 21:43:44,502:INFO:              sktime: 0.26.0
2024-06-11 21:43:44,503:INFO:               tbats: 1.1.3
2024-06-11 21:43:44,503:INFO:            pmdarima: 2.0.4
2024-06-11 21:43:44,503:INFO:              psutil: 5.9.8
2024-06-11 21:43:44,503:INFO:          markupsafe: 2.1.5
2024-06-11 21:43:44,503:INFO:             pickle5: Not installed
2024-06-11 21:43:44,503:INFO:         cloudpickle: 3.0.0
2024-06-11 21:43:44,503:INFO:         deprecation: 2.1.0
2024-06-11 21:43:44,503:INFO:              xxhash: 3.4.1
2024-06-11 21:43:44,503:INFO:           wurlitzer: Not installed
2024-06-11 21:43:44,503:INFO:PyCaret optional dependencies:
2024-06-11 21:43:44,513:INFO:                shap: Not installed
2024-06-11 21:43:44,513:INFO:           interpret: Not installed
2024-06-11 21:43:44,513:INFO:                umap: Not installed
2024-06-11 21:43:44,513:INFO:     ydata_profiling: Not installed
2024-06-11 21:43:44,513:INFO:  explainerdashboard: Not installed
2024-06-11 21:43:44,513:INFO:             autoviz: Not installed
2024-06-11 21:43:44,513:INFO:           fairlearn: Not installed
2024-06-11 21:43:44,513:INFO:          deepchecks: Not installed
2024-06-11 21:43:44,513:INFO:             xgboost: Not installed
2024-06-11 21:43:44,513:INFO:            catboost: Not installed
2024-06-11 21:43:44,514:INFO:              kmodes: Not installed
2024-06-11 21:43:44,514:INFO:             mlxtend: Not installed
2024-06-11 21:43:44,514:INFO:       statsforecast: Not installed
2024-06-11 21:43:44,514:INFO:        tune_sklearn: Not installed
2024-06-11 21:43:44,514:INFO:                 ray: Not installed
2024-06-11 21:43:44,514:INFO:            hyperopt: Not installed
2024-06-11 21:43:44,514:INFO:              optuna: Not installed
2024-06-11 21:43:44,514:INFO:               skopt: Not installed
2024-06-11 21:43:44,514:INFO:              mlflow: Not installed
2024-06-11 21:43:44,514:INFO:              gradio: Not installed
2024-06-11 21:43:44,514:INFO:             fastapi: Not installed
2024-06-11 21:43:44,514:INFO:             uvicorn: Not installed
2024-06-11 21:43:44,514:INFO:              m2cgen: Not installed
2024-06-11 21:43:44,514:INFO:           evidently: Not installed
2024-06-11 21:43:44,514:INFO:               fugue: Not installed
2024-06-11 21:43:44,514:INFO:           streamlit: 1.35.0
2024-06-11 21:43:44,514:INFO:             prophet: Not installed
2024-06-11 21:43:44,514:INFO:None
2024-06-11 21:43:44,514:INFO:Set up data.
2024-06-11 21:43:44,551:INFO:Set up folding strategy.
2024-06-11 21:43:44,552:INFO:Set up train/test split.
2024-06-11 21:43:44,576:INFO:Set up index.
2024-06-11 21:43:44,577:INFO:Assigning column types.
2024-06-11 21:43:44,587:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:43:44,628:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:43:44,631:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:43:44,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:44,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:44,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:43:44,705:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:43:44,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:44,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:44,731:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:43:44,784:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:43:44,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:44,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:44,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:43:44,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:44,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:44,893:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:43:44,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:44,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:45,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:45,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:45,041:INFO:Preparing preprocessing pipeline...
2024-06-11 21:43:45,043:INFO:Set up date feature engineering.
2024-06-11 21:43:45,043:INFO:Set up simple imputation.
2024-06-11 21:43:45,053:INFO:Set up encoding of ordinal features.
2024-06-11 21:43:45,064:INFO:Set up encoding of categorical features.
2024-06-11 21:43:45,064:INFO:Set up removing outliers.
2024-06-11 21:43:45,064:INFO:Set up imbalanced handling.
2024-06-11 21:43:45,065:INFO:Set up feature normalization.
2024-06-11 21:43:45,065:INFO:Set up PCA.
2024-06-11 21:43:45,513:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:43:45,548:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-11 21:43:45,548:INFO:Creating final display dataframe.
2024-06-11 21:43:46,267:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (47137, 34)
5   Transformed train set shape       (32137, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method        TomekLinks
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method            linear
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              d8e2
2024-06-11 21:43:46,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:46,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:46,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:46,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:43:46,433:INFO:setup() successfully completed in 2.03s...............
2024-06-11 21:43:46,448:INFO:Initializing create_model()
2024-06-11 21:43:46,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:43:46,449:INFO:Checking exceptions
2024-06-11 21:43:46,464:INFO:Importing libraries
2024-06-11 21:43:46,464:INFO:Copying training dataset
2024-06-11 21:43:46,483:INFO:Defining folds
2024-06-11 21:43:46,483:INFO:Declaring metric variables
2024-06-11 21:43:46,488:INFO:Importing untrained model
2024-06-11 21:43:46,492:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:43:46,499:INFO:Starting cross validation
2024-06-11 21:43:46,501:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:43:57,280:INFO:Calculating mean and std
2024-06-11 21:43:57,281:INFO:Creating metrics dataframe
2024-06-11 21:43:57,291:INFO:Finalizing model
2024-06-11 21:43:59,770:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-11 21:43:59,773:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003113 seconds.
2024-06-11 21:43:59,774:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:43:59,774:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:43:59,775:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-11 21:43:59,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-11 21:43:59,776:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-11 21:43:59,976:INFO:Uploading results into container
2024-06-11 21:43:59,978:INFO:Uploading model into container now
2024-06-11 21:43:59,991:INFO:_master_model_container: 1
2024-06-11 21:43:59,991:INFO:_display_container: 2
2024-06-11 21:43:59,992:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:43:59,992:INFO:create_model() successfully completed......................................
2024-06-11 21:44:00,106:INFO:Initializing tune_model()
2024-06-11 21:44:00,106:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:44:00,106:INFO:Checking exceptions
2024-06-11 21:44:00,132:INFO:Copying training dataset
2024-06-11 21:44:00,147:INFO:Checking base model
2024-06-11 21:44:00,147:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:44:00,150:INFO:Declaring metric variables
2024-06-11 21:44:00,154:INFO:Defining Hyperparameters
2024-06-11 21:44:00,231:INFO:Tuning with n_jobs=-1
2024-06-11 21:44:00,231:INFO:Initializing RandomizedSearchCV
2024-06-11 21:46:09,327:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 21:46:09,328:INFO:Hyperparameter search completed
2024-06-11 21:46:09,329:INFO:SubProcess create_model() called ==================================
2024-06-11 21:46:09,330:INFO:Initializing create_model()
2024-06-11 21:46:09,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218A3ABB890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 21:46:09,331:INFO:Checking exceptions
2024-06-11 21:46:09,331:INFO:Importing libraries
2024-06-11 21:46:09,331:INFO:Copying training dataset
2024-06-11 21:46:09,367:INFO:Defining folds
2024-06-11 21:46:09,367:INFO:Declaring metric variables
2024-06-11 21:46:09,373:INFO:Importing untrained model
2024-06-11 21:46:09,373:INFO:Declaring custom model
2024-06-11 21:46:09,381:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:46:09,392:INFO:Starting cross validation
2024-06-11 21:46:09,398:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:46:22,289:INFO:Calculating mean and std
2024-06-11 21:46:22,292:INFO:Creating metrics dataframe
2024-06-11 21:46:22,301:INFO:Finalizing model
2024-06-11 21:46:25,030:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:46:25,031:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:46:25,031:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:46:25,091:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 21:46:25,091:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 21:46:25,092:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 21:46:25,092:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-11 21:46:25,097:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003822 seconds.
2024-06-11 21:46:25,097:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:46:25,098:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:46:25,100:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-11 21:46:25,102:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-11 21:46:25,102:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-11 21:46:25,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:25,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 21:46:26,056:INFO:Uploading results into container
2024-06-11 21:46:26,058:INFO:Uploading model into container now
2024-06-11 21:46:26,059:INFO:_master_model_container: 2
2024-06-11 21:46:26,059:INFO:_display_container: 3
2024-06-11 21:46:26,061:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:46:26,061:INFO:create_model() successfully completed......................................
2024-06-11 21:46:26,182:INFO:SubProcess create_model() end ==================================
2024-06-11 21:46:26,182:INFO:choose_better activated
2024-06-11 21:46:26,186:INFO:SubProcess create_model() called ==================================
2024-06-11 21:46:26,187:INFO:Initializing create_model()
2024-06-11 21:46:26,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:46:26,187:INFO:Checking exceptions
2024-06-11 21:46:26,190:INFO:Importing libraries
2024-06-11 21:46:26,190:INFO:Copying training dataset
2024-06-11 21:46:26,221:INFO:Defining folds
2024-06-11 21:46:26,221:INFO:Declaring metric variables
2024-06-11 21:46:26,222:INFO:Importing untrained model
2024-06-11 21:46:26,222:INFO:Declaring custom model
2024-06-11 21:46:26,223:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:46:26,223:INFO:Starting cross validation
2024-06-11 21:46:26,227:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:46:36,540:INFO:Calculating mean and std
2024-06-11 21:46:36,541:INFO:Creating metrics dataframe
2024-06-11 21:46:36,543:INFO:Finalizing model
2024-06-11 21:46:39,300:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-11 21:46:39,304:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003119 seconds.
2024-06-11 21:46:39,304:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:46:39,304:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:46:39,305:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-11 21:46:39,305:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-11 21:46:39,306:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-11 21:46:39,573:INFO:Uploading results into container
2024-06-11 21:46:39,574:INFO:Uploading model into container now
2024-06-11 21:46:39,574:INFO:_master_model_container: 3
2024-06-11 21:46:39,575:INFO:_display_container: 4
2024-06-11 21:46:39,575:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:46:39,576:INFO:create_model() successfully completed......................................
2024-06-11 21:46:39,677:INFO:SubProcess create_model() end ==================================
2024-06-11 21:46:39,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1202
2024-06-11 21:46:39,679:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1145
2024-06-11 21:46:39,679:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:46:39,679:INFO:choose_better completed
2024-06-11 21:46:39,679:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-11 21:46:39,688:INFO:_master_model_container: 3
2024-06-11 21:46:39,689:INFO:_display_container: 3
2024-06-11 21:46:39,690:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:46:39,690:INFO:tune_model() successfully completed......................................
2024-06-11 21:46:39,827:INFO:Initializing plot_model()
2024-06-11 21:46:39,827:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:46:39,827:INFO:Checking exceptions
2024-06-11 21:46:39,837:INFO:Preloading libraries
2024-06-11 21:46:39,844:INFO:Copying training dataset
2024-06-11 21:46:39,845:INFO:Plot type: auc
2024-06-11 21:46:40,034:INFO:Fitting Model
2024-06-11 21:46:40,035:INFO:Scoring test/hold-out set
2024-06-11 21:46:40,324:INFO:Visual Rendered Successfully
2024-06-11 21:46:40,403:INFO:plot_model() successfully completed......................................
2024-06-11 21:46:40,425:INFO:Initializing plot_model()
2024-06-11 21:46:40,425:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:46:40,425:INFO:Checking exceptions
2024-06-11 21:46:40,434:INFO:Preloading libraries
2024-06-11 21:46:40,444:INFO:Copying training dataset
2024-06-11 21:46:40,444:INFO:Plot type: confusion_matrix
2024-06-11 21:46:40,628:INFO:Fitting Model
2024-06-11 21:46:40,628:INFO:Scoring test/hold-out set
2024-06-11 21:46:40,814:INFO:Visual Rendered Successfully
2024-06-11 21:46:40,888:INFO:plot_model() successfully completed......................................
2024-06-11 21:46:40,903:INFO:Initializing finalize_model()
2024-06-11 21:46:40,903:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:46:40,904:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:46:40,914:INFO:Initializing create_model()
2024-06-11 21:46:40,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:46:40,914:INFO:Checking exceptions
2024-06-11 21:46:40,915:INFO:Importing libraries
2024-06-11 21:46:40,915:INFO:Copying training dataset
2024-06-11 21:46:40,916:INFO:Defining folds
2024-06-11 21:46:40,916:INFO:Declaring metric variables
2024-06-11 21:46:40,917:INFO:Importing untrained model
2024-06-11 21:46:40,917:INFO:Declaring custom model
2024-06-11 21:46:40,917:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:46:40,919:INFO:Cross validation set to False
2024-06-11 21:46:40,919:INFO:Fitting Model
2024-06-11 21:46:45,451:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 42323
2024-06-11 21:46:45,455:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003899 seconds.
2024-06-11 21:46:45,456:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:46:45,456:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:46:45,457:INFO:[LightGBM] [Info] Number of data points in the train set: 46075, number of used features: 33
2024-06-11 21:46:45,457:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081432 -> initscore=-2.423042
2024-06-11 21:46:45,457:INFO:[LightGBM] [Info] Start training from score -2.423042
2024-06-11 21:46:45,780:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:46:45,780:INFO:create_model() successfully completed......................................
2024-06-11 21:46:45,863:INFO:_master_model_container: 3
2024-06-11 21:46:45,863:INFO:_display_container: 3
2024-06-11 21:46:45,901:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:46:45,901:INFO:finalize_model() successfully completed......................................
2024-06-11 21:46:46,125:INFO:Initializing evaluate_model()
2024-06-11 21:46:46,125:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:46:46,182:INFO:Initializing plot_model()
2024-06-11 21:46:46,182:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:46:46,182:INFO:Checking exceptions
2024-06-11 21:46:46,189:INFO:Preloading libraries
2024-06-11 21:46:46,197:INFO:Copying training dataset
2024-06-11 21:46:46,197:INFO:Plot type: pipeline
2024-06-11 21:46:46,489:INFO:Visual Rendered Successfully
2024-06-11 21:46:46,562:INFO:plot_model() successfully completed......................................
2024-06-11 21:46:58,084:INFO:Initializing plot_model()
2024-06-11 21:46:58,084:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:46:58,084:INFO:Checking exceptions
2024-06-11 21:46:58,092:INFO:Preloading libraries
2024-06-11 21:46:58,099:INFO:Copying training dataset
2024-06-11 21:46:58,099:INFO:Plot type: auc
2024-06-11 21:46:58,291:INFO:Fitting Model
2024-06-11 21:46:58,292:INFO:Scoring test/hold-out set
2024-06-11 21:46:58,549:INFO:Visual Rendered Successfully
2024-06-11 21:46:58,625:INFO:plot_model() successfully completed......................................
2024-06-11 21:47:00,851:INFO:Initializing plot_model()
2024-06-11 21:47:00,851:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A489D650>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:47:00,851:INFO:Checking exceptions
2024-06-11 21:47:00,858:INFO:Preloading libraries
2024-06-11 21:47:00,865:INFO:Copying training dataset
2024-06-11 21:47:00,865:INFO:Plot type: confusion_matrix
2024-06-11 21:47:01,049:INFO:Fitting Model
2024-06-11 21:47:01,050:INFO:Scoring test/hold-out set
2024-06-11 21:47:01,226:INFO:Visual Rendered Successfully
2024-06-11 21:47:01,304:INFO:plot_model() successfully completed......................................
2024-06-11 21:49:48,538:INFO:PyCaret ClassificationExperiment
2024-06-11 21:49:48,539:INFO:Logging name: clf-default-name
2024-06-11 21:49:48,539:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:49:48,539:INFO:version 3.3.2
2024-06-11 21:49:48,539:INFO:Initializing setup()
2024-06-11 21:49:48,539:INFO:self.USI: c7cd
2024-06-11 21:49:48,539:INFO:self._variable_keys: {'idx', 'gpu_param', 'y_train', 'data', 'exp_name_log', 'seed', '_available_plots', 'fix_imbalance', 'is_multiclass', '_ml_usecase', 'html_param', 'n_jobs_param', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_n_jobs_param', 'log_plots_param', 'pipeline', 'USI', 'memory', 'logging_param', 'fold_generator', 'X', 'y_test', 'y', 'fold_shuffle_param', 'X_train', 'X_test'}
2024-06-11 21:49:48,539:INFO:Checking environment
2024-06-11 21:49:48,539:INFO:python_version: 3.11.9
2024-06-11 21:49:48,539:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:49:48,539:INFO:machine: AMD64
2024-06-11 21:49:48,539:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:49:48,539:INFO:Memory: svmem(total=34056318976, available=23303221248, percent=31.6, used=10753097728, free=23303221248)
2024-06-11 21:49:48,539:INFO:Physical Core: 6
2024-06-11 21:49:48,540:INFO:Logical Core: 12
2024-06-11 21:49:48,540:INFO:Checking libraries
2024-06-11 21:49:48,540:INFO:System:
2024-06-11 21:49:48,540:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:49:48,540:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:49:48,540:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:49:48,540:INFO:PyCaret required dependencies:
2024-06-11 21:49:48,540:INFO:                 pip: 24.0
2024-06-11 21:49:48,540:INFO:          setuptools: 69.5.1
2024-06-11 21:49:48,540:INFO:             pycaret: 3.3.2
2024-06-11 21:49:48,540:INFO:             IPython: 8.25.0
2024-06-11 21:49:48,540:INFO:          ipywidgets: 8.1.3
2024-06-11 21:49:48,541:INFO:                tqdm: 4.66.4
2024-06-11 21:49:48,541:INFO:               numpy: 1.26.4
2024-06-11 21:49:48,541:INFO:              pandas: 2.1.4
2024-06-11 21:49:48,541:INFO:              jinja2: 3.1.4
2024-06-11 21:49:48,541:INFO:               scipy: 1.11.4
2024-06-11 21:49:48,541:INFO:              joblib: 1.3.2
2024-06-11 21:49:48,541:INFO:             sklearn: 1.4.2
2024-06-11 21:49:48,541:INFO:                pyod: 2.0.0
2024-06-11 21:49:48,541:INFO:            imblearn: 0.12.3
2024-06-11 21:49:48,541:INFO:   category_encoders: 2.6.3
2024-06-11 21:49:48,541:INFO:            lightgbm: 4.3.0
2024-06-11 21:49:48,541:INFO:               numba: 0.59.1
2024-06-11 21:49:48,541:INFO:            requests: 2.32.3
2024-06-11 21:49:48,541:INFO:          matplotlib: 3.7.5
2024-06-11 21:49:48,541:INFO:          scikitplot: 0.3.7
2024-06-11 21:49:48,541:INFO:         yellowbrick: 1.5
2024-06-11 21:49:48,541:INFO:              plotly: 5.22.0
2024-06-11 21:49:48,542:INFO:    plotly-resampler: Not installed
2024-06-11 21:49:48,542:INFO:             kaleido: 0.2.1
2024-06-11 21:49:48,542:INFO:           schemdraw: 0.15
2024-06-11 21:49:48,542:INFO:         statsmodels: 0.14.2
2024-06-11 21:49:48,542:INFO:              sktime: 0.26.0
2024-06-11 21:49:48,542:INFO:               tbats: 1.1.3
2024-06-11 21:49:48,542:INFO:            pmdarima: 2.0.4
2024-06-11 21:49:48,542:INFO:              psutil: 5.9.8
2024-06-11 21:49:48,542:INFO:          markupsafe: 2.1.5
2024-06-11 21:49:48,542:INFO:             pickle5: Not installed
2024-06-11 21:49:48,542:INFO:         cloudpickle: 3.0.0
2024-06-11 21:49:48,542:INFO:         deprecation: 2.1.0
2024-06-11 21:49:48,542:INFO:              xxhash: 3.4.1
2024-06-11 21:49:48,542:INFO:           wurlitzer: Not installed
2024-06-11 21:49:48,542:INFO:PyCaret optional dependencies:
2024-06-11 21:49:48,543:INFO:                shap: Not installed
2024-06-11 21:49:48,543:INFO:           interpret: Not installed
2024-06-11 21:49:48,543:INFO:                umap: Not installed
2024-06-11 21:49:48,543:INFO:     ydata_profiling: Not installed
2024-06-11 21:49:48,543:INFO:  explainerdashboard: Not installed
2024-06-11 21:49:48,543:INFO:             autoviz: Not installed
2024-06-11 21:49:48,543:INFO:           fairlearn: Not installed
2024-06-11 21:49:48,543:INFO:          deepchecks: Not installed
2024-06-11 21:49:48,543:INFO:             xgboost: Not installed
2024-06-11 21:49:48,543:INFO:            catboost: Not installed
2024-06-11 21:49:48,543:INFO:              kmodes: Not installed
2024-06-11 21:49:48,543:INFO:             mlxtend: Not installed
2024-06-11 21:49:48,543:INFO:       statsforecast: Not installed
2024-06-11 21:49:48,543:INFO:        tune_sklearn: Not installed
2024-06-11 21:49:48,543:INFO:                 ray: Not installed
2024-06-11 21:49:48,543:INFO:            hyperopt: Not installed
2024-06-11 21:49:48,543:INFO:              optuna: Not installed
2024-06-11 21:49:48,543:INFO:               skopt: Not installed
2024-06-11 21:49:48,544:INFO:              mlflow: Not installed
2024-06-11 21:49:48,544:INFO:              gradio: Not installed
2024-06-11 21:49:48,544:INFO:             fastapi: Not installed
2024-06-11 21:49:48,544:INFO:             uvicorn: Not installed
2024-06-11 21:49:48,544:INFO:              m2cgen: Not installed
2024-06-11 21:49:48,544:INFO:           evidently: Not installed
2024-06-11 21:49:48,544:INFO:               fugue: Not installed
2024-06-11 21:49:48,544:INFO:           streamlit: 1.35.0
2024-06-11 21:49:48,544:INFO:             prophet: Not installed
2024-06-11 21:49:48,544:INFO:None
2024-06-11 21:49:48,544:INFO:Set up data.
2024-06-11 21:49:48,588:INFO:Set up folding strategy.
2024-06-11 21:49:48,588:INFO:Set up train/test split.
2024-06-11 21:49:48,614:INFO:Set up index.
2024-06-11 21:49:48,615:INFO:Assigning column types.
2024-06-11 21:49:48,625:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:49:48,672:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:49:48,673:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:49:48,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:48,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:48,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:49:48,757:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:49:48,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:48,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:48,789:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:49:48,833:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:49:48,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:48,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:48,905:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:49:48,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:48,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:48,933:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:49:49,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:49,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:49,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:49,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:49:49,081:INFO:Preparing preprocessing pipeline...
2024-06-11 21:49:49,084:INFO:Set up date feature engineering.
2024-06-11 21:49:49,084:INFO:Set up simple imputation.
2024-06-11 21:49:49,096:INFO:Set up encoding of ordinal features.
2024-06-11 21:49:49,107:INFO:Set up encoding of categorical features.
2024-06-11 21:49:49,107:INFO:Set up removing outliers.
2024-06-11 21:49:49,107:INFO:Set up imbalanced handling.
2024-06-11 21:49:49,108:INFO:Set up feature normalization.
2024-06-11 21:49:49,108:INFO:Set up PCA.
2024-06-11 21:49:49,496:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:49:58,197:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:49:58,230:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-11 21:49:58,230:INFO:Creating final display dataframe.
2024-06-11 21:49:58,472:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:06,960:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (47112, 34)
5   Transformed train set shape       (32112, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method        TomekLinks
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method            linear
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              c7cd
2024-06-11 21:50:07,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:50:07,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:50:07,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:50:07,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:50:07,104:INFO:setup() successfully completed in 18.65s...............
2024-06-11 21:50:07,121:INFO:Initializing create_model()
2024-06-11 21:50:07,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:50:07,122:INFO:Checking exceptions
2024-06-11 21:50:07,136:INFO:Importing libraries
2024-06-11 21:50:07,136:INFO:Copying training dataset
2024-06-11 21:50:07,156:INFO:Defining folds
2024-06-11 21:50:07,156:INFO:Declaring metric variables
2024-06-11 21:50:07,159:INFO:Importing untrained model
2024-06-11 21:50:07,162:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:50:07,167:INFO:Starting cross validation
2024-06-11 21:50:07,170:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:50:07,504:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:07,507:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:07,520:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:07,530:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:07,537:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:16,546:INFO:Calculating mean and std
2024-06-11 21:50:16,548:INFO:Creating metrics dataframe
2024-06-11 21:50:16,555:INFO:Finalizing model
2024-06-11 21:50:16,876:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:24,799:INFO:[LightGBM] [Info] Number of positive: 2711, number of negative: 29401
2024-06-11 21:50:24,802:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002546 seconds.
2024-06-11 21:50:24,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:50:24,802:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:50:24,803:INFO:[LightGBM] [Info] Number of data points in the train set: 32112, number of used features: 33
2024-06-11 21:50:24,804:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.084423 -> initscore=-2.383711
2024-06-11 21:50:24,804:INFO:[LightGBM] [Info] Start training from score -2.383711
2024-06-11 21:50:24,979:INFO:Uploading results into container
2024-06-11 21:50:24,981:INFO:Uploading model into container now
2024-06-11 21:50:24,991:INFO:_master_model_container: 1
2024-06-11 21:50:24,991:INFO:_display_container: 2
2024-06-11 21:50:24,992:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:50:24,993:INFO:create_model() successfully completed......................................
2024-06-11 21:50:25,120:INFO:Initializing tune_model()
2024-06-11 21:50:25,120:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:50:25,120:INFO:Checking exceptions
2024-06-11 21:50:25,144:INFO:Copying training dataset
2024-06-11 21:50:25,155:INFO:Checking base model
2024-06-11 21:50:25,155:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:50:25,159:INFO:Declaring metric variables
2024-06-11 21:50:25,162:INFO:Defining Hyperparameters
2024-06-11 21:50:25,237:INFO:Tuning with n_jobs=-1
2024-06-11 21:50:25,237:INFO:Initializing RandomizedSearchCV
2024-06-11 21:50:25,896:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:25,927:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:25,929:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:25,939:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:25,955:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:25,967:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:25,973:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:25,992:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:26,014:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:26,036:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:26,046:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:26,050:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:45,720:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:45,762:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:45,763:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:45,767:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:50:46,198:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:01,640:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:01,953:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:02,975:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:03,594:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:16,189:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:17,159:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:18,508:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:19,388:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:26,302:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:32,638:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:33,205:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:35,120:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:41,816:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:47,480:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:48,123:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:50,069:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:53,846:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:51:55,799:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:05,973:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:09,406:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:13,919:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:14,168:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:17,115:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:25,843:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:30,383:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:38,671:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:40,456:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:41,216:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:43,747:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:52:52,477:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:00,504:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:00,639:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:00,898:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:13,776:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-11 21:53:13,778:INFO:Hyperparameter search completed
2024-06-11 21:53:13,778:INFO:SubProcess create_model() called ==================================
2024-06-11 21:53:13,779:INFO:Initializing create_model()
2024-06-11 21:53:13,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218A8B26F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-11 21:53:13,780:INFO:Checking exceptions
2024-06-11 21:53:13,780:INFO:Importing libraries
2024-06-11 21:53:13,780:INFO:Copying training dataset
2024-06-11 21:53:13,816:INFO:Defining folds
2024-06-11 21:53:13,816:INFO:Declaring metric variables
2024-06-11 21:53:13,821:INFO:Importing untrained model
2024-06-11 21:53:13,821:INFO:Declaring custom model
2024-06-11 21:53:13,827:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:53:13,838:INFO:Starting cross validation
2024-06-11 21:53:13,842:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:53:14,223:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:14,233:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:14,242:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:14,243:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:14,250:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:25,137:INFO:Calculating mean and std
2024-06-11 21:53:25,139:INFO:Creating metrics dataframe
2024-06-11 21:53:25,146:INFO:Finalizing model
2024-06-11 21:53:25,468:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:33,749:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:53:33,749:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:53:33,749:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:53:33,802:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:53:33,802:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:53:33,802:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:53:33,802:INFO:[LightGBM] [Info] Number of positive: 2711, number of negative: 29401
2024-06-11 21:53:33,807:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003570 seconds.
2024-06-11 21:53:33,807:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:53:33,808:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:53:33,809:INFO:[LightGBM] [Info] Number of data points in the train set: 32112, number of used features: 33
2024-06-11 21:53:33,811:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.084423 -> initscore=-2.383711
2024-06-11 21:53:33,811:INFO:[LightGBM] [Info] Start training from score -2.383711
2024-06-11 21:53:34,264:INFO:Uploading results into container
2024-06-11 21:53:34,265:INFO:Uploading model into container now
2024-06-11 21:53:34,266:INFO:_master_model_container: 2
2024-06-11 21:53:34,267:INFO:_display_container: 3
2024-06-11 21:53:34,268:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:53:34,268:INFO:create_model() successfully completed......................................
2024-06-11 21:53:34,381:INFO:SubProcess create_model() end ==================================
2024-06-11 21:53:34,381:INFO:choose_better activated
2024-06-11 21:53:34,385:INFO:SubProcess create_model() called ==================================
2024-06-11 21:53:34,386:INFO:Initializing create_model()
2024-06-11 21:53:34,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:53:34,386:INFO:Checking exceptions
2024-06-11 21:53:34,388:INFO:Importing libraries
2024-06-11 21:53:34,388:INFO:Copying training dataset
2024-06-11 21:53:34,410:INFO:Defining folds
2024-06-11 21:53:34,410:INFO:Declaring metric variables
2024-06-11 21:53:34,411:INFO:Importing untrained model
2024-06-11 21:53:34,411:INFO:Declaring custom model
2024-06-11 21:53:34,411:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:53:34,412:INFO:Starting cross validation
2024-06-11 21:53:34,414:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:53:34,873:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:34,888:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:34,894:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:34,895:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:34,906:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:46,039:INFO:Calculating mean and std
2024-06-11 21:53:46,039:INFO:Creating metrics dataframe
2024-06-11 21:53:46,042:INFO:Finalizing model
2024-06-11 21:53:46,361:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:53:54,746:INFO:[LightGBM] [Info] Number of positive: 2711, number of negative: 29401
2024-06-11 21:53:54,749:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002676 seconds.
2024-06-11 21:53:54,750:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:53:54,750:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:53:54,751:INFO:[LightGBM] [Info] Number of data points in the train set: 32112, number of used features: 33
2024-06-11 21:53:54,751:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.084423 -> initscore=-2.383711
2024-06-11 21:53:54,751:INFO:[LightGBM] [Info] Start training from score -2.383711
2024-06-11 21:53:54,956:INFO:Uploading results into container
2024-06-11 21:53:54,957:INFO:Uploading model into container now
2024-06-11 21:53:54,957:INFO:_master_model_container: 3
2024-06-11 21:53:54,957:INFO:_display_container: 4
2024-06-11 21:53:54,958:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:53:54,958:INFO:create_model() successfully completed......................................
2024-06-11 21:53:55,056:INFO:SubProcess create_model() end ==================================
2024-06-11 21:53:55,056:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0828
2024-06-11 21:53:55,057:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1013
2024-06-11 21:53:55,058:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:53:55,058:INFO:choose_better completed
2024-06-11 21:53:55,067:INFO:_master_model_container: 3
2024-06-11 21:53:55,067:INFO:_display_container: 3
2024-06-11 21:53:55,068:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:53:55,068:INFO:tune_model() successfully completed......................................
2024-06-11 21:53:55,193:INFO:Initializing plot_model()
2024-06-11 21:53:55,193:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:53:55,193:INFO:Checking exceptions
2024-06-11 21:53:55,203:INFO:Preloading libraries
2024-06-11 21:53:55,218:INFO:Copying training dataset
2024-06-11 21:53:55,218:INFO:Plot type: auc
2024-06-11 21:53:55,400:INFO:Fitting Model
2024-06-11 21:53:55,401:INFO:Scoring test/hold-out set
2024-06-11 21:53:55,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:53:55,403:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:53:55,403:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:53:55,431:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:53:55,431:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:53:55,431:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:53:55,680:INFO:Visual Rendered Successfully
2024-06-11 21:53:55,757:INFO:plot_model() successfully completed......................................
2024-06-11 21:53:55,778:INFO:Initializing plot_model()
2024-06-11 21:53:55,778:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:53:55,778:INFO:Checking exceptions
2024-06-11 21:53:55,788:INFO:Preloading libraries
2024-06-11 21:53:55,807:INFO:Copying training dataset
2024-06-11 21:53:55,807:INFO:Plot type: confusion_matrix
2024-06-11 21:53:55,999:INFO:Fitting Model
2024-06-11 21:53:56,000:INFO:Scoring test/hold-out set
2024-06-11 21:53:56,002:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:53:56,002:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:53:56,002:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:53:56,025:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:53:56,025:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:53:56,025:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:53:56,193:INFO:Visual Rendered Successfully
2024-06-11 21:53:56,267:INFO:plot_model() successfully completed......................................
2024-06-11 21:53:56,283:INFO:Initializing finalize_model()
2024-06-11 21:53:56,283:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:53:56,284:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:53:56,294:INFO:Initializing create_model()
2024-06-11 21:53:56,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:53:56,294:INFO:Checking exceptions
2024-06-11 21:53:56,296:INFO:Importing libraries
2024-06-11 21:53:56,296:INFO:Copying training dataset
2024-06-11 21:53:56,297:INFO:Defining folds
2024-06-11 21:53:56,297:INFO:Declaring metric variables
2024-06-11 21:53:56,298:INFO:Importing untrained model
2024-06-11 21:53:56,298:INFO:Declaring custom model
2024-06-11 21:53:56,298:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:53:56,301:INFO:Cross validation set to False
2024-06-11 21:53:56,301:INFO:Fitting Model
2024-06-11 21:53:56,681:WARNING:c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\covariance\_robust_covariance.py:747: UserWarning: The covariance matrix associated to your dataset is not full rank
  warnings.warn(

2024-06-11 21:54:09,447:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:54:09,447:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:54:09,447:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:54:09,509:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:54:09,509:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:54:09,509:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:54:09,510:INFO:[LightGBM] [Info] Number of positive: 3841, number of negative: 42196
2024-06-11 21:54:09,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003661 seconds.
2024-06-11 21:54:09,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:54:09,515:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:54:09,517:INFO:[LightGBM] [Info] Number of data points in the train set: 46037, number of used features: 33
2024-06-11 21:54:09,518:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.083433 -> initscore=-2.396593
2024-06-11 21:54:09,518:INFO:[LightGBM] [Info] Start training from score -2.396593
2024-06-11 21:54:09,993:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:54:09,993:INFO:create_model() successfully completed......................................
2024-06-11 21:54:10,081:INFO:_master_model_container: 3
2024-06-11 21:54:10,081:INFO:_display_container: 3
2024-06-11 21:54:10,118:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:54:10,118:INFO:finalize_model() successfully completed......................................
2024-06-11 21:54:10,292:INFO:Initializing evaluate_model()
2024-06-11 21:54:10,292:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:54:10,345:INFO:Initializing plot_model()
2024-06-11 21:54:10,345:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:54:10,345:INFO:Checking exceptions
2024-06-11 21:54:10,352:INFO:Preloading libraries
2024-06-11 21:54:10,370:INFO:Copying training dataset
2024-06-11 21:54:10,370:INFO:Plot type: pipeline
2024-06-11 21:54:10,614:INFO:Visual Rendered Successfully
2024-06-11 21:54:10,690:INFO:plot_model() successfully completed......................................
2024-06-11 21:54:17,633:INFO:Initializing plot_model()
2024-06-11 21:54:17,633:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:54:17,633:INFO:Checking exceptions
2024-06-11 21:54:17,644:INFO:Preloading libraries
2024-06-11 21:54:17,664:INFO:Copying training dataset
2024-06-11 21:54:17,664:INFO:Plot type: confusion_matrix
2024-06-11 21:54:17,867:INFO:Fitting Model
2024-06-11 21:54:17,867:INFO:Scoring test/hold-out set
2024-06-11 21:54:17,869:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:54:17,869:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:54:17,870:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:54:17,897:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:54:17,897:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:54:17,897:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:54:18,077:INFO:Visual Rendered Successfully
2024-06-11 21:54:18,152:INFO:plot_model() successfully completed......................................
2024-06-11 21:54:20,206:INFO:Initializing plot_model()
2024-06-11 21:54:20,206:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:54:20,206:INFO:Checking exceptions
2024-06-11 21:54:20,213:INFO:Preloading libraries
2024-06-11 21:54:20,223:INFO:Copying training dataset
2024-06-11 21:54:20,223:INFO:Plot type: auc
2024-06-11 21:54:20,405:INFO:Fitting Model
2024-06-11 21:54:20,406:INFO:Scoring test/hold-out set
2024-06-11 21:54:20,408:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:54:20,408:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:54:20,408:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:54:20,435:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:54:20,435:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:54:20,435:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:54:20,678:INFO:Visual Rendered Successfully
2024-06-11 21:54:20,772:INFO:plot_model() successfully completed......................................
2024-06-11 21:54:36,471:INFO:Initializing plot_model()
2024-06-11 21:54:36,471:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4887F50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:54:36,471:INFO:Checking exceptions
2024-06-11 21:54:36,477:INFO:Preloading libraries
2024-06-11 21:54:36,487:INFO:Copying training dataset
2024-06-11 21:54:36,487:INFO:Plot type: confusion_matrix
2024-06-11 21:54:36,663:INFO:Fitting Model
2024-06-11 21:54:36,664:INFO:Scoring test/hold-out set
2024-06-11 21:54:36,666:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:54:36,666:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:54:36,666:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:54:36,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:54:36,693:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:54:36,693:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:54:36,853:INFO:Visual Rendered Successfully
2024-06-11 21:54:36,928:INFO:plot_model() successfully completed......................................
2024-06-11 21:55:20,423:INFO:PyCaret ClassificationExperiment
2024-06-11 21:55:20,423:INFO:Logging name: clf-default-name
2024-06-11 21:55:20,424:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 21:55:20,424:INFO:version 3.3.2
2024-06-11 21:55:20,424:INFO:Initializing setup()
2024-06-11 21:55:20,424:INFO:self.USI: b8fc
2024-06-11 21:55:20,424:INFO:self._variable_keys: {'idx', 'gpu_param', 'y_train', 'data', 'exp_name_log', 'seed', '_available_plots', 'fix_imbalance', 'is_multiclass', '_ml_usecase', 'html_param', 'n_jobs_param', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_n_jobs_param', 'log_plots_param', 'pipeline', 'USI', 'memory', 'logging_param', 'fold_generator', 'X', 'y_test', 'y', 'fold_shuffle_param', 'X_train', 'X_test'}
2024-06-11 21:55:20,424:INFO:Checking environment
2024-06-11 21:55:20,424:INFO:python_version: 3.11.9
2024-06-11 21:55:20,424:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 21:55:20,424:INFO:machine: AMD64
2024-06-11 21:55:20,424:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 21:55:20,424:INFO:Memory: svmem(total=34056318976, available=23239929856, percent=31.8, used=10816389120, free=23239929856)
2024-06-11 21:55:20,424:INFO:Physical Core: 6
2024-06-11 21:55:20,424:INFO:Logical Core: 12
2024-06-11 21:55:20,424:INFO:Checking libraries
2024-06-11 21:55:20,424:INFO:System:
2024-06-11 21:55:20,425:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 21:55:20,425:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 21:55:20,425:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 21:55:20,425:INFO:PyCaret required dependencies:
2024-06-11 21:55:20,425:INFO:                 pip: 24.0
2024-06-11 21:55:20,425:INFO:          setuptools: 69.5.1
2024-06-11 21:55:20,425:INFO:             pycaret: 3.3.2
2024-06-11 21:55:20,425:INFO:             IPython: 8.25.0
2024-06-11 21:55:20,425:INFO:          ipywidgets: 8.1.3
2024-06-11 21:55:20,425:INFO:                tqdm: 4.66.4
2024-06-11 21:55:20,425:INFO:               numpy: 1.26.4
2024-06-11 21:55:20,425:INFO:              pandas: 2.1.4
2024-06-11 21:55:20,425:INFO:              jinja2: 3.1.4
2024-06-11 21:55:20,425:INFO:               scipy: 1.11.4
2024-06-11 21:55:20,425:INFO:              joblib: 1.3.2
2024-06-11 21:55:20,425:INFO:             sklearn: 1.4.2
2024-06-11 21:55:20,425:INFO:                pyod: 2.0.0
2024-06-11 21:55:20,425:INFO:            imblearn: 0.12.3
2024-06-11 21:55:20,426:INFO:   category_encoders: 2.6.3
2024-06-11 21:55:20,426:INFO:            lightgbm: 4.3.0
2024-06-11 21:55:20,426:INFO:               numba: 0.59.1
2024-06-11 21:55:20,426:INFO:            requests: 2.32.3
2024-06-11 21:55:20,426:INFO:          matplotlib: 3.7.5
2024-06-11 21:55:20,426:INFO:          scikitplot: 0.3.7
2024-06-11 21:55:20,426:INFO:         yellowbrick: 1.5
2024-06-11 21:55:20,426:INFO:              plotly: 5.22.0
2024-06-11 21:55:20,426:INFO:    plotly-resampler: Not installed
2024-06-11 21:55:20,426:INFO:             kaleido: 0.2.1
2024-06-11 21:55:20,426:INFO:           schemdraw: 0.15
2024-06-11 21:55:20,426:INFO:         statsmodels: 0.14.2
2024-06-11 21:55:20,426:INFO:              sktime: 0.26.0
2024-06-11 21:55:20,426:INFO:               tbats: 1.1.3
2024-06-11 21:55:20,426:INFO:            pmdarima: 2.0.4
2024-06-11 21:55:20,426:INFO:              psutil: 5.9.8
2024-06-11 21:55:20,426:INFO:          markupsafe: 2.1.5
2024-06-11 21:55:20,426:INFO:             pickle5: Not installed
2024-06-11 21:55:20,426:INFO:         cloudpickle: 3.0.0
2024-06-11 21:55:20,427:INFO:         deprecation: 2.1.0
2024-06-11 21:55:20,427:INFO:              xxhash: 3.4.1
2024-06-11 21:55:20,427:INFO:           wurlitzer: Not installed
2024-06-11 21:55:20,427:INFO:PyCaret optional dependencies:
2024-06-11 21:55:20,427:INFO:                shap: Not installed
2024-06-11 21:55:20,427:INFO:           interpret: Not installed
2024-06-11 21:55:20,427:INFO:                umap: Not installed
2024-06-11 21:55:20,427:INFO:     ydata_profiling: Not installed
2024-06-11 21:55:20,427:INFO:  explainerdashboard: Not installed
2024-06-11 21:55:20,427:INFO:             autoviz: Not installed
2024-06-11 21:55:20,427:INFO:           fairlearn: Not installed
2024-06-11 21:55:20,427:INFO:          deepchecks: Not installed
2024-06-11 21:55:20,427:INFO:             xgboost: Not installed
2024-06-11 21:55:20,428:INFO:            catboost: Not installed
2024-06-11 21:55:20,428:INFO:              kmodes: Not installed
2024-06-11 21:55:20,428:INFO:             mlxtend: Not installed
2024-06-11 21:55:20,428:INFO:       statsforecast: Not installed
2024-06-11 21:55:20,428:INFO:        tune_sklearn: Not installed
2024-06-11 21:55:20,428:INFO:                 ray: Not installed
2024-06-11 21:55:20,428:INFO:            hyperopt: Not installed
2024-06-11 21:55:20,428:INFO:              optuna: Not installed
2024-06-11 21:55:20,428:INFO:               skopt: Not installed
2024-06-11 21:55:20,428:INFO:              mlflow: Not installed
2024-06-11 21:55:20,428:INFO:              gradio: Not installed
2024-06-11 21:55:20,428:INFO:             fastapi: Not installed
2024-06-11 21:55:20,428:INFO:             uvicorn: Not installed
2024-06-11 21:55:20,428:INFO:              m2cgen: Not installed
2024-06-11 21:55:20,428:INFO:           evidently: Not installed
2024-06-11 21:55:20,428:INFO:               fugue: Not installed
2024-06-11 21:55:20,429:INFO:           streamlit: 1.35.0
2024-06-11 21:55:20,429:INFO:             prophet: Not installed
2024-06-11 21:55:20,429:INFO:None
2024-06-11 21:55:20,429:INFO:Set up data.
2024-06-11 21:55:20,475:INFO:Set up folding strategy.
2024-06-11 21:55:20,475:INFO:Set up train/test split.
2024-06-11 21:55:20,499:INFO:Set up index.
2024-06-11 21:55:20,500:INFO:Assigning column types.
2024-06-11 21:55:20,510:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 21:55:20,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:55:20,556:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:55:20,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:20,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:20,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 21:55:20,628:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:55:20,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:20,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:20,666:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 21:55:20,713:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:55:20,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:20,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:20,811:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 21:55:20,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:20,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:20,840:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 21:55:20,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:20,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:21,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:21,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:21,004:INFO:Preparing preprocessing pipeline...
2024-06-11 21:55:21,008:INFO:Set up date feature engineering.
2024-06-11 21:55:21,008:INFO:Set up simple imputation.
2024-06-11 21:55:21,021:INFO:Set up encoding of ordinal features.
2024-06-11 21:55:21,040:INFO:Set up encoding of categorical features.
2024-06-11 21:55:21,040:INFO:Set up removing outliers.
2024-06-11 21:55:21,040:INFO:Set up imbalanced handling.
2024-06-11 21:55:21,040:INFO:Set up feature normalization.
2024-06-11 21:55:21,040:INFO:Set up PCA.
2024-06-11 21:55:24,730:INFO:Finished creating preprocessing pipeline.
2024-06-11 21:55:24,763:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-11 21:55:24,763:INFO:Creating final display dataframe.
2024-06-11 21:55:28,436:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (47145, 34)
5   Transformed train set shape       (32145, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method        TomekLinks
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method            linear
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              b8fc
2024-06-11 21:55:28,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:28,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:28,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:28,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 21:55:28,594:INFO:setup() successfully completed in 8.26s...............
2024-06-11 21:55:28,610:INFO:Initializing create_model()
2024-06-11 21:55:28,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:55:28,610:INFO:Checking exceptions
2024-06-11 21:55:28,625:INFO:Importing libraries
2024-06-11 21:55:28,625:INFO:Copying training dataset
2024-06-11 21:55:28,643:INFO:Defining folds
2024-06-11 21:55:28,643:INFO:Declaring metric variables
2024-06-11 21:55:28,646:INFO:Importing untrained model
2024-06-11 21:55:28,649:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:55:28,656:INFO:Starting cross validation
2024-06-11 21:55:28,662:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:55:39,689:INFO:Calculating mean and std
2024-06-11 21:55:39,690:INFO:Creating metrics dataframe
2024-06-11 21:55:39,697:INFO:Finalizing model
2024-06-11 21:55:42,957:INFO:[LightGBM] [Info] Number of positive: 2574, number of negative: 29571
2024-06-11 21:55:42,960:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002437 seconds.
2024-06-11 21:55:42,960:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:55:42,961:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:55:42,962:INFO:[LightGBM] [Info] Number of data points in the train set: 32145, number of used features: 33
2024-06-11 21:55:42,962:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080075 -> initscore=-2.441333
2024-06-11 21:55:42,962:INFO:[LightGBM] [Info] Start training from score -2.441333
2024-06-11 21:55:43,120:INFO:Uploading results into container
2024-06-11 21:55:43,121:INFO:Uploading model into container now
2024-06-11 21:55:43,132:INFO:_master_model_container: 1
2024-06-11 21:55:43,132:INFO:_display_container: 2
2024-06-11 21:55:43,133:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:55:43,134:INFO:create_model() successfully completed......................................
2024-06-11 21:55:43,265:INFO:Initializing tune_model()
2024-06-11 21:55:43,265:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 21:55:43,265:INFO:Checking exceptions
2024-06-11 21:55:43,289:INFO:Copying training dataset
2024-06-11 21:55:43,303:INFO:Checking base model
2024-06-11 21:55:43,303:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 21:55:43,307:INFO:Declaring metric variables
2024-06-11 21:55:43,311:INFO:Defining Hyperparameters
2024-06-11 21:55:43,393:INFO:Tuning with n_jobs=-1
2024-06-11 21:55:43,393:INFO:Initializing RandomizedSearchCV
2024-06-11 21:59:03,372:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-11 21:59:03,373:INFO:Hyperparameter search completed
2024-06-11 21:59:03,373:INFO:SubProcess create_model() called ==================================
2024-06-11 21:59:03,375:INFO:Initializing create_model()
2024-06-11 21:59:03,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218A8CA2350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-11 21:59:03,375:INFO:Checking exceptions
2024-06-11 21:59:03,375:INFO:Importing libraries
2024-06-11 21:59:03,376:INFO:Copying training dataset
2024-06-11 21:59:03,411:INFO:Defining folds
2024-06-11 21:59:03,411:INFO:Declaring metric variables
2024-06-11 21:59:03,416:INFO:Importing untrained model
2024-06-11 21:59:03,417:INFO:Declaring custom model
2024-06-11 21:59:03,423:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:59:03,434:INFO:Starting cross validation
2024-06-11 21:59:03,445:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:59:17,674:INFO:Calculating mean and std
2024-06-11 21:59:17,676:INFO:Creating metrics dataframe
2024-06-11 21:59:17,685:INFO:Finalizing model
2024-06-11 21:59:21,088:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:59:21,088:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:59:21,088:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:59:21,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:59:21,136:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:59:21,136:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:59:21,136:INFO:[LightGBM] [Info] Number of positive: 2574, number of negative: 29571
2024-06-11 21:59:21,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002185 seconds.
2024-06-11 21:59:21,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:59:21,139:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:59:21,141:INFO:[LightGBM] [Info] Number of data points in the train set: 32145, number of used features: 33
2024-06-11 21:59:21,142:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080075 -> initscore=-2.441333
2024-06-11 21:59:21,142:INFO:[LightGBM] [Info] Start training from score -2.441333
2024-06-11 21:59:21,484:INFO:Uploading results into container
2024-06-11 21:59:21,485:INFO:Uploading model into container now
2024-06-11 21:59:21,487:INFO:_master_model_container: 2
2024-06-11 21:59:21,487:INFO:_display_container: 3
2024-06-11 21:59:21,488:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:59:21,489:INFO:create_model() successfully completed......................................
2024-06-11 21:59:21,598:INFO:SubProcess create_model() end ==================================
2024-06-11 21:59:21,598:INFO:choose_better activated
2024-06-11 21:59:21,601:INFO:SubProcess create_model() called ==================================
2024-06-11 21:59:21,602:INFO:Initializing create_model()
2024-06-11 21:59:21,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:59:21,602:INFO:Checking exceptions
2024-06-11 21:59:21,603:INFO:Importing libraries
2024-06-11 21:59:21,603:INFO:Copying training dataset
2024-06-11 21:59:21,623:INFO:Defining folds
2024-06-11 21:59:21,623:INFO:Declaring metric variables
2024-06-11 21:59:21,623:INFO:Importing untrained model
2024-06-11 21:59:21,623:INFO:Declaring custom model
2024-06-11 21:59:21,624:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:59:21,624:INFO:Starting cross validation
2024-06-11 21:59:21,630:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 21:59:33,354:INFO:Calculating mean and std
2024-06-11 21:59:33,355:INFO:Creating metrics dataframe
2024-06-11 21:59:33,357:INFO:Finalizing model
2024-06-11 21:59:36,809:INFO:[LightGBM] [Info] Number of positive: 2574, number of negative: 29571
2024-06-11 21:59:36,812:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002484 seconds.
2024-06-11 21:59:36,812:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:59:36,813:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:59:36,813:INFO:[LightGBM] [Info] Number of data points in the train set: 32145, number of used features: 33
2024-06-11 21:59:36,814:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080075 -> initscore=-2.441333
2024-06-11 21:59:36,814:INFO:[LightGBM] [Info] Start training from score -2.441333
2024-06-11 21:59:36,977:INFO:Uploading results into container
2024-06-11 21:59:36,977:INFO:Uploading model into container now
2024-06-11 21:59:36,978:INFO:_master_model_container: 3
2024-06-11 21:59:36,978:INFO:_display_container: 4
2024-06-11 21:59:36,979:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:59:36,979:INFO:create_model() successfully completed......................................
2024-06-11 21:59:37,074:INFO:SubProcess create_model() end ==================================
2024-06-11 21:59:37,075:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0997
2024-06-11 21:59:37,076:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1093
2024-06-11 21:59:37,077:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 21:59:37,077:INFO:choose_better completed
2024-06-11 21:59:37,085:INFO:_master_model_container: 3
2024-06-11 21:59:37,085:INFO:_display_container: 3
2024-06-11 21:59:37,086:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:59:37,086:INFO:tune_model() successfully completed......................................
2024-06-11 21:59:37,213:INFO:Initializing plot_model()
2024-06-11 21:59:37,213:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:59:37,213:INFO:Checking exceptions
2024-06-11 21:59:37,223:INFO:Preloading libraries
2024-06-11 21:59:37,237:INFO:Copying training dataset
2024-06-11 21:59:37,237:INFO:Plot type: auc
2024-06-11 21:59:37,430:INFO:Fitting Model
2024-06-11 21:59:37,431:INFO:Scoring test/hold-out set
2024-06-11 21:59:37,433:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:59:37,433:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:59:37,433:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:59:37,461:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:59:37,461:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:59:37,461:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:59:37,710:INFO:Visual Rendered Successfully
2024-06-11 21:59:37,787:INFO:plot_model() successfully completed......................................
2024-06-11 21:59:37,812:INFO:Initializing plot_model()
2024-06-11 21:59:37,812:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 21:59:37,812:INFO:Checking exceptions
2024-06-11 21:59:37,822:INFO:Preloading libraries
2024-06-11 21:59:37,834:INFO:Copying training dataset
2024-06-11 21:59:37,835:INFO:Plot type: confusion_matrix
2024-06-11 21:59:38,016:INFO:Fitting Model
2024-06-11 21:59:38,017:INFO:Scoring test/hold-out set
2024-06-11 21:59:38,019:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:59:38,019:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:59:38,019:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:59:38,043:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:59:38,043:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:59:38,043:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:59:38,202:INFO:Visual Rendered Successfully
2024-06-11 21:59:38,277:INFO:plot_model() successfully completed......................................
2024-06-11 21:59:38,298:INFO:Initializing finalize_model()
2024-06-11 21:59:38,299:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 21:59:38,300:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-11 21:59:38,316:INFO:Initializing create_model()
2024-06-11 21:59:38,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 21:59:38,317:INFO:Checking exceptions
2024-06-11 21:59:38,318:INFO:Importing libraries
2024-06-11 21:59:38,319:INFO:Copying training dataset
2024-06-11 21:59:38,320:INFO:Defining folds
2024-06-11 21:59:38,320:INFO:Declaring metric variables
2024-06-11 21:59:38,320:INFO:Importing untrained model
2024-06-11 21:59:38,320:INFO:Declaring custom model
2024-06-11 21:59:38,322:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 21:59:38,330:INFO:Cross validation set to False
2024-06-11 21:59:38,330:INFO:Fitting Model
2024-06-11 21:59:44,531:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:59:44,531:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:59:44,531:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:59:44,602:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 21:59:44,602:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 21:59:44,602:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 21:59:44,602:INFO:[LightGBM] [Info] Number of positive: 3705, number of negative: 42350
2024-06-11 21:59:44,606:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003193 seconds.
2024-06-11 21:59:44,607:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 21:59:44,607:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 21:59:44,609:INFO:[LightGBM] [Info] Number of data points in the train set: 46055, number of used features: 33
2024-06-11 21:59:44,611:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080447 -> initscore=-2.436285
2024-06-11 21:59:44,612:INFO:[LightGBM] [Info] Start training from score -2.436285
2024-06-11 21:59:45,056:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:59:45,056:INFO:create_model() successfully completed......................................
2024-06-11 21:59:45,143:INFO:_master_model_container: 3
2024-06-11 21:59:45,144:INFO:_display_container: 3
2024-06-11 21:59:45,182:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 21:59:45,182:INFO:finalize_model() successfully completed......................................
2024-06-11 21:59:45,377:INFO:Initializing evaluate_model()
2024-06-11 21:59:45,377:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 21:59:45,428:INFO:Initializing plot_model()
2024-06-11 21:59:45,428:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 21:59:45,428:INFO:Checking exceptions
2024-06-11 21:59:45,435:INFO:Preloading libraries
2024-06-11 21:59:45,448:INFO:Copying training dataset
2024-06-11 21:59:45,448:INFO:Plot type: pipeline
2024-06-11 21:59:45,695:INFO:Visual Rendered Successfully
2024-06-11 21:59:45,772:INFO:plot_model() successfully completed......................................
2024-06-11 22:00:41,001:INFO:Initializing plot_model()
2024-06-11 22:00:41,001:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A4885750>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 22:00:41,001:INFO:Checking exceptions
2024-06-11 22:00:41,009:INFO:Preloading libraries
2024-06-11 22:00:41,021:INFO:Copying training dataset
2024-06-11 22:00:41,021:INFO:Plot type: confusion_matrix
2024-06-11 22:00:41,209:INFO:Fitting Model
2024-06-11 22:00:41,210:INFO:Scoring test/hold-out set
2024-06-11 22:00:41,211:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 22:00:41,212:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 22:00:41,212:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 22:00:41,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-11 22:00:41,235:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-11 22:00:41,235:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-11 22:00:41,384:INFO:Visual Rendered Successfully
2024-06-11 22:00:41,462:INFO:plot_model() successfully completed......................................
2024-06-11 22:01:04,008:INFO:PyCaret ClassificationExperiment
2024-06-11 22:01:04,008:INFO:Logging name: clf-default-name
2024-06-11 22:01:04,008:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:01:04,008:INFO:version 3.3.2
2024-06-11 22:01:04,008:INFO:Initializing setup()
2024-06-11 22:01:04,008:INFO:self.USI: a9a8
2024-06-11 22:01:04,008:INFO:self._variable_keys: {'idx', 'gpu_param', 'y_train', 'data', 'exp_name_log', 'seed', '_available_plots', 'fix_imbalance', 'is_multiclass', '_ml_usecase', 'html_param', 'n_jobs_param', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_n_jobs_param', 'log_plots_param', 'pipeline', 'USI', 'memory', 'logging_param', 'fold_generator', 'X', 'y_test', 'y', 'fold_shuffle_param', 'X_train', 'X_test'}
2024-06-11 22:01:04,008:INFO:Checking environment
2024-06-11 22:01:04,008:INFO:python_version: 3.11.9
2024-06-11 22:01:04,008:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:01:04,008:INFO:machine: AMD64
2024-06-11 22:01:04,008:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:01:04,008:INFO:Memory: svmem(total=34056318976, available=23145648128, percent=32.0, used=10910670848, free=23145648128)
2024-06-11 22:01:04,008:INFO:Physical Core: 6
2024-06-11 22:01:04,009:INFO:Logical Core: 12
2024-06-11 22:01:04,009:INFO:Checking libraries
2024-06-11 22:01:04,009:INFO:System:
2024-06-11 22:01:04,009:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:01:04,009:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:01:04,009:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:01:04,009:INFO:PyCaret required dependencies:
2024-06-11 22:01:04,009:INFO:                 pip: 24.0
2024-06-11 22:01:04,009:INFO:          setuptools: 69.5.1
2024-06-11 22:01:04,009:INFO:             pycaret: 3.3.2
2024-06-11 22:01:04,009:INFO:             IPython: 8.25.0
2024-06-11 22:01:04,009:INFO:          ipywidgets: 8.1.3
2024-06-11 22:01:04,009:INFO:                tqdm: 4.66.4
2024-06-11 22:01:04,009:INFO:               numpy: 1.26.4
2024-06-11 22:01:04,009:INFO:              pandas: 2.1.4
2024-06-11 22:01:04,009:INFO:              jinja2: 3.1.4
2024-06-11 22:01:04,010:INFO:               scipy: 1.11.4
2024-06-11 22:01:04,010:INFO:              joblib: 1.3.2
2024-06-11 22:01:04,010:INFO:             sklearn: 1.4.2
2024-06-11 22:01:04,010:INFO:                pyod: 2.0.0
2024-06-11 22:01:04,010:INFO:            imblearn: 0.12.3
2024-06-11 22:01:04,010:INFO:   category_encoders: 2.6.3
2024-06-11 22:01:04,010:INFO:            lightgbm: 4.3.0
2024-06-11 22:01:04,010:INFO:               numba: 0.59.1
2024-06-11 22:01:04,010:INFO:            requests: 2.32.3
2024-06-11 22:01:04,010:INFO:          matplotlib: 3.7.5
2024-06-11 22:01:04,010:INFO:          scikitplot: 0.3.7
2024-06-11 22:01:04,010:INFO:         yellowbrick: 1.5
2024-06-11 22:01:04,010:INFO:              plotly: 5.22.0
2024-06-11 22:01:04,010:INFO:    plotly-resampler: Not installed
2024-06-11 22:01:04,010:INFO:             kaleido: 0.2.1
2024-06-11 22:01:04,010:INFO:           schemdraw: 0.15
2024-06-11 22:01:04,010:INFO:         statsmodels: 0.14.2
2024-06-11 22:01:04,010:INFO:              sktime: 0.26.0
2024-06-11 22:01:04,010:INFO:               tbats: 1.1.3
2024-06-11 22:01:04,010:INFO:            pmdarima: 2.0.4
2024-06-11 22:01:04,010:INFO:              psutil: 5.9.8
2024-06-11 22:01:04,011:INFO:          markupsafe: 2.1.5
2024-06-11 22:01:04,011:INFO:             pickle5: Not installed
2024-06-11 22:01:04,011:INFO:         cloudpickle: 3.0.0
2024-06-11 22:01:04,011:INFO:         deprecation: 2.1.0
2024-06-11 22:01:04,011:INFO:              xxhash: 3.4.1
2024-06-11 22:01:04,011:INFO:           wurlitzer: Not installed
2024-06-11 22:01:04,011:INFO:PyCaret optional dependencies:
2024-06-11 22:01:04,011:INFO:                shap: Not installed
2024-06-11 22:01:04,011:INFO:           interpret: Not installed
2024-06-11 22:01:04,011:INFO:                umap: Not installed
2024-06-11 22:01:04,011:INFO:     ydata_profiling: Not installed
2024-06-11 22:01:04,011:INFO:  explainerdashboard: Not installed
2024-06-11 22:01:04,011:INFO:             autoviz: Not installed
2024-06-11 22:01:04,011:INFO:           fairlearn: Not installed
2024-06-11 22:01:04,011:INFO:          deepchecks: Not installed
2024-06-11 22:01:04,011:INFO:             xgboost: Not installed
2024-06-11 22:01:04,011:INFO:            catboost: Not installed
2024-06-11 22:01:04,011:INFO:              kmodes: Not installed
2024-06-11 22:01:04,011:INFO:             mlxtend: Not installed
2024-06-11 22:01:04,011:INFO:       statsforecast: Not installed
2024-06-11 22:01:04,012:INFO:        tune_sklearn: Not installed
2024-06-11 22:01:04,012:INFO:                 ray: Not installed
2024-06-11 22:01:04,012:INFO:            hyperopt: Not installed
2024-06-11 22:01:04,012:INFO:              optuna: Not installed
2024-06-11 22:01:04,012:INFO:               skopt: Not installed
2024-06-11 22:01:04,012:INFO:              mlflow: Not installed
2024-06-11 22:01:04,012:INFO:              gradio: Not installed
2024-06-11 22:01:04,012:INFO:             fastapi: Not installed
2024-06-11 22:01:04,012:INFO:             uvicorn: Not installed
2024-06-11 22:01:04,012:INFO:              m2cgen: Not installed
2024-06-11 22:01:04,012:INFO:           evidently: Not installed
2024-06-11 22:01:04,012:INFO:               fugue: Not installed
2024-06-11 22:01:04,012:INFO:           streamlit: 1.35.0
2024-06-11 22:01:04,012:INFO:             prophet: Not installed
2024-06-11 22:01:04,012:INFO:None
2024-06-11 22:01:04,012:INFO:Set up data.
2024-06-11 22:01:04,078:INFO:Set up folding strategy.
2024-06-11 22:01:04,078:INFO:Set up train/test split.
2024-06-11 22:01:04,107:INFO:Set up index.
2024-06-11 22:01:04,110:INFO:Assigning column types.
2024-06-11 22:01:04,126:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 22:01:04,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:01:04,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:01:04,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,247:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:01:04,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:01:04,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,284:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 22:01:04,327:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:01:04,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:01:04,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,428:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 22:01:04,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:04,597:INFO:Preparing preprocessing pipeline...
2024-06-11 22:01:04,599:INFO:Set up date feature engineering.
2024-06-11 22:01:04,599:INFO:Set up simple imputation.
2024-06-11 22:01:04,611:INFO:Set up encoding of ordinal features.
2024-06-11 22:01:04,622:INFO:Set up encoding of categorical features.
2024-06-11 22:01:04,622:INFO:Set up removing outliers.
2024-06-11 22:01:27,293:INFO:PyCaret ClassificationExperiment
2024-06-11 22:01:27,294:INFO:Logging name: clf-default-name
2024-06-11 22:01:27,294:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:01:27,294:INFO:version 3.3.2
2024-06-11 22:01:27,294:INFO:Initializing setup()
2024-06-11 22:01:27,294:INFO:self.USI: 7737
2024-06-11 22:01:27,294:INFO:self._variable_keys: {'idx', 'gpu_param', 'y_train', 'data', 'exp_name_log', 'seed', '_available_plots', 'fix_imbalance', 'is_multiclass', '_ml_usecase', 'html_param', 'n_jobs_param', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_n_jobs_param', 'log_plots_param', 'pipeline', 'USI', 'memory', 'logging_param', 'fold_generator', 'X', 'y_test', 'y', 'fold_shuffle_param', 'X_train', 'X_test'}
2024-06-11 22:01:27,294:INFO:Checking environment
2024-06-11 22:01:27,294:INFO:python_version: 3.11.9
2024-06-11 22:01:27,294:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:01:27,294:INFO:machine: AMD64
2024-06-11 22:01:27,294:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:01:27,295:INFO:Memory: svmem(total=34056318976, available=23094476800, percent=32.2, used=10961842176, free=23094476800)
2024-06-11 22:01:27,295:INFO:Physical Core: 6
2024-06-11 22:01:27,295:INFO:Logical Core: 12
2024-06-11 22:01:27,295:INFO:Checking libraries
2024-06-11 22:01:27,295:INFO:System:
2024-06-11 22:01:27,295:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:01:27,295:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:01:27,295:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:01:27,295:INFO:PyCaret required dependencies:
2024-06-11 22:01:27,296:INFO:                 pip: 24.0
2024-06-11 22:01:27,296:INFO:          setuptools: 69.5.1
2024-06-11 22:01:27,296:INFO:             pycaret: 3.3.2
2024-06-11 22:01:27,296:INFO:             IPython: 8.25.0
2024-06-11 22:01:27,296:INFO:          ipywidgets: 8.1.3
2024-06-11 22:01:27,296:INFO:                tqdm: 4.66.4
2024-06-11 22:01:27,296:INFO:               numpy: 1.26.4
2024-06-11 22:01:27,296:INFO:              pandas: 2.1.4
2024-06-11 22:01:27,296:INFO:              jinja2: 3.1.4
2024-06-11 22:01:27,296:INFO:               scipy: 1.11.4
2024-06-11 22:01:27,296:INFO:              joblib: 1.3.2
2024-06-11 22:01:27,296:INFO:             sklearn: 1.4.2
2024-06-11 22:01:27,296:INFO:                pyod: 2.0.0
2024-06-11 22:01:27,296:INFO:            imblearn: 0.12.3
2024-06-11 22:01:27,296:INFO:   category_encoders: 2.6.3
2024-06-11 22:01:27,296:INFO:            lightgbm: 4.3.0
2024-06-11 22:01:27,297:INFO:               numba: 0.59.1
2024-06-11 22:01:27,297:INFO:            requests: 2.32.3
2024-06-11 22:01:27,297:INFO:          matplotlib: 3.7.5
2024-06-11 22:01:27,297:INFO:          scikitplot: 0.3.7
2024-06-11 22:01:27,297:INFO:         yellowbrick: 1.5
2024-06-11 22:01:27,297:INFO:              plotly: 5.22.0
2024-06-11 22:01:27,297:INFO:    plotly-resampler: Not installed
2024-06-11 22:01:27,297:INFO:             kaleido: 0.2.1
2024-06-11 22:01:27,297:INFO:           schemdraw: 0.15
2024-06-11 22:01:27,297:INFO:         statsmodels: 0.14.2
2024-06-11 22:01:27,297:INFO:              sktime: 0.26.0
2024-06-11 22:01:27,297:INFO:               tbats: 1.1.3
2024-06-11 22:01:27,297:INFO:            pmdarima: 2.0.4
2024-06-11 22:01:27,297:INFO:              psutil: 5.9.8
2024-06-11 22:01:27,297:INFO:          markupsafe: 2.1.5
2024-06-11 22:01:27,297:INFO:             pickle5: Not installed
2024-06-11 22:01:27,297:INFO:         cloudpickle: 3.0.0
2024-06-11 22:01:27,297:INFO:         deprecation: 2.1.0
2024-06-11 22:01:27,297:INFO:              xxhash: 3.4.1
2024-06-11 22:01:27,298:INFO:           wurlitzer: Not installed
2024-06-11 22:01:27,298:INFO:PyCaret optional dependencies:
2024-06-11 22:01:27,298:INFO:                shap: Not installed
2024-06-11 22:01:27,298:INFO:           interpret: Not installed
2024-06-11 22:01:27,298:INFO:                umap: Not installed
2024-06-11 22:01:27,298:INFO:     ydata_profiling: Not installed
2024-06-11 22:01:27,298:INFO:  explainerdashboard: Not installed
2024-06-11 22:01:27,298:INFO:             autoviz: Not installed
2024-06-11 22:01:27,298:INFO:           fairlearn: Not installed
2024-06-11 22:01:27,298:INFO:          deepchecks: Not installed
2024-06-11 22:01:27,298:INFO:             xgboost: Not installed
2024-06-11 22:01:27,298:INFO:            catboost: Not installed
2024-06-11 22:01:27,298:INFO:              kmodes: Not installed
2024-06-11 22:01:27,298:INFO:             mlxtend: Not installed
2024-06-11 22:01:27,298:INFO:       statsforecast: Not installed
2024-06-11 22:01:27,298:INFO:        tune_sklearn: Not installed
2024-06-11 22:01:27,298:INFO:                 ray: Not installed
2024-06-11 22:01:27,298:INFO:            hyperopt: Not installed
2024-06-11 22:01:27,299:INFO:              optuna: Not installed
2024-06-11 22:01:27,299:INFO:               skopt: Not installed
2024-06-11 22:01:27,299:INFO:              mlflow: Not installed
2024-06-11 22:01:27,299:INFO:              gradio: Not installed
2024-06-11 22:01:27,299:INFO:             fastapi: Not installed
2024-06-11 22:01:27,299:INFO:             uvicorn: Not installed
2024-06-11 22:01:27,299:INFO:              m2cgen: Not installed
2024-06-11 22:01:27,299:INFO:           evidently: Not installed
2024-06-11 22:01:27,299:INFO:               fugue: Not installed
2024-06-11 22:01:27,299:INFO:           streamlit: 1.35.0
2024-06-11 22:01:27,299:INFO:             prophet: Not installed
2024-06-11 22:01:27,299:INFO:None
2024-06-11 22:01:27,299:INFO:Set up data.
2024-06-11 22:01:27,336:INFO:Set up folding strategy.
2024-06-11 22:01:27,336:INFO:Set up train/test split.
2024-06-11 22:01:27,369:INFO:Set up index.
2024-06-11 22:01:27,371:INFO:Assigning column types.
2024-06-11 22:01:27,383:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 22:01:27,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:01:27,425:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:01:27,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:01:27,494:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:01:27,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,522:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 22:01:27,565:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:01:27,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,634:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:01:27,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,661:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 22:01:27,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:27,805:INFO:Preparing preprocessing pipeline...
2024-06-11 22:01:27,807:INFO:Set up date feature engineering.
2024-06-11 22:01:27,807:INFO:Set up simple imputation.
2024-06-11 22:01:27,818:INFO:Set up encoding of ordinal features.
2024-06-11 22:01:27,829:INFO:Set up encoding of categorical features.
2024-06-11 22:01:27,829:INFO:Set up imbalanced handling.
2024-06-11 22:01:27,829:INFO:Set up feature normalization.
2024-06-11 22:01:27,829:INFO:Set up PCA.
2024-06-11 22:01:29,980:INFO:Finished creating preprocessing pipeline.
2024-06-11 22:01:30,018:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-11 22:01:30,018:INFO:Creating final display dataframe.
2024-06-11 22:01:32,236:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (48823, 34)
5   Transformed train set shape       (33823, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method        TomekLinks
19                    Normalize              True
20             Normalize method            robust
21                          PCA              True
22                   PCA method            linear
23               PCA components              None
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              7737
2024-06-11 22:01:32,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:32,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:32,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:32,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:01:32,386:INFO:setup() successfully completed in 5.17s...............
2024-06-11 22:01:32,399:INFO:Initializing create_model()
2024-06-11 22:01:32,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:01:32,400:INFO:Checking exceptions
2024-06-11 22:01:32,413:INFO:Importing libraries
2024-06-11 22:01:32,413:INFO:Copying training dataset
2024-06-11 22:01:32,430:INFO:Defining folds
2024-06-11 22:01:32,430:INFO:Declaring metric variables
2024-06-11 22:01:32,433:INFO:Importing untrained model
2024-06-11 22:01:32,436:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:01:32,442:INFO:Starting cross validation
2024-06-11 22:01:32,445:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:01:39,438:INFO:Calculating mean and std
2024-06-11 22:01:39,439:INFO:Creating metrics dataframe
2024-06-11 22:01:39,445:INFO:Finalizing model
2024-06-11 22:01:41,595:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 31029
2024-06-11 22:01:41,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004476 seconds.
2024-06-11 22:01:41,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:01:41,601:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:01:41,601:INFO:[LightGBM] [Info] Number of data points in the train set: 33823, number of used features: 33
2024-06-11 22:01:41,602:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082607 -> initscore=-2.407448
2024-06-11 22:01:41,602:INFO:[LightGBM] [Info] Start training from score -2.407448
2024-06-11 22:01:41,789:INFO:Uploading results into container
2024-06-11 22:01:41,790:INFO:Uploading model into container now
2024-06-11 22:01:41,802:INFO:_master_model_container: 1
2024-06-11 22:01:41,802:INFO:_display_container: 2
2024-06-11 22:01:41,803:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:01:41,803:INFO:create_model() successfully completed......................................
2024-06-11 22:01:41,950:INFO:Initializing tune_model()
2024-06-11 22:01:41,950:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 22:01:41,951:INFO:Checking exceptions
2024-06-11 22:01:41,976:INFO:Copying training dataset
2024-06-11 22:01:41,990:INFO:Checking base model
2024-06-11 22:01:41,990:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 22:01:41,994:INFO:Declaring metric variables
2024-06-11 22:01:41,997:INFO:Defining Hyperparameters
2024-06-11 22:01:42,095:INFO:Tuning with n_jobs=-1
2024-06-11 22:01:42,095:INFO:Initializing RandomizedSearchCV
2024-06-11 22:03:39,219:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 22:03:39,220:INFO:Hyperparameter search completed
2024-06-11 22:03:39,220:INFO:SubProcess create_model() called ==================================
2024-06-11 22:03:39,222:INFO:Initializing create_model()
2024-06-11 22:03:39,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218A4871ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 22:03:39,222:INFO:Checking exceptions
2024-06-11 22:03:39,223:INFO:Importing libraries
2024-06-11 22:03:39,223:INFO:Copying training dataset
2024-06-11 22:03:39,258:INFO:Defining folds
2024-06-11 22:03:39,259:INFO:Declaring metric variables
2024-06-11 22:03:39,264:INFO:Importing untrained model
2024-06-11 22:03:39,264:INFO:Declaring custom model
2024-06-11 22:03:39,271:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:03:39,282:INFO:Starting cross validation
2024-06-11 22:03:39,288:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:03:51,202:INFO:Calculating mean and std
2024-06-11 22:03:51,204:INFO:Creating metrics dataframe
2024-06-11 22:03:51,214:INFO:Finalizing model
2024-06-11 22:03:53,855:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:03:53,855:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:03:53,855:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:03:53,913:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:03:53,913:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:03:53,914:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:03:53,914:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 31029
2024-06-11 22:03:53,918:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003262 seconds.
2024-06-11 22:03:53,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:03:53,919:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:03:53,920:INFO:[LightGBM] [Info] Number of data points in the train set: 33823, number of used features: 33
2024-06-11 22:03:53,922:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082607 -> initscore=-2.407448
2024-06-11 22:03:53,922:INFO:[LightGBM] [Info] Start training from score -2.407448
2024-06-11 22:03:53,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:53,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:53,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:03:54,906:INFO:Uploading results into container
2024-06-11 22:03:54,907:INFO:Uploading model into container now
2024-06-11 22:03:54,908:INFO:_master_model_container: 2
2024-06-11 22:03:54,908:INFO:_display_container: 3
2024-06-11 22:03:54,909:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:03:54,910:INFO:create_model() successfully completed......................................
2024-06-11 22:03:55,038:INFO:SubProcess create_model() end ==================================
2024-06-11 22:03:55,038:INFO:choose_better activated
2024-06-11 22:03:55,042:INFO:SubProcess create_model() called ==================================
2024-06-11 22:03:55,043:INFO:Initializing create_model()
2024-06-11 22:03:55,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:03:55,043:INFO:Checking exceptions
2024-06-11 22:03:55,044:INFO:Importing libraries
2024-06-11 22:03:55,044:INFO:Copying training dataset
2024-06-11 22:03:55,067:INFO:Defining folds
2024-06-11 22:03:55,067:INFO:Declaring metric variables
2024-06-11 22:03:55,067:INFO:Importing untrained model
2024-06-11 22:03:55,067:INFO:Declaring custom model
2024-06-11 22:03:55,068:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:03:55,068:INFO:Starting cross validation
2024-06-11 22:03:55,071:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:04:03,716:INFO:Calculating mean and std
2024-06-11 22:04:03,717:INFO:Creating metrics dataframe
2024-06-11 22:04:03,719:INFO:Finalizing model
2024-06-11 22:04:05,941:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 31029
2024-06-11 22:04:05,946:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003666 seconds.
2024-06-11 22:04:05,946:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:04:05,946:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:04:05,947:INFO:[LightGBM] [Info] Number of data points in the train set: 33823, number of used features: 33
2024-06-11 22:04:05,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082607 -> initscore=-2.407448
2024-06-11 22:04:05,948:INFO:[LightGBM] [Info] Start training from score -2.407448
2024-06-11 22:04:06,118:INFO:Uploading results into container
2024-06-11 22:04:06,119:INFO:Uploading model into container now
2024-06-11 22:04:06,120:INFO:_master_model_container: 3
2024-06-11 22:04:06,120:INFO:_display_container: 4
2024-06-11 22:04:06,120:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:04:06,120:INFO:create_model() successfully completed......................................
2024-06-11 22:04:06,229:INFO:SubProcess create_model() end ==================================
2024-06-11 22:04:06,229:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1235
2024-06-11 22:04:06,230:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1271
2024-06-11 22:04:06,230:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 22:04:06,230:INFO:choose_better completed
2024-06-11 22:04:06,239:INFO:_master_model_container: 3
2024-06-11 22:04:06,239:INFO:_display_container: 3
2024-06-11 22:04:06,239:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:04:06,240:INFO:tune_model() successfully completed......................................
2024-06-11 22:04:07,665:INFO:Initializing plot_model()
2024-06-11 22:04:07,665:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 22:04:07,665:INFO:Checking exceptions
2024-06-11 22:04:07,678:INFO:Preloading libraries
2024-06-11 22:04:07,740:INFO:Copying training dataset
2024-06-11 22:04:07,740:INFO:Plot type: auc
2024-06-11 22:04:07,940:INFO:Fitting Model
2024-06-11 22:04:07,941:INFO:Scoring test/hold-out set
2024-06-11 22:04:07,944:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:04:07,944:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:04:07,944:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:04:08,030:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:04:08,030:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:04:08,030:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:04:08,353:INFO:Visual Rendered Successfully
2024-06-11 22:04:08,444:INFO:plot_model() successfully completed......................................
2024-06-11 22:04:08,553:INFO:Initializing plot_model()
2024-06-11 22:04:08,553:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 22:04:08,553:INFO:Checking exceptions
2024-06-11 22:04:08,563:INFO:Preloading libraries
2024-06-11 22:04:08,595:INFO:Copying training dataset
2024-06-11 22:04:08,595:INFO:Plot type: confusion_matrix
2024-06-11 22:04:08,776:INFO:Fitting Model
2024-06-11 22:04:08,776:INFO:Scoring test/hold-out set
2024-06-11 22:04:08,778:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:04:08,778:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:04:08,778:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:04:08,830:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:04:08,830:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:04:08,830:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:04:09,046:INFO:Visual Rendered Successfully
2024-06-11 22:04:09,132:INFO:plot_model() successfully completed......................................
2024-06-11 22:04:09,153:INFO:Initializing finalize_model()
2024-06-11 22:04:09,153:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 22:04:09,154:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:04:09,165:INFO:Initializing create_model()
2024-06-11 22:04:09,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:04:09,165:INFO:Checking exceptions
2024-06-11 22:04:09,166:INFO:Importing libraries
2024-06-11 22:04:09,166:INFO:Copying training dataset
2024-06-11 22:04:09,167:INFO:Defining folds
2024-06-11 22:04:09,167:INFO:Declaring metric variables
2024-06-11 22:04:09,167:INFO:Importing untrained model
2024-06-11 22:04:09,167:INFO:Declaring custom model
2024-06-11 22:04:09,168:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:04:09,170:INFO:Cross validation set to False
2024-06-11 22:04:09,170:INFO:Fitting Model
2024-06-11 22:04:13,082:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:04:13,082:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:04:13,082:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:04:13,153:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:04:13,153:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:04:13,153:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:04:13,153:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 44479
2024-06-11 22:04:13,158:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003523 seconds.
2024-06-11 22:04:13,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:04:13,158:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:04:13,159:INFO:[LightGBM] [Info] Number of data points in the train set: 48470, number of used features: 33
2024-06-11 22:04:13,161:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082340 -> initscore=-2.410975
2024-06-11 22:04:13,161:INFO:[LightGBM] [Info] Start training from score -2.410975
2024-06-11 22:04:13,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:13,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:04:14,091:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 22:04:14,091:INFO:create_model() successfully completed......................................
2024-06-11 22:04:14,188:INFO:_master_model_container: 3
2024-06-11 22:04:14,188:INFO:_display_container: 3
2024-06-11 22:04:14,224:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 22:04:14,224:INFO:finalize_model() successfully completed......................................
2024-06-11 22:04:14,443:INFO:Initializing evaluate_model()
2024-06-11 22:04:14,443:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 22:04:14,491:INFO:Initializing plot_model()
2024-06-11 22:04:14,491:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 22:04:14,491:INFO:Checking exceptions
2024-06-11 22:04:14,498:INFO:Preloading libraries
2024-06-11 22:04:14,536:INFO:Copying training dataset
2024-06-11 22:04:14,537:INFO:Plot type: pipeline
2024-06-11 22:04:14,772:INFO:Visual Rendered Successfully
2024-06-11 22:04:14,859:INFO:plot_model() successfully completed......................................
2024-06-11 22:04:16,371:INFO:Initializing plot_model()
2024-06-11 22:04:16,371:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A89A31D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 22:04:16,371:INFO:Checking exceptions
2024-06-11 22:04:16,377:INFO:Preloading libraries
2024-06-11 22:04:16,418:INFO:Copying training dataset
2024-06-11 22:04:16,418:INFO:Plot type: confusion_matrix
2024-06-11 22:04:16,600:INFO:Fitting Model
2024-06-11 22:04:16,601:INFO:Scoring test/hold-out set
2024-06-11 22:04:16,603:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:04:16,603:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:04:16,603:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:04:16,665:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:04:16,665:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:04:16,666:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:04:16,862:INFO:Visual Rendered Successfully
2024-06-11 22:04:16,953:INFO:plot_model() successfully completed......................................
2024-06-11 22:04:41,740:INFO:PyCaret ClassificationExperiment
2024-06-11 22:04:41,740:INFO:Logging name: clf-default-name
2024-06-11 22:04:41,740:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:04:41,740:INFO:version 3.3.2
2024-06-11 22:04:41,740:INFO:Initializing setup()
2024-06-11 22:04:41,741:INFO:self.USI: cafb
2024-06-11 22:04:41,741:INFO:self._variable_keys: {'idx', 'gpu_param', 'y_train', 'data', 'exp_name_log', 'seed', '_available_plots', 'fix_imbalance', 'is_multiclass', '_ml_usecase', 'html_param', 'n_jobs_param', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_n_jobs_param', 'log_plots_param', 'pipeline', 'USI', 'memory', 'logging_param', 'fold_generator', 'X', 'y_test', 'y', 'fold_shuffle_param', 'X_train', 'X_test'}
2024-06-11 22:04:41,741:INFO:Checking environment
2024-06-11 22:04:41,741:INFO:python_version: 3.11.9
2024-06-11 22:04:41,741:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:04:41,741:INFO:machine: AMD64
2024-06-11 22:04:41,741:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:04:41,741:INFO:Memory: svmem(total=34056318976, available=23114637312, percent=32.1, used=10941681664, free=23114637312)
2024-06-11 22:04:41,741:INFO:Physical Core: 6
2024-06-11 22:04:41,741:INFO:Logical Core: 12
2024-06-11 22:04:41,741:INFO:Checking libraries
2024-06-11 22:04:41,741:INFO:System:
2024-06-11 22:04:41,741:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:04:41,741:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:04:41,741:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:04:41,741:INFO:PyCaret required dependencies:
2024-06-11 22:04:41,742:INFO:                 pip: 24.0
2024-06-11 22:04:41,742:INFO:          setuptools: 69.5.1
2024-06-11 22:04:41,742:INFO:             pycaret: 3.3.2
2024-06-11 22:04:41,742:INFO:             IPython: 8.25.0
2024-06-11 22:04:41,742:INFO:          ipywidgets: 8.1.3
2024-06-11 22:04:41,742:INFO:                tqdm: 4.66.4
2024-06-11 22:04:41,742:INFO:               numpy: 1.26.4
2024-06-11 22:04:41,742:INFO:              pandas: 2.1.4
2024-06-11 22:04:41,742:INFO:              jinja2: 3.1.4
2024-06-11 22:04:41,742:INFO:               scipy: 1.11.4
2024-06-11 22:04:41,742:INFO:              joblib: 1.3.2
2024-06-11 22:04:41,742:INFO:             sklearn: 1.4.2
2024-06-11 22:04:41,742:INFO:                pyod: 2.0.0
2024-06-11 22:04:41,742:INFO:            imblearn: 0.12.3
2024-06-11 22:04:41,742:INFO:   category_encoders: 2.6.3
2024-06-11 22:04:41,742:INFO:            lightgbm: 4.3.0
2024-06-11 22:04:41,742:INFO:               numba: 0.59.1
2024-06-11 22:04:41,743:INFO:            requests: 2.32.3
2024-06-11 22:04:41,743:INFO:          matplotlib: 3.7.5
2024-06-11 22:04:41,743:INFO:          scikitplot: 0.3.7
2024-06-11 22:04:41,743:INFO:         yellowbrick: 1.5
2024-06-11 22:04:41,743:INFO:              plotly: 5.22.0
2024-06-11 22:04:41,743:INFO:    plotly-resampler: Not installed
2024-06-11 22:04:41,743:INFO:             kaleido: 0.2.1
2024-06-11 22:04:41,743:INFO:           schemdraw: 0.15
2024-06-11 22:04:41,743:INFO:         statsmodels: 0.14.2
2024-06-11 22:04:41,743:INFO:              sktime: 0.26.0
2024-06-11 22:04:41,743:INFO:               tbats: 1.1.3
2024-06-11 22:04:41,743:INFO:            pmdarima: 2.0.4
2024-06-11 22:04:41,743:INFO:              psutil: 5.9.8
2024-06-11 22:04:41,743:INFO:          markupsafe: 2.1.5
2024-06-11 22:04:41,743:INFO:             pickle5: Not installed
2024-06-11 22:04:41,743:INFO:         cloudpickle: 3.0.0
2024-06-11 22:04:41,743:INFO:         deprecation: 2.1.0
2024-06-11 22:04:41,743:INFO:              xxhash: 3.4.1
2024-06-11 22:04:41,743:INFO:           wurlitzer: Not installed
2024-06-11 22:04:41,743:INFO:PyCaret optional dependencies:
2024-06-11 22:04:41,744:INFO:                shap: Not installed
2024-06-11 22:04:41,744:INFO:           interpret: Not installed
2024-06-11 22:04:41,744:INFO:                umap: Not installed
2024-06-11 22:04:41,744:INFO:     ydata_profiling: Not installed
2024-06-11 22:04:41,744:INFO:  explainerdashboard: Not installed
2024-06-11 22:04:41,744:INFO:             autoviz: Not installed
2024-06-11 22:04:41,744:INFO:           fairlearn: Not installed
2024-06-11 22:04:41,744:INFO:          deepchecks: Not installed
2024-06-11 22:04:41,744:INFO:             xgboost: Not installed
2024-06-11 22:04:41,744:INFO:            catboost: Not installed
2024-06-11 22:04:41,744:INFO:              kmodes: Not installed
2024-06-11 22:04:41,744:INFO:             mlxtend: Not installed
2024-06-11 22:04:41,744:INFO:       statsforecast: Not installed
2024-06-11 22:04:41,744:INFO:        tune_sklearn: Not installed
2024-06-11 22:04:41,744:INFO:                 ray: Not installed
2024-06-11 22:04:41,744:INFO:            hyperopt: Not installed
2024-06-11 22:04:41,744:INFO:              optuna: Not installed
2024-06-11 22:04:41,744:INFO:               skopt: Not installed
2024-06-11 22:04:41,744:INFO:              mlflow: Not installed
2024-06-11 22:04:41,745:INFO:              gradio: Not installed
2024-06-11 22:04:41,745:INFO:             fastapi: Not installed
2024-06-11 22:04:41,745:INFO:             uvicorn: Not installed
2024-06-11 22:04:41,745:INFO:              m2cgen: Not installed
2024-06-11 22:04:41,745:INFO:           evidently: Not installed
2024-06-11 22:04:41,745:INFO:               fugue: Not installed
2024-06-11 22:04:41,745:INFO:           streamlit: 1.35.0
2024-06-11 22:04:41,745:INFO:             prophet: Not installed
2024-06-11 22:04:41,745:INFO:None
2024-06-11 22:04:41,745:INFO:Set up data.
2024-06-11 22:04:41,790:INFO:Set up folding strategy.
2024-06-11 22:04:41,790:INFO:Set up train/test split.
2024-06-11 22:04:41,818:INFO:Set up index.
2024-06-11 22:04:41,820:INFO:Assigning column types.
2024-06-11 22:04:41,830:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 22:04:41,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:04:41,873:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:04:41,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:41,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:41,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:04:41,954:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:04:41,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:41,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:41,984:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 22:04:42,031:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:04:42,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:42,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:42,107:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:04:42,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:42,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:42,135:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 22:04:42,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:42,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:42,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:42,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:42,343:INFO:Preparing preprocessing pipeline...
2024-06-11 22:04:42,347:INFO:Set up date feature engineering.
2024-06-11 22:04:42,347:INFO:Set up simple imputation.
2024-06-11 22:04:42,366:INFO:Set up encoding of ordinal features.
2024-06-11 22:04:42,379:INFO:Set up encoding of categorical features.
2024-06-11 22:04:42,379:INFO:Set up removing outliers.
2024-06-11 22:04:42,379:INFO:Set up imbalanced handling.
2024-06-11 22:04:42,379:INFO:Set up feature normalization.
2024-06-11 22:04:42,379:INFO:Set up PCA.
2024-06-11 22:04:42,874:INFO:Finished creating preprocessing pipeline.
2024-06-11 22:04:42,911:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-11 22:04:42,911:INFO:Creating final display dataframe.
2024-06-11 22:04:43,059:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (47137, 34)
5   Transformed train set shape       (32137, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method        TomekLinks
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method            linear
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              cafb
2024-06-11 22:04:43,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:43,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:43,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:43,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:04:43,215:INFO:setup() successfully completed in 1.56s...............
2024-06-11 22:04:43,227:INFO:Initializing create_model()
2024-06-11 22:04:43,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:04:43,228:INFO:Checking exceptions
2024-06-11 22:04:43,240:INFO:Importing libraries
2024-06-11 22:04:43,241:INFO:Copying training dataset
2024-06-11 22:04:43,269:INFO:Defining folds
2024-06-11 22:04:43,269:INFO:Declaring metric variables
2024-06-11 22:04:43,272:INFO:Importing untrained model
2024-06-11 22:04:43,275:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:04:43,282:INFO:Starting cross validation
2024-06-11 22:04:43,284:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:04:50,795:INFO:Calculating mean and std
2024-06-11 22:04:50,796:INFO:Creating metrics dataframe
2024-06-11 22:04:50,803:INFO:Finalizing model
2024-06-11 22:04:53,331:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-11 22:04:53,335:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003603 seconds.
2024-06-11 22:04:53,335:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:04:53,336:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:04:53,337:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-11 22:04:53,337:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-11 22:04:53,337:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-11 22:04:53,515:INFO:Uploading results into container
2024-06-11 22:04:53,516:INFO:Uploading model into container now
2024-06-11 22:04:53,528:INFO:_master_model_container: 1
2024-06-11 22:04:53,528:INFO:_display_container: 2
2024-06-11 22:04:53,529:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:04:53,529:INFO:create_model() successfully completed......................................
2024-06-11 22:04:53,742:INFO:Initializing tune_model()
2024-06-11 22:04:53,742:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 22:04:53,743:INFO:Checking exceptions
2024-06-11 22:04:53,770:INFO:Copying training dataset
2024-06-11 22:04:53,785:INFO:Checking base model
2024-06-11 22:04:53,785:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 22:04:53,789:INFO:Declaring metric variables
2024-06-11 22:04:53,795:INFO:Defining Hyperparameters
2024-06-11 22:04:53,912:INFO:Tuning with n_jobs=-1
2024-06-11 22:04:53,912:INFO:Initializing RandomizedSearchCV
2024-06-11 22:06:54,882:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 22:06:54,883:INFO:Hyperparameter search completed
2024-06-11 22:06:54,883:INFO:SubProcess create_model() called ==================================
2024-06-11 22:06:54,885:INFO:Initializing create_model()
2024-06-11 22:06:54,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218A48783D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 22:06:54,885:INFO:Checking exceptions
2024-06-11 22:06:54,885:INFO:Importing libraries
2024-06-11 22:06:54,885:INFO:Copying training dataset
2024-06-11 22:06:54,919:INFO:Defining folds
2024-06-11 22:06:54,920:INFO:Declaring metric variables
2024-06-11 22:06:54,924:INFO:Importing untrained model
2024-06-11 22:06:54,925:INFO:Declaring custom model
2024-06-11 22:06:54,930:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:06:54,941:INFO:Starting cross validation
2024-06-11 22:06:54,946:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:07:05,351:INFO:Calculating mean and std
2024-06-11 22:07:05,353:INFO:Creating metrics dataframe
2024-06-11 22:07:05,361:INFO:Finalizing model
2024-06-11 22:07:08,293:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:07:08,294:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:07:08,294:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:07:08,346:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:07:08,346:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:07:08,346:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:07:08,346:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-11 22:07:08,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003415 seconds.
2024-06-11 22:07:08,351:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:07:08,351:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:07:08,353:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-11 22:07:08,354:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-11 22:07:08,354:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-11 22:07:08,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:08,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:09,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:09,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:09,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:09,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:09,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:09,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:07:09,071:INFO:Uploading results into container
2024-06-11 22:07:09,073:INFO:Uploading model into container now
2024-06-11 22:07:09,073:INFO:_master_model_container: 2
2024-06-11 22:07:09,074:INFO:_display_container: 3
2024-06-11 22:07:09,075:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:07:09,075:INFO:create_model() successfully completed......................................
2024-06-11 22:07:09,200:INFO:SubProcess create_model() end ==================================
2024-06-11 22:07:09,200:INFO:choose_better activated
2024-06-11 22:07:09,204:INFO:SubProcess create_model() called ==================================
2024-06-11 22:07:09,205:INFO:Initializing create_model()
2024-06-11 22:07:09,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:07:09,205:INFO:Checking exceptions
2024-06-11 22:07:09,207:INFO:Importing libraries
2024-06-11 22:07:09,207:INFO:Copying training dataset
2024-06-11 22:07:09,229:INFO:Defining folds
2024-06-11 22:07:09,230:INFO:Declaring metric variables
2024-06-11 22:07:09,230:INFO:Importing untrained model
2024-06-11 22:07:09,230:INFO:Declaring custom model
2024-06-11 22:07:09,231:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:07:09,232:INFO:Starting cross validation
2024-06-11 22:07:09,236:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:07:17,422:INFO:Calculating mean and std
2024-06-11 22:07:17,423:INFO:Creating metrics dataframe
2024-06-11 22:07:17,425:INFO:Finalizing model
2024-06-11 22:07:20,014:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-11 22:07:20,019:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004309 seconds.
2024-06-11 22:07:20,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:07:20,020:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:07:20,021:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-11 22:07:20,021:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-11 22:07:20,021:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-11 22:07:20,362:INFO:Uploading results into container
2024-06-11 22:07:20,363:INFO:Uploading model into container now
2024-06-11 22:07:20,363:INFO:_master_model_container: 3
2024-06-11 22:07:20,363:INFO:_display_container: 4
2024-06-11 22:07:20,364:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:07:20,364:INFO:create_model() successfully completed......................................
2024-06-11 22:07:20,483:INFO:SubProcess create_model() end ==================================
2024-06-11 22:07:20,483:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1202
2024-06-11 22:07:20,484:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1145
2024-06-11 22:07:20,484:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 22:07:20,485:INFO:choose_better completed
2024-06-11 22:07:20,485:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-11 22:07:20,494:INFO:_master_model_container: 3
2024-06-11 22:07:20,494:INFO:_display_container: 3
2024-06-11 22:07:20,495:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:07:20,495:INFO:tune_model() successfully completed......................................
2024-06-11 22:07:20,614:INFO:Initializing plot_model()
2024-06-11 22:07:20,614:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 22:07:20,615:INFO:Checking exceptions
2024-06-11 22:07:20,633:INFO:Preloading libraries
2024-06-11 22:07:20,657:INFO:Copying training dataset
2024-06-11 22:07:20,657:INFO:Plot type: auc
2024-06-11 22:07:20,868:INFO:Fitting Model
2024-06-11 22:07:20,869:INFO:Scoring test/hold-out set
2024-06-11 22:07:21,151:INFO:Visual Rendered Successfully
2024-06-11 22:07:21,242:INFO:plot_model() successfully completed......................................
2024-06-11 22:07:21,265:INFO:Initializing plot_model()
2024-06-11 22:07:21,265:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 22:07:21,265:INFO:Checking exceptions
2024-06-11 22:07:21,277:INFO:Preloading libraries
2024-06-11 22:07:21,283:INFO:Copying training dataset
2024-06-11 22:07:21,283:INFO:Plot type: confusion_matrix
2024-06-11 22:07:21,477:INFO:Fitting Model
2024-06-11 22:07:21,477:INFO:Scoring test/hold-out set
2024-06-11 22:07:21,661:INFO:Visual Rendered Successfully
2024-06-11 22:07:21,753:INFO:plot_model() successfully completed......................................
2024-06-11 22:07:21,767:INFO:Initializing finalize_model()
2024-06-11 22:07:21,768:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 22:07:21,768:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:07:21,777:INFO:Initializing create_model()
2024-06-11 22:07:21,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:07:21,778:INFO:Checking exceptions
2024-06-11 22:07:21,779:INFO:Importing libraries
2024-06-11 22:07:21,779:INFO:Copying training dataset
2024-06-11 22:07:21,780:INFO:Defining folds
2024-06-11 22:07:21,780:INFO:Declaring metric variables
2024-06-11 22:07:21,780:INFO:Importing untrained model
2024-06-11 22:07:21,780:INFO:Declaring custom model
2024-06-11 22:07:21,780:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:07:21,782:INFO:Cross validation set to False
2024-06-11 22:07:21,782:INFO:Fitting Model
2024-06-11 22:07:26,310:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 42323
2024-06-11 22:07:26,317:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005764 seconds.
2024-06-11 22:07:26,317:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:07:26,317:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:07:26,318:INFO:[LightGBM] [Info] Number of data points in the train set: 46075, number of used features: 33
2024-06-11 22:07:26,319:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081432 -> initscore=-2.423042
2024-06-11 22:07:26,319:INFO:[LightGBM] [Info] Start training from score -2.423042
2024-06-11 22:07:26,642:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 22:07:26,642:INFO:create_model() successfully completed......................................
2024-06-11 22:07:26,743:INFO:_master_model_container: 3
2024-06-11 22:07:26,743:INFO:_display_container: 3
2024-06-11 22:07:26,781:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 22:07:26,781:INFO:finalize_model() successfully completed......................................
2024-06-11 22:07:26,975:INFO:Initializing evaluate_model()
2024-06-11 22:07:26,975:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 22:07:27,029:INFO:Initializing plot_model()
2024-06-11 22:07:27,030:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 22:07:27,030:INFO:Checking exceptions
2024-06-11 22:07:27,036:INFO:Preloading libraries
2024-06-11 22:07:27,043:INFO:Copying training dataset
2024-06-11 22:07:27,044:INFO:Plot type: pipeline
2024-06-11 22:07:27,309:INFO:Visual Rendered Successfully
2024-06-11 22:07:27,392:INFO:plot_model() successfully completed......................................
2024-06-11 22:07:46,374:INFO:Initializing plot_model()
2024-06-11 22:07:46,374:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 22:07:46,374:INFO:Checking exceptions
2024-06-11 22:07:46,380:INFO:Preloading libraries
2024-06-11 22:07:46,385:INFO:Copying training dataset
2024-06-11 22:07:46,386:INFO:Plot type: confusion_matrix
2024-06-11 22:07:46,563:INFO:Fitting Model
2024-06-11 22:07:46,563:INFO:Scoring test/hold-out set
2024-06-11 22:07:46,729:INFO:Visual Rendered Successfully
2024-06-11 22:07:46,821:INFO:plot_model() successfully completed......................................
2024-06-11 22:08:12,360:INFO:Initializing plot_model()
2024-06-11 22:08:12,360:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 22:08:12,360:INFO:Checking exceptions
2024-06-11 22:08:12,366:INFO:Preloading libraries
2024-06-11 22:08:12,373:INFO:Copying training dataset
2024-06-11 22:08:12,374:INFO:Plot type: auc
2024-06-11 22:08:12,562:INFO:Fitting Model
2024-06-11 22:08:12,563:INFO:Scoring test/hold-out set
2024-06-11 22:08:12,820:INFO:Visual Rendered Successfully
2024-06-11 22:08:12,925:INFO:plot_model() successfully completed......................................
2024-06-11 22:08:33,073:INFO:Initializing plot_model()
2024-06-11 22:08:33,073:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A894B950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 22:08:33,073:INFO:Checking exceptions
2024-06-11 22:08:33,080:INFO:Preloading libraries
2024-06-11 22:08:33,088:INFO:Copying training dataset
2024-06-11 22:08:33,088:INFO:Plot type: confusion_matrix
2024-06-11 22:08:33,274:INFO:Fitting Model
2024-06-11 22:08:33,275:INFO:Scoring test/hold-out set
2024-06-11 22:08:33,441:INFO:Visual Rendered Successfully
2024-06-11 22:08:33,526:INFO:plot_model() successfully completed......................................
2024-06-11 22:09:21,298:INFO:PyCaret ClassificationExperiment
2024-06-11 22:09:21,299:INFO:Logging name: clf-default-name
2024-06-11 22:09:21,299:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:09:21,299:INFO:version 3.3.2
2024-06-11 22:09:21,299:INFO:Initializing setup()
2024-06-11 22:09:21,299:INFO:self.USI: cdca
2024-06-11 22:09:21,299:INFO:self._variable_keys: {'idx', 'gpu_param', 'y_train', 'data', 'exp_name_log', 'seed', '_available_plots', 'fix_imbalance', 'is_multiclass', '_ml_usecase', 'html_param', 'n_jobs_param', 'target_param', 'exp_id', 'fold_groups_param', 'gpu_n_jobs_param', 'log_plots_param', 'pipeline', 'USI', 'memory', 'logging_param', 'fold_generator', 'X', 'y_test', 'y', 'fold_shuffle_param', 'X_train', 'X_test'}
2024-06-11 22:09:21,299:INFO:Checking environment
2024-06-11 22:09:21,300:INFO:python_version: 3.11.9
2024-06-11 22:09:21,300:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:09:21,300:INFO:machine: AMD64
2024-06-11 22:09:21,300:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:09:21,300:INFO:Memory: svmem(total=34056318976, available=23002390528, percent=32.5, used=11053928448, free=23002390528)
2024-06-11 22:09:21,301:INFO:Physical Core: 6
2024-06-11 22:09:21,301:INFO:Logical Core: 12
2024-06-11 22:09:21,301:INFO:Checking libraries
2024-06-11 22:09:21,301:INFO:System:
2024-06-11 22:09:21,301:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:09:21,301:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:09:21,301:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:09:21,301:INFO:PyCaret required dependencies:
2024-06-11 22:09:21,301:INFO:                 pip: 24.0
2024-06-11 22:09:21,302:INFO:          setuptools: 69.5.1
2024-06-11 22:09:21,302:INFO:             pycaret: 3.3.2
2024-06-11 22:09:21,302:INFO:             IPython: 8.25.0
2024-06-11 22:09:21,302:INFO:          ipywidgets: 8.1.3
2024-06-11 22:09:21,302:INFO:                tqdm: 4.66.4
2024-06-11 22:09:21,302:INFO:               numpy: 1.26.4
2024-06-11 22:09:21,302:INFO:              pandas: 2.1.4
2024-06-11 22:09:21,302:INFO:              jinja2: 3.1.4
2024-06-11 22:09:21,302:INFO:               scipy: 1.11.4
2024-06-11 22:09:21,302:INFO:              joblib: 1.3.2
2024-06-11 22:09:21,302:INFO:             sklearn: 1.4.2
2024-06-11 22:09:21,303:INFO:                pyod: 2.0.0
2024-06-11 22:09:21,303:INFO:            imblearn: 0.12.3
2024-06-11 22:09:21,303:INFO:   category_encoders: 2.6.3
2024-06-11 22:09:21,303:INFO:            lightgbm: 4.3.0
2024-06-11 22:09:21,303:INFO:               numba: 0.59.1
2024-06-11 22:09:21,303:INFO:            requests: 2.32.3
2024-06-11 22:09:21,303:INFO:          matplotlib: 3.7.5
2024-06-11 22:09:21,303:INFO:          scikitplot: 0.3.7
2024-06-11 22:09:21,303:INFO:         yellowbrick: 1.5
2024-06-11 22:09:21,304:INFO:              plotly: 5.22.0
2024-06-11 22:09:21,304:INFO:    plotly-resampler: Not installed
2024-06-11 22:09:21,304:INFO:             kaleido: 0.2.1
2024-06-11 22:09:21,304:INFO:           schemdraw: 0.15
2024-06-11 22:09:21,304:INFO:         statsmodels: 0.14.2
2024-06-11 22:09:21,304:INFO:              sktime: 0.26.0
2024-06-11 22:09:21,304:INFO:               tbats: 1.1.3
2024-06-11 22:09:21,304:INFO:            pmdarima: 2.0.4
2024-06-11 22:09:21,304:INFO:              psutil: 5.9.8
2024-06-11 22:09:21,305:INFO:          markupsafe: 2.1.5
2024-06-11 22:09:21,305:INFO:             pickle5: Not installed
2024-06-11 22:09:21,305:INFO:         cloudpickle: 3.0.0
2024-06-11 22:09:21,305:INFO:         deprecation: 2.1.0
2024-06-11 22:09:21,305:INFO:              xxhash: 3.4.1
2024-06-11 22:09:21,305:INFO:           wurlitzer: Not installed
2024-06-11 22:09:21,305:INFO:PyCaret optional dependencies:
2024-06-11 22:09:21,305:INFO:                shap: Not installed
2024-06-11 22:09:21,305:INFO:           interpret: Not installed
2024-06-11 22:09:21,305:INFO:                umap: Not installed
2024-06-11 22:09:21,305:INFO:     ydata_profiling: Not installed
2024-06-11 22:09:21,306:INFO:  explainerdashboard: Not installed
2024-06-11 22:09:21,306:INFO:             autoviz: Not installed
2024-06-11 22:09:21,306:INFO:           fairlearn: Not installed
2024-06-11 22:09:21,306:INFO:          deepchecks: Not installed
2024-06-11 22:09:21,306:INFO:             xgboost: Not installed
2024-06-11 22:09:21,306:INFO:            catboost: Not installed
2024-06-11 22:09:21,306:INFO:              kmodes: Not installed
2024-06-11 22:09:21,306:INFO:             mlxtend: Not installed
2024-06-11 22:09:21,306:INFO:       statsforecast: Not installed
2024-06-11 22:09:21,306:INFO:        tune_sklearn: Not installed
2024-06-11 22:09:21,307:INFO:                 ray: Not installed
2024-06-11 22:09:21,307:INFO:            hyperopt: Not installed
2024-06-11 22:09:21,307:INFO:              optuna: Not installed
2024-06-11 22:09:21,307:INFO:               skopt: Not installed
2024-06-11 22:09:21,307:INFO:              mlflow: Not installed
2024-06-11 22:09:21,307:INFO:              gradio: Not installed
2024-06-11 22:09:21,307:INFO:             fastapi: Not installed
2024-06-11 22:09:21,307:INFO:             uvicorn: Not installed
2024-06-11 22:09:21,307:INFO:              m2cgen: Not installed
2024-06-11 22:09:21,307:INFO:           evidently: Not installed
2024-06-11 22:09:21,307:INFO:               fugue: Not installed
2024-06-11 22:09:21,307:INFO:           streamlit: 1.35.0
2024-06-11 22:09:21,307:INFO:             prophet: Not installed
2024-06-11 22:09:21,308:INFO:None
2024-06-11 22:09:21,308:INFO:Set up data.
2024-06-11 22:09:21,352:INFO:Set up folding strategy.
2024-06-11 22:09:21,352:INFO:Set up train/test split.
2024-06-11 22:09:21,376:INFO:Set up index.
2024-06-11 22:09:21,378:INFO:Assigning column types.
2024-06-11 22:09:21,388:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 22:09:21,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:09:21,432:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:09:21,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:09:21,538:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:09:21,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,583:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 22:09:21,658:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:09:21,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,742:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:09:21,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,776:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 22:09:21,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:21,963:INFO:Preparing preprocessing pipeline...
2024-06-11 22:09:21,965:INFO:Set up date feature engineering.
2024-06-11 22:09:21,965:INFO:Set up simple imputation.
2024-06-11 22:09:21,992:INFO:Set up encoding of ordinal features.
2024-06-11 22:09:22,015:INFO:Set up encoding of categorical features.
2024-06-11 22:09:22,015:INFO:Set up removing outliers.
2024-06-11 22:09:22,015:INFO:Set up imbalanced handling.
2024-06-11 22:09:22,015:INFO:Set up feature normalization.
2024-06-11 22:09:22,015:INFO:Set up PCA.
2024-06-11 22:09:24,715:INFO:Finished creating preprocessing pipeline.
2024-06-11 22:09:24,748:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-11 22:09:24,748:INFO:Creating final display dataframe.
2024-06-11 22:09:28,155:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (47138, 34)
5   Transformed train set shape       (32138, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                 0
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method        TomekLinks
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method            linear
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              cdca
2024-06-11 22:09:28,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:28,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:28,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:28,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:09:28,301:INFO:setup() successfully completed in 7.12s...............
2024-06-11 22:09:28,316:INFO:Initializing create_model()
2024-06-11 22:09:28,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:09:28,317:INFO:Checking exceptions
2024-06-11 22:09:28,330:INFO:Importing libraries
2024-06-11 22:09:28,330:INFO:Copying training dataset
2024-06-11 22:09:28,348:INFO:Defining folds
2024-06-11 22:09:28,348:INFO:Declaring metric variables
2024-06-11 22:09:28,351:INFO:Importing untrained model
2024-06-11 22:09:28,354:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:09:28,360:INFO:Starting cross validation
2024-06-11 22:09:28,372:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:09:36,079:INFO:Calculating mean and std
2024-06-11 22:09:36,081:INFO:Creating metrics dataframe
2024-06-11 22:09:36,088:INFO:Finalizing model
2024-06-11 22:09:38,699:INFO:[LightGBM] [Info] Number of positive: 2636, number of negative: 29502
2024-06-11 22:09:38,702:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002594 seconds.
2024-06-11 22:09:38,702:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:09:38,702:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:09:38,703:INFO:[LightGBM] [Info] Number of data points in the train set: 32138, number of used features: 33
2024-06-11 22:09:38,703:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082021 -> initscore=-2.415195
2024-06-11 22:09:38,703:INFO:[LightGBM] [Info] Start training from score -2.415195
2024-06-11 22:09:39,004:INFO:Uploading results into container
2024-06-11 22:09:39,005:INFO:Uploading model into container now
2024-06-11 22:09:39,018:INFO:_master_model_container: 1
2024-06-11 22:09:39,019:INFO:_display_container: 2
2024-06-11 22:09:39,019:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:09:39,020:INFO:create_model() successfully completed......................................
2024-06-11 22:09:39,236:INFO:Initializing tune_model()
2024-06-11 22:09:39,236:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-11 22:09:39,236:INFO:Checking exceptions
2024-06-11 22:09:39,262:INFO:Copying training dataset
2024-06-11 22:09:39,274:INFO:Checking base model
2024-06-11 22:09:39,274:INFO:Base model : Light Gradient Boosting Machine
2024-06-11 22:09:39,277:INFO:Declaring metric variables
2024-06-11 22:09:39,280:INFO:Defining Hyperparameters
2024-06-11 22:09:39,391:INFO:Tuning with n_jobs=-1
2024-06-11 22:09:39,391:INFO:Initializing RandomizedSearchCV
2024-06-11 22:11:39,544:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-11 22:11:39,545:INFO:Hyperparameter search completed
2024-06-11 22:11:39,545:INFO:SubProcess create_model() called ==================================
2024-06-11 22:11:39,546:INFO:Initializing create_model()
2024-06-11 22:11:39,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218A8EFDBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-11 22:11:39,547:INFO:Checking exceptions
2024-06-11 22:11:39,547:INFO:Importing libraries
2024-06-11 22:11:39,547:INFO:Copying training dataset
2024-06-11 22:11:39,581:INFO:Defining folds
2024-06-11 22:11:39,581:INFO:Declaring metric variables
2024-06-11 22:11:39,588:INFO:Importing untrained model
2024-06-11 22:11:39,588:INFO:Declaring custom model
2024-06-11 22:11:39,594:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:11:39,605:INFO:Starting cross validation
2024-06-11 22:11:39,627:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:11:49,218:INFO:Calculating mean and std
2024-06-11 22:11:49,220:INFO:Creating metrics dataframe
2024-06-11 22:11:49,228:INFO:Finalizing model
2024-06-11 22:11:51,618:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:11:51,619:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:11:51,619:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:11:51,668:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:11:51,668:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:11:51,668:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:11:51,669:INFO:[LightGBM] [Info] Number of positive: 2636, number of negative: 29502
2024-06-11 22:11:51,672:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002335 seconds.
2024-06-11 22:11:51,672:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:11:51,672:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:11:51,673:INFO:[LightGBM] [Info] Number of data points in the train set: 32138, number of used features: 33
2024-06-11 22:11:51,674:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082021 -> initscore=-2.415195
2024-06-11 22:11:51,674:INFO:[LightGBM] [Info] Start training from score -2.415195
2024-06-11 22:11:51,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:11:52,269:INFO:Uploading results into container
2024-06-11 22:11:52,270:INFO:Uploading model into container now
2024-06-11 22:11:52,271:INFO:_master_model_container: 2
2024-06-11 22:11:52,271:INFO:_display_container: 3
2024-06-11 22:11:52,273:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:11:52,273:INFO:create_model() successfully completed......................................
2024-06-11 22:11:52,392:INFO:SubProcess create_model() end ==================================
2024-06-11 22:11:52,392:INFO:choose_better activated
2024-06-11 22:11:52,396:INFO:SubProcess create_model() called ==================================
2024-06-11 22:11:52,397:INFO:Initializing create_model()
2024-06-11 22:11:52,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:11:52,397:INFO:Checking exceptions
2024-06-11 22:11:52,399:INFO:Importing libraries
2024-06-11 22:11:52,399:INFO:Copying training dataset
2024-06-11 22:11:52,419:INFO:Defining folds
2024-06-11 22:11:52,419:INFO:Declaring metric variables
2024-06-11 22:11:52,419:INFO:Importing untrained model
2024-06-11 22:11:52,419:INFO:Declaring custom model
2024-06-11 22:11:52,420:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:11:52,420:INFO:Starting cross validation
2024-06-11 22:11:52,431:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:11:59,999:INFO:Calculating mean and std
2024-06-11 22:12:00,000:INFO:Creating metrics dataframe
2024-06-11 22:12:00,003:INFO:Finalizing model
2024-06-11 22:12:02,388:INFO:[LightGBM] [Info] Number of positive: 2636, number of negative: 29502
2024-06-11 22:12:02,391:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002683 seconds.
2024-06-11 22:12:02,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:12:02,392:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:12:02,392:INFO:[LightGBM] [Info] Number of data points in the train set: 32138, number of used features: 33
2024-06-11 22:12:02,393:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082021 -> initscore=-2.415195
2024-06-11 22:12:02,394:INFO:[LightGBM] [Info] Start training from score -2.415195
2024-06-11 22:12:02,566:INFO:Uploading results into container
2024-06-11 22:12:02,567:INFO:Uploading model into container now
2024-06-11 22:12:02,568:INFO:_master_model_container: 3
2024-06-11 22:12:02,568:INFO:_display_container: 4
2024-06-11 22:12:02,568:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:12:02,568:INFO:create_model() successfully completed......................................
2024-06-11 22:12:02,682:INFO:SubProcess create_model() end ==================================
2024-06-11 22:12:02,683:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1176
2024-06-11 22:12:02,683:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1321
2024-06-11 22:12:02,684:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-11 22:12:02,684:INFO:choose_better completed
2024-06-11 22:12:02,692:INFO:_master_model_container: 3
2024-06-11 22:12:02,692:INFO:_display_container: 3
2024-06-11 22:12:02,693:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:12:02,693:INFO:tune_model() successfully completed......................................
2024-06-11 22:12:03,880:INFO:Initializing plot_model()
2024-06-11 22:12:03,880:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 22:12:03,880:INFO:Checking exceptions
2024-06-11 22:12:03,889:INFO:Preloading libraries
2024-06-11 22:12:03,919:INFO:Copying training dataset
2024-06-11 22:12:03,919:INFO:Plot type: auc
2024-06-11 22:12:04,238:INFO:Fitting Model
2024-06-11 22:12:04,239:INFO:Scoring test/hold-out set
2024-06-11 22:12:04,241:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:12:04,241:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:12:04,241:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:12:04,290:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:12:04,290:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:12:04,290:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:12:04,555:INFO:Visual Rendered Successfully
2024-06-11 22:12:04,645:INFO:plot_model() successfully completed......................................
2024-06-11 22:12:04,674:INFO:Initializing plot_model()
2024-06-11 22:12:04,675:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-11 22:12:04,675:INFO:Checking exceptions
2024-06-11 22:12:04,687:INFO:Preloading libraries
2024-06-11 22:12:04,719:INFO:Copying training dataset
2024-06-11 22:12:04,719:INFO:Plot type: confusion_matrix
2024-06-11 22:12:05,039:INFO:Fitting Model
2024-06-11 22:12:05,040:INFO:Scoring test/hold-out set
2024-06-11 22:12:05,042:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:12:05,042:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:12:05,042:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:12:05,090:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:12:05,090:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:12:05,090:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:12:05,280:INFO:Visual Rendered Successfully
2024-06-11 22:12:05,371:INFO:plot_model() successfully completed......................................
2024-06-11 22:12:05,386:INFO:Initializing finalize_model()
2024-06-11 22:12:05,386:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-11 22:12:05,386:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:12:05,398:INFO:Initializing create_model()
2024-06-11 22:12:05,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:12:05,398:INFO:Checking exceptions
2024-06-11 22:12:05,399:INFO:Importing libraries
2024-06-11 22:12:05,399:INFO:Copying training dataset
2024-06-11 22:12:05,401:INFO:Defining folds
2024-06-11 22:12:05,401:INFO:Declaring metric variables
2024-06-11 22:12:05,401:INFO:Importing untrained model
2024-06-11 22:12:05,401:INFO:Declaring custom model
2024-06-11 22:12:05,402:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:12:05,411:INFO:Cross validation set to False
2024-06-11 22:12:05,411:INFO:Fitting Model
2024-06-11 22:12:09,283:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:12:09,283:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:12:09,283:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:12:09,338:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:12:09,338:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:12:09,338:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:12:09,338:INFO:[LightGBM] [Info] Number of positive: 3747, number of negative: 42323
2024-06-11 22:12:09,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002659 seconds.
2024-06-11 22:12:09,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-11 22:12:09,342:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-11 22:12:09,343:INFO:[LightGBM] [Info] Number of data points in the train set: 46070, number of used features: 33
2024-06-11 22:12:09,345:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081333 -> initscore=-2.424375
2024-06-11 22:12:09,345:INFO:[LightGBM] [Info] Start training from score -2.424375
2024-06-11 22:12:09,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:09,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-11 22:12:10,116:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 22:12:10,116:INFO:create_model() successfully completed......................................
2024-06-11 22:12:10,214:INFO:_master_model_container: 3
2024-06-11 22:12:10,214:INFO:_display_container: 3
2024-06-11 22:12:10,252:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-11 22:12:10,253:INFO:finalize_model() successfully completed......................................
2024-06-11 22:12:10,456:INFO:Initializing evaluate_model()
2024-06-11 22:12:10,456:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-11 22:12:10,506:INFO:Initializing plot_model()
2024-06-11 22:12:10,506:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 22:12:10,506:INFO:Checking exceptions
2024-06-11 22:12:10,513:INFO:Preloading libraries
2024-06-11 22:12:10,544:INFO:Copying training dataset
2024-06-11 22:12:10,545:INFO:Plot type: pipeline
2024-06-11 22:12:10,796:INFO:Visual Rendered Successfully
2024-06-11 22:12:10,885:INFO:plot_model() successfully completed......................................
2024-06-11 22:12:19,325:INFO:Initializing plot_model()
2024-06-11 22:12:19,326:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-11 22:12:19,326:INFO:Checking exceptions
2024-06-11 22:12:19,332:INFO:Preloading libraries
2024-06-11 22:12:19,368:INFO:Copying training dataset
2024-06-11 22:12:19,368:INFO:Plot type: confusion_matrix
2024-06-11 22:12:19,694:INFO:Fitting Model
2024-06-11 22:12:19,695:INFO:Scoring test/hold-out set
2024-06-11 22:12:19,697:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:12:19,697:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:12:19,697:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:12:19,751:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-11 22:12:19,751:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-11 22:12:19,751:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-11 22:12:19,936:INFO:Visual Rendered Successfully
2024-06-11 22:12:20,026:INFO:plot_model() successfully completed......................................
2024-06-11 22:20:45,415:INFO:Initializing predict_model()
2024-06-11 22:20:45,416:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000218C080EB60>)
2024-06-11 22:20:45,416:INFO:Checking exceptions
2024-06-11 22:20:45,416:INFO:Preloading libraries
2024-06-11 22:20:45,419:INFO:Set up data.
2024-06-11 22:20:45,853:INFO:Set up index.
2024-06-11 22:24:11,316:INFO:Initializing predict_model()
2024-06-11 22:24:11,316:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000218A9322CA0>)
2024-06-11 22:24:11,316:INFO:Checking exceptions
2024-06-11 22:24:11,316:INFO:Preloading libraries
2024-06-11 22:24:11,318:INFO:Set up data.
2024-06-11 22:24:11,329:INFO:Set up index.
2024-06-11 22:24:25,624:INFO:Initializing predict_model()
2024-06-11 22:24:25,624:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000218A9322340>)
2024-06-11 22:24:25,624:INFO:Checking exceptions
2024-06-11 22:24:25,624:INFO:Preloading libraries
2024-06-11 22:24:25,627:INFO:Set up data.
2024-06-11 22:24:25,667:INFO:Set up index.
2024-06-11 22:25:04,094:INFO:Initializing predict_model()
2024-06-11 22:25:04,094:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218A9A3A890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000218A9323100>)
2024-06-11 22:25:04,094:INFO:Checking exceptions
2024-06-11 22:25:04,094:INFO:Preloading libraries
2024-06-11 22:25:04,096:INFO:Set up data.
2024-06-11 22:25:04,111:INFO:Set up index.
2024-06-11 22:40:34,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:40:34,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:40:34,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:40:34,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:44:19,738:INFO:PyCaret ClassificationExperiment
2024-06-11 22:44:19,739:INFO:Logging name: clf-default-name
2024-06-11 22:44:19,739:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:44:19,739:INFO:version 3.3.2
2024-06-11 22:44:19,739:INFO:Initializing setup()
2024-06-11 22:44:19,740:INFO:self.USI: e816
2024-06-11 22:44:19,740:INFO:self._variable_keys: {'y', 'fix_imbalance', 'X_train', 'n_jobs_param', 'data', 'html_param', 'y_test', 'is_multiclass', 'X_test', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'logging_param', 'memory', 'gpu_param', 'target_param', 'pipeline', 'exp_id', 'idx', '_ml_usecase', 'y_train', 'fold_groups_param', 'log_plots_param', 'fold_shuffle_param', 'X', 'exp_name_log', '_available_plots', 'seed'}
2024-06-11 22:44:19,740:INFO:Checking environment
2024-06-11 22:44:19,740:INFO:python_version: 3.11.9
2024-06-11 22:44:19,740:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:44:19,740:INFO:machine: AMD64
2024-06-11 22:44:19,757:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:44:19,757:INFO:Memory: svmem(total=34056318976, available=23760269312, percent=30.2, used=10296049664, free=23760269312)
2024-06-11 22:44:19,757:INFO:Physical Core: 6
2024-06-11 22:44:19,757:INFO:Logical Core: 12
2024-06-11 22:44:19,757:INFO:Checking libraries
2024-06-11 22:44:19,757:INFO:System:
2024-06-11 22:44:19,757:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:44:19,757:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:44:19,757:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:44:19,757:INFO:PyCaret required dependencies:
2024-06-11 22:44:19,782:INFO:                 pip: 24.0
2024-06-11 22:44:19,782:INFO:          setuptools: 69.5.1
2024-06-11 22:44:19,782:INFO:             pycaret: 3.3.2
2024-06-11 22:44:19,782:INFO:             IPython: 8.25.0
2024-06-11 22:44:19,782:INFO:          ipywidgets: 8.1.3
2024-06-11 22:44:19,782:INFO:                tqdm: 4.66.4
2024-06-11 22:44:19,782:INFO:               numpy: 1.26.4
2024-06-11 22:44:19,782:INFO:              pandas: 2.1.4
2024-06-11 22:44:19,782:INFO:              jinja2: 3.1.4
2024-06-11 22:44:19,782:INFO:               scipy: 1.11.4
2024-06-11 22:44:19,782:INFO:              joblib: 1.3.2
2024-06-11 22:44:19,782:INFO:             sklearn: 1.4.2
2024-06-11 22:44:19,782:INFO:                pyod: 2.0.0
2024-06-11 22:44:19,782:INFO:            imblearn: 0.12.3
2024-06-11 22:44:19,782:INFO:   category_encoders: 2.6.3
2024-06-11 22:44:19,782:INFO:            lightgbm: 4.3.0
2024-06-11 22:44:19,783:INFO:               numba: 0.59.1
2024-06-11 22:44:19,783:INFO:            requests: 2.32.3
2024-06-11 22:44:19,783:INFO:          matplotlib: 3.7.5
2024-06-11 22:44:19,783:INFO:          scikitplot: 0.3.7
2024-06-11 22:44:19,783:INFO:         yellowbrick: 1.5
2024-06-11 22:44:19,783:INFO:              plotly: 5.22.0
2024-06-11 22:44:19,783:INFO:    plotly-resampler: Not installed
2024-06-11 22:44:19,783:INFO:             kaleido: 0.2.1
2024-06-11 22:44:19,783:INFO:           schemdraw: 0.15
2024-06-11 22:44:19,783:INFO:         statsmodels: 0.14.2
2024-06-11 22:44:19,783:INFO:              sktime: 0.26.0
2024-06-11 22:44:19,783:INFO:               tbats: 1.1.3
2024-06-11 22:44:19,783:INFO:            pmdarima: 2.0.4
2024-06-11 22:44:19,783:INFO:              psutil: 5.9.8
2024-06-11 22:44:19,783:INFO:          markupsafe: 2.1.5
2024-06-11 22:44:19,783:INFO:             pickle5: Not installed
2024-06-11 22:44:19,783:INFO:         cloudpickle: 3.0.0
2024-06-11 22:44:19,783:INFO:         deprecation: 2.1.0
2024-06-11 22:44:19,783:INFO:              xxhash: 3.4.1
2024-06-11 22:44:19,783:INFO:           wurlitzer: Not installed
2024-06-11 22:44:19,783:INFO:PyCaret optional dependencies:
2024-06-11 22:44:19,793:INFO:                shap: Not installed
2024-06-11 22:44:19,793:INFO:           interpret: Not installed
2024-06-11 22:44:19,793:INFO:                umap: Not installed
2024-06-11 22:44:19,793:INFO:     ydata_profiling: Not installed
2024-06-11 22:44:19,794:INFO:  explainerdashboard: Not installed
2024-06-11 22:44:19,794:INFO:             autoviz: Not installed
2024-06-11 22:44:19,794:INFO:           fairlearn: Not installed
2024-06-11 22:44:19,794:INFO:          deepchecks: Not installed
2024-06-11 22:44:19,794:INFO:             xgboost: Not installed
2024-06-11 22:44:19,794:INFO:            catboost: Not installed
2024-06-11 22:44:19,794:INFO:              kmodes: Not installed
2024-06-11 22:44:19,794:INFO:             mlxtend: Not installed
2024-06-11 22:44:19,794:INFO:       statsforecast: Not installed
2024-06-11 22:44:19,794:INFO:        tune_sklearn: Not installed
2024-06-11 22:44:19,794:INFO:                 ray: Not installed
2024-06-11 22:44:19,794:INFO:            hyperopt: Not installed
2024-06-11 22:44:19,794:INFO:              optuna: Not installed
2024-06-11 22:44:19,794:INFO:               skopt: Not installed
2024-06-11 22:44:19,794:INFO:              mlflow: Not installed
2024-06-11 22:44:19,794:INFO:              gradio: Not installed
2024-06-11 22:44:19,794:INFO:             fastapi: Not installed
2024-06-11 22:44:19,794:INFO:             uvicorn: Not installed
2024-06-11 22:44:19,794:INFO:              m2cgen: Not installed
2024-06-11 22:44:19,794:INFO:           evidently: Not installed
2024-06-11 22:44:19,794:INFO:               fugue: Not installed
2024-06-11 22:44:19,794:INFO:           streamlit: 1.35.0
2024-06-11 22:44:19,794:INFO:             prophet: Not installed
2024-06-11 22:44:19,794:INFO:None
2024-06-11 22:44:19,795:INFO:Set up data.
2024-06-11 22:46:00,196:INFO:Set up folding strategy.
2024-06-11 22:46:00,204:INFO:Set up train/test split.
2024-06-11 22:48:47,229:INFO:Set up index.
2024-06-11 22:50:43,564:INFO:PyCaret ClassificationExperiment
2024-06-11 22:50:43,564:INFO:Logging name: clf-default-name
2024-06-11 22:50:43,564:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:50:43,564:INFO:version 3.3.2
2024-06-11 22:50:43,565:INFO:Initializing setup()
2024-06-11 22:50:43,565:INFO:self.USI: b702
2024-06-11 22:50:43,565:INFO:self._variable_keys: {'y', 'fix_imbalance', 'X_train', 'n_jobs_param', 'data', 'html_param', 'y_test', 'is_multiclass', 'X_test', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'logging_param', 'memory', 'gpu_param', 'target_param', 'pipeline', 'exp_id', 'idx', '_ml_usecase', 'y_train', 'fold_groups_param', 'log_plots_param', 'fold_shuffle_param', 'X', 'exp_name_log', '_available_plots', 'seed'}
2024-06-11 22:50:43,565:INFO:Checking environment
2024-06-11 22:50:43,565:INFO:python_version: 3.11.9
2024-06-11 22:50:43,565:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:50:43,565:INFO:machine: AMD64
2024-06-11 22:50:43,565:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:50:43,565:INFO:Memory: svmem(total=34056318976, available=28276879360, percent=17.0, used=5779439616, free=28276879360)
2024-06-11 22:50:43,566:INFO:Physical Core: 6
2024-06-11 22:50:43,566:INFO:Logical Core: 12
2024-06-11 22:50:43,566:INFO:Checking libraries
2024-06-11 22:50:43,566:INFO:System:
2024-06-11 22:50:43,566:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:50:43,566:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:50:43,566:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:50:43,566:INFO:PyCaret required dependencies:
2024-06-11 22:50:43,566:INFO:                 pip: 24.0
2024-06-11 22:50:43,566:INFO:          setuptools: 69.5.1
2024-06-11 22:50:43,567:INFO:             pycaret: 3.3.2
2024-06-11 22:50:43,567:INFO:             IPython: 8.25.0
2024-06-11 22:50:43,567:INFO:          ipywidgets: 8.1.3
2024-06-11 22:50:43,567:INFO:                tqdm: 4.66.4
2024-06-11 22:50:43,567:INFO:               numpy: 1.26.4
2024-06-11 22:50:43,567:INFO:              pandas: 2.1.4
2024-06-11 22:50:43,567:INFO:              jinja2: 3.1.4
2024-06-11 22:50:43,568:INFO:               scipy: 1.11.4
2024-06-11 22:50:43,568:INFO:              joblib: 1.3.2
2024-06-11 22:50:43,568:INFO:             sklearn: 1.4.2
2024-06-11 22:50:43,568:INFO:                pyod: 2.0.0
2024-06-11 22:50:43,568:INFO:            imblearn: 0.12.3
2024-06-11 22:50:43,568:INFO:   category_encoders: 2.6.3
2024-06-11 22:50:43,568:INFO:            lightgbm: 4.3.0
2024-06-11 22:50:43,568:INFO:               numba: 0.59.1
2024-06-11 22:50:43,568:INFO:            requests: 2.32.3
2024-06-11 22:50:43,568:INFO:          matplotlib: 3.7.5
2024-06-11 22:50:43,568:INFO:          scikitplot: 0.3.7
2024-06-11 22:50:43,569:INFO:         yellowbrick: 1.5
2024-06-11 22:50:43,569:INFO:              plotly: 5.22.0
2024-06-11 22:50:43,569:INFO:    plotly-resampler: Not installed
2024-06-11 22:50:43,569:INFO:             kaleido: 0.2.1
2024-06-11 22:50:43,569:INFO:           schemdraw: 0.15
2024-06-11 22:50:43,569:INFO:         statsmodels: 0.14.2
2024-06-11 22:50:43,569:INFO:              sktime: 0.26.0
2024-06-11 22:50:43,569:INFO:               tbats: 1.1.3
2024-06-11 22:50:43,569:INFO:            pmdarima: 2.0.4
2024-06-11 22:50:43,569:INFO:              psutil: 5.9.8
2024-06-11 22:50:43,570:INFO:          markupsafe: 2.1.5
2024-06-11 22:50:43,570:INFO:             pickle5: Not installed
2024-06-11 22:50:43,570:INFO:         cloudpickle: 3.0.0
2024-06-11 22:50:43,570:INFO:         deprecation: 2.1.0
2024-06-11 22:50:43,570:INFO:              xxhash: 3.4.1
2024-06-11 22:50:43,570:INFO:           wurlitzer: Not installed
2024-06-11 22:50:43,570:INFO:PyCaret optional dependencies:
2024-06-11 22:50:43,570:INFO:                shap: Not installed
2024-06-11 22:50:43,571:INFO:           interpret: Not installed
2024-06-11 22:50:43,571:INFO:                umap: Not installed
2024-06-11 22:50:43,571:INFO:     ydata_profiling: Not installed
2024-06-11 22:50:43,571:INFO:  explainerdashboard: Not installed
2024-06-11 22:50:43,571:INFO:             autoviz: Not installed
2024-06-11 22:50:43,571:INFO:           fairlearn: Not installed
2024-06-11 22:50:43,572:INFO:          deepchecks: Not installed
2024-06-11 22:50:43,572:INFO:             xgboost: Not installed
2024-06-11 22:50:43,572:INFO:            catboost: Not installed
2024-06-11 22:50:43,572:INFO:              kmodes: Not installed
2024-06-11 22:50:43,572:INFO:             mlxtend: Not installed
2024-06-11 22:50:43,572:INFO:       statsforecast: Not installed
2024-06-11 22:50:43,573:INFO:        tune_sklearn: Not installed
2024-06-11 22:50:43,573:INFO:                 ray: Not installed
2024-06-11 22:50:43,573:INFO:            hyperopt: Not installed
2024-06-11 22:50:43,573:INFO:              optuna: Not installed
2024-06-11 22:50:43,573:INFO:               skopt: Not installed
2024-06-11 22:50:43,573:INFO:              mlflow: Not installed
2024-06-11 22:50:43,573:INFO:              gradio: Not installed
2024-06-11 22:50:43,573:INFO:             fastapi: Not installed
2024-06-11 22:50:43,573:INFO:             uvicorn: Not installed
2024-06-11 22:50:43,573:INFO:              m2cgen: Not installed
2024-06-11 22:50:43,574:INFO:           evidently: Not installed
2024-06-11 22:50:43,574:INFO:               fugue: Not installed
2024-06-11 22:50:43,574:INFO:           streamlit: 1.35.0
2024-06-11 22:50:43,574:INFO:             prophet: Not installed
2024-06-11 22:50:43,574:INFO:None
2024-06-11 22:50:43,574:INFO:Set up data.
2024-06-11 22:50:43,609:INFO:Set up folding strategy.
2024-06-11 22:50:43,609:INFO:Set up train/test split.
2024-06-11 22:50:43,630:INFO:Set up index.
2024-06-11 22:50:43,632:INFO:Assigning column types.
2024-06-11 22:50:43,641:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-11 22:50:43,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:50:43,688:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:50:43,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:43,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:43,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-11 22:50:43,771:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:50:43,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:43,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:43,798:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-11 22:50:43,842:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:50:43,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:43,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:43,911:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-11 22:50:43,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:43,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:43,961:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-11 22:50:44,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,112:INFO:Preparing preprocessing pipeline...
2024-06-11 22:50:44,115:INFO:Set up simple imputation.
2024-06-11 22:50:44,125:INFO:Set up encoding of ordinal features.
2024-06-11 22:50:44,134:INFO:Set up encoding of categorical features.
2024-06-11 22:50:44,134:INFO:Set up removing outliers.
2024-06-11 22:50:44,134:INFO:Set up imbalanced handling.
2024-06-11 22:50:44,134:INFO:Set up PCA.
2024-06-11 22:50:44,411:INFO:Finished creating preprocessing pipeline.
2024-06-11 22:50:44,460:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-11 22:50:44,460:INFO:Creating final display dataframe.
2024-06-11 22:50:44,624:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (76276, 30)
5   Transformed train set shape       (61276, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                          PCA              True
21                   PCA method            linear
22               PCA components              None
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              b702
2024-06-11 22:50:44,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,780:INFO:setup() successfully completed in 1.29s...............
2024-06-11 22:50:44,820:INFO:gpu_param set to False
2024-06-11 22:50:44,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:44,988:INFO:gpu_param set to False
2024-06-11 22:50:45,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,137:INFO:gpu_param set to False
2024-06-11 22:50:45,209:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,286:INFO:gpu_param set to False
2024-06-11 22:50:45,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-11 22:50:45,444:INFO:Initializing create_model()
2024-06-11 22:50:45,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BBC6DD0ED0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-11 22:50:45,444:INFO:Checking exceptions
2024-06-11 22:50:45,447:INFO:Importing libraries
2024-06-11 22:50:45,447:INFO:Copying training dataset
2024-06-11 22:50:45,459:INFO:Defining folds
2024-06-11 22:50:45,460:INFO:Declaring metric variables
2024-06-11 22:50:45,460:INFO:Importing untrained model
2024-06-11 22:50:45,460:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-11 22:50:45,460:INFO:Starting cross validation
2024-06-11 22:50:45,462:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-11 22:50:53,713:INFO:PyCaret ClassificationExperiment
2024-06-11 22:50:53,714:INFO:Logging name: clf-default-name
2024-06-11 22:50:53,714:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:50:53,714:INFO:version 3.3.2
2024-06-11 22:50:53,714:INFO:Initializing setup()
2024-06-11 22:50:53,714:INFO:self.USI: f267
2024-06-11 22:50:53,714:INFO:self._variable_keys: {'y', 'fix_imbalance', 'X_train', 'n_jobs_param', 'data', 'html_param', 'y_test', 'is_multiclass', 'X_test', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'logging_param', 'memory', 'gpu_param', 'target_param', 'pipeline', 'exp_id', 'idx', '_ml_usecase', 'y_train', 'fold_groups_param', 'log_plots_param', 'fold_shuffle_param', 'X', 'exp_name_log', '_available_plots', 'seed'}
2024-06-11 22:50:53,714:INFO:Checking environment
2024-06-11 22:50:53,714:INFO:python_version: 3.11.9
2024-06-11 22:50:53,714:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:50:53,714:INFO:machine: AMD64
2024-06-11 22:50:53,714:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:50:53,714:INFO:Memory: svmem(total=34056318976, available=26882347008, percent=21.1, used=7173971968, free=26882347008)
2024-06-11 22:50:53,714:INFO:Physical Core: 6
2024-06-11 22:50:53,714:INFO:Logical Core: 12
2024-06-11 22:50:53,714:INFO:Checking libraries
2024-06-11 22:50:53,714:INFO:System:
2024-06-11 22:50:53,715:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:50:53,715:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:50:53,715:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:50:53,715:INFO:PyCaret required dependencies:
2024-06-11 22:50:53,715:INFO:                 pip: 24.0
2024-06-11 22:50:53,715:INFO:          setuptools: 69.5.1
2024-06-11 22:50:53,715:INFO:             pycaret: 3.3.2
2024-06-11 22:50:53,715:INFO:             IPython: 8.25.0
2024-06-11 22:50:53,715:INFO:          ipywidgets: 8.1.3
2024-06-11 22:50:53,715:INFO:                tqdm: 4.66.4
2024-06-11 22:50:53,715:INFO:               numpy: 1.26.4
2024-06-11 22:50:53,716:INFO:              pandas: 2.1.4
2024-06-11 22:50:53,716:INFO:              jinja2: 3.1.4
2024-06-11 22:50:53,716:INFO:               scipy: 1.11.4
2024-06-11 22:50:53,716:INFO:              joblib: 1.3.2
2024-06-11 22:50:53,716:INFO:             sklearn: 1.4.2
2024-06-11 22:50:53,716:INFO:                pyod: 2.0.0
2024-06-11 22:50:53,716:INFO:            imblearn: 0.12.3
2024-06-11 22:50:53,716:INFO:   category_encoders: 2.6.3
2024-06-11 22:50:53,716:INFO:            lightgbm: 4.3.0
2024-06-11 22:50:53,716:INFO:               numba: 0.59.1
2024-06-11 22:50:53,716:INFO:            requests: 2.32.3
2024-06-11 22:50:53,716:INFO:          matplotlib: 3.7.5
2024-06-11 22:50:53,716:INFO:          scikitplot: 0.3.7
2024-06-11 22:50:53,716:INFO:         yellowbrick: 1.5
2024-06-11 22:50:53,717:INFO:              plotly: 5.22.0
2024-06-11 22:50:53,717:INFO:    plotly-resampler: Not installed
2024-06-11 22:50:53,717:INFO:             kaleido: 0.2.1
2024-06-11 22:50:53,717:INFO:           schemdraw: 0.15
2024-06-11 22:50:53,717:INFO:         statsmodels: 0.14.2
2024-06-11 22:50:53,717:INFO:              sktime: 0.26.0
2024-06-11 22:50:53,717:INFO:               tbats: 1.1.3
2024-06-11 22:50:53,717:INFO:            pmdarima: 2.0.4
2024-06-11 22:50:53,717:INFO:              psutil: 5.9.8
2024-06-11 22:50:53,717:INFO:          markupsafe: 2.1.5
2024-06-11 22:50:53,718:INFO:             pickle5: Not installed
2024-06-11 22:50:53,718:INFO:         cloudpickle: 3.0.0
2024-06-11 22:50:53,718:INFO:         deprecation: 2.1.0
2024-06-11 22:50:53,718:INFO:              xxhash: 3.4.1
2024-06-11 22:50:53,718:INFO:           wurlitzer: Not installed
2024-06-11 22:50:53,718:INFO:PyCaret optional dependencies:
2024-06-11 22:50:53,718:INFO:                shap: Not installed
2024-06-11 22:50:53,718:INFO:           interpret: Not installed
2024-06-11 22:50:53,718:INFO:                umap: Not installed
2024-06-11 22:50:53,718:INFO:     ydata_profiling: Not installed
2024-06-11 22:50:53,718:INFO:  explainerdashboard: Not installed
2024-06-11 22:50:53,718:INFO:             autoviz: Not installed
2024-06-11 22:50:53,718:INFO:           fairlearn: Not installed
2024-06-11 22:50:53,718:INFO:          deepchecks: Not installed
2024-06-11 22:50:53,719:INFO:             xgboost: Not installed
2024-06-11 22:50:53,719:INFO:            catboost: Not installed
2024-06-11 22:50:53,719:INFO:              kmodes: Not installed
2024-06-11 22:50:53,719:INFO:             mlxtend: Not installed
2024-06-11 22:50:53,719:INFO:       statsforecast: Not installed
2024-06-11 22:50:53,719:INFO:        tune_sklearn: Not installed
2024-06-11 22:50:53,719:INFO:                 ray: Not installed
2024-06-11 22:50:53,719:INFO:            hyperopt: Not installed
2024-06-11 22:50:53,719:INFO:              optuna: Not installed
2024-06-11 22:50:53,719:INFO:               skopt: Not installed
2024-06-11 22:50:53,719:INFO:              mlflow: Not installed
2024-06-11 22:50:53,719:INFO:              gradio: Not installed
2024-06-11 22:50:53,719:INFO:             fastapi: Not installed
2024-06-11 22:50:53,719:INFO:             uvicorn: Not installed
2024-06-11 22:50:53,719:INFO:              m2cgen: Not installed
2024-06-11 22:50:53,720:INFO:           evidently: Not installed
2024-06-11 22:50:53,720:INFO:               fugue: Not installed
2024-06-11 22:50:53,720:INFO:           streamlit: 1.35.0
2024-06-11 22:50:53,720:INFO:             prophet: Not installed
2024-06-11 22:50:53,720:INFO:None
2024-06-11 22:50:53,720:INFO:Set up data.
2024-06-11 22:50:58,617:INFO:Calculating mean and std
2024-06-11 22:50:58,618:INFO:Creating metrics dataframe
2024-06-11 22:50:58,620:INFO:Finalizing model
2024-06-11 22:51:38,972:INFO:  Stopping...
2024-06-11 22:51:39,704:INFO:Uploading results into container
2024-06-11 22:51:39,705:INFO:Uploading model into container now
2024-06-11 22:51:39,734:INFO:_master_model_container: 1
2024-06-11 22:51:39,734:INFO:_display_container: 2
2024-06-11 22:51:39,735:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-11 22:51:39,735:INFO:create_model() successfully completed......................................
2024-06-11 22:51:56,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:51:56,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:51:56,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:51:56,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:52:06,906:INFO:PyCaret ClassificationExperiment
2024-06-11 22:52:06,907:INFO:Logging name: clf-default-name
2024-06-11 22:52:06,907:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:52:06,907:INFO:version 3.3.2
2024-06-11 22:52:06,907:INFO:Initializing setup()
2024-06-11 22:52:06,907:INFO:self.USI: ccbf
2024-06-11 22:52:06,907:INFO:self._variable_keys: {'idx', 'fix_imbalance', 'y_train', 'fold_groups_param', '_available_plots', 'X_train', 'X', 'X_test', 'y_test', 'memory', 'y', 'gpu_param', 'html_param', '_ml_usecase', 'log_plots_param', 'gpu_n_jobs_param', 'is_multiclass', 'data', 'pipeline', 'n_jobs_param', 'target_param', 'seed', 'fold_shuffle_param', 'USI', 'logging_param', 'exp_id', 'fold_generator', 'exp_name_log'}
2024-06-11 22:52:06,907:INFO:Checking environment
2024-06-11 22:52:06,907:INFO:python_version: 3.11.9
2024-06-11 22:52:06,908:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:52:06,908:INFO:machine: AMD64
2024-06-11 22:52:06,925:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:52:06,925:INFO:Memory: svmem(total=34056318976, available=27913969664, percent=18.0, used=6142349312, free=27913969664)
2024-06-11 22:52:06,925:INFO:Physical Core: 6
2024-06-11 22:52:06,925:INFO:Logical Core: 12
2024-06-11 22:52:06,925:INFO:Checking libraries
2024-06-11 22:52:06,925:INFO:System:
2024-06-11 22:52:06,927:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:52:06,927:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:52:06,927:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:52:06,927:INFO:PyCaret required dependencies:
2024-06-11 22:52:06,964:INFO:                 pip: 24.0
2024-06-11 22:52:06,965:INFO:          setuptools: 69.5.1
2024-06-11 22:52:06,965:INFO:             pycaret: 3.3.2
2024-06-11 22:52:06,965:INFO:             IPython: 8.25.0
2024-06-11 22:52:06,965:INFO:          ipywidgets: 8.1.3
2024-06-11 22:52:06,965:INFO:                tqdm: 4.66.4
2024-06-11 22:52:06,965:INFO:               numpy: 1.26.4
2024-06-11 22:52:06,966:INFO:              pandas: 2.1.4
2024-06-11 22:52:06,966:INFO:              jinja2: 3.1.4
2024-06-11 22:52:06,966:INFO:               scipy: 1.11.4
2024-06-11 22:52:06,966:INFO:              joblib: 1.3.2
2024-06-11 22:52:06,966:INFO:             sklearn: 1.4.2
2024-06-11 22:52:06,966:INFO:                pyod: 2.0.0
2024-06-11 22:52:06,966:INFO:            imblearn: 0.12.3
2024-06-11 22:52:06,966:INFO:   category_encoders: 2.6.3
2024-06-11 22:52:06,966:INFO:            lightgbm: 4.3.0
2024-06-11 22:52:06,967:INFO:               numba: 0.59.1
2024-06-11 22:52:06,967:INFO:            requests: 2.32.3
2024-06-11 22:52:06,967:INFO:          matplotlib: 3.7.5
2024-06-11 22:52:06,967:INFO:          scikitplot: 0.3.7
2024-06-11 22:52:06,967:INFO:         yellowbrick: 1.5
2024-06-11 22:52:06,967:INFO:              plotly: 5.22.0
2024-06-11 22:52:06,967:INFO:    plotly-resampler: Not installed
2024-06-11 22:52:06,967:INFO:             kaleido: 0.2.1
2024-06-11 22:52:06,968:INFO:           schemdraw: 0.15
2024-06-11 22:52:06,968:INFO:         statsmodels: 0.14.2
2024-06-11 22:52:06,968:INFO:              sktime: 0.26.0
2024-06-11 22:52:06,968:INFO:               tbats: 1.1.3
2024-06-11 22:52:06,969:INFO:            pmdarima: 2.0.4
2024-06-11 22:52:06,969:INFO:              psutil: 5.9.8
2024-06-11 22:52:06,969:INFO:          markupsafe: 2.1.5
2024-06-11 22:52:06,969:INFO:             pickle5: Not installed
2024-06-11 22:52:06,969:INFO:         cloudpickle: 3.0.0
2024-06-11 22:52:06,969:INFO:         deprecation: 2.1.0
2024-06-11 22:52:06,969:INFO:              xxhash: 3.4.1
2024-06-11 22:52:06,969:INFO:           wurlitzer: Not installed
2024-06-11 22:52:06,969:INFO:PyCaret optional dependencies:
2024-06-11 22:52:06,987:INFO:                shap: Not installed
2024-06-11 22:52:06,987:INFO:           interpret: Not installed
2024-06-11 22:52:06,987:INFO:                umap: Not installed
2024-06-11 22:52:06,987:INFO:     ydata_profiling: Not installed
2024-06-11 22:52:06,987:INFO:  explainerdashboard: Not installed
2024-06-11 22:52:06,987:INFO:             autoviz: Not installed
2024-06-11 22:52:06,987:INFO:           fairlearn: Not installed
2024-06-11 22:52:06,987:INFO:          deepchecks: Not installed
2024-06-11 22:52:06,987:INFO:             xgboost: Not installed
2024-06-11 22:52:06,987:INFO:            catboost: Not installed
2024-06-11 22:52:06,987:INFO:              kmodes: Not installed
2024-06-11 22:52:06,987:INFO:             mlxtend: Not installed
2024-06-11 22:52:06,987:INFO:       statsforecast: Not installed
2024-06-11 22:52:06,987:INFO:        tune_sklearn: Not installed
2024-06-11 22:52:06,987:INFO:                 ray: Not installed
2024-06-11 22:52:06,988:INFO:            hyperopt: Not installed
2024-06-11 22:52:06,988:INFO:              optuna: Not installed
2024-06-11 22:52:06,988:INFO:               skopt: Not installed
2024-06-11 22:52:06,988:INFO:              mlflow: Not installed
2024-06-11 22:52:06,988:INFO:              gradio: Not installed
2024-06-11 22:52:06,988:INFO:             fastapi: Not installed
2024-06-11 22:52:06,988:INFO:             uvicorn: Not installed
2024-06-11 22:52:06,988:INFO:              m2cgen: Not installed
2024-06-11 22:52:06,988:INFO:           evidently: Not installed
2024-06-11 22:52:06,988:INFO:               fugue: Not installed
2024-06-11 22:52:06,988:INFO:           streamlit: 1.35.0
2024-06-11 22:52:06,988:INFO:             prophet: Not installed
2024-06-11 22:52:06,988:INFO:None
2024-06-11 22:52:06,988:INFO:Set up data.
2024-06-11 22:53:50,678:INFO:Set up folding strategy.
2024-06-11 22:53:50,705:INFO:Set up train/test split.
2024-06-11 22:55:38,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:55:38,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:55:38,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:55:38,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:55:49,810:INFO:PyCaret ClassificationExperiment
2024-06-11 22:55:49,811:INFO:Logging name: clf-default-name
2024-06-11 22:55:49,811:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:55:49,811:INFO:version 3.3.2
2024-06-11 22:55:49,811:INFO:Initializing setup()
2024-06-11 22:55:49,811:INFO:self.USI: 6c12
2024-06-11 22:55:49,811:INFO:self._variable_keys: {'html_param', 'pipeline', 'logging_param', 'target_param', 'gpu_param', 'y_train', 'log_plots_param', 'fold_groups_param', 'n_jobs_param', 'fix_imbalance', '_ml_usecase', 'y', 'seed', 'USI', 'y_test', 'fold_shuffle_param', 'X_train', 'memory', 'X_test', 'fold_generator', 'exp_name_log', 'X', '_available_plots', 'data', 'idx', 'exp_id', 'gpu_n_jobs_param', 'is_multiclass'}
2024-06-11 22:55:49,811:INFO:Checking environment
2024-06-11 22:55:49,811:INFO:python_version: 3.11.9
2024-06-11 22:55:49,812:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:55:49,812:INFO:machine: AMD64
2024-06-11 22:55:49,827:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:55:49,828:INFO:Memory: svmem(total=34056318976, available=28688703488, percent=15.8, used=5367615488, free=28688703488)
2024-06-11 22:55:49,828:INFO:Physical Core: 6
2024-06-11 22:55:49,828:INFO:Logical Core: 12
2024-06-11 22:55:49,828:INFO:Checking libraries
2024-06-11 22:55:49,828:INFO:System:
2024-06-11 22:55:49,828:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:55:49,828:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:55:49,828:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:55:49,828:INFO:PyCaret required dependencies:
2024-06-11 22:55:49,854:INFO:                 pip: 24.0
2024-06-11 22:55:49,854:INFO:          setuptools: 69.5.1
2024-06-11 22:55:49,854:INFO:             pycaret: 3.3.2
2024-06-11 22:55:49,854:INFO:             IPython: 8.25.0
2024-06-11 22:55:49,854:INFO:          ipywidgets: 8.1.3
2024-06-11 22:55:49,854:INFO:                tqdm: 4.66.4
2024-06-11 22:55:49,854:INFO:               numpy: 1.26.4
2024-06-11 22:55:49,854:INFO:              pandas: 2.1.4
2024-06-11 22:55:49,854:INFO:              jinja2: 3.1.4
2024-06-11 22:55:49,854:INFO:               scipy: 1.11.4
2024-06-11 22:55:49,854:INFO:              joblib: 1.3.2
2024-06-11 22:55:49,854:INFO:             sklearn: 1.4.2
2024-06-11 22:55:49,854:INFO:                pyod: 2.0.0
2024-06-11 22:55:49,854:INFO:            imblearn: 0.12.3
2024-06-11 22:55:49,854:INFO:   category_encoders: 2.6.3
2024-06-11 22:55:49,854:INFO:            lightgbm: 4.3.0
2024-06-11 22:55:49,854:INFO:               numba: 0.59.1
2024-06-11 22:55:49,854:INFO:            requests: 2.32.3
2024-06-11 22:55:49,854:INFO:          matplotlib: 3.7.5
2024-06-11 22:55:49,855:INFO:          scikitplot: 0.3.7
2024-06-11 22:55:49,855:INFO:         yellowbrick: 1.5
2024-06-11 22:55:49,855:INFO:              plotly: 5.22.0
2024-06-11 22:55:49,855:INFO:    plotly-resampler: Not installed
2024-06-11 22:55:49,855:INFO:             kaleido: 0.2.1
2024-06-11 22:55:49,855:INFO:           schemdraw: 0.15
2024-06-11 22:55:49,855:INFO:         statsmodels: 0.14.2
2024-06-11 22:55:49,855:INFO:              sktime: 0.26.0
2024-06-11 22:55:49,855:INFO:               tbats: 1.1.3
2024-06-11 22:55:49,855:INFO:            pmdarima: 2.0.4
2024-06-11 22:55:49,855:INFO:              psutil: 5.9.8
2024-06-11 22:55:49,855:INFO:          markupsafe: 2.1.5
2024-06-11 22:55:49,855:INFO:             pickle5: Not installed
2024-06-11 22:55:49,855:INFO:         cloudpickle: 3.0.0
2024-06-11 22:55:49,855:INFO:         deprecation: 2.1.0
2024-06-11 22:55:49,855:INFO:              xxhash: 3.4.1
2024-06-11 22:55:49,855:INFO:           wurlitzer: Not installed
2024-06-11 22:55:49,855:INFO:PyCaret optional dependencies:
2024-06-11 22:55:49,865:INFO:                shap: Not installed
2024-06-11 22:55:49,866:INFO:           interpret: Not installed
2024-06-11 22:55:49,866:INFO:                umap: Not installed
2024-06-11 22:55:49,866:INFO:     ydata_profiling: Not installed
2024-06-11 22:55:49,866:INFO:  explainerdashboard: Not installed
2024-06-11 22:55:49,866:INFO:             autoviz: Not installed
2024-06-11 22:55:49,866:INFO:           fairlearn: Not installed
2024-06-11 22:55:49,866:INFO:          deepchecks: Not installed
2024-06-11 22:55:49,866:INFO:             xgboost: Not installed
2024-06-11 22:55:49,866:INFO:            catboost: Not installed
2024-06-11 22:55:49,866:INFO:              kmodes: Not installed
2024-06-11 22:55:49,866:INFO:             mlxtend: Not installed
2024-06-11 22:55:49,866:INFO:       statsforecast: Not installed
2024-06-11 22:55:49,866:INFO:        tune_sklearn: Not installed
2024-06-11 22:55:49,866:INFO:                 ray: Not installed
2024-06-11 22:55:49,866:INFO:            hyperopt: Not installed
2024-06-11 22:55:49,866:INFO:              optuna: Not installed
2024-06-11 22:55:49,866:INFO:               skopt: Not installed
2024-06-11 22:55:49,866:INFO:              mlflow: Not installed
2024-06-11 22:55:49,866:INFO:              gradio: Not installed
2024-06-11 22:55:49,866:INFO:             fastapi: Not installed
2024-06-11 22:55:49,866:INFO:             uvicorn: Not installed
2024-06-11 22:55:49,867:INFO:              m2cgen: Not installed
2024-06-11 22:55:49,867:INFO:           evidently: Not installed
2024-06-11 22:55:49,867:INFO:               fugue: Not installed
2024-06-11 22:55:49,867:INFO:           streamlit: 1.35.0
2024-06-11 22:55:49,867:INFO:             prophet: Not installed
2024-06-11 22:55:49,867:INFO:None
2024-06-11 22:55:49,867:INFO:Set up data.
2024-06-11 22:57:41,117:INFO:Set up folding strategy.
2024-06-11 22:57:41,123:INFO:Set up train/test split.
2024-06-11 22:58:22,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:58:22,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:58:22,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:58:22,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 22:58:43,862:INFO:PyCaret ClassificationExperiment
2024-06-11 22:58:43,862:INFO:Logging name: clf-default-name
2024-06-11 22:58:43,862:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 22:58:43,862:INFO:version 3.3.2
2024-06-11 22:58:43,862:INFO:Initializing setup()
2024-06-11 22:58:43,863:INFO:self.USI: 8499
2024-06-11 22:58:43,863:INFO:self._variable_keys: {'seed', 'fold_generator', '_available_plots', 'gpu_n_jobs_param', 'fix_imbalance', 'USI', 'y', 'y_train', 'y_test', 'X_train', 'logging_param', 'X', 'data', 'n_jobs_param', 'target_param', 'html_param', 'log_plots_param', 'exp_id', 'is_multiclass', '_ml_usecase', 'fold_groups_param', 'fold_shuffle_param', 'exp_name_log', 'gpu_param', 'pipeline', 'X_test', 'memory', 'idx'}
2024-06-11 22:58:43,863:INFO:Checking environment
2024-06-11 22:58:43,863:INFO:python_version: 3.11.9
2024-06-11 22:58:43,863:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 22:58:43,863:INFO:machine: AMD64
2024-06-11 22:58:43,879:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 22:58:43,879:INFO:Memory: svmem(total=34056318976, available=28339359744, percent=16.8, used=5716959232, free=28339359744)
2024-06-11 22:58:43,879:INFO:Physical Core: 6
2024-06-11 22:58:43,879:INFO:Logical Core: 12
2024-06-11 22:58:43,879:INFO:Checking libraries
2024-06-11 22:58:43,879:INFO:System:
2024-06-11 22:58:43,879:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 22:58:43,879:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 22:58:43,879:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 22:58:43,879:INFO:PyCaret required dependencies:
2024-06-11 22:58:43,904:INFO:                 pip: 24.0
2024-06-11 22:58:43,905:INFO:          setuptools: 69.5.1
2024-06-11 22:58:43,905:INFO:             pycaret: 3.3.2
2024-06-11 22:58:43,905:INFO:             IPython: 8.25.0
2024-06-11 22:58:43,905:INFO:          ipywidgets: 8.1.3
2024-06-11 22:58:43,905:INFO:                tqdm: 4.66.4
2024-06-11 22:58:43,905:INFO:               numpy: 1.26.4
2024-06-11 22:58:43,905:INFO:              pandas: 2.1.4
2024-06-11 22:58:43,905:INFO:              jinja2: 3.1.4
2024-06-11 22:58:43,905:INFO:               scipy: 1.11.4
2024-06-11 22:58:43,905:INFO:              joblib: 1.3.2
2024-06-11 22:58:43,905:INFO:             sklearn: 1.4.2
2024-06-11 22:58:43,905:INFO:                pyod: 2.0.0
2024-06-11 22:58:43,905:INFO:            imblearn: 0.12.3
2024-06-11 22:58:43,905:INFO:   category_encoders: 2.6.3
2024-06-11 22:58:43,905:INFO:            lightgbm: 4.3.0
2024-06-11 22:58:43,905:INFO:               numba: 0.59.1
2024-06-11 22:58:43,905:INFO:            requests: 2.32.3
2024-06-11 22:58:43,905:INFO:          matplotlib: 3.7.5
2024-06-11 22:58:43,905:INFO:          scikitplot: 0.3.7
2024-06-11 22:58:43,905:INFO:         yellowbrick: 1.5
2024-06-11 22:58:43,905:INFO:              plotly: 5.22.0
2024-06-11 22:58:43,906:INFO:    plotly-resampler: Not installed
2024-06-11 22:58:43,906:INFO:             kaleido: 0.2.1
2024-06-11 22:58:43,906:INFO:           schemdraw: 0.15
2024-06-11 22:58:43,906:INFO:         statsmodels: 0.14.2
2024-06-11 22:58:43,906:INFO:              sktime: 0.26.0
2024-06-11 22:58:43,906:INFO:               tbats: 1.1.3
2024-06-11 22:58:43,906:INFO:            pmdarima: 2.0.4
2024-06-11 22:58:43,906:INFO:              psutil: 5.9.8
2024-06-11 22:58:43,906:INFO:          markupsafe: 2.1.5
2024-06-11 22:58:43,906:INFO:             pickle5: Not installed
2024-06-11 22:58:43,906:INFO:         cloudpickle: 3.0.0
2024-06-11 22:58:43,906:INFO:         deprecation: 2.1.0
2024-06-11 22:58:43,906:INFO:              xxhash: 3.4.1
2024-06-11 22:58:43,906:INFO:           wurlitzer: Not installed
2024-06-11 22:58:43,906:INFO:PyCaret optional dependencies:
2024-06-11 22:58:43,916:INFO:                shap: Not installed
2024-06-11 22:58:43,916:INFO:           interpret: Not installed
2024-06-11 22:58:43,916:INFO:                umap: Not installed
2024-06-11 22:58:43,916:INFO:     ydata_profiling: Not installed
2024-06-11 22:58:43,917:INFO:  explainerdashboard: Not installed
2024-06-11 22:58:43,917:INFO:             autoviz: Not installed
2024-06-11 22:58:43,917:INFO:           fairlearn: Not installed
2024-06-11 22:58:43,917:INFO:          deepchecks: Not installed
2024-06-11 22:58:43,917:INFO:             xgboost: Not installed
2024-06-11 22:58:43,917:INFO:            catboost: Not installed
2024-06-11 22:58:43,917:INFO:              kmodes: Not installed
2024-06-11 22:58:43,917:INFO:             mlxtend: Not installed
2024-06-11 22:58:43,917:INFO:       statsforecast: Not installed
2024-06-11 22:58:43,917:INFO:        tune_sklearn: Not installed
2024-06-11 22:58:43,917:INFO:                 ray: Not installed
2024-06-11 22:58:43,917:INFO:            hyperopt: Not installed
2024-06-11 22:58:43,917:INFO:              optuna: Not installed
2024-06-11 22:58:43,917:INFO:               skopt: Not installed
2024-06-11 22:58:43,917:INFO:              mlflow: Not installed
2024-06-11 22:58:43,917:INFO:              gradio: Not installed
2024-06-11 22:58:43,917:INFO:             fastapi: Not installed
2024-06-11 22:58:43,917:INFO:             uvicorn: Not installed
2024-06-11 22:58:43,917:INFO:              m2cgen: Not installed
2024-06-11 22:58:43,917:INFO:           evidently: Not installed
2024-06-11 22:58:43,917:INFO:               fugue: Not installed
2024-06-11 22:58:43,917:INFO:           streamlit: 1.35.0
2024-06-11 22:58:43,917:INFO:             prophet: Not installed
2024-06-11 22:58:43,917:INFO:None
2024-06-11 22:58:43,918:INFO:Set up data.
2024-06-11 23:00:29,026:INFO:Set up folding strategy.
2024-06-11 23:00:29,034:INFO:Set up train/test split.
2024-06-11 23:00:33,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 23:00:33,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 23:00:33,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 23:00:33,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-11 23:00:52,086:INFO:PyCaret ClassificationExperiment
2024-06-11 23:00:52,086:INFO:Logging name: clf-default-name
2024-06-11 23:00:52,086:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-11 23:00:52,086:INFO:version 3.3.2
2024-06-11 23:00:52,086:INFO:Initializing setup()
2024-06-11 23:00:52,086:INFO:self.USI: 1c8a
2024-06-11 23:00:52,086:INFO:self._variable_keys: {'X_train', 'idx', 'fold_generator', 'exp_name_log', 'X_test', 'USI', 'n_jobs_param', 'gpu_param', 'X', 'fold_groups_param', '_available_plots', 'data', '_ml_usecase', 'seed', 'log_plots_param', 'exp_id', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'fix_imbalance', 'memory', 'target_param', 'fold_shuffle_param', 'y', 'y_test', 'y_train', 'is_multiclass', 'logging_param'}
2024-06-11 23:00:52,086:INFO:Checking environment
2024-06-11 23:00:52,086:INFO:python_version: 3.11.9
2024-06-11 23:00:52,086:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-11 23:00:52,086:INFO:machine: AMD64
2024-06-11 23:00:52,086:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-11 23:00:52,087:INFO:Memory: svmem(total=34056318976, available=21327998976, percent=37.4, used=12728320000, free=21327998976)
2024-06-11 23:00:52,087:INFO:Physical Core: 6
2024-06-11 23:00:52,087:INFO:Logical Core: 12
2024-06-11 23:00:52,087:INFO:Checking libraries
2024-06-11 23:00:52,087:INFO:System:
2024-06-11 23:00:52,087:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-11 23:00:52,087:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-11 23:00:52,087:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-11 23:00:52,087:INFO:PyCaret required dependencies:
2024-06-11 23:00:52,116:INFO:                 pip: 24.0
2024-06-11 23:00:52,116:INFO:          setuptools: 69.5.1
2024-06-11 23:00:52,116:INFO:             pycaret: 3.3.2
2024-06-11 23:00:52,116:INFO:             IPython: 8.25.0
2024-06-11 23:00:52,116:INFO:          ipywidgets: 8.1.3
2024-06-11 23:00:52,116:INFO:                tqdm: 4.66.4
2024-06-11 23:00:52,116:INFO:               numpy: 1.26.4
2024-06-11 23:00:52,116:INFO:              pandas: 2.1.4
2024-06-11 23:00:52,116:INFO:              jinja2: 3.1.4
2024-06-11 23:00:52,116:INFO:               scipy: 1.11.4
2024-06-11 23:00:52,116:INFO:              joblib: 1.3.2
2024-06-11 23:00:52,116:INFO:             sklearn: 1.4.2
2024-06-11 23:00:52,116:INFO:                pyod: 2.0.0
2024-06-11 23:00:52,117:INFO:            imblearn: 0.12.3
2024-06-11 23:00:52,117:INFO:   category_encoders: 2.6.3
2024-06-11 23:00:52,117:INFO:            lightgbm: 4.3.0
2024-06-11 23:00:52,117:INFO:               numba: 0.59.1
2024-06-11 23:00:52,117:INFO:            requests: 2.32.3
2024-06-11 23:00:52,117:INFO:          matplotlib: 3.7.5
2024-06-11 23:00:52,117:INFO:          scikitplot: 0.3.7
2024-06-11 23:00:52,117:INFO:         yellowbrick: 1.5
2024-06-11 23:00:52,117:INFO:              plotly: 5.22.0
2024-06-11 23:00:52,117:INFO:    plotly-resampler: Not installed
2024-06-11 23:00:52,117:INFO:             kaleido: 0.2.1
2024-06-11 23:00:52,117:INFO:           schemdraw: 0.15
2024-06-11 23:00:52,117:INFO:         statsmodels: 0.14.2
2024-06-11 23:00:52,117:INFO:              sktime: 0.26.0
2024-06-11 23:00:52,117:INFO:               tbats: 1.1.3
2024-06-11 23:00:52,117:INFO:            pmdarima: 2.0.4
2024-06-11 23:00:52,117:INFO:              psutil: 5.9.8
2024-06-11 23:00:52,117:INFO:          markupsafe: 2.1.5
2024-06-11 23:00:52,117:INFO:             pickle5: Not installed
2024-06-11 23:00:52,117:INFO:         cloudpickle: 3.0.0
2024-06-11 23:00:52,117:INFO:         deprecation: 2.1.0
2024-06-11 23:00:52,117:INFO:              xxhash: 3.4.1
2024-06-11 23:00:52,117:INFO:           wurlitzer: Not installed
2024-06-11 23:00:52,117:INFO:PyCaret optional dependencies:
2024-06-11 23:00:52,127:INFO:                shap: Not installed
2024-06-11 23:00:52,128:INFO:           interpret: Not installed
2024-06-11 23:00:52,128:INFO:                umap: Not installed
2024-06-11 23:00:52,128:INFO:     ydata_profiling: Not installed
2024-06-11 23:00:52,128:INFO:  explainerdashboard: Not installed
2024-06-11 23:00:52,128:INFO:             autoviz: Not installed
2024-06-11 23:00:52,128:INFO:           fairlearn: Not installed
2024-06-11 23:00:52,128:INFO:          deepchecks: Not installed
2024-06-11 23:00:52,128:INFO:             xgboost: Not installed
2024-06-11 23:00:52,128:INFO:            catboost: Not installed
2024-06-11 23:00:52,128:INFO:              kmodes: Not installed
2024-06-11 23:00:52,128:INFO:             mlxtend: Not installed
2024-06-11 23:00:52,128:INFO:       statsforecast: Not installed
2024-06-11 23:00:52,128:INFO:        tune_sklearn: Not installed
2024-06-11 23:00:52,128:INFO:                 ray: Not installed
2024-06-11 23:00:52,128:INFO:            hyperopt: Not installed
2024-06-11 23:00:52,128:INFO:              optuna: Not installed
2024-06-11 23:00:52,128:INFO:               skopt: Not installed
2024-06-11 23:00:52,128:INFO:              mlflow: Not installed
2024-06-11 23:00:52,128:INFO:              gradio: Not installed
2024-06-11 23:00:52,128:INFO:             fastapi: Not installed
2024-06-11 23:00:52,128:INFO:             uvicorn: Not installed
2024-06-11 23:00:52,129:INFO:              m2cgen: Not installed
2024-06-11 23:00:52,129:INFO:           evidently: Not installed
2024-06-11 23:00:52,129:INFO:               fugue: Not installed
2024-06-11 23:00:52,129:INFO:           streamlit: 1.35.0
2024-06-11 23:00:52,129:INFO:             prophet: Not installed
2024-06-11 23:00:52,129:INFO:None
2024-06-11 23:00:52,129:INFO:Set up data.
2024-06-12 09:53:31,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:53:31,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:53:31,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:53:31,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:54:36,922:INFO:PyCaret ClassificationExperiment
2024-06-12 09:54:36,922:INFO:Logging name: clf-default-name
2024-06-12 09:54:36,922:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 09:54:36,922:INFO:version 3.3.2
2024-06-12 09:54:36,922:INFO:Initializing setup()
2024-06-12 09:54:36,922:INFO:self.USI: b8a9
2024-06-12 09:54:36,922:INFO:self._variable_keys: {'_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'data', 'fix_imbalance', 'y_test', 'y', 'idx', 'is_multiclass', 'fold_shuffle_param', 'seed', 'log_plots_param', 'y_train', 'USI', 'logging_param', '_available_plots', 'target_param', 'html_param', 'X_test', 'n_jobs_param', 'X', 'X_train', 'exp_name_log', 'fold_generator', 'pipeline', 'memory', 'gpu_param'}
2024-06-12 09:54:36,922:INFO:Checking environment
2024-06-12 09:54:36,922:INFO:python_version: 3.11.9
2024-06-12 09:54:36,922:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 09:54:36,922:INFO:machine: AMD64
2024-06-12 09:54:36,922:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 09:54:36,922:INFO:Memory: svmem(total=34056318976, available=25553518592, percent=25.0, used=8502800384, free=25553518592)
2024-06-12 09:54:36,922:INFO:Physical Core: 6
2024-06-12 09:54:36,922:INFO:Logical Core: 12
2024-06-12 09:54:36,922:INFO:Checking libraries
2024-06-12 09:54:36,922:INFO:System:
2024-06-12 09:54:36,922:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 09:54:36,922:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 09:54:36,922:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 09:54:36,922:INFO:PyCaret required dependencies:
2024-06-12 09:54:36,972:INFO:                 pip: 24.0
2024-06-12 09:54:36,972:INFO:          setuptools: 69.5.1
2024-06-12 09:54:36,972:INFO:             pycaret: 3.3.2
2024-06-12 09:54:36,972:INFO:             IPython: 8.25.0
2024-06-12 09:54:36,972:INFO:          ipywidgets: 8.1.3
2024-06-12 09:54:36,972:INFO:                tqdm: 4.66.4
2024-06-12 09:54:36,972:INFO:               numpy: 1.26.4
2024-06-12 09:54:36,972:INFO:              pandas: 2.1.4
2024-06-12 09:54:36,972:INFO:              jinja2: 3.1.4
2024-06-12 09:54:36,972:INFO:               scipy: 1.11.4
2024-06-12 09:54:36,972:INFO:              joblib: 1.3.2
2024-06-12 09:54:36,972:INFO:             sklearn: 1.4.2
2024-06-12 09:54:36,972:INFO:                pyod: 2.0.0
2024-06-12 09:54:36,972:INFO:            imblearn: 0.12.3
2024-06-12 09:54:36,972:INFO:   category_encoders: 2.6.3
2024-06-12 09:54:36,972:INFO:            lightgbm: 4.3.0
2024-06-12 09:54:36,972:INFO:               numba: 0.59.1
2024-06-12 09:54:36,972:INFO:            requests: 2.32.3
2024-06-12 09:54:36,972:INFO:          matplotlib: 3.7.5
2024-06-12 09:54:36,972:INFO:          scikitplot: 0.3.7
2024-06-12 09:54:36,972:INFO:         yellowbrick: 1.5
2024-06-12 09:54:36,972:INFO:              plotly: 5.22.0
2024-06-12 09:54:36,972:INFO:    plotly-resampler: Not installed
2024-06-12 09:54:36,972:INFO:             kaleido: 0.2.1
2024-06-12 09:54:36,972:INFO:           schemdraw: 0.15
2024-06-12 09:54:36,972:INFO:         statsmodels: 0.14.2
2024-06-12 09:54:36,972:INFO:              sktime: 0.26.0
2024-06-12 09:54:36,972:INFO:               tbats: 1.1.3
2024-06-12 09:54:36,972:INFO:            pmdarima: 2.0.4
2024-06-12 09:54:36,972:INFO:              psutil: 5.9.8
2024-06-12 09:54:36,972:INFO:          markupsafe: 2.1.5
2024-06-12 09:54:36,972:INFO:             pickle5: Not installed
2024-06-12 09:54:36,972:INFO:         cloudpickle: 3.0.0
2024-06-12 09:54:36,972:INFO:         deprecation: 2.1.0
2024-06-12 09:54:36,972:INFO:              xxhash: 3.4.1
2024-06-12 09:54:36,972:INFO:           wurlitzer: Not installed
2024-06-12 09:54:36,972:INFO:PyCaret optional dependencies:
2024-06-12 09:54:36,981:INFO:                shap: Not installed
2024-06-12 09:54:36,981:INFO:           interpret: Not installed
2024-06-12 09:54:36,981:INFO:                umap: Not installed
2024-06-12 09:54:36,981:INFO:     ydata_profiling: Not installed
2024-06-12 09:54:36,981:INFO:  explainerdashboard: Not installed
2024-06-12 09:54:36,981:INFO:             autoviz: Not installed
2024-06-12 09:54:36,981:INFO:           fairlearn: Not installed
2024-06-12 09:54:36,981:INFO:          deepchecks: Not installed
2024-06-12 09:54:36,981:INFO:             xgboost: Not installed
2024-06-12 09:54:36,981:INFO:            catboost: Not installed
2024-06-12 09:54:36,981:INFO:              kmodes: Not installed
2024-06-12 09:54:36,981:INFO:             mlxtend: Not installed
2024-06-12 09:54:36,981:INFO:       statsforecast: Not installed
2024-06-12 09:54:36,981:INFO:        tune_sklearn: Not installed
2024-06-12 09:54:36,981:INFO:                 ray: Not installed
2024-06-12 09:54:36,981:INFO:            hyperopt: Not installed
2024-06-12 09:54:36,981:INFO:              optuna: Not installed
2024-06-12 09:54:36,981:INFO:               skopt: Not installed
2024-06-12 09:54:36,981:INFO:              mlflow: Not installed
2024-06-12 09:54:36,981:INFO:              gradio: Not installed
2024-06-12 09:54:36,981:INFO:             fastapi: Not installed
2024-06-12 09:54:36,981:INFO:             uvicorn: Not installed
2024-06-12 09:54:36,981:INFO:              m2cgen: Not installed
2024-06-12 09:54:36,981:INFO:           evidently: Not installed
2024-06-12 09:54:36,981:INFO:               fugue: Not installed
2024-06-12 09:54:36,981:INFO:           streamlit: 1.35.0
2024-06-12 09:54:36,981:INFO:             prophet: Not installed
2024-06-12 09:54:36,981:INFO:None
2024-06-12 09:54:36,981:INFO:Set up data.
2024-06-12 09:55:41,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:55:41,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:55:41,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:55:41,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:55:44,372:INFO:PyCaret ClassificationExperiment
2024-06-12 09:55:44,373:INFO:Logging name: clf-default-name
2024-06-12 09:55:44,373:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 09:55:44,373:INFO:version 3.3.2
2024-06-12 09:55:44,373:INFO:Initializing setup()
2024-06-12 09:55:44,373:INFO:self.USI: 88c0
2024-06-12 09:55:44,373:INFO:self._variable_keys: {'fold_groups_param', 'y_test', 'y_train', '_ml_usecase', 'exp_name_log', 'target_param', 'X_train', 'gpu_param', 'html_param', 'memory', 'pipeline', 'data', 'seed', 'fold_shuffle_param', 'logging_param', 'n_jobs_param', 'y', 'X', 'X_test', 'USI', 'fix_imbalance', '_available_plots', 'idx', 'gpu_n_jobs_param', 'log_plots_param', 'exp_id', 'fold_generator', 'is_multiclass'}
2024-06-12 09:55:44,374:INFO:Checking environment
2024-06-12 09:55:44,374:INFO:python_version: 3.11.9
2024-06-12 09:55:44,374:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 09:55:44,374:INFO:machine: AMD64
2024-06-12 09:55:44,374:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 09:55:44,374:INFO:Memory: svmem(total=34056318976, available=28463087616, percent=16.4, used=5593231360, free=28463087616)
2024-06-12 09:55:44,374:INFO:Physical Core: 6
2024-06-12 09:55:44,374:INFO:Logical Core: 12
2024-06-12 09:55:44,374:INFO:Checking libraries
2024-06-12 09:55:44,374:INFO:System:
2024-06-12 09:55:44,374:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 09:55:44,374:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 09:55:44,374:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 09:55:44,374:INFO:PyCaret required dependencies:
2024-06-12 09:55:44,417:INFO:                 pip: 24.0
2024-06-12 09:55:44,417:INFO:          setuptools: 69.5.1
2024-06-12 09:55:44,417:INFO:             pycaret: 3.3.2
2024-06-12 09:55:44,418:INFO:             IPython: 8.25.0
2024-06-12 09:55:44,418:INFO:          ipywidgets: 8.1.3
2024-06-12 09:55:44,418:INFO:                tqdm: 4.66.4
2024-06-12 09:55:44,418:INFO:               numpy: 1.26.4
2024-06-12 09:55:44,418:INFO:              pandas: 2.1.4
2024-06-12 09:55:44,418:INFO:              jinja2: 3.1.4
2024-06-12 09:55:44,418:INFO:               scipy: 1.11.4
2024-06-12 09:55:44,418:INFO:              joblib: 1.3.2
2024-06-12 09:55:44,418:INFO:             sklearn: 1.4.2
2024-06-12 09:55:44,419:INFO:                pyod: 2.0.0
2024-06-12 09:55:44,419:INFO:            imblearn: 0.12.3
2024-06-12 09:55:44,419:INFO:   category_encoders: 2.6.3
2024-06-12 09:55:44,419:INFO:            lightgbm: 4.3.0
2024-06-12 09:55:44,419:INFO:               numba: 0.59.1
2024-06-12 09:55:44,419:INFO:            requests: 2.32.3
2024-06-12 09:55:44,419:INFO:          matplotlib: 3.7.5
2024-06-12 09:55:44,419:INFO:          scikitplot: 0.3.7
2024-06-12 09:55:44,419:INFO:         yellowbrick: 1.5
2024-06-12 09:55:44,419:INFO:              plotly: 5.22.0
2024-06-12 09:55:44,419:INFO:    plotly-resampler: Not installed
2024-06-12 09:55:44,419:INFO:             kaleido: 0.2.1
2024-06-12 09:55:44,419:INFO:           schemdraw: 0.15
2024-06-12 09:55:44,419:INFO:         statsmodels: 0.14.2
2024-06-12 09:55:44,419:INFO:              sktime: 0.26.0
2024-06-12 09:55:44,419:INFO:               tbats: 1.1.3
2024-06-12 09:55:44,419:INFO:            pmdarima: 2.0.4
2024-06-12 09:55:44,419:INFO:              psutil: 5.9.8
2024-06-12 09:55:44,419:INFO:          markupsafe: 2.1.5
2024-06-12 09:55:44,420:INFO:             pickle5: Not installed
2024-06-12 09:55:44,420:INFO:         cloudpickle: 3.0.0
2024-06-12 09:55:44,420:INFO:         deprecation: 2.1.0
2024-06-12 09:55:44,420:INFO:              xxhash: 3.4.1
2024-06-12 09:55:44,420:INFO:           wurlitzer: Not installed
2024-06-12 09:55:44,420:INFO:PyCaret optional dependencies:
2024-06-12 09:55:44,432:INFO:                shap: Not installed
2024-06-12 09:55:44,433:INFO:           interpret: Not installed
2024-06-12 09:55:44,433:INFO:                umap: Not installed
2024-06-12 09:55:44,433:INFO:     ydata_profiling: Not installed
2024-06-12 09:55:44,433:INFO:  explainerdashboard: Not installed
2024-06-12 09:55:44,433:INFO:             autoviz: Not installed
2024-06-12 09:55:44,433:INFO:           fairlearn: Not installed
2024-06-12 09:55:44,433:INFO:          deepchecks: Not installed
2024-06-12 09:55:44,433:INFO:             xgboost: Not installed
2024-06-12 09:55:44,433:INFO:            catboost: Not installed
2024-06-12 09:55:44,433:INFO:              kmodes: Not installed
2024-06-12 09:55:44,433:INFO:             mlxtend: Not installed
2024-06-12 09:55:44,433:INFO:       statsforecast: Not installed
2024-06-12 09:55:44,433:INFO:        tune_sklearn: Not installed
2024-06-12 09:55:44,433:INFO:                 ray: Not installed
2024-06-12 09:55:44,433:INFO:            hyperopt: Not installed
2024-06-12 09:55:44,433:INFO:              optuna: Not installed
2024-06-12 09:55:44,433:INFO:               skopt: Not installed
2024-06-12 09:55:44,433:INFO:              mlflow: Not installed
2024-06-12 09:55:44,433:INFO:              gradio: Not installed
2024-06-12 09:55:44,433:INFO:             fastapi: Not installed
2024-06-12 09:55:44,433:INFO:             uvicorn: Not installed
2024-06-12 09:55:44,433:INFO:              m2cgen: Not installed
2024-06-12 09:55:44,433:INFO:           evidently: Not installed
2024-06-12 09:55:44,433:INFO:               fugue: Not installed
2024-06-12 09:55:44,433:INFO:           streamlit: 1.35.0
2024-06-12 09:55:44,435:INFO:             prophet: Not installed
2024-06-12 09:55:44,435:INFO:None
2024-06-12 09:55:44,435:INFO:Set up data.
2024-06-12 09:58:42,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:58:42,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:58:42,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:58:42,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:58:51,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:58:51,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:58:51,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 09:58:51,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:01:57,112:INFO:PyCaret ClassificationExperiment
2024-06-12 10:01:57,112:INFO:Logging name: clf-default-name
2024-06-12 10:01:57,112:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 10:01:57,112:INFO:version 3.3.2
2024-06-12 10:01:57,112:INFO:Initializing setup()
2024-06-12 10:01:57,112:INFO:self.USI: a636
2024-06-12 10:01:57,112:INFO:self._variable_keys: {'exp_name_log', 'target_param', 'exp_id', 'y_train', 'is_multiclass', 'html_param', 'y', '_available_plots', 'gpu_n_jobs_param', 'fix_imbalance', 'log_plots_param', 'fold_groups_param', 'data', 'pipeline', 'logging_param', 'X_train', '_ml_usecase', 'idx', 'USI', 'X_test', 'n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'gpu_param', 'y_test', 'X', 'seed', 'memory'}
2024-06-12 10:01:57,112:INFO:Checking environment
2024-06-12 10:01:57,112:INFO:python_version: 3.11.9
2024-06-12 10:01:57,112:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 10:01:57,112:INFO:machine: AMD64
2024-06-12 10:01:57,114:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 10:01:57,114:INFO:Memory: svmem(total=34056318976, available=28812705792, percent=15.4, used=5243613184, free=28812705792)
2024-06-12 10:01:57,114:INFO:Physical Core: 6
2024-06-12 10:01:57,114:INFO:Logical Core: 12
2024-06-12 10:01:57,114:INFO:Checking libraries
2024-06-12 10:01:57,114:INFO:System:
2024-06-12 10:01:57,114:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 10:01:57,114:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 10:01:57,114:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 10:01:57,114:INFO:PyCaret required dependencies:
2024-06-12 10:01:57,151:INFO:                 pip: 24.0
2024-06-12 10:01:57,151:INFO:          setuptools: 69.5.1
2024-06-12 10:01:57,151:INFO:             pycaret: 3.3.2
2024-06-12 10:01:57,151:INFO:             IPython: 8.25.0
2024-06-12 10:01:57,151:INFO:          ipywidgets: 8.1.3
2024-06-12 10:01:57,151:INFO:                tqdm: 4.66.4
2024-06-12 10:01:57,151:INFO:               numpy: 1.26.4
2024-06-12 10:01:57,151:INFO:              pandas: 2.1.4
2024-06-12 10:01:57,151:INFO:              jinja2: 3.1.4
2024-06-12 10:01:57,151:INFO:               scipy: 1.11.4
2024-06-12 10:01:57,151:INFO:              joblib: 1.3.2
2024-06-12 10:01:57,151:INFO:             sklearn: 1.4.2
2024-06-12 10:01:57,151:INFO:                pyod: 2.0.0
2024-06-12 10:01:57,151:INFO:            imblearn: 0.12.3
2024-06-12 10:01:57,151:INFO:   category_encoders: 2.6.3
2024-06-12 10:01:57,151:INFO:            lightgbm: 4.3.0
2024-06-12 10:01:57,151:INFO:               numba: 0.59.1
2024-06-12 10:01:57,151:INFO:            requests: 2.32.3
2024-06-12 10:01:57,151:INFO:          matplotlib: 3.7.5
2024-06-12 10:01:57,151:INFO:          scikitplot: 0.3.7
2024-06-12 10:01:57,151:INFO:         yellowbrick: 1.5
2024-06-12 10:01:57,151:INFO:              plotly: 5.22.0
2024-06-12 10:01:57,151:INFO:    plotly-resampler: Not installed
2024-06-12 10:01:57,151:INFO:             kaleido: 0.2.1
2024-06-12 10:01:57,151:INFO:           schemdraw: 0.15
2024-06-12 10:01:57,151:INFO:         statsmodels: 0.14.2
2024-06-12 10:01:57,151:INFO:              sktime: 0.26.0
2024-06-12 10:01:57,151:INFO:               tbats: 1.1.3
2024-06-12 10:01:57,151:INFO:            pmdarima: 2.0.4
2024-06-12 10:01:57,151:INFO:              psutil: 5.9.8
2024-06-12 10:01:57,151:INFO:          markupsafe: 2.1.5
2024-06-12 10:01:57,151:INFO:             pickle5: Not installed
2024-06-12 10:01:57,151:INFO:         cloudpickle: 3.0.0
2024-06-12 10:01:57,151:INFO:         deprecation: 2.1.0
2024-06-12 10:01:57,151:INFO:              xxhash: 3.4.1
2024-06-12 10:01:57,151:INFO:           wurlitzer: Not installed
2024-06-12 10:01:57,151:INFO:PyCaret optional dependencies:
2024-06-12 10:01:57,169:INFO:                shap: Not installed
2024-06-12 10:01:57,169:INFO:           interpret: Not installed
2024-06-12 10:01:57,169:INFO:                umap: Not installed
2024-06-12 10:01:57,169:INFO:     ydata_profiling: Not installed
2024-06-12 10:01:57,169:INFO:  explainerdashboard: Not installed
2024-06-12 10:01:57,169:INFO:             autoviz: Not installed
2024-06-12 10:01:57,169:INFO:           fairlearn: Not installed
2024-06-12 10:01:57,169:INFO:          deepchecks: Not installed
2024-06-12 10:01:57,169:INFO:             xgboost: Not installed
2024-06-12 10:01:57,169:INFO:            catboost: Not installed
2024-06-12 10:01:57,169:INFO:              kmodes: Not installed
2024-06-12 10:01:57,169:INFO:             mlxtend: Not installed
2024-06-12 10:01:57,169:INFO:       statsforecast: Not installed
2024-06-12 10:01:57,169:INFO:        tune_sklearn: Not installed
2024-06-12 10:01:57,169:INFO:                 ray: Not installed
2024-06-12 10:01:57,169:INFO:            hyperopt: Not installed
2024-06-12 10:01:57,169:INFO:              optuna: Not installed
2024-06-12 10:01:57,169:INFO:               skopt: Not installed
2024-06-12 10:01:57,169:INFO:              mlflow: Not installed
2024-06-12 10:01:57,169:INFO:              gradio: Not installed
2024-06-12 10:01:57,169:INFO:             fastapi: Not installed
2024-06-12 10:01:57,169:INFO:             uvicorn: Not installed
2024-06-12 10:01:57,169:INFO:              m2cgen: Not installed
2024-06-12 10:01:57,169:INFO:           evidently: Not installed
2024-06-12 10:01:57,169:INFO:               fugue: Not installed
2024-06-12 10:01:57,169:INFO:           streamlit: 1.35.0
2024-06-12 10:01:57,169:INFO:             prophet: Not installed
2024-06-12 10:01:57,169:INFO:None
2024-06-12 10:01:57,169:INFO:Set up data.
2024-06-12 10:03:59,979:INFO:Set up folding strategy.
2024-06-12 10:03:59,990:INFO:Set up train/test split.
2024-06-12 10:05:19,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:05:19,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:05:19,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:05:19,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:05:22,172:INFO:PyCaret ClassificationExperiment
2024-06-12 10:05:22,172:INFO:Logging name: clf-default-name
2024-06-12 10:05:22,172:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 10:05:22,172:INFO:version 3.3.2
2024-06-12 10:05:22,173:INFO:Initializing setup()
2024-06-12 10:05:22,173:INFO:self.USI: 670d
2024-06-12 10:05:22,173:INFO:self._variable_keys: {'X_train', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', '_available_plots', 'is_multiclass', 'idx', 'n_jobs_param', 'gpu_param', 'y_train', 'gpu_n_jobs_param', 'log_plots_param', 'X', 'html_param', 'USI', '_ml_usecase', 'X_test', 'logging_param', 'target_param', 'exp_name_log', 'memory', 'seed', 'data', 'y', 'y_test', 'fold_generator', 'pipeline', 'fix_imbalance'}
2024-06-12 10:05:22,173:INFO:Checking environment
2024-06-12 10:05:22,173:INFO:python_version: 3.11.9
2024-06-12 10:05:22,173:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 10:05:22,173:INFO:machine: AMD64
2024-06-12 10:05:22,173:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 10:05:22,173:INFO:Memory: svmem(total=34056318976, available=28811423744, percent=15.4, used=5244895232, free=28811423744)
2024-06-12 10:05:22,173:INFO:Physical Core: 6
2024-06-12 10:05:22,173:INFO:Logical Core: 12
2024-06-12 10:05:22,173:INFO:Checking libraries
2024-06-12 10:05:22,173:INFO:System:
2024-06-12 10:05:22,173:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 10:05:22,173:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 10:05:22,173:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 10:05:22,173:INFO:PyCaret required dependencies:
2024-06-12 10:05:22,196:INFO:                 pip: 24.0
2024-06-12 10:05:22,196:INFO:          setuptools: 69.5.1
2024-06-12 10:05:22,196:INFO:             pycaret: 3.3.2
2024-06-12 10:05:22,196:INFO:             IPython: 8.25.0
2024-06-12 10:05:22,196:INFO:          ipywidgets: 8.1.3
2024-06-12 10:05:22,196:INFO:                tqdm: 4.66.4
2024-06-12 10:05:22,196:INFO:               numpy: 1.26.4
2024-06-12 10:05:22,196:INFO:              pandas: 2.1.4
2024-06-12 10:05:22,196:INFO:              jinja2: 3.1.4
2024-06-12 10:05:22,196:INFO:               scipy: 1.11.4
2024-06-12 10:05:22,196:INFO:              joblib: 1.3.2
2024-06-12 10:05:22,196:INFO:             sklearn: 1.4.2
2024-06-12 10:05:22,196:INFO:                pyod: 2.0.0
2024-06-12 10:05:22,196:INFO:            imblearn: 0.12.3
2024-06-12 10:05:22,196:INFO:   category_encoders: 2.6.3
2024-06-12 10:05:22,196:INFO:            lightgbm: 4.3.0
2024-06-12 10:05:22,196:INFO:               numba: 0.59.1
2024-06-12 10:05:22,196:INFO:            requests: 2.32.3
2024-06-12 10:05:22,196:INFO:          matplotlib: 3.7.5
2024-06-12 10:05:22,196:INFO:          scikitplot: 0.3.7
2024-06-12 10:05:22,196:INFO:         yellowbrick: 1.5
2024-06-12 10:05:22,196:INFO:              plotly: 5.22.0
2024-06-12 10:05:22,196:INFO:    plotly-resampler: Not installed
2024-06-12 10:05:22,196:INFO:             kaleido: 0.2.1
2024-06-12 10:05:22,196:INFO:           schemdraw: 0.15
2024-06-12 10:05:22,196:INFO:         statsmodels: 0.14.2
2024-06-12 10:05:22,196:INFO:              sktime: 0.26.0
2024-06-12 10:05:22,196:INFO:               tbats: 1.1.3
2024-06-12 10:05:22,196:INFO:            pmdarima: 2.0.4
2024-06-12 10:05:22,196:INFO:              psutil: 5.9.8
2024-06-12 10:05:22,196:INFO:          markupsafe: 2.1.5
2024-06-12 10:05:22,196:INFO:             pickle5: Not installed
2024-06-12 10:05:22,196:INFO:         cloudpickle: 3.0.0
2024-06-12 10:05:22,196:INFO:         deprecation: 2.1.0
2024-06-12 10:05:22,196:INFO:              xxhash: 3.4.1
2024-06-12 10:05:22,196:INFO:           wurlitzer: Not installed
2024-06-12 10:05:22,196:INFO:PyCaret optional dependencies:
2024-06-12 10:05:22,213:INFO:                shap: Not installed
2024-06-12 10:05:22,213:INFO:           interpret: Not installed
2024-06-12 10:05:22,213:INFO:                umap: Not installed
2024-06-12 10:05:22,213:INFO:     ydata_profiling: Not installed
2024-06-12 10:05:22,213:INFO:  explainerdashboard: Not installed
2024-06-12 10:05:22,213:INFO:             autoviz: Not installed
2024-06-12 10:05:22,213:INFO:           fairlearn: Not installed
2024-06-12 10:05:22,213:INFO:          deepchecks: Not installed
2024-06-12 10:05:22,213:INFO:             xgboost: Not installed
2024-06-12 10:05:22,213:INFO:            catboost: Not installed
2024-06-12 10:05:22,213:INFO:              kmodes: Not installed
2024-06-12 10:05:22,213:INFO:             mlxtend: Not installed
2024-06-12 10:05:22,213:INFO:       statsforecast: Not installed
2024-06-12 10:05:22,213:INFO:        tune_sklearn: Not installed
2024-06-12 10:05:22,213:INFO:                 ray: Not installed
2024-06-12 10:05:22,213:INFO:            hyperopt: Not installed
2024-06-12 10:05:22,213:INFO:              optuna: Not installed
2024-06-12 10:05:22,213:INFO:               skopt: Not installed
2024-06-12 10:05:22,213:INFO:              mlflow: Not installed
2024-06-12 10:05:22,213:INFO:              gradio: Not installed
2024-06-12 10:05:22,213:INFO:             fastapi: Not installed
2024-06-12 10:05:22,213:INFO:             uvicorn: Not installed
2024-06-12 10:05:22,214:INFO:              m2cgen: Not installed
2024-06-12 10:05:22,214:INFO:           evidently: Not installed
2024-06-12 10:05:22,214:INFO:               fugue: Not installed
2024-06-12 10:05:22,214:INFO:           streamlit: 1.35.0
2024-06-12 10:05:22,214:INFO:             prophet: Not installed
2024-06-12 10:05:22,214:INFO:None
2024-06-12 10:05:22,214:INFO:Set up data.
2024-06-12 10:05:22,246:INFO:Set up folding strategy.
2024-06-12 10:05:22,246:INFO:Set up train/test split.
2024-06-12 10:05:22,262:INFO:Set up index.
2024-06-12 10:05:22,277:INFO:Assigning column types.
2024-06-12 10:05:22,286:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 10:05:22,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:05:22,332:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:05:22,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:05:22,412:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:05:22,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,439:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 10:05:22,484:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:05:22,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,564:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:05:22,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,598:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 10:05:22,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:22,763:INFO:Preparing preprocessing pipeline...
2024-06-12 10:05:22,763:INFO:Set up simple imputation.
2024-06-12 10:05:22,778:INFO:Set up encoding of ordinal features.
2024-06-12 10:05:22,780:INFO:Set up encoding of categorical features.
2024-06-12 10:05:22,780:INFO:Set up removing outliers.
2024-06-12 10:05:22,780:INFO:Set up imbalanced handling.
2024-06-12 10:05:22,780:INFO:Set up feature normalization.
2024-06-12 10:05:22,780:INFO:Set up PCA.
2024-06-12 10:05:26,133:INFO:Finished creating preprocessing pipeline.
2024-06-12 10:05:26,167:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 10:05:26,167:INFO:Creating final display dataframe.
2024-06-12 10:05:29,719:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (47395, 30)
5   Transformed train set shape       (32395, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method        TomekLinks
20                    Normalize              True
21             Normalize method            robust
22                          PCA              True
23                   PCA method            linear
24               PCA components              None
25               Fold Generator   StratifiedKFold
26                  Fold Number                10
27                     CPU Jobs                -1
28                      Use GPU             False
29               Log Experiment             False
30              Experiment Name  clf-default-name
31                          USI              670d
2024-06-12 10:05:29,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:29,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:29,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:29,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:05:29,941:INFO:setup() successfully completed in 7.93s...............
2024-06-12 10:05:29,962:INFO:Initializing create_model()
2024-06-12 10:05:29,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FEA5150CD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:05:29,963:INFO:Checking exceptions
2024-06-12 10:05:29,980:INFO:Importing libraries
2024-06-12 10:05:29,980:INFO:Copying training dataset
2024-06-12 10:05:30,011:INFO:Defining folds
2024-06-12 10:05:30,011:INFO:Declaring metric variables
2024-06-12 10:05:30,013:INFO:Importing untrained model
2024-06-12 10:05:30,022:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:05:30,029:INFO:Starting cross validation
2024-06-12 10:05:30,045:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:05:46,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:05:46,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:05:46,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:05:46,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:05:47,494:INFO:PyCaret ClassificationExperiment
2024-06-12 10:05:47,494:INFO:Logging name: clf-default-name
2024-06-12 10:05:47,494:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 10:05:47,494:INFO:version 3.3.2
2024-06-12 10:05:47,494:INFO:Initializing setup()
2024-06-12 10:05:47,494:INFO:self.USI: a8a1
2024-06-12 10:05:47,494:INFO:self._variable_keys: {'is_multiclass', 'fold_groups_param', 'html_param', '_available_plots', 'USI', 'pipeline', 'X', 'seed', '_ml_usecase', 'fold_generator', 'X_train', 'fold_shuffle_param', 'memory', 'exp_name_log', 'gpu_param', 'data', 'y_train', 'idx', 'y_test', 'logging_param', 'fix_imbalance', 'log_plots_param', 'exp_id', 'n_jobs_param', 'y', 'X_test', 'target_param', 'gpu_n_jobs_param'}
2024-06-12 10:05:47,494:INFO:Checking environment
2024-06-12 10:05:47,494:INFO:python_version: 3.11.9
2024-06-12 10:05:47,494:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 10:05:47,494:INFO:machine: AMD64
2024-06-12 10:05:47,494:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 10:05:47,494:INFO:Memory: svmem(total=34056318976, available=28608548864, percent=16.0, used=5447770112, free=28608548864)
2024-06-12 10:05:47,494:INFO:Physical Core: 6
2024-06-12 10:05:47,494:INFO:Logical Core: 12
2024-06-12 10:05:47,494:INFO:Checking libraries
2024-06-12 10:05:47,494:INFO:System:
2024-06-12 10:05:47,494:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 10:05:47,494:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 10:05:47,494:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 10:05:47,494:INFO:PyCaret required dependencies:
2024-06-12 10:05:47,527:INFO:                 pip: 24.0
2024-06-12 10:05:47,527:INFO:          setuptools: 69.5.1
2024-06-12 10:05:47,527:INFO:             pycaret: 3.3.2
2024-06-12 10:05:47,527:INFO:             IPython: 8.25.0
2024-06-12 10:05:47,527:INFO:          ipywidgets: 8.1.3
2024-06-12 10:05:47,527:INFO:                tqdm: 4.66.4
2024-06-12 10:05:47,527:INFO:               numpy: 1.26.4
2024-06-12 10:05:47,527:INFO:              pandas: 2.1.4
2024-06-12 10:05:47,527:INFO:              jinja2: 3.1.4
2024-06-12 10:05:47,527:INFO:               scipy: 1.11.4
2024-06-12 10:05:47,527:INFO:              joblib: 1.3.2
2024-06-12 10:05:47,527:INFO:             sklearn: 1.4.2
2024-06-12 10:05:47,527:INFO:                pyod: 2.0.0
2024-06-12 10:05:47,527:INFO:            imblearn: 0.12.3
2024-06-12 10:05:47,527:INFO:   category_encoders: 2.6.3
2024-06-12 10:05:47,527:INFO:            lightgbm: 4.3.0
2024-06-12 10:05:47,527:INFO:               numba: 0.59.1
2024-06-12 10:05:47,527:INFO:            requests: 2.32.3
2024-06-12 10:05:47,527:INFO:          matplotlib: 3.7.5
2024-06-12 10:05:47,527:INFO:          scikitplot: 0.3.7
2024-06-12 10:05:47,528:INFO:         yellowbrick: 1.5
2024-06-12 10:05:47,528:INFO:              plotly: 5.22.0
2024-06-12 10:05:47,528:INFO:    plotly-resampler: Not installed
2024-06-12 10:05:47,528:INFO:             kaleido: 0.2.1
2024-06-12 10:05:47,528:INFO:           schemdraw: 0.15
2024-06-12 10:05:47,528:INFO:         statsmodels: 0.14.2
2024-06-12 10:05:47,528:INFO:              sktime: 0.26.0
2024-06-12 10:05:47,528:INFO:               tbats: 1.1.3
2024-06-12 10:05:47,528:INFO:            pmdarima: 2.0.4
2024-06-12 10:05:47,528:INFO:              psutil: 5.9.8
2024-06-12 10:05:47,528:INFO:          markupsafe: 2.1.5
2024-06-12 10:05:47,528:INFO:             pickle5: Not installed
2024-06-12 10:05:47,528:INFO:         cloudpickle: 3.0.0
2024-06-12 10:05:47,528:INFO:         deprecation: 2.1.0
2024-06-12 10:05:47,528:INFO:              xxhash: 3.4.1
2024-06-12 10:05:47,528:INFO:           wurlitzer: Not installed
2024-06-12 10:05:47,528:INFO:PyCaret optional dependencies:
2024-06-12 10:05:47,539:INFO:                shap: Not installed
2024-06-12 10:05:47,539:INFO:           interpret: Not installed
2024-06-12 10:05:47,539:INFO:                umap: Not installed
2024-06-12 10:05:47,539:INFO:     ydata_profiling: Not installed
2024-06-12 10:05:47,539:INFO:  explainerdashboard: Not installed
2024-06-12 10:05:47,539:INFO:             autoviz: Not installed
2024-06-12 10:05:47,539:INFO:           fairlearn: Not installed
2024-06-12 10:05:47,539:INFO:          deepchecks: Not installed
2024-06-12 10:05:47,539:INFO:             xgboost: Not installed
2024-06-12 10:05:47,539:INFO:            catboost: Not installed
2024-06-12 10:05:47,539:INFO:              kmodes: Not installed
2024-06-12 10:05:47,539:INFO:             mlxtend: Not installed
2024-06-12 10:05:47,539:INFO:       statsforecast: Not installed
2024-06-12 10:05:47,539:INFO:        tune_sklearn: Not installed
2024-06-12 10:05:47,539:INFO:                 ray: Not installed
2024-06-12 10:05:47,540:INFO:            hyperopt: Not installed
2024-06-12 10:05:47,540:INFO:              optuna: Not installed
2024-06-12 10:05:47,540:INFO:               skopt: Not installed
2024-06-12 10:05:47,540:INFO:              mlflow: Not installed
2024-06-12 10:05:47,540:INFO:              gradio: Not installed
2024-06-12 10:05:47,540:INFO:             fastapi: Not installed
2024-06-12 10:05:47,540:INFO:             uvicorn: Not installed
2024-06-12 10:05:47,540:INFO:              m2cgen: Not installed
2024-06-12 10:05:47,540:INFO:           evidently: Not installed
2024-06-12 10:05:47,540:INFO:               fugue: Not installed
2024-06-12 10:05:47,540:INFO:           streamlit: 1.35.0
2024-06-12 10:05:47,540:INFO:             prophet: Not installed
2024-06-12 10:05:47,540:INFO:None
2024-06-12 10:05:47,540:INFO:Set up data.
2024-06-12 10:06:19,380:INFO:PyCaret ClassificationExperiment
2024-06-12 10:06:19,380:INFO:Logging name: clf-default-name
2024-06-12 10:06:19,380:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 10:06:19,380:INFO:version 3.3.2
2024-06-12 10:06:19,380:INFO:Initializing setup()
2024-06-12 10:06:19,380:INFO:self.USI: 33a3
2024-06-12 10:06:19,380:INFO:self._variable_keys: {'is_multiclass', 'fold_groups_param', 'html_param', '_available_plots', 'USI', 'pipeline', 'X', 'seed', '_ml_usecase', 'fold_generator', 'X_train', 'fold_shuffle_param', 'memory', 'exp_name_log', 'gpu_param', 'data', 'y_train', 'idx', 'y_test', 'logging_param', 'fix_imbalance', 'log_plots_param', 'exp_id', 'n_jobs_param', 'y', 'X_test', 'target_param', 'gpu_n_jobs_param'}
2024-06-12 10:06:19,380:INFO:Checking environment
2024-06-12 10:06:19,380:INFO:python_version: 3.11.9
2024-06-12 10:06:19,380:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 10:06:19,380:INFO:machine: AMD64
2024-06-12 10:06:19,380:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 10:06:19,380:INFO:Memory: svmem(total=34056318976, available=5154148352, percent=84.9, used=28902170624, free=5154148352)
2024-06-12 10:06:19,380:INFO:Physical Core: 6
2024-06-12 10:06:19,380:INFO:Logical Core: 12
2024-06-12 10:06:19,380:INFO:Checking libraries
2024-06-12 10:06:19,380:INFO:System:
2024-06-12 10:06:19,380:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 10:06:19,380:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 10:06:19,380:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 10:06:19,380:INFO:PyCaret required dependencies:
2024-06-12 10:06:19,380:INFO:                 pip: 24.0
2024-06-12 10:06:19,380:INFO:          setuptools: 69.5.1
2024-06-12 10:06:19,380:INFO:             pycaret: 3.3.2
2024-06-12 10:06:19,380:INFO:             IPython: 8.25.0
2024-06-12 10:06:19,380:INFO:          ipywidgets: 8.1.3
2024-06-12 10:06:19,380:INFO:                tqdm: 4.66.4
2024-06-12 10:06:19,380:INFO:               numpy: 1.26.4
2024-06-12 10:06:19,380:INFO:              pandas: 2.1.4
2024-06-12 10:06:19,380:INFO:              jinja2: 3.1.4
2024-06-12 10:06:19,380:INFO:               scipy: 1.11.4
2024-06-12 10:06:19,380:INFO:              joblib: 1.3.2
2024-06-12 10:06:19,380:INFO:             sklearn: 1.4.2
2024-06-12 10:06:19,380:INFO:                pyod: 2.0.0
2024-06-12 10:06:19,380:INFO:            imblearn: 0.12.3
2024-06-12 10:06:19,380:INFO:   category_encoders: 2.6.3
2024-06-12 10:06:19,380:INFO:            lightgbm: 4.3.0
2024-06-12 10:06:19,380:INFO:               numba: 0.59.1
2024-06-12 10:06:19,380:INFO:            requests: 2.32.3
2024-06-12 10:06:19,380:INFO:          matplotlib: 3.7.5
2024-06-12 10:06:19,380:INFO:          scikitplot: 0.3.7
2024-06-12 10:06:19,380:INFO:         yellowbrick: 1.5
2024-06-12 10:06:19,380:INFO:              plotly: 5.22.0
2024-06-12 10:06:19,380:INFO:    plotly-resampler: Not installed
2024-06-12 10:06:19,380:INFO:             kaleido: 0.2.1
2024-06-12 10:06:19,380:INFO:           schemdraw: 0.15
2024-06-12 10:06:19,380:INFO:         statsmodels: 0.14.2
2024-06-12 10:06:19,380:INFO:              sktime: 0.26.0
2024-06-12 10:06:19,380:INFO:               tbats: 1.1.3
2024-06-12 10:06:19,380:INFO:            pmdarima: 2.0.4
2024-06-12 10:06:19,380:INFO:              psutil: 5.9.8
2024-06-12 10:06:19,380:INFO:          markupsafe: 2.1.5
2024-06-12 10:06:19,380:INFO:             pickle5: Not installed
2024-06-12 10:06:19,380:INFO:         cloudpickle: 3.0.0
2024-06-12 10:06:19,380:INFO:         deprecation: 2.1.0
2024-06-12 10:06:19,380:INFO:              xxhash: 3.4.1
2024-06-12 10:06:19,380:INFO:           wurlitzer: Not installed
2024-06-12 10:06:19,380:INFO:PyCaret optional dependencies:
2024-06-12 10:06:19,380:INFO:                shap: Not installed
2024-06-12 10:06:19,380:INFO:           interpret: Not installed
2024-06-12 10:06:19,380:INFO:                umap: Not installed
2024-06-12 10:06:19,380:INFO:     ydata_profiling: Not installed
2024-06-12 10:06:19,380:INFO:  explainerdashboard: Not installed
2024-06-12 10:06:19,380:INFO:             autoviz: Not installed
2024-06-12 10:06:19,380:INFO:           fairlearn: Not installed
2024-06-12 10:06:19,380:INFO:          deepchecks: Not installed
2024-06-12 10:06:19,380:INFO:             xgboost: Not installed
2024-06-12 10:06:19,380:INFO:            catboost: Not installed
2024-06-12 10:06:19,380:INFO:              kmodes: Not installed
2024-06-12 10:06:19,380:INFO:             mlxtend: Not installed
2024-06-12 10:06:19,380:INFO:       statsforecast: Not installed
2024-06-12 10:06:19,380:INFO:        tune_sklearn: Not installed
2024-06-12 10:06:19,380:INFO:                 ray: Not installed
2024-06-12 10:06:19,380:INFO:            hyperopt: Not installed
2024-06-12 10:06:19,380:INFO:              optuna: Not installed
2024-06-12 10:06:19,380:INFO:               skopt: Not installed
2024-06-12 10:06:19,380:INFO:              mlflow: Not installed
2024-06-12 10:06:19,380:INFO:              gradio: Not installed
2024-06-12 10:06:19,380:INFO:             fastapi: Not installed
2024-06-12 10:06:19,380:INFO:             uvicorn: Not installed
2024-06-12 10:06:19,380:INFO:              m2cgen: Not installed
2024-06-12 10:06:19,380:INFO:           evidently: Not installed
2024-06-12 10:06:19,380:INFO:               fugue: Not installed
2024-06-12 10:06:19,390:INFO:           streamlit: 1.35.0
2024-06-12 10:06:19,390:INFO:             prophet: Not installed
2024-06-12 10:06:19,390:INFO:None
2024-06-12 10:06:19,390:INFO:Set up data.
2024-06-12 10:06:19,443:INFO:Set up folding strategy.
2024-06-12 10:06:19,443:INFO:Set up train/test split.
2024-06-12 10:06:19,480:INFO:Set up index.
2024-06-12 10:06:19,480:INFO:Assigning column types.
2024-06-12 10:06:19,493:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 10:06:19,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:06:19,542:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:06:19,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:19,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:19,641:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:06:19,641:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:06:19,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:19,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:19,691:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 10:06:19,758:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:06:19,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:19,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:19,872:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:06:19,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:19,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:19,921:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 10:06:20,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:20,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:20,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:20,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:20,109:INFO:Preparing preprocessing pipeline...
2024-06-12 10:06:20,112:INFO:Set up simple imputation.
2024-06-12 10:06:20,129:INFO:Set up encoding of ordinal features.
2024-06-12 10:06:20,142:INFO:Set up encoding of categorical features.
2024-06-12 10:06:20,142:INFO:Set up removing outliers.
2024-06-12 10:06:20,142:INFO:Set up imbalanced handling.
2024-06-12 10:06:20,142:INFO:Set up feature normalization.
2024-06-12 10:06:20,143:INFO:Set up PCA.
2024-06-12 10:06:20,911:INFO:Finished creating preprocessing pipeline.
2024-06-12 10:06:20,958:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 10:06:20,958:INFO:Creating final display dataframe.
2024-06-12 10:06:21,705:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (47395, 30)
5   Transformed train set shape       (32395, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method        TomekLinks
20                    Normalize              True
21             Normalize method            robust
22                          PCA              True
23                   PCA method            linear
24               PCA components              None
25               Fold Generator   StratifiedKFold
26                  Fold Number                10
27                     CPU Jobs                -1
28                      Use GPU             False
29               Log Experiment             False
30              Experiment Name  clf-default-name
31                          USI              33a3
2024-06-12 10:06:21,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:21,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:21,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:21,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:06:21,856:INFO:setup() successfully completed in 2.66s...............
2024-06-12 10:06:21,872:INFO:Initializing create_model()
2024-06-12 10:06:21,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:06:21,874:INFO:Checking exceptions
2024-06-12 10:06:21,890:INFO:Importing libraries
2024-06-12 10:06:21,890:INFO:Copying training dataset
2024-06-12 10:06:21,891:INFO:Defining folds
2024-06-12 10:06:21,891:INFO:Declaring metric variables
2024-06-12 10:06:21,909:INFO:Importing untrained model
2024-06-12 10:06:21,912:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:06:21,926:INFO:Starting cross validation
2024-06-12 10:06:21,933:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:06:35,616:INFO:Calculating mean and std
2024-06-12 10:06:35,618:INFO:Creating metrics dataframe
2024-06-12 10:06:35,628:INFO:Finalizing model
2024-06-12 10:06:38,663:INFO:[LightGBM] [Info] Number of positive: 2655, number of negative: 29740
2024-06-12 10:06:38,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003944 seconds.
2024-06-12 10:06:38,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:06:38,663:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 10:06:38,663:INFO:[LightGBM] [Info] Number of data points in the train set: 32395, number of used features: 29
2024-06-12 10:06:38,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081957 -> initscore=-2.416048
2024-06-12 10:06:38,663:INFO:[LightGBM] [Info] Start training from score -2.416048
2024-06-12 10:06:38,956:INFO:Uploading results into container
2024-06-12 10:06:38,957:INFO:Uploading model into container now
2024-06-12 10:06:38,971:INFO:_master_model_container: 1
2024-06-12 10:06:38,971:INFO:_display_container: 2
2024-06-12 10:06:38,972:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:06:38,973:INFO:create_model() successfully completed......................................
2024-06-12 10:06:39,214:INFO:Initializing tune_model()
2024-06-12 10:06:39,214:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 10:06:39,215:INFO:Checking exceptions
2024-06-12 10:06:39,243:INFO:Copying training dataset
2024-06-12 10:06:39,256:INFO:Checking base model
2024-06-12 10:06:39,256:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 10:06:39,259:INFO:Declaring metric variables
2024-06-12 10:06:39,264:INFO:Defining Hyperparameters
2024-06-12 10:06:39,375:INFO:Tuning with n_jobs=-1
2024-06-12 10:06:39,375:INFO:Initializing RandomizedSearchCV
2024-06-12 10:09:05,423:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-12 10:09:05,425:INFO:Hyperparameter search completed
2024-06-12 10:09:05,425:INFO:SubProcess create_model() called ==================================
2024-06-12 10:09:05,427:INFO:Initializing create_model()
2024-06-12 10:09:05,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014B76822690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-12 10:09:05,427:INFO:Checking exceptions
2024-06-12 10:09:05,427:INFO:Importing libraries
2024-06-12 10:09:05,428:INFO:Copying training dataset
2024-06-12 10:09:05,457:INFO:Defining folds
2024-06-12 10:09:05,457:INFO:Declaring metric variables
2024-06-12 10:09:05,468:INFO:Importing untrained model
2024-06-12 10:09:05,469:INFO:Declaring custom model
2024-06-12 10:09:05,471:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:09:05,488:INFO:Starting cross validation
2024-06-12 10:09:05,493:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:09:16,266:INFO:Calculating mean and std
2024-06-12 10:09:16,266:INFO:Creating metrics dataframe
2024-06-12 10:09:16,273:INFO:Finalizing model
2024-06-12 10:09:18,885:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:09:18,885:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:09:18,885:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:09:18,939:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:09:18,939:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:09:18,939:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:09:18,939:INFO:[LightGBM] [Info] Number of positive: 2655, number of negative: 29740
2024-06-12 10:09:18,942:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002286 seconds.
2024-06-12 10:09:18,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:09:18,943:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 10:09:18,944:INFO:[LightGBM] [Info] Number of data points in the train set: 32395, number of used features: 29
2024-06-12 10:09:18,946:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081957 -> initscore=-2.416048
2024-06-12 10:09:18,946:INFO:[LightGBM] [Info] Start training from score -2.416048
2024-06-12 10:09:19,355:INFO:Uploading results into container
2024-06-12 10:09:19,355:INFO:Uploading model into container now
2024-06-12 10:09:19,355:INFO:_master_model_container: 2
2024-06-12 10:09:19,355:INFO:_display_container: 3
2024-06-12 10:09:19,355:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:09:19,355:INFO:create_model() successfully completed......................................
2024-06-12 10:09:19,509:INFO:SubProcess create_model() end ==================================
2024-06-12 10:09:19,509:INFO:choose_better activated
2024-06-12 10:09:19,512:INFO:SubProcess create_model() called ==================================
2024-06-12 10:09:19,513:INFO:Initializing create_model()
2024-06-12 10:09:19,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:09:19,521:INFO:Checking exceptions
2024-06-12 10:09:19,521:INFO:Importing libraries
2024-06-12 10:09:19,521:INFO:Copying training dataset
2024-06-12 10:09:19,570:INFO:Defining folds
2024-06-12 10:09:19,570:INFO:Declaring metric variables
2024-06-12 10:09:19,570:INFO:Importing untrained model
2024-06-12 10:09:19,570:INFO:Declaring custom model
2024-06-12 10:09:19,571:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:09:19,572:INFO:Starting cross validation
2024-06-12 10:09:19,575:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:09:27,941:INFO:Calculating mean and std
2024-06-12 10:09:27,942:INFO:Creating metrics dataframe
2024-06-12 10:09:27,945:INFO:Finalizing model
2024-06-12 10:09:30,448:INFO:[LightGBM] [Info] Number of positive: 2655, number of negative: 29740
2024-06-12 10:09:30,448:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002819 seconds.
2024-06-12 10:09:30,448:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:09:30,448:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 10:09:30,448:INFO:[LightGBM] [Info] Number of data points in the train set: 32395, number of used features: 29
2024-06-12 10:09:30,448:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081957 -> initscore=-2.416048
2024-06-12 10:09:30,448:INFO:[LightGBM] [Info] Start training from score -2.416048
2024-06-12 10:09:30,682:INFO:Uploading results into container
2024-06-12 10:09:30,682:INFO:Uploading model into container now
2024-06-12 10:09:30,682:INFO:_master_model_container: 3
2024-06-12 10:09:30,682:INFO:_display_container: 4
2024-06-12 10:09:30,682:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:09:30,682:INFO:create_model() successfully completed......................................
2024-06-12 10:09:30,834:INFO:SubProcess create_model() end ==================================
2024-06-12 10:09:30,834:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1254
2024-06-12 10:09:30,835:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1262
2024-06-12 10:09:30,835:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 10:09:30,835:INFO:choose_better completed
2024-06-12 10:09:30,844:INFO:_master_model_container: 3
2024-06-12 10:09:30,844:INFO:_display_container: 3
2024-06-12 10:09:30,845:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:09:30,845:INFO:tune_model() successfully completed......................................
2024-06-12 10:09:31,182:INFO:Initializing plot_model()
2024-06-12 10:09:31,182:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:09:31,182:INFO:Checking exceptions
2024-06-12 10:09:31,188:INFO:Preloading libraries
2024-06-12 10:09:31,206:INFO:Copying training dataset
2024-06-12 10:09:31,206:INFO:Plot type: auc
2024-06-12 10:09:31,393:INFO:Fitting Model
2024-06-12 10:09:31,395:INFO:Scoring test/hold-out set
2024-06-12 10:09:31,397:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:09:31,397:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:09:31,397:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:09:31,417:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:09:31,417:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:09:31,417:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:09:31,732:INFO:Visual Rendered Successfully
2024-06-12 10:09:31,847:INFO:plot_model() successfully completed......................................
2024-06-12 10:09:31,906:INFO:Initializing plot_model()
2024-06-12 10:09:31,906:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:09:31,906:INFO:Checking exceptions
2024-06-12 10:09:31,921:INFO:Preloading libraries
2024-06-12 10:09:31,939:INFO:Copying training dataset
2024-06-12 10:09:31,940:INFO:Plot type: confusion_matrix
2024-06-12 10:09:32,114:INFO:Fitting Model
2024-06-12 10:09:32,114:INFO:Scoring test/hold-out set
2024-06-12 10:09:32,114:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:09:32,114:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:09:32,114:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:09:32,148:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:09:32,148:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:09:32,149:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:09:32,321:INFO:Visual Rendered Successfully
2024-06-12 10:09:32,436:INFO:plot_model() successfully completed......................................
2024-06-12 10:09:32,450:INFO:Initializing finalize_model()
2024-06-12 10:09:32,451:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 10:09:32,451:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:09:32,460:INFO:Initializing create_model()
2024-06-12 10:09:32,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:09:32,460:INFO:Checking exceptions
2024-06-12 10:09:32,460:INFO:Importing libraries
2024-06-12 10:09:32,460:INFO:Copying training dataset
2024-06-12 10:09:32,460:INFO:Defining folds
2024-06-12 10:09:32,460:INFO:Declaring metric variables
2024-06-12 10:09:32,460:INFO:Importing untrained model
2024-06-12 10:09:32,460:INFO:Declaring custom model
2024-06-12 10:09:32,460:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:09:32,460:INFO:Cross validation set to False
2024-06-12 10:09:32,460:INFO:Fitting Model
2024-06-12 10:09:36,558:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:09:36,558:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:09:36,558:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:09:36,622:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:09:36,622:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:09:36,622:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:09:36,622:INFO:[LightGBM] [Info] Number of positive: 3814, number of negative: 42631
2024-06-12 10:09:36,622:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003909 seconds.
2024-06-12 10:09:36,622:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:09:36,622:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 10:09:36,633:INFO:[LightGBM] [Info] Number of data points in the train set: 46445, number of used features: 29
2024-06-12 10:09:36,635:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082119 -> initscore=-2.413903
2024-06-12 10:09:36,635:INFO:[LightGBM] [Info] Start training from score -2.413903
2024-06-12 10:09:37,089:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:09:37,089:INFO:create_model() successfully completed......................................
2024-06-12 10:09:37,198:INFO:_master_model_container: 3
2024-06-12 10:09:37,198:INFO:_display_container: 3
2024-06-12 10:09:37,245:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:09:37,245:INFO:finalize_model() successfully completed......................................
2024-06-12 10:09:37,427:INFO:Initializing evaluate_model()
2024-06-12 10:09:37,427:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-12 10:09:37,480:INFO:Initializing plot_model()
2024-06-12 10:09:37,480:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:09:37,480:INFO:Checking exceptions
2024-06-12 10:09:37,486:INFO:Preloading libraries
2024-06-12 10:09:37,500:INFO:Copying training dataset
2024-06-12 10:09:37,501:INFO:Plot type: pipeline
2024-06-12 10:09:37,748:INFO:Visual Rendered Successfully
2024-06-12 10:09:37,857:INFO:plot_model() successfully completed......................................
2024-06-12 10:09:37,931:INFO:Initializing predict_model()
2024-06-12 10:09:37,931:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014B00FA39C0>)
2024-06-12 10:09:37,931:INFO:Checking exceptions
2024-06-12 10:09:37,931:INFO:Preloading libraries
2024-06-12 10:09:37,947:INFO:Set up data.
2024-06-12 10:09:38,374:INFO:Set up index.
2024-06-12 10:27:17,292:INFO:Initializing plot_model()
2024-06-12 10:27:17,292:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B08E4D090>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:27:17,292:INFO:Checking exceptions
2024-06-12 10:27:17,308:INFO:Preloading libraries
2024-06-12 10:27:17,342:INFO:Copying training dataset
2024-06-12 10:27:17,342:INFO:Plot type: confusion_matrix
2024-06-12 10:27:17,508:INFO:Fitting Model
2024-06-12 10:27:17,508:INFO:Scoring test/hold-out set
2024-06-12 10:27:17,508:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:27:17,508:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:27:17,508:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:27:17,558:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:27:17,558:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:27:17,558:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:27:17,709:INFO:Visual Rendered Successfully
2024-06-12 10:27:17,825:INFO:plot_model() successfully completed......................................
2024-06-12 10:44:06,764:INFO:PyCaret ClassificationExperiment
2024-06-12 10:44:06,764:INFO:Logging name: clf-default-name
2024-06-12 10:44:06,764:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 10:44:06,764:INFO:version 3.3.2
2024-06-12 10:44:06,764:INFO:Initializing setup()
2024-06-12 10:44:06,764:INFO:self.USI: a98d
2024-06-12 10:44:06,764:INFO:self._variable_keys: {'is_multiclass', 'fold_groups_param', 'html_param', '_available_plots', 'USI', 'pipeline', 'X', 'seed', '_ml_usecase', 'fold_generator', 'X_train', 'fold_shuffle_param', 'memory', 'exp_name_log', 'gpu_param', 'data', 'y_train', 'idx', 'y_test', 'logging_param', 'fix_imbalance', 'log_plots_param', 'exp_id', 'n_jobs_param', 'y', 'X_test', 'target_param', 'gpu_n_jobs_param'}
2024-06-12 10:44:06,764:INFO:Checking environment
2024-06-12 10:44:06,765:INFO:python_version: 3.11.9
2024-06-12 10:44:06,765:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 10:44:06,765:INFO:machine: AMD64
2024-06-12 10:44:06,765:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 10:44:06,765:INFO:Memory: svmem(total=34056318976, available=18041225216, percent=47.0, used=16015093760, free=18041225216)
2024-06-12 10:44:06,765:INFO:Physical Core: 6
2024-06-12 10:44:06,765:INFO:Logical Core: 12
2024-06-12 10:44:06,765:INFO:Checking libraries
2024-06-12 10:44:06,765:INFO:System:
2024-06-12 10:44:06,765:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 10:44:06,765:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 10:44:06,765:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 10:44:06,765:INFO:PyCaret required dependencies:
2024-06-12 10:44:06,765:INFO:                 pip: 24.0
2024-06-12 10:44:06,766:INFO:          setuptools: 69.5.1
2024-06-12 10:44:06,766:INFO:             pycaret: 3.3.2
2024-06-12 10:44:06,766:INFO:             IPython: 8.25.0
2024-06-12 10:44:06,766:INFO:          ipywidgets: 8.1.3
2024-06-12 10:44:06,766:INFO:                tqdm: 4.66.4
2024-06-12 10:44:06,766:INFO:               numpy: 1.26.4
2024-06-12 10:44:06,766:INFO:              pandas: 2.1.4
2024-06-12 10:44:06,766:INFO:              jinja2: 3.1.4
2024-06-12 10:44:06,766:INFO:               scipy: 1.11.4
2024-06-12 10:44:06,766:INFO:              joblib: 1.3.2
2024-06-12 10:44:06,766:INFO:             sklearn: 1.4.2
2024-06-12 10:44:06,766:INFO:                pyod: 2.0.0
2024-06-12 10:44:06,766:INFO:            imblearn: 0.12.3
2024-06-12 10:44:06,766:INFO:   category_encoders: 2.6.3
2024-06-12 10:44:06,766:INFO:            lightgbm: 4.3.0
2024-06-12 10:44:06,766:INFO:               numba: 0.59.1
2024-06-12 10:44:06,767:INFO:            requests: 2.32.3
2024-06-12 10:44:06,767:INFO:          matplotlib: 3.7.5
2024-06-12 10:44:06,767:INFO:          scikitplot: 0.3.7
2024-06-12 10:44:06,768:INFO:         yellowbrick: 1.5
2024-06-12 10:44:06,768:INFO:              plotly: 5.22.0
2024-06-12 10:44:06,768:INFO:    plotly-resampler: Not installed
2024-06-12 10:44:06,768:INFO:             kaleido: 0.2.1
2024-06-12 10:44:06,768:INFO:           schemdraw: 0.15
2024-06-12 10:44:06,768:INFO:         statsmodels: 0.14.2
2024-06-12 10:44:06,768:INFO:              sktime: 0.26.0
2024-06-12 10:44:06,768:INFO:               tbats: 1.1.3
2024-06-12 10:44:06,768:INFO:            pmdarima: 2.0.4
2024-06-12 10:44:06,768:INFO:              psutil: 5.9.8
2024-06-12 10:44:06,768:INFO:          markupsafe: 2.1.5
2024-06-12 10:44:06,768:INFO:             pickle5: Not installed
2024-06-12 10:44:06,768:INFO:         cloudpickle: 3.0.0
2024-06-12 10:44:06,768:INFO:         deprecation: 2.1.0
2024-06-12 10:44:06,768:INFO:              xxhash: 3.4.1
2024-06-12 10:44:06,768:INFO:           wurlitzer: Not installed
2024-06-12 10:44:06,768:INFO:PyCaret optional dependencies:
2024-06-12 10:44:06,768:INFO:                shap: Not installed
2024-06-12 10:44:06,768:INFO:           interpret: Not installed
2024-06-12 10:44:06,768:INFO:                umap: Not installed
2024-06-12 10:44:06,768:INFO:     ydata_profiling: Not installed
2024-06-12 10:44:06,768:INFO:  explainerdashboard: Not installed
2024-06-12 10:44:06,768:INFO:             autoviz: Not installed
2024-06-12 10:44:06,768:INFO:           fairlearn: Not installed
2024-06-12 10:44:06,768:INFO:          deepchecks: Not installed
2024-06-12 10:44:06,768:INFO:             xgboost: Not installed
2024-06-12 10:44:06,768:INFO:            catboost: Not installed
2024-06-12 10:44:06,768:INFO:              kmodes: Not installed
2024-06-12 10:44:06,768:INFO:             mlxtend: Not installed
2024-06-12 10:44:06,768:INFO:       statsforecast: Not installed
2024-06-12 10:44:06,768:INFO:        tune_sklearn: Not installed
2024-06-12 10:44:06,768:INFO:                 ray: Not installed
2024-06-12 10:44:06,768:INFO:            hyperopt: Not installed
2024-06-12 10:44:06,768:INFO:              optuna: Not installed
2024-06-12 10:44:06,768:INFO:               skopt: Not installed
2024-06-12 10:44:06,768:INFO:              mlflow: Not installed
2024-06-12 10:44:06,768:INFO:              gradio: Not installed
2024-06-12 10:44:06,768:INFO:             fastapi: Not installed
2024-06-12 10:44:06,768:INFO:             uvicorn: Not installed
2024-06-12 10:44:06,768:INFO:              m2cgen: Not installed
2024-06-12 10:44:06,768:INFO:           evidently: Not installed
2024-06-12 10:44:06,768:INFO:               fugue: Not installed
2024-06-12 10:44:06,768:INFO:           streamlit: 1.35.0
2024-06-12 10:44:06,768:INFO:             prophet: Not installed
2024-06-12 10:44:06,768:INFO:None
2024-06-12 10:44:06,768:INFO:Set up data.
2024-06-12 10:44:06,813:INFO:Set up folding strategy.
2024-06-12 10:44:06,813:INFO:Set up train/test split.
2024-06-12 10:44:06,846:INFO:Set up index.
2024-06-12 10:44:06,847:INFO:Assigning column types.
2024-06-12 10:44:06,847:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 10:44:06,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:44:06,901:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:44:06,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:06,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:06,974:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:44:06,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:44:07,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,004:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 10:44:07,047:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:44:07,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,114:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:44:07,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,134:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 10:44:07,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:07,275:INFO:Preparing preprocessing pipeline...
2024-06-12 10:44:07,278:INFO:Set up date feature engineering.
2024-06-12 10:44:07,278:INFO:Set up simple imputation.
2024-06-12 10:44:07,289:INFO:Set up encoding of ordinal features.
2024-06-12 10:44:07,297:INFO:Set up encoding of categorical features.
2024-06-12 10:44:07,297:INFO:Set up removing outliers.
2024-06-12 10:44:07,297:INFO:Set up imbalanced handling.
2024-06-12 10:44:07,297:INFO:Set up feature normalization.
2024-06-12 10:44:07,297:INFO:Set up PCA.
2024-06-12 10:44:07,814:INFO:Finished creating preprocessing pipeline.
2024-06-12 10:44:07,848:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pe...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 10:44:07,848:INFO:Creating final display dataframe.
2024-06-12 10:44:08,047:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 15)
4        Transformed data shape       (47137, 34)
5   Transformed train set shape       (32137, 34)
6    Transformed test set shape       (15000, 34)
7              Numeric features                 6
8                 Date features                 1
9          Categorical features                 7
10     Rows with missing values             17.1%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation                -1
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method        TomekLinks
21                    Normalize              True
22             Normalize method            robust
23                          PCA              True
24                   PCA method            linear
25               PCA components              None
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              a98d
2024-06-12 10:44:08,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:08,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:08,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:08,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:44:08,197:INFO:setup() successfully completed in 1.52s...............
2024-06-12 10:44:08,223:INFO:Initializing create_model()
2024-06-12 10:44:08,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:44:08,223:INFO:Checking exceptions
2024-06-12 10:44:08,235:INFO:Importing libraries
2024-06-12 10:44:08,235:INFO:Copying training dataset
2024-06-12 10:44:08,260:INFO:Defining folds
2024-06-12 10:44:08,260:INFO:Declaring metric variables
2024-06-12 10:44:08,264:INFO:Importing untrained model
2024-06-12 10:44:08,267:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:44:08,276:INFO:Starting cross validation
2024-06-12 10:44:08,279:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:44:20,471:INFO:Calculating mean and std
2024-06-12 10:44:20,473:INFO:Creating metrics dataframe
2024-06-12 10:44:20,481:INFO:Finalizing model
2024-06-12 10:44:23,241:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-12 10:44:23,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004081 seconds.
2024-06-12 10:44:23,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:44:23,246:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-12 10:44:23,247:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-12 10:44:23,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-12 10:44:23,248:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-12 10:44:23,598:INFO:Uploading results into container
2024-06-12 10:44:23,600:INFO:Uploading model into container now
2024-06-12 10:44:23,613:INFO:_master_model_container: 1
2024-06-12 10:44:23,613:INFO:_display_container: 2
2024-06-12 10:44:23,614:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:44:23,615:INFO:create_model() successfully completed......................................
2024-06-12 10:44:23,773:INFO:Initializing tune_model()
2024-06-12 10:44:23,773:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 10:44:23,774:INFO:Checking exceptions
2024-06-12 10:44:23,800:INFO:Copying training dataset
2024-06-12 10:44:23,816:INFO:Checking base model
2024-06-12 10:44:23,816:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 10:44:23,820:INFO:Declaring metric variables
2024-06-12 10:44:23,824:INFO:Defining Hyperparameters
2024-06-12 10:44:23,933:INFO:Tuning with n_jobs=-1
2024-06-12 10:44:23,933:INFO:Initializing RandomizedSearchCV
2024-06-12 10:46:40,300:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-12 10:46:40,300:INFO:Hyperparameter search completed
2024-06-12 10:46:40,300:INFO:SubProcess create_model() called ==================================
2024-06-12 10:46:40,300:INFO:Initializing create_model()
2024-06-12 10:46:40,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014B78602D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-12 10:46:40,300:INFO:Checking exceptions
2024-06-12 10:46:40,300:INFO:Importing libraries
2024-06-12 10:46:40,300:INFO:Copying training dataset
2024-06-12 10:46:40,332:INFO:Defining folds
2024-06-12 10:46:40,332:INFO:Declaring metric variables
2024-06-12 10:46:40,332:INFO:Importing untrained model
2024-06-12 10:46:40,332:INFO:Declaring custom model
2024-06-12 10:46:40,348:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:46:40,348:INFO:Starting cross validation
2024-06-12 10:46:40,348:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:46:50,435:INFO:Calculating mean and std
2024-06-12 10:46:50,435:INFO:Creating metrics dataframe
2024-06-12 10:46:50,435:INFO:Finalizing model
2024-06-12 10:46:52,964:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:46:52,964:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:46:52,964:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:46:53,019:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:46:53,019:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:46:53,019:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:46:53,019:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-12 10:46:53,024:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003586 seconds.
2024-06-12 10:46:53,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:46:53,024:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-12 10:46:53,026:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-12 10:46:53,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-12 10:46:53,028:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-12 10:46:53,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:46:53,687:INFO:Uploading results into container
2024-06-12 10:46:53,687:INFO:Uploading model into container now
2024-06-12 10:46:53,687:INFO:_master_model_container: 2
2024-06-12 10:46:53,687:INFO:_display_container: 3
2024-06-12 10:46:53,687:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:46:53,687:INFO:create_model() successfully completed......................................
2024-06-12 10:46:53,830:INFO:SubProcess create_model() end ==================================
2024-06-12 10:46:53,830:INFO:choose_better activated
2024-06-12 10:46:53,830:INFO:SubProcess create_model() called ==================================
2024-06-12 10:46:53,830:INFO:Initializing create_model()
2024-06-12 10:46:53,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:46:53,830:INFO:Checking exceptions
2024-06-12 10:46:53,830:INFO:Importing libraries
2024-06-12 10:46:53,830:INFO:Copying training dataset
2024-06-12 10:46:53,847:INFO:Defining folds
2024-06-12 10:46:53,847:INFO:Declaring metric variables
2024-06-12 10:46:53,847:INFO:Importing untrained model
2024-06-12 10:46:53,847:INFO:Declaring custom model
2024-06-12 10:46:53,847:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:46:53,847:INFO:Starting cross validation
2024-06-12 10:46:53,863:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:47:01,675:INFO:Calculating mean and std
2024-06-12 10:47:01,675:INFO:Creating metrics dataframe
2024-06-12 10:47:01,678:INFO:Finalizing model
2024-06-12 10:47:04,275:INFO:[LightGBM] [Info] Number of positive: 2637, number of negative: 29500
2024-06-12 10:47:04,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004397 seconds.
2024-06-12 10:47:04,280:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:47:04,280:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-12 10:47:04,281:INFO:[LightGBM] [Info] Number of data points in the train set: 32137, number of used features: 33
2024-06-12 10:47:04,281:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082055 -> initscore=-2.414748
2024-06-12 10:47:04,282:INFO:[LightGBM] [Info] Start training from score -2.414748
2024-06-12 10:47:04,562:INFO:Uploading results into container
2024-06-12 10:47:04,562:INFO:Uploading model into container now
2024-06-12 10:47:04,562:INFO:_master_model_container: 3
2024-06-12 10:47:04,562:INFO:_display_container: 4
2024-06-12 10:47:04,562:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:47:04,562:INFO:create_model() successfully completed......................................
2024-06-12 10:47:04,679:INFO:SubProcess create_model() end ==================================
2024-06-12 10:47:04,679:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1202
2024-06-12 10:47:04,679:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1145
2024-06-12 10:47:04,679:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 10:47:04,679:INFO:choose_better completed
2024-06-12 10:47:04,679:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-12 10:47:04,696:INFO:_master_model_container: 3
2024-06-12 10:47:04,696:INFO:_display_container: 3
2024-06-12 10:47:04,696:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:47:04,696:INFO:tune_model() successfully completed......................................
2024-06-12 10:47:04,851:INFO:Initializing plot_model()
2024-06-12 10:47:04,851:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:47:04,851:INFO:Checking exceptions
2024-06-12 10:47:04,864:INFO:Preloading libraries
2024-06-12 10:47:04,865:INFO:Copying training dataset
2024-06-12 10:47:04,865:INFO:Plot type: auc
2024-06-12 10:47:05,046:INFO:Fitting Model
2024-06-12 10:47:05,046:INFO:Scoring test/hold-out set
2024-06-12 10:47:05,285:INFO:Visual Rendered Successfully
2024-06-12 10:47:05,411:INFO:plot_model() successfully completed......................................
2024-06-12 10:47:05,413:INFO:Initializing plot_model()
2024-06-12 10:47:05,413:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:47:05,413:INFO:Checking exceptions
2024-06-12 10:47:05,429:INFO:Preloading libraries
2024-06-12 10:47:05,429:INFO:Copying training dataset
2024-06-12 10:47:05,429:INFO:Plot type: confusion_matrix
2024-06-12 10:47:05,612:INFO:Fitting Model
2024-06-12 10:47:05,628:INFO:Scoring test/hold-out set
2024-06-12 10:47:05,805:INFO:Visual Rendered Successfully
2024-06-12 10:47:05,916:INFO:plot_model() successfully completed......................................
2024-06-12 10:47:05,945:INFO:Initializing finalize_model()
2024-06-12 10:47:05,945:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 10:47:05,945:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:47:05,954:INFO:Initializing create_model()
2024-06-12 10:47:05,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:47:05,954:INFO:Checking exceptions
2024-06-12 10:47:05,954:INFO:Importing libraries
2024-06-12 10:47:05,954:INFO:Copying training dataset
2024-06-12 10:47:05,954:INFO:Defining folds
2024-06-12 10:47:05,954:INFO:Declaring metric variables
2024-06-12 10:47:05,954:INFO:Importing untrained model
2024-06-12 10:47:05,954:INFO:Declaring custom model
2024-06-12 10:47:05,954:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:47:05,963:INFO:Cross validation set to False
2024-06-12 10:47:05,963:INFO:Fitting Model
2024-06-12 10:47:10,031:INFO:[LightGBM] [Info] Number of positive: 3752, number of negative: 42323
2024-06-12 10:47:10,031:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004258 seconds.
2024-06-12 10:47:10,031:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:47:10,031:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-12 10:47:10,031:INFO:[LightGBM] [Info] Number of data points in the train set: 46075, number of used features: 33
2024-06-12 10:47:10,047:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081432 -> initscore=-2.423042
2024-06-12 10:47:10,047:INFO:[LightGBM] [Info] Start training from score -2.423042
2024-06-12 10:47:10,298:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:47:10,298:INFO:create_model() successfully completed......................................
2024-06-12 10:47:10,408:INFO:_master_model_container: 3
2024-06-12 10:47:10,408:INFO:_display_container: 3
2024-06-12 10:47:10,439:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:47:10,439:INFO:finalize_model() successfully completed......................................
2024-06-12 10:47:10,612:INFO:Initializing evaluate_model()
2024-06-12 10:47:10,612:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-12 10:47:10,670:INFO:Initializing plot_model()
2024-06-12 10:47:10,670:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:47:10,670:INFO:Checking exceptions
2024-06-12 10:47:10,676:INFO:Preloading libraries
2024-06-12 10:47:10,683:INFO:Copying training dataset
2024-06-12 10:47:10,683:INFO:Plot type: pipeline
2024-06-12 10:47:10,917:INFO:Visual Rendered Successfully
2024-06-12 10:47:11,043:INFO:plot_model() successfully completed......................................
2024-06-12 10:47:11,131:INFO:Initializing predict_model()
2024-06-12 10:47:11,131:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014B011BB6A0>)
2024-06-12 10:47:11,131:INFO:Checking exceptions
2024-06-12 10:47:11,131:INFO:Preloading libraries
2024-06-12 10:47:11,134:INFO:Set up data.
2024-06-12 10:47:11,545:INFO:Set up index.
2024-06-12 10:47:20,027:INFO:Initializing plot_model()
2024-06-12 10:47:20,027:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014B09104A10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:47:20,027:INFO:Checking exceptions
2024-06-12 10:47:20,027:INFO:Preloading libraries
2024-06-12 10:47:20,044:INFO:Copying training dataset
2024-06-12 10:47:20,044:INFO:Plot type: confusion_matrix
2024-06-12 10:47:20,230:INFO:Fitting Model
2024-06-12 10:47:20,231:INFO:Scoring test/hold-out set
2024-06-12 10:47:20,393:INFO:Visual Rendered Successfully
2024-06-12 10:47:29,889:INFO:plot_model() successfully completed......................................
2024-06-12 10:49:30,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:49:30,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:49:30,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:49:30,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:49:31,898:INFO:PyCaret ClassificationExperiment
2024-06-12 10:49:31,898:INFO:Logging name: clf-default-name
2024-06-12 10:49:31,898:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 10:49:31,898:INFO:version 3.3.2
2024-06-12 10:49:31,898:INFO:Initializing setup()
2024-06-12 10:49:31,898:INFO:self.USI: 1a81
2024-06-12 10:49:31,898:INFO:self._variable_keys: {'gpu_param', '_ml_usecase', 'seed', 'html_param', 'y_train', 'target_param', 'X_test', 'is_multiclass', 'fold_generator', 'X', 'n_jobs_param', 'USI', 'fold_groups_param', 'gpu_n_jobs_param', 'y_test', 'pipeline', 'log_plots_param', 'exp_id', 'data', 'X_train', 'logging_param', 'fold_shuffle_param', '_available_plots', 'fix_imbalance', 'idx', 'y', 'memory', 'exp_name_log'}
2024-06-12 10:49:31,898:INFO:Checking environment
2024-06-12 10:49:31,898:INFO:python_version: 3.11.9
2024-06-12 10:49:31,898:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 10:49:31,898:INFO:machine: AMD64
2024-06-12 10:49:31,898:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 10:49:31,898:INFO:Memory: svmem(total=34056318976, available=28048687104, percent=17.6, used=6007631872, free=28048687104)
2024-06-12 10:49:31,898:INFO:Physical Core: 6
2024-06-12 10:49:31,898:INFO:Logical Core: 12
2024-06-12 10:49:31,898:INFO:Checking libraries
2024-06-12 10:49:31,898:INFO:System:
2024-06-12 10:49:31,898:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 10:49:31,898:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 10:49:31,898:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 10:49:31,898:INFO:PyCaret required dependencies:
2024-06-12 10:49:31,920:INFO:                 pip: 24.0
2024-06-12 10:49:31,920:INFO:          setuptools: 69.5.1
2024-06-12 10:49:31,920:INFO:             pycaret: 3.3.2
2024-06-12 10:49:31,920:INFO:             IPython: 8.25.0
2024-06-12 10:49:31,920:INFO:          ipywidgets: 8.1.3
2024-06-12 10:49:31,920:INFO:                tqdm: 4.66.4
2024-06-12 10:49:31,920:INFO:               numpy: 1.26.4
2024-06-12 10:49:31,920:INFO:              pandas: 2.1.4
2024-06-12 10:49:31,920:INFO:              jinja2: 3.1.4
2024-06-12 10:49:31,920:INFO:               scipy: 1.11.4
2024-06-12 10:49:31,920:INFO:              joblib: 1.3.2
2024-06-12 10:49:31,920:INFO:             sklearn: 1.4.2
2024-06-12 10:49:31,920:INFO:                pyod: 2.0.0
2024-06-12 10:49:31,920:INFO:            imblearn: 0.12.3
2024-06-12 10:49:31,920:INFO:   category_encoders: 2.6.3
2024-06-12 10:49:31,920:INFO:            lightgbm: 4.3.0
2024-06-12 10:49:31,920:INFO:               numba: 0.59.1
2024-06-12 10:49:31,920:INFO:            requests: 2.32.3
2024-06-12 10:49:31,920:INFO:          matplotlib: 3.7.5
2024-06-12 10:49:31,920:INFO:          scikitplot: 0.3.7
2024-06-12 10:49:31,920:INFO:         yellowbrick: 1.5
2024-06-12 10:49:31,920:INFO:              plotly: 5.22.0
2024-06-12 10:49:31,920:INFO:    plotly-resampler: Not installed
2024-06-12 10:49:31,920:INFO:             kaleido: 0.2.1
2024-06-12 10:49:31,920:INFO:           schemdraw: 0.15
2024-06-12 10:49:31,920:INFO:         statsmodels: 0.14.2
2024-06-12 10:49:31,920:INFO:              sktime: 0.26.0
2024-06-12 10:49:31,920:INFO:               tbats: 1.1.3
2024-06-12 10:49:31,920:INFO:            pmdarima: 2.0.4
2024-06-12 10:49:31,920:INFO:              psutil: 5.9.8
2024-06-12 10:49:31,920:INFO:          markupsafe: 2.1.5
2024-06-12 10:49:31,920:INFO:             pickle5: Not installed
2024-06-12 10:49:31,920:INFO:         cloudpickle: 3.0.0
2024-06-12 10:49:31,920:INFO:         deprecation: 2.1.0
2024-06-12 10:49:31,920:INFO:              xxhash: 3.4.1
2024-06-12 10:49:31,920:INFO:           wurlitzer: Not installed
2024-06-12 10:49:31,920:INFO:PyCaret optional dependencies:
2024-06-12 10:49:31,933:INFO:                shap: Not installed
2024-06-12 10:49:31,933:INFO:           interpret: Not installed
2024-06-12 10:49:31,933:INFO:                umap: Not installed
2024-06-12 10:49:31,933:INFO:     ydata_profiling: Not installed
2024-06-12 10:49:31,933:INFO:  explainerdashboard: Not installed
2024-06-12 10:49:31,933:INFO:             autoviz: Not installed
2024-06-12 10:49:31,933:INFO:           fairlearn: Not installed
2024-06-12 10:49:31,933:INFO:          deepchecks: Not installed
2024-06-12 10:49:31,933:INFO:             xgboost: Not installed
2024-06-12 10:49:31,933:INFO:            catboost: Not installed
2024-06-12 10:49:31,933:INFO:              kmodes: Not installed
2024-06-12 10:49:31,933:INFO:             mlxtend: Not installed
2024-06-12 10:49:31,933:INFO:       statsforecast: Not installed
2024-06-12 10:49:31,933:INFO:        tune_sklearn: Not installed
2024-06-12 10:49:31,933:INFO:                 ray: Not installed
2024-06-12 10:49:31,933:INFO:            hyperopt: Not installed
2024-06-12 10:49:31,933:INFO:              optuna: Not installed
2024-06-12 10:49:31,933:INFO:               skopt: Not installed
2024-06-12 10:49:31,933:INFO:              mlflow: Not installed
2024-06-12 10:49:31,933:INFO:              gradio: Not installed
2024-06-12 10:49:31,933:INFO:             fastapi: Not installed
2024-06-12 10:49:31,933:INFO:             uvicorn: Not installed
2024-06-12 10:49:31,933:INFO:              m2cgen: Not installed
2024-06-12 10:49:31,933:INFO:           evidently: Not installed
2024-06-12 10:49:31,933:INFO:               fugue: Not installed
2024-06-12 10:49:31,933:INFO:           streamlit: 1.35.0
2024-06-12 10:49:31,933:INFO:             prophet: Not installed
2024-06-12 10:49:31,933:INFO:None
2024-06-12 10:49:31,933:INFO:Set up data.
2024-06-12 10:49:31,964:INFO:Set up folding strategy.
2024-06-12 10:49:31,964:INFO:Set up train/test split.
2024-06-12 10:49:31,995:INFO:Set up index.
2024-06-12 10:49:31,997:INFO:Assigning column types.
2024-06-12 10:49:32,005:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 10:49:32,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:49:32,049:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:49:32,081:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:49:32,113:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:49:32,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,151:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 10:49:32,181:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:49:32,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,263:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:49:32,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,280:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 10:49:32,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:32,433:INFO:Preparing preprocessing pipeline...
2024-06-12 10:49:32,439:INFO:Set up simple imputation.
2024-06-12 10:49:32,450:INFO:Set up encoding of ordinal features.
2024-06-12 10:49:32,452:INFO:Set up encoding of categorical features.
2024-06-12 10:49:32,733:INFO:Finished creating preprocessing pipeline.
2024-06-12 10:49:32,766:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-06-12 10:49:32,766:INFO:Creating final display dataframe.
2024-06-12 10:49:33,314:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              1a81
2024-06-12 10:49:33,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:33,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:33,464:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:33,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:49:33,464:INFO:setup() successfully completed in 1.64s...............
2024-06-12 10:49:33,485:INFO:Initializing create_model()
2024-06-12 10:49:33,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:49:33,485:INFO:Checking exceptions
2024-06-12 10:49:33,497:INFO:Importing libraries
2024-06-12 10:49:33,497:INFO:Copying training dataset
2024-06-12 10:49:33,522:INFO:Defining folds
2024-06-12 10:49:33,522:INFO:Declaring metric variables
2024-06-12 10:49:33,525:INFO:Importing untrained model
2024-06-12 10:49:33,529:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:49:33,540:INFO:Starting cross validation
2024-06-12 10:49:33,543:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:49:39,599:INFO:Calculating mean and std
2024-06-12 10:49:39,599:INFO:Creating metrics dataframe
2024-06-12 10:49:39,613:INFO:Finalizing model
2024-06-12 10:49:40,021:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 10:49:40,021:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 10:49:40,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001489 seconds.
2024-06-12 10:49:40,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 10:49:40,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 10:49:40,021:INFO:[LightGBM] [Info] Total Bins 623
2024-06-12 10:49:40,021:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 10:49:40,021:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 10:49:40,021:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 10:49:40,167:INFO:Uploading results into container
2024-06-12 10:49:40,167:INFO:Uploading model into container now
2024-06-12 10:49:40,184:INFO:_master_model_container: 1
2024-06-12 10:49:40,184:INFO:_display_container: 2
2024-06-12 10:49:40,185:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:49:40,185:INFO:create_model() successfully completed......................................
2024-06-12 10:49:40,276:INFO:Initializing tune_model()
2024-06-12 10:49:40,276:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 10:49:40,276:INFO:Checking exceptions
2024-06-12 10:49:40,303:INFO:Copying training dataset
2024-06-12 10:49:40,319:INFO:Checking base model
2024-06-12 10:49:40,319:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 10:49:40,319:INFO:Declaring metric variables
2024-06-12 10:49:40,325:INFO:Defining Hyperparameters
2024-06-12 10:49:40,393:INFO:Tuning with n_jobs=-1
2024-06-12 10:49:40,393:INFO:Initializing RandomizedSearchCV
2024-06-12 10:50:08,898:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-12 10:50:08,898:INFO:Hyperparameter search completed
2024-06-12 10:50:08,898:INFO:SubProcess create_model() called ==================================
2024-06-12 10:50:08,898:INFO:Initializing create_model()
2024-06-12 10:50:08,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026C871274D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-12 10:50:08,898:INFO:Checking exceptions
2024-06-12 10:50:08,898:INFO:Importing libraries
2024-06-12 10:50:08,898:INFO:Copying training dataset
2024-06-12 10:50:08,928:INFO:Defining folds
2024-06-12 10:50:08,928:INFO:Declaring metric variables
2024-06-12 10:50:08,943:INFO:Importing untrained model
2024-06-12 10:50:08,943:INFO:Declaring custom model
2024-06-12 10:50:08,943:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:50:08,962:INFO:Starting cross validation
2024-06-12 10:50:08,967:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:50:11,511:INFO:Calculating mean and std
2024-06-12 10:50:11,511:INFO:Creating metrics dataframe
2024-06-12 10:50:11,511:INFO:Finalizing model
2024-06-12 10:50:11,827:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:11,827:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:11,827:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:11,843:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 10:50:11,843:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:11,843:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:11,843:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:11,843:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 10:50:11,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001529 seconds.
2024-06-12 10:50:11,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 10:50:11,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 10:50:11,843:INFO:[LightGBM] [Info] Total Bins 619
2024-06-12 10:50:11,843:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 27
2024-06-12 10:50:11,843:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 10:50:11,843:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 10:50:11,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:11,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:11,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:11,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:11,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:11,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:11,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:11,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:11,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:12,154:INFO:Uploading results into container
2024-06-12 10:50:12,155:INFO:Uploading model into container now
2024-06-12 10:50:12,155:INFO:_master_model_container: 2
2024-06-12 10:50:12,155:INFO:_display_container: 3
2024-06-12 10:50:12,155:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:50:12,155:INFO:create_model() successfully completed......................................
2024-06-12 10:50:12,248:INFO:SubProcess create_model() end ==================================
2024-06-12 10:50:12,248:INFO:choose_better activated
2024-06-12 10:50:12,260:INFO:SubProcess create_model() called ==================================
2024-06-12 10:50:12,261:INFO:Initializing create_model()
2024-06-12 10:50:12,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:50:12,261:INFO:Checking exceptions
2024-06-12 10:50:12,261:INFO:Importing libraries
2024-06-12 10:50:12,261:INFO:Copying training dataset
2024-06-12 10:50:12,276:INFO:Defining folds
2024-06-12 10:50:12,276:INFO:Declaring metric variables
2024-06-12 10:50:12,276:INFO:Importing untrained model
2024-06-12 10:50:12,276:INFO:Declaring custom model
2024-06-12 10:50:12,276:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:50:12,276:INFO:Starting cross validation
2024-06-12 10:50:12,276:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:50:13,815:INFO:Calculating mean and std
2024-06-12 10:50:13,815:INFO:Creating metrics dataframe
2024-06-12 10:50:13,815:INFO:Finalizing model
2024-06-12 10:50:14,147:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 10:50:14,147:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 10:50:14,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.
2024-06-12 10:50:14,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 10:50:14,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 10:50:14,147:INFO:[LightGBM] [Info] Total Bins 623
2024-06-12 10:50:14,147:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 10:50:14,147:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 10:50:14,147:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 10:50:14,272:INFO:Uploading results into container
2024-06-12 10:50:14,272:INFO:Uploading model into container now
2024-06-12 10:50:14,272:INFO:_master_model_container: 3
2024-06-12 10:50:14,272:INFO:_display_container: 4
2024-06-12 10:50:14,272:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:50:14,272:INFO:create_model() successfully completed......................................
2024-06-12 10:50:14,366:INFO:SubProcess create_model() end ==================================
2024-06-12 10:50:14,366:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.134
2024-06-12 10:50:14,366:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1351
2024-06-12 10:50:14,366:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 10:50:14,366:INFO:choose_better completed
2024-06-12 10:50:14,381:INFO:_master_model_container: 3
2024-06-12 10:50:14,381:INFO:_display_container: 3
2024-06-12 10:50:14,381:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:50:14,381:INFO:tune_model() successfully completed......................................
2024-06-12 10:50:14,514:INFO:Initializing plot_model()
2024-06-12 10:50:14,514:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:50:14,514:INFO:Checking exceptions
2024-06-12 10:50:14,524:INFO:Preloading libraries
2024-06-12 10:50:14,543:INFO:Copying training dataset
2024-06-12 10:50:14,543:INFO:Plot type: auc
2024-06-12 10:50:14,998:INFO:Fitting Model
2024-06-12 10:50:14,998:INFO:Scoring test/hold-out set
2024-06-12 10:50:14,998:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:14,998:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:14,998:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:15,033:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:15,033:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:15,033:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:15,343:INFO:Visual Rendered Successfully
2024-06-12 10:50:15,417:INFO:plot_model() successfully completed......................................
2024-06-12 10:50:15,447:INFO:Initializing plot_model()
2024-06-12 10:50:15,447:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:50:15,447:INFO:Checking exceptions
2024-06-12 10:50:15,465:INFO:Preloading libraries
2024-06-12 10:50:15,479:INFO:Copying training dataset
2024-06-12 10:50:15,480:INFO:Plot type: confusion_matrix
2024-06-12 10:50:15,658:INFO:Fitting Model
2024-06-12 10:50:15,658:INFO:Scoring test/hold-out set
2024-06-12 10:50:15,674:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:15,674:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:15,674:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:15,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:15,693:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:15,693:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:15,873:INFO:Visual Rendered Successfully
2024-06-12 10:50:15,936:INFO:plot_model() successfully completed......................................
2024-06-12 10:50:15,959:INFO:Initializing finalize_model()
2024-06-12 10:50:15,959:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 10:50:15,959:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:50:15,976:INFO:Initializing create_model()
2024-06-12 10:50:15,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:50:15,976:INFO:Checking exceptions
2024-06-12 10:50:15,977:INFO:Importing libraries
2024-06-12 10:50:15,977:INFO:Copying training dataset
2024-06-12 10:50:15,978:INFO:Defining folds
2024-06-12 10:50:15,978:INFO:Declaring metric variables
2024-06-12 10:50:15,978:INFO:Importing untrained model
2024-06-12 10:50:15,978:INFO:Declaring custom model
2024-06-12 10:50:15,979:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:50:15,980:INFO:Cross validation set to False
2024-06-12 10:50:15,980:INFO:Fitting Model
2024-06-12 10:50:16,326:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:16,326:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:16,326:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:16,357:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 10:50:16,357:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:16,357:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:16,357:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:16,357:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 10:50:16,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001798 seconds.
2024-06-12 10:50:16,373:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 10:50:16,373:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 10:50:16,373:INFO:[LightGBM] [Info] Total Bins 619
2024-06-12 10:50:16,373:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 27
2024-06-12 10:50:16,373:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 10:50:16,373:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 10:50:16,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:50:16,826:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:50:16,826:INFO:create_model() successfully completed......................................
2024-06-12 10:50:16,909:INFO:_master_model_container: 3
2024-06-12 10:50:16,909:INFO:_display_container: 3
2024-06-12 10:50:16,943:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:50:16,943:INFO:finalize_model() successfully completed......................................
2024-06-12 10:50:17,060:INFO:Initializing evaluate_model()
2024-06-12 10:50:17,060:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-12 10:50:17,104:INFO:Initializing plot_model()
2024-06-12 10:50:17,104:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:50:17,104:INFO:Checking exceptions
2024-06-12 10:50:17,110:INFO:Preloading libraries
2024-06-12 10:50:17,143:INFO:Copying training dataset
2024-06-12 10:50:17,143:INFO:Plot type: pipeline
2024-06-12 10:50:17,327:INFO:Visual Rendered Successfully
2024-06-12 10:50:17,395:INFO:plot_model() successfully completed......................................
2024-06-12 10:50:17,462:INFO:Initializing predict_model()
2024-06-12 10:50:17,462:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026C8A343C40>)
2024-06-12 10:50:17,462:INFO:Checking exceptions
2024-06-12 10:50:17,462:INFO:Preloading libraries
2024-06-12 10:50:17,462:INFO:Set up data.
2024-06-12 10:50:17,931:INFO:Set up index.
2024-06-12 10:50:34,901:INFO:Initializing plot_model()
2024-06-12 10:50:34,901:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:50:34,901:INFO:Checking exceptions
2024-06-12 10:50:34,909:INFO:Preloading libraries
2024-06-12 10:50:34,922:INFO:Copying training dataset
2024-06-12 10:50:34,922:INFO:Plot type: confusion_matrix
2024-06-12 10:50:35,093:INFO:Fitting Model
2024-06-12 10:50:35,093:INFO:Scoring test/hold-out set
2024-06-12 10:50:35,093:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:35,093:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:35,093:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:35,130:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:35,130:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:35,130:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:35,291:INFO:Visual Rendered Successfully
2024-06-12 10:50:35,362:INFO:plot_model() successfully completed......................................
2024-06-12 10:50:42,556:INFO:Initializing plot_model()
2024-06-12 10:50:42,556:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:50:42,556:INFO:Checking exceptions
2024-06-12 10:50:42,556:INFO:Preloading libraries
2024-06-12 10:50:42,575:INFO:Copying training dataset
2024-06-12 10:50:42,575:INFO:Plot type: auc
2024-06-12 10:50:42,723:INFO:Fitting Model
2024-06-12 10:50:42,723:INFO:Scoring test/hold-out set
2024-06-12 10:50:42,723:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:42,723:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:42,723:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:42,759:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:42,759:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:42,759:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:43,025:INFO:Visual Rendered Successfully
2024-06-12 10:50:43,097:INFO:plot_model() successfully completed......................................
2024-06-12 10:50:45,840:INFO:Initializing plot_model()
2024-06-12 10:50:45,840:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:50:45,840:INFO:Checking exceptions
2024-06-12 10:50:45,857:INFO:Preloading libraries
2024-06-12 10:50:45,869:INFO:Copying training dataset
2024-06-12 10:50:45,869:INFO:Plot type: confusion_matrix
2024-06-12 10:50:46,025:INFO:Fitting Model
2024-06-12 10:50:46,025:INFO:Scoring test/hold-out set
2024-06-12 10:50:46,025:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:46,025:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:46,025:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:46,057:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:50:46,057:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:50:46,057:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:50:46,214:INFO:Visual Rendered Successfully
2024-06-12 10:50:46,288:INFO:plot_model() successfully completed......................................
2024-06-12 10:54:43,364:INFO:Initializing plot_model()
2024-06-12 10:54:43,364:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:54:43,364:INFO:Checking exceptions
2024-06-12 10:54:43,370:INFO:Preloading libraries
2024-06-12 10:54:43,383:INFO:Copying training dataset
2024-06-12 10:54:43,384:INFO:Plot type: auc
2024-06-12 10:54:43,559:INFO:Fitting Model
2024-06-12 10:54:43,559:INFO:Scoring test/hold-out set
2024-06-12 10:54:43,559:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:54:43,559:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:54:43,559:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:54:43,595:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:54:43,595:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:54:43,595:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:54:43,893:INFO:Visual Rendered Successfully
2024-06-12 10:54:43,977:INFO:plot_model() successfully completed......................................
2024-06-12 10:54:44,562:INFO:Initializing plot_model()
2024-06-12 10:54:44,562:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:54:44,562:INFO:Checking exceptions
2024-06-12 10:54:44,562:INFO:Preloading libraries
2024-06-12 10:54:44,582:INFO:Copying training dataset
2024-06-12 10:54:44,582:INFO:Plot type: confusion_matrix
2024-06-12 10:54:44,747:INFO:Fitting Model
2024-06-12 10:54:44,747:INFO:Scoring test/hold-out set
2024-06-12 10:54:44,747:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:54:44,747:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:54:44,747:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:54:44,798:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:54:44,798:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:54:44,798:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:54:44,979:INFO:Visual Rendered Successfully
2024-06-12 10:54:45,046:INFO:plot_model() successfully completed......................................
2024-06-12 10:55:09,339:INFO:Initializing plot_model()
2024-06-12 10:55:09,339:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:55:09,339:INFO:Checking exceptions
2024-06-12 10:55:09,359:INFO:Preloading libraries
2024-06-12 10:55:09,376:INFO:Copying training dataset
2024-06-12 10:55:09,376:INFO:Plot type: confusion_matrix
2024-06-12 10:55:09,576:INFO:Fitting Model
2024-06-12 10:55:09,577:INFO:Scoring test/hold-out set
2024-06-12 10:55:09,579:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:55:09,581:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:55:09,581:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:55:09,616:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:55:09,617:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:55:09,617:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:55:09,788:INFO:Visual Rendered Successfully
2024-06-12 10:55:09,864:INFO:plot_model() successfully completed......................................
2024-06-12 10:55:31,029:INFO:Initializing plot_model()
2024-06-12 10:55:31,029:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:55:31,029:INFO:Checking exceptions
2024-06-12 10:55:31,034:INFO:Preloading libraries
2024-06-12 10:55:31,051:INFO:Copying training dataset
2024-06-12 10:55:31,051:INFO:Plot type: auc
2024-06-12 10:55:31,227:INFO:Fitting Model
2024-06-12 10:55:31,227:INFO:Scoring test/hold-out set
2024-06-12 10:55:31,227:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:55:31,227:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:55:31,227:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:55:31,262:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:55:31,262:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:55:31,262:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:55:31,524:INFO:Visual Rendered Successfully
2024-06-12 10:55:31,599:INFO:plot_model() successfully completed......................................
2024-06-12 10:55:43,441:INFO:Initializing plot_model()
2024-06-12 10:55:43,441:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026C8906FC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-12 10:55:43,441:INFO:Checking exceptions
2024-06-12 10:55:43,456:INFO:Preloading libraries
2024-06-12 10:55:43,468:INFO:Copying training dataset
2024-06-12 10:55:43,468:INFO:Plot type: auc
2024-06-12 10:55:43,632:INFO:Fitting Model
2024-06-12 10:55:43,633:INFO:Scoring test/hold-out set
2024-06-12 10:55:43,636:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:55:43,636:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:55:43,636:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:55:43,655:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:55:43,655:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:55:43,655:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:55:43,907:INFO:Visual Rendered Successfully
2024-06-12 10:55:44,008:INFO:plot_model() successfully completed......................................
2024-06-12 10:56:06,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:56:06,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:56:06,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:56:06,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 10:56:07,750:INFO:PyCaret ClassificationExperiment
2024-06-12 10:56:07,750:INFO:Logging name: clf-default-name
2024-06-12 10:56:07,750:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 10:56:07,750:INFO:version 3.3.2
2024-06-12 10:56:07,750:INFO:Initializing setup()
2024-06-12 10:56:07,750:INFO:self.USI: d1df
2024-06-12 10:56:07,750:INFO:self._variable_keys: {'X', 'memory', 'target_param', 'y_train', 'fix_imbalance', '_ml_usecase', 'is_multiclass', 'USI', 'fold_shuffle_param', 'html_param', 'fold_groups_param', 'exp_name_log', 'n_jobs_param', 'X_test', 'seed', 'logging_param', '_available_plots', 'X_train', 'exp_id', 'pipeline', 'fold_generator', 'idx', 'gpu_param', 'y', 'data', 'gpu_n_jobs_param', 'y_test', 'log_plots_param'}
2024-06-12 10:56:07,750:INFO:Checking environment
2024-06-12 10:56:07,750:INFO:python_version: 3.11.9
2024-06-12 10:56:07,750:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 10:56:07,750:INFO:machine: AMD64
2024-06-12 10:56:07,750:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 10:56:07,750:INFO:Memory: svmem(total=34056318976, available=26919088128, percent=21.0, used=7137230848, free=26919088128)
2024-06-12 10:56:07,751:INFO:Physical Core: 6
2024-06-12 10:56:07,751:INFO:Logical Core: 12
2024-06-12 10:56:07,751:INFO:Checking libraries
2024-06-12 10:56:07,751:INFO:System:
2024-06-12 10:56:07,751:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 10:56:07,751:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 10:56:07,751:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 10:56:07,751:INFO:PyCaret required dependencies:
2024-06-12 10:56:07,808:INFO:                 pip: 24.0
2024-06-12 10:56:07,808:INFO:          setuptools: 69.5.1
2024-06-12 10:56:07,808:INFO:             pycaret: 3.3.2
2024-06-12 10:56:07,808:INFO:             IPython: 8.25.0
2024-06-12 10:56:07,808:INFO:          ipywidgets: 8.1.3
2024-06-12 10:56:07,808:INFO:                tqdm: 4.66.4
2024-06-12 10:56:07,808:INFO:               numpy: 1.26.4
2024-06-12 10:56:07,808:INFO:              pandas: 2.1.4
2024-06-12 10:56:07,808:INFO:              jinja2: 3.1.4
2024-06-12 10:56:07,808:INFO:               scipy: 1.11.4
2024-06-12 10:56:07,808:INFO:              joblib: 1.3.2
2024-06-12 10:56:07,808:INFO:             sklearn: 1.4.2
2024-06-12 10:56:07,808:INFO:                pyod: 2.0.0
2024-06-12 10:56:07,808:INFO:            imblearn: 0.12.3
2024-06-12 10:56:07,808:INFO:   category_encoders: 2.6.3
2024-06-12 10:56:07,808:INFO:            lightgbm: 4.3.0
2024-06-12 10:56:07,808:INFO:               numba: 0.59.1
2024-06-12 10:56:07,808:INFO:            requests: 2.32.3
2024-06-12 10:56:07,808:INFO:          matplotlib: 3.7.5
2024-06-12 10:56:07,808:INFO:          scikitplot: 0.3.7
2024-06-12 10:56:07,808:INFO:         yellowbrick: 1.5
2024-06-12 10:56:07,808:INFO:              plotly: 5.22.0
2024-06-12 10:56:07,808:INFO:    plotly-resampler: Not installed
2024-06-12 10:56:07,808:INFO:             kaleido: 0.2.1
2024-06-12 10:56:07,808:INFO:           schemdraw: 0.15
2024-06-12 10:56:07,808:INFO:         statsmodels: 0.14.2
2024-06-12 10:56:07,808:INFO:              sktime: 0.26.0
2024-06-12 10:56:07,808:INFO:               tbats: 1.1.3
2024-06-12 10:56:07,808:INFO:            pmdarima: 2.0.4
2024-06-12 10:56:07,808:INFO:              psutil: 5.9.8
2024-06-12 10:56:07,808:INFO:          markupsafe: 2.1.5
2024-06-12 10:56:07,808:INFO:             pickle5: Not installed
2024-06-12 10:56:07,808:INFO:         cloudpickle: 3.0.0
2024-06-12 10:56:07,808:INFO:         deprecation: 2.1.0
2024-06-12 10:56:07,808:INFO:              xxhash: 3.4.1
2024-06-12 10:56:07,808:INFO:           wurlitzer: Not installed
2024-06-12 10:56:07,808:INFO:PyCaret optional dependencies:
2024-06-12 10:56:07,808:INFO:                shap: Not installed
2024-06-12 10:56:07,808:INFO:           interpret: Not installed
2024-06-12 10:56:07,808:INFO:                umap: Not installed
2024-06-12 10:56:07,808:INFO:     ydata_profiling: Not installed
2024-06-12 10:56:07,808:INFO:  explainerdashboard: Not installed
2024-06-12 10:56:07,808:INFO:             autoviz: Not installed
2024-06-12 10:56:07,808:INFO:           fairlearn: Not installed
2024-06-12 10:56:07,808:INFO:          deepchecks: Not installed
2024-06-12 10:56:07,808:INFO:             xgboost: Not installed
2024-06-12 10:56:07,808:INFO:            catboost: Not installed
2024-06-12 10:56:07,808:INFO:              kmodes: Not installed
2024-06-12 10:56:07,808:INFO:             mlxtend: Not installed
2024-06-12 10:56:07,808:INFO:       statsforecast: Not installed
2024-06-12 10:56:07,808:INFO:        tune_sklearn: Not installed
2024-06-12 10:56:07,808:INFO:                 ray: Not installed
2024-06-12 10:56:07,808:INFO:            hyperopt: Not installed
2024-06-12 10:56:07,808:INFO:              optuna: Not installed
2024-06-12 10:56:07,808:INFO:               skopt: Not installed
2024-06-12 10:56:07,808:INFO:              mlflow: Not installed
2024-06-12 10:56:07,808:INFO:              gradio: Not installed
2024-06-12 10:56:07,808:INFO:             fastapi: Not installed
2024-06-12 10:56:07,808:INFO:             uvicorn: Not installed
2024-06-12 10:56:07,808:INFO:              m2cgen: Not installed
2024-06-12 10:56:07,808:INFO:           evidently: Not installed
2024-06-12 10:56:07,808:INFO:               fugue: Not installed
2024-06-12 10:56:07,808:INFO:           streamlit: 1.35.0
2024-06-12 10:56:07,808:INFO:             prophet: Not installed
2024-06-12 10:56:07,808:INFO:None
2024-06-12 10:56:07,808:INFO:Set up data.
2024-06-12 10:56:07,856:INFO:Set up folding strategy.
2024-06-12 10:56:07,856:INFO:Set up train/test split.
2024-06-12 10:56:07,875:INFO:Set up index.
2024-06-12 10:56:07,875:INFO:Assigning column types.
2024-06-12 10:56:07,886:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 10:56:07,927:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:56:07,927:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:56:07,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:07,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:56:08,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:56:08,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,041:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 10:56:08,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:56:08,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,151:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:56:08,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,174:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 10:56:08,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,320:INFO:Preparing preprocessing pipeline...
2024-06-12 10:56:08,320:INFO:Set up simple imputation.
2024-06-12 10:56:08,336:INFO:Set up encoding of ordinal features.
2024-06-12 10:56:08,351:INFO:Set up encoding of categorical features.
2024-06-12 10:56:08,660:INFO:Finished creating preprocessing pipeline.
2024-06-12 10:56:08,693:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-06-12 10:56:08,693:INFO:Creating final display dataframe.
2024-06-12 10:56:08,819:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              d1df
2024-06-12 10:56:08,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:56:08,973:INFO:setup() successfully completed in 1.37s...............
2024-06-12 10:56:08,975:INFO:Initializing create_model()
2024-06-12 10:56:08,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:56:08,975:INFO:Checking exceptions
2024-06-12 10:56:08,994:INFO:Importing libraries
2024-06-12 10:56:08,994:INFO:Copying training dataset
2024-06-12 10:56:09,017:INFO:Defining folds
2024-06-12 10:56:09,017:INFO:Declaring metric variables
2024-06-12 10:56:09,021:INFO:Importing untrained model
2024-06-12 10:56:09,024:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:56:09,030:INFO:Starting cross validation
2024-06-12 10:56:09,032:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:56:13,998:INFO:Calculating mean and std
2024-06-12 10:56:13,998:INFO:Creating metrics dataframe
2024-06-12 10:56:14,008:INFO:Finalizing model
2024-06-12 10:56:14,356:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 10:56:14,372:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 10:56:14,372:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.
2024-06-12 10:56:14,372:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 10:56:14,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 10:56:14,372:INFO:[LightGBM] [Info] Total Bins 623
2024-06-12 10:56:14,372:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 10:56:14,372:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 10:56:14,372:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 10:56:14,523:INFO:Uploading results into container
2024-06-12 10:56:14,524:INFO:Uploading model into container now
2024-06-12 10:56:14,526:INFO:_master_model_container: 1
2024-06-12 10:56:14,539:INFO:_display_container: 2
2024-06-12 10:56:14,539:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:56:14,540:INFO:create_model() successfully completed......................................
2024-06-12 10:56:14,641:INFO:Initializing tune_model()
2024-06-12 10:56:14,641:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 10:56:14,641:INFO:Checking exceptions
2024-06-12 10:56:14,687:INFO:Copying training dataset
2024-06-12 10:56:14,705:INFO:Checking base model
2024-06-12 10:56:14,705:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 10:56:14,712:INFO:Declaring metric variables
2024-06-12 10:56:14,718:INFO:Defining Hyperparameters
2024-06-12 10:56:14,815:INFO:Tuning with n_jobs=-1
2024-06-12 10:56:14,816:INFO:Initializing RandomizedSearchCV
2024-06-12 10:56:44,762:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-12 10:56:44,763:INFO:Hyperparameter search completed
2024-06-12 10:56:44,763:INFO:SubProcess create_model() called ==================================
2024-06-12 10:56:44,764:INFO:Initializing create_model()
2024-06-12 10:56:44,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0E0780510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-12 10:56:44,764:INFO:Checking exceptions
2024-06-12 10:56:44,765:INFO:Importing libraries
2024-06-12 10:56:44,766:INFO:Copying training dataset
2024-06-12 10:56:44,794:INFO:Defining folds
2024-06-12 10:56:44,794:INFO:Declaring metric variables
2024-06-12 10:56:44,799:INFO:Importing untrained model
2024-06-12 10:56:44,799:INFO:Declaring custom model
2024-06-12 10:56:44,805:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:56:44,816:INFO:Starting cross validation
2024-06-12 10:56:44,819:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:56:47,343:INFO:Calculating mean and std
2024-06-12 10:56:47,343:INFO:Creating metrics dataframe
2024-06-12 10:56:47,352:INFO:Finalizing model
2024-06-12 10:56:47,640:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:47,640:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:47,640:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:47,659:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 10:56:47,660:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:47,660:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:47,660:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:47,660:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 10:56:47,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001308 seconds.
2024-06-12 10:56:47,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 10:56:47,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 10:56:47,664:INFO:[LightGBM] [Info] Total Bins 619
2024-06-12 10:56:47,664:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 27
2024-06-12 10:56:47,665:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 10:56:47,665:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 10:56:47,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:47,963:INFO:Uploading results into container
2024-06-12 10:56:47,965:INFO:Uploading model into container now
2024-06-12 10:56:47,965:INFO:_master_model_container: 2
2024-06-12 10:56:47,965:INFO:_display_container: 3
2024-06-12 10:56:47,965:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:56:47,965:INFO:create_model() successfully completed......................................
2024-06-12 10:56:48,070:INFO:SubProcess create_model() end ==================================
2024-06-12 10:56:48,070:INFO:choose_better activated
2024-06-12 10:56:48,072:INFO:SubProcess create_model() called ==================================
2024-06-12 10:56:48,072:INFO:Initializing create_model()
2024-06-12 10:56:48,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:56:48,072:INFO:Checking exceptions
2024-06-12 10:56:48,072:INFO:Importing libraries
2024-06-12 10:56:48,072:INFO:Copying training dataset
2024-06-12 10:56:48,096:INFO:Defining folds
2024-06-12 10:56:48,096:INFO:Declaring metric variables
2024-06-12 10:56:48,096:INFO:Importing untrained model
2024-06-12 10:56:48,096:INFO:Declaring custom model
2024-06-12 10:56:48,096:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:56:48,096:INFO:Starting cross validation
2024-06-12 10:56:48,102:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:56:49,682:INFO:Calculating mean and std
2024-06-12 10:56:49,683:INFO:Creating metrics dataframe
2024-06-12 10:56:49,685:INFO:Finalizing model
2024-06-12 10:56:50,006:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 10:56:50,006:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 10:56:50,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001873 seconds.
2024-06-12 10:56:50,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 10:56:50,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 10:56:50,006:INFO:[LightGBM] [Info] Total Bins 623
2024-06-12 10:56:50,006:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 10:56:50,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 10:56:50,006:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 10:56:50,198:INFO:Uploading results into container
2024-06-12 10:56:50,199:INFO:Uploading model into container now
2024-06-12 10:56:50,199:INFO:_master_model_container: 3
2024-06-12 10:56:50,200:INFO:_display_container: 4
2024-06-12 10:56:50,200:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:56:50,200:INFO:create_model() successfully completed......................................
2024-06-12 10:56:50,291:INFO:SubProcess create_model() end ==================================
2024-06-12 10:56:50,291:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.134
2024-06-12 10:56:50,291:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1351
2024-06-12 10:56:50,291:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 10:56:50,291:INFO:choose_better completed
2024-06-12 10:56:50,305:INFO:_master_model_container: 3
2024-06-12 10:56:50,305:INFO:_display_container: 3
2024-06-12 10:56:50,305:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:56:50,305:INFO:tune_model() successfully completed......................................
2024-06-12 10:56:50,638:INFO:Initializing plot_model()
2024-06-12 10:56:50,640:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:56:50,640:INFO:Checking exceptions
2024-06-12 10:56:50,640:INFO:Preloading libraries
2024-06-12 10:56:50,668:INFO:Copying training dataset
2024-06-12 10:56:50,668:INFO:Plot type: auc
2024-06-12 10:56:50,875:INFO:Fitting Model
2024-06-12 10:56:50,875:INFO:Scoring test/hold-out set
2024-06-12 10:56:50,875:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:50,875:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:50,875:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:50,903:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:50,903:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:50,903:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:51,204:INFO:Visual Rendered Successfully
2024-06-12 10:56:51,270:INFO:plot_model() successfully completed......................................
2024-06-12 10:56:51,336:INFO:Initializing plot_model()
2024-06-12 10:56:51,336:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:56:51,337:INFO:Checking exceptions
2024-06-12 10:56:51,353:INFO:Preloading libraries
2024-06-12 10:56:51,377:INFO:Copying training dataset
2024-06-12 10:56:51,378:INFO:Plot type: confusion_matrix
2024-06-12 10:56:51,550:INFO:Fitting Model
2024-06-12 10:56:51,550:INFO:Scoring test/hold-out set
2024-06-12 10:56:51,550:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:51,550:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:51,550:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:51,585:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:51,585:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:51,585:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:51,761:INFO:Visual Rendered Successfully
2024-06-12 10:56:51,832:INFO:plot_model() successfully completed......................................
2024-06-12 10:56:51,845:INFO:Initializing finalize_model()
2024-06-12 10:56:51,845:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 10:56:51,845:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:56:51,845:INFO:Initializing create_model()
2024-06-12 10:56:51,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:56:51,845:INFO:Checking exceptions
2024-06-12 10:56:51,845:INFO:Importing libraries
2024-06-12 10:56:51,845:INFO:Copying training dataset
2024-06-12 10:56:51,845:INFO:Defining folds
2024-06-12 10:56:51,845:INFO:Declaring metric variables
2024-06-12 10:56:51,845:INFO:Importing untrained model
2024-06-12 10:56:51,845:INFO:Declaring custom model
2024-06-12 10:56:51,861:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:56:51,862:INFO:Cross validation set to False
2024-06-12 10:56:51,862:INFO:Fitting Model
2024-06-12 10:56:52,212:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:52,212:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:52,212:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:52,262:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 10:56:52,262:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:52,262:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:52,262:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:52,262:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 10:56:52,262:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002651 seconds.
2024-06-12 10:56:52,262:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 10:56:52,262:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 10:56:52,262:INFO:[LightGBM] [Info] Total Bins 619
2024-06-12 10:56:52,262:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 27
2024-06-12 10:56:52,262:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 10:56:52,262:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 10:56:52,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:56:52,912:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:56:52,912:INFO:create_model() successfully completed......................................
2024-06-12 10:56:52,995:INFO:_master_model_container: 3
2024-06-12 10:56:52,995:INFO:_display_container: 3
2024-06-12 10:56:53,031:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:56:53,031:INFO:finalize_model() successfully completed......................................
2024-06-12 10:56:53,149:INFO:Initializing plot_model()
2024-06-12 10:56:53,149:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:56:53,149:INFO:Checking exceptions
2024-06-12 10:56:53,171:INFO:Preloading libraries
2024-06-12 10:56:53,191:INFO:Copying training dataset
2024-06-12 10:56:53,191:INFO:Plot type: auc
2024-06-12 10:56:53,379:INFO:Fitting Model
2024-06-12 10:56:53,379:INFO:Scoring test/hold-out set
2024-06-12 10:56:53,379:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:53,379:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:53,379:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:53,405:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:53,405:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:53,405:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:53,664:INFO:Visual Rendered Successfully
2024-06-12 10:56:53,749:INFO:plot_model() successfully completed......................................
2024-06-12 10:56:53,818:INFO:Initializing plot_model()
2024-06-12 10:56:53,818:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:56:53,818:INFO:Checking exceptions
2024-06-12 10:56:53,827:INFO:Preloading libraries
2024-06-12 10:56:53,840:INFO:Copying training dataset
2024-06-12 10:56:53,840:INFO:Plot type: confusion_matrix
2024-06-12 10:56:54,007:INFO:Fitting Model
2024-06-12 10:56:54,016:INFO:Scoring test/hold-out set
2024-06-12 10:56:54,017:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:54,017:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:54,017:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:54,047:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 10:56:54,047:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 10:56:54,047:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 10:56:54,226:INFO:Visual Rendered Successfully
2024-06-12 10:56:54,301:INFO:plot_model() successfully completed......................................
2024-06-12 10:56:54,343:INFO:Initializing predict_model()
2024-06-12 10:56:54,343:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949E4DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B095CDFE20>)
2024-06-12 10:56:54,343:INFO:Checking exceptions
2024-06-12 10:56:54,343:INFO:Preloading libraries
2024-06-12 10:56:54,359:INFO:Set up data.
2024-06-12 10:56:54,819:INFO:Set up index.
2024-06-12 10:58:21,516:INFO:PyCaret ClassificationExperiment
2024-06-12 10:58:21,516:INFO:Logging name: clf-default-name
2024-06-12 10:58:21,516:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 10:58:21,517:INFO:version 3.3.2
2024-06-12 10:58:21,517:INFO:Initializing setup()
2024-06-12 10:58:21,517:INFO:self.USI: 0864
2024-06-12 10:58:21,517:INFO:self._variable_keys: {'X', 'memory', 'target_param', 'y_train', 'fix_imbalance', '_ml_usecase', 'is_multiclass', 'USI', 'fold_shuffle_param', 'html_param', 'fold_groups_param', 'exp_name_log', 'n_jobs_param', 'X_test', 'seed', 'logging_param', '_available_plots', 'X_train', 'exp_id', 'pipeline', 'fold_generator', 'idx', 'gpu_param', 'y', 'data', 'gpu_n_jobs_param', 'y_test', 'log_plots_param'}
2024-06-12 10:58:21,517:INFO:Checking environment
2024-06-12 10:58:21,517:INFO:python_version: 3.11.9
2024-06-12 10:58:21,517:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 10:58:21,517:INFO:machine: AMD64
2024-06-12 10:58:21,517:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 10:58:21,517:INFO:Memory: svmem(total=34056318976, available=25376571392, percent=25.5, used=8679747584, free=25376571392)
2024-06-12 10:58:21,517:INFO:Physical Core: 6
2024-06-12 10:58:21,517:INFO:Logical Core: 12
2024-06-12 10:58:21,518:INFO:Checking libraries
2024-06-12 10:58:21,518:INFO:System:
2024-06-12 10:58:21,518:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 10:58:21,518:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 10:58:21,518:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 10:58:21,518:INFO:PyCaret required dependencies:
2024-06-12 10:58:21,518:INFO:                 pip: 24.0
2024-06-12 10:58:21,518:INFO:          setuptools: 69.5.1
2024-06-12 10:58:21,518:INFO:             pycaret: 3.3.2
2024-06-12 10:58:21,518:INFO:             IPython: 8.25.0
2024-06-12 10:58:21,518:INFO:          ipywidgets: 8.1.3
2024-06-12 10:58:21,518:INFO:                tqdm: 4.66.4
2024-06-12 10:58:21,519:INFO:               numpy: 1.26.4
2024-06-12 10:58:21,519:INFO:              pandas: 2.1.4
2024-06-12 10:58:21,519:INFO:              jinja2: 3.1.4
2024-06-12 10:58:21,519:INFO:               scipy: 1.11.4
2024-06-12 10:58:21,519:INFO:              joblib: 1.3.2
2024-06-12 10:58:21,519:INFO:             sklearn: 1.4.2
2024-06-12 10:58:21,519:INFO:                pyod: 2.0.0
2024-06-12 10:58:21,519:INFO:            imblearn: 0.12.3
2024-06-12 10:58:21,519:INFO:   category_encoders: 2.6.3
2024-06-12 10:58:21,519:INFO:            lightgbm: 4.3.0
2024-06-12 10:58:21,519:INFO:               numba: 0.59.1
2024-06-12 10:58:21,519:INFO:            requests: 2.32.3
2024-06-12 10:58:21,519:INFO:          matplotlib: 3.7.5
2024-06-12 10:58:21,519:INFO:          scikitplot: 0.3.7
2024-06-12 10:58:21,519:INFO:         yellowbrick: 1.5
2024-06-12 10:58:21,519:INFO:              plotly: 5.22.0
2024-06-12 10:58:21,520:INFO:    plotly-resampler: Not installed
2024-06-12 10:58:21,520:INFO:             kaleido: 0.2.1
2024-06-12 10:58:21,520:INFO:           schemdraw: 0.15
2024-06-12 10:58:21,520:INFO:         statsmodels: 0.14.2
2024-06-12 10:58:21,520:INFO:              sktime: 0.26.0
2024-06-12 10:58:21,520:INFO:               tbats: 1.1.3
2024-06-12 10:58:21,520:INFO:            pmdarima: 2.0.4
2024-06-12 10:58:21,520:INFO:              psutil: 5.9.8
2024-06-12 10:58:21,520:INFO:          markupsafe: 2.1.5
2024-06-12 10:58:21,520:INFO:             pickle5: Not installed
2024-06-12 10:58:21,521:INFO:         cloudpickle: 3.0.0
2024-06-12 10:58:21,521:INFO:         deprecation: 2.1.0
2024-06-12 10:58:21,521:INFO:              xxhash: 3.4.1
2024-06-12 10:58:21,521:INFO:           wurlitzer: Not installed
2024-06-12 10:58:21,521:INFO:PyCaret optional dependencies:
2024-06-12 10:58:21,521:INFO:                shap: Not installed
2024-06-12 10:58:21,521:INFO:           interpret: Not installed
2024-06-12 10:58:21,521:INFO:                umap: Not installed
2024-06-12 10:58:21,521:INFO:     ydata_profiling: Not installed
2024-06-12 10:58:21,521:INFO:  explainerdashboard: Not installed
2024-06-12 10:58:21,521:INFO:             autoviz: Not installed
2024-06-12 10:58:21,521:INFO:           fairlearn: Not installed
2024-06-12 10:58:21,521:INFO:          deepchecks: Not installed
2024-06-12 10:58:21,521:INFO:             xgboost: Not installed
2024-06-12 10:58:21,521:INFO:            catboost: Not installed
2024-06-12 10:58:21,521:INFO:              kmodes: Not installed
2024-06-12 10:58:21,522:INFO:             mlxtend: Not installed
2024-06-12 10:58:21,522:INFO:       statsforecast: Not installed
2024-06-12 10:58:21,522:INFO:        tune_sklearn: Not installed
2024-06-12 10:58:21,522:INFO:                 ray: Not installed
2024-06-12 10:58:21,522:INFO:            hyperopt: Not installed
2024-06-12 10:58:21,522:INFO:              optuna: Not installed
2024-06-12 10:58:21,522:INFO:               skopt: Not installed
2024-06-12 10:58:21,522:INFO:              mlflow: Not installed
2024-06-12 10:58:21,522:INFO:              gradio: Not installed
2024-06-12 10:58:21,522:INFO:             fastapi: Not installed
2024-06-12 10:58:21,522:INFO:             uvicorn: Not installed
2024-06-12 10:58:21,522:INFO:              m2cgen: Not installed
2024-06-12 10:58:21,522:INFO:           evidently: Not installed
2024-06-12 10:58:21,522:INFO:               fugue: Not installed
2024-06-12 10:58:21,522:INFO:           streamlit: 1.35.0
2024-06-12 10:58:21,523:INFO:             prophet: Not installed
2024-06-12 10:58:21,523:INFO:None
2024-06-12 10:58:21,523:INFO:Set up data.
2024-06-12 10:58:21,559:INFO:Set up folding strategy.
2024-06-12 10:58:21,559:INFO:Set up train/test split.
2024-06-12 10:58:21,572:INFO:Set up index.
2024-06-12 10:58:21,588:INFO:Assigning column types.
2024-06-12 10:58:21,596:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 10:58:21,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:58:21,639:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:58:21,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:21,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:21,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 10:58:21,710:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:58:21,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:21,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:21,749:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 10:58:21,794:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:58:21,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:21,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:21,872:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 10:58:21,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:21,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:21,917:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 10:58:21,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:21,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:22,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:22,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:22,072:INFO:Preparing preprocessing pipeline...
2024-06-12 10:58:22,072:INFO:Set up simple imputation.
2024-06-12 10:58:22,088:INFO:Set up encoding of ordinal features.
2024-06-12 10:58:22,105:INFO:Set up encoding of categorical features.
2024-06-12 10:58:22,105:INFO:Set up PCA.
2024-06-12 10:58:22,588:INFO:Finished creating preprocessing pipeline.
2024-06-12 10:58:22,622:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 10:58:22,622:INFO:Creating final display dataframe.
2024-06-12 10:58:23,212:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                          PCA              True
17                   PCA method            linear
18               PCA components              None
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              0864
2024-06-12 10:58:23,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:23,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:23,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:23,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 10:58:23,388:INFO:setup() successfully completed in 1.97s...............
2024-06-12 10:58:23,475:INFO:Initializing create_model()
2024-06-12 10:58:23,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:58:23,475:INFO:Checking exceptions
2024-06-12 10:58:23,488:INFO:Importing libraries
2024-06-12 10:58:23,488:INFO:Copying training dataset
2024-06-12 10:58:23,509:INFO:Defining folds
2024-06-12 10:58:23,509:INFO:Declaring metric variables
2024-06-12 10:58:23,512:INFO:Importing untrained model
2024-06-12 10:58:23,515:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:58:23,521:INFO:Starting cross validation
2024-06-12 10:58:23,526:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:58:25,617:INFO:Calculating mean and std
2024-06-12 10:58:25,617:INFO:Creating metrics dataframe
2024-06-12 10:58:25,622:INFO:Finalizing model
2024-06-12 10:58:26,023:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 10:58:26,023:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004289 seconds.
2024-06-12 10:58:26,023:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:58:26,023:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 10:58:26,023:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 10:58:26,023:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 10:58:26,038:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 10:58:26,245:INFO:Uploading results into container
2024-06-12 10:58:26,246:INFO:Uploading model into container now
2024-06-12 10:58:26,258:INFO:_master_model_container: 1
2024-06-12 10:58:26,259:INFO:_display_container: 2
2024-06-12 10:58:26,260:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:58:26,260:INFO:create_model() successfully completed......................................
2024-06-12 10:58:26,370:INFO:Initializing tune_model()
2024-06-12 10:58:26,370:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 10:58:26,370:INFO:Checking exceptions
2024-06-12 10:58:26,406:INFO:Copying training dataset
2024-06-12 10:58:26,417:INFO:Checking base model
2024-06-12 10:58:26,417:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 10:58:26,419:INFO:Declaring metric variables
2024-06-12 10:58:26,423:INFO:Defining Hyperparameters
2024-06-12 10:58:26,492:INFO:Tuning with n_jobs=-1
2024-06-12 10:58:26,492:INFO:Initializing RandomizedSearchCV
2024-06-12 10:58:54,190:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-12 10:58:54,191:INFO:Hyperparameter search completed
2024-06-12 10:58:54,192:INFO:SubProcess create_model() called ==================================
2024-06-12 10:58:54,193:INFO:Initializing create_model()
2024-06-12 10:58:54,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0E0751610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-12 10:58:54,193:INFO:Checking exceptions
2024-06-12 10:58:54,193:INFO:Importing libraries
2024-06-12 10:58:54,193:INFO:Copying training dataset
2024-06-12 10:58:54,222:INFO:Defining folds
2024-06-12 10:58:54,223:INFO:Declaring metric variables
2024-06-12 10:58:54,228:INFO:Importing untrained model
2024-06-12 10:58:54,228:INFO:Declaring custom model
2024-06-12 10:58:54,234:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:58:54,245:INFO:Starting cross validation
2024-06-12 10:58:54,249:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:58:58,717:INFO:Calculating mean and std
2024-06-12 10:58:58,719:INFO:Creating metrics dataframe
2024-06-12 10:58:58,726:INFO:Finalizing model
2024-06-12 10:58:59,074:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:58:59,075:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:58:59,075:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:58:59,125:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:58:59,125:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:58:59,125:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:58:59,125:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 10:58:59,130:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003858 seconds.
2024-06-12 10:58:59,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:58:59,131:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 10:58:59,132:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 10:58:59,135:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 10:58:59,135:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 10:58:59,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:58:59,824:INFO:Uploading results into container
2024-06-12 10:58:59,826:INFO:Uploading model into container now
2024-06-12 10:58:59,826:INFO:_master_model_container: 2
2024-06-12 10:58:59,826:INFO:_display_container: 3
2024-06-12 10:58:59,826:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:58:59,826:INFO:create_model() successfully completed......................................
2024-06-12 10:58:59,919:INFO:SubProcess create_model() end ==================================
2024-06-12 10:58:59,919:INFO:choose_better activated
2024-06-12 10:58:59,919:INFO:SubProcess create_model() called ==================================
2024-06-12 10:58:59,919:INFO:Initializing create_model()
2024-06-12 10:58:59,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:58:59,919:INFO:Checking exceptions
2024-06-12 10:58:59,919:INFO:Importing libraries
2024-06-12 10:58:59,919:INFO:Copying training dataset
2024-06-12 10:58:59,944:INFO:Defining folds
2024-06-12 10:58:59,944:INFO:Declaring metric variables
2024-06-12 10:58:59,944:INFO:Importing untrained model
2024-06-12 10:58:59,944:INFO:Declaring custom model
2024-06-12 10:58:59,945:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:58:59,945:INFO:Starting cross validation
2024-06-12 10:58:59,947:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 10:59:02,192:INFO:Calculating mean and std
2024-06-12 10:59:02,193:INFO:Creating metrics dataframe
2024-06-12 10:59:02,195:INFO:Finalizing model
2024-06-12 10:59:02,562:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 10:59:02,566:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003625 seconds.
2024-06-12 10:59:02,566:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:59:02,567:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 10:59:02,568:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 10:59:02,568:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 10:59:02,568:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 10:59:02,757:INFO:Uploading results into container
2024-06-12 10:59:02,757:INFO:Uploading model into container now
2024-06-12 10:59:02,757:INFO:_master_model_container: 3
2024-06-12 10:59:02,757:INFO:_display_container: 4
2024-06-12 10:59:02,757:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:59:02,757:INFO:create_model() successfully completed......................................
2024-06-12 10:59:02,857:INFO:SubProcess create_model() end ==================================
2024-06-12 10:59:02,858:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1137
2024-06-12 10:59:02,858:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1296
2024-06-12 10:59:02,859:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 10:59:02,859:INFO:choose_better completed
2024-06-12 10:59:02,867:INFO:_master_model_container: 3
2024-06-12 10:59:02,868:INFO:_display_container: 3
2024-06-12 10:59:02,868:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:59:02,868:INFO:tune_model() successfully completed......................................
2024-06-12 10:59:02,956:INFO:Initializing plot_model()
2024-06-12 10:59:02,956:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:59:02,956:INFO:Checking exceptions
2024-06-12 10:59:02,966:INFO:Preloading libraries
2024-06-12 10:59:03,001:INFO:Copying training dataset
2024-06-12 10:59:03,001:INFO:Plot type: auc
2024-06-12 10:59:03,170:INFO:Fitting Model
2024-06-12 10:59:03,171:INFO:Scoring test/hold-out set
2024-06-12 10:59:03,173:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:03,173:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:03,173:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:03,234:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:03,234:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:03,234:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:03,518:INFO:Visual Rendered Successfully
2024-06-12 10:59:03,585:INFO:plot_model() successfully completed......................................
2024-06-12 10:59:03,618:INFO:Initializing plot_model()
2024-06-12 10:59:03,618:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:59:03,619:INFO:Checking exceptions
2024-06-12 10:59:03,629:INFO:Preloading libraries
2024-06-12 10:59:03,664:INFO:Copying training dataset
2024-06-12 10:59:03,664:INFO:Plot type: confusion_matrix
2024-06-12 10:59:03,850:INFO:Fitting Model
2024-06-12 10:59:03,850:INFO:Scoring test/hold-out set
2024-06-12 10:59:03,850:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:03,850:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:03,850:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:03,933:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:03,933:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:03,933:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:04,169:INFO:Visual Rendered Successfully
2024-06-12 10:59:04,240:INFO:plot_model() successfully completed......................................
2024-06-12 10:59:04,257:INFO:Initializing finalize_model()
2024-06-12 10:59:04,257:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 10:59:04,257:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 10:59:04,276:INFO:Initializing create_model()
2024-06-12 10:59:04,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 10:59:04,276:INFO:Checking exceptions
2024-06-12 10:59:04,278:INFO:Importing libraries
2024-06-12 10:59:04,279:INFO:Copying training dataset
2024-06-12 10:59:04,280:INFO:Defining folds
2024-06-12 10:59:04,280:INFO:Declaring metric variables
2024-06-12 10:59:04,280:INFO:Importing untrained model
2024-06-12 10:59:04,281:INFO:Declaring custom model
2024-06-12 10:59:04,282:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 10:59:04,285:INFO:Cross validation set to False
2024-06-12 10:59:04,285:INFO:Fitting Model
2024-06-12 10:59:04,720:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:04,720:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:04,720:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:04,803:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:04,804:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:04,804:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:04,804:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 10:59:04,810:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004273 seconds.
2024-06-12 10:59:04,810:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 10:59:04,810:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 10:59:04,811:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 10:59:04,813:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 10:59:04,814:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 10:59:04,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:04,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:04,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:04,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 10:59:05,723:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:59:05,723:INFO:create_model() successfully completed......................................
2024-06-12 10:59:05,804:INFO:_master_model_container: 3
2024-06-12 10:59:05,804:INFO:_display_container: 3
2024-06-12 10:59:05,836:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 10:59:05,836:INFO:finalize_model() successfully completed......................................
2024-06-12 10:59:05,957:INFO:Initializing plot_model()
2024-06-12 10:59:05,957:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:59:05,957:INFO:Checking exceptions
2024-06-12 10:59:05,957:INFO:Preloading libraries
2024-06-12 10:59:06,005:INFO:Copying training dataset
2024-06-12 10:59:06,005:INFO:Plot type: auc
2024-06-12 10:59:06,189:INFO:Fitting Model
2024-06-12 10:59:06,189:INFO:Scoring test/hold-out set
2024-06-12 10:59:06,189:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:06,189:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:06,189:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:06,283:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:06,283:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:06,283:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:06,587:INFO:Visual Rendered Successfully
2024-06-12 10:59:06,658:INFO:plot_model() successfully completed......................................
2024-06-12 10:59:06,706:INFO:Initializing plot_model()
2024-06-12 10:59:06,707:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 10:59:06,707:INFO:Checking exceptions
2024-06-12 10:59:06,716:INFO:Preloading libraries
2024-06-12 10:59:06,746:INFO:Copying training dataset
2024-06-12 10:59:06,746:INFO:Plot type: confusion_matrix
2024-06-12 10:59:06,923:INFO:Fitting Model
2024-06-12 10:59:06,923:INFO:Scoring test/hold-out set
2024-06-12 10:59:06,925:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:06,925:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:06,925:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:06,969:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 10:59:06,969:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 10:59:06,969:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 10:59:07,201:INFO:Visual Rendered Successfully
2024-06-12 10:59:07,273:INFO:plot_model() successfully completed......................................
2024-06-12 10:59:07,331:INFO:Initializing predict_model()
2024-06-12 10:59:07,331:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B095BDF890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B095FCED40>)
2024-06-12 10:59:07,331:INFO:Checking exceptions
2024-06-12 10:59:07,331:INFO:Preloading libraries
2024-06-12 10:59:07,334:INFO:Set up data.
2024-06-12 10:59:07,753:INFO:Set up index.
2024-06-12 11:00:08,516:INFO:PyCaret ClassificationExperiment
2024-06-12 11:00:08,516:INFO:Logging name: clf-default-name
2024-06-12 11:00:08,516:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 11:00:08,516:INFO:version 3.3.2
2024-06-12 11:00:08,516:INFO:Initializing setup()
2024-06-12 11:00:08,516:INFO:self.USI: c6d2
2024-06-12 11:00:08,517:INFO:self._variable_keys: {'X', 'memory', 'target_param', 'y_train', 'fix_imbalance', '_ml_usecase', 'is_multiclass', 'USI', 'fold_shuffle_param', 'html_param', 'fold_groups_param', 'exp_name_log', 'n_jobs_param', 'X_test', 'seed', 'logging_param', '_available_plots', 'X_train', 'exp_id', 'pipeline', 'fold_generator', 'idx', 'gpu_param', 'y', 'data', 'gpu_n_jobs_param', 'y_test', 'log_plots_param'}
2024-06-12 11:00:08,517:INFO:Checking environment
2024-06-12 11:00:08,517:INFO:python_version: 3.11.9
2024-06-12 11:00:08,517:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 11:00:08,517:INFO:machine: AMD64
2024-06-12 11:00:08,517:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 11:00:08,517:INFO:Memory: svmem(total=34056318976, available=25073381376, percent=26.4, used=8982937600, free=25073381376)
2024-06-12 11:00:08,517:INFO:Physical Core: 6
2024-06-12 11:00:08,517:INFO:Logical Core: 12
2024-06-12 11:00:08,517:INFO:Checking libraries
2024-06-12 11:00:08,517:INFO:System:
2024-06-12 11:00:08,517:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 11:00:08,517:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 11:00:08,517:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 11:00:08,517:INFO:PyCaret required dependencies:
2024-06-12 11:00:08,517:INFO:                 pip: 24.0
2024-06-12 11:00:08,518:INFO:          setuptools: 69.5.1
2024-06-12 11:00:08,518:INFO:             pycaret: 3.3.2
2024-06-12 11:00:08,518:INFO:             IPython: 8.25.0
2024-06-12 11:00:08,518:INFO:          ipywidgets: 8.1.3
2024-06-12 11:00:08,518:INFO:                tqdm: 4.66.4
2024-06-12 11:00:08,518:INFO:               numpy: 1.26.4
2024-06-12 11:00:08,518:INFO:              pandas: 2.1.4
2024-06-12 11:00:08,518:INFO:              jinja2: 3.1.4
2024-06-12 11:00:08,518:INFO:               scipy: 1.11.4
2024-06-12 11:00:08,518:INFO:              joblib: 1.3.2
2024-06-12 11:00:08,518:INFO:             sklearn: 1.4.2
2024-06-12 11:00:08,518:INFO:                pyod: 2.0.0
2024-06-12 11:00:08,518:INFO:            imblearn: 0.12.3
2024-06-12 11:00:08,518:INFO:   category_encoders: 2.6.3
2024-06-12 11:00:08,518:INFO:            lightgbm: 4.3.0
2024-06-12 11:00:08,518:INFO:               numba: 0.59.1
2024-06-12 11:00:08,518:INFO:            requests: 2.32.3
2024-06-12 11:00:08,518:INFO:          matplotlib: 3.7.5
2024-06-12 11:00:08,518:INFO:          scikitplot: 0.3.7
2024-06-12 11:00:08,518:INFO:         yellowbrick: 1.5
2024-06-12 11:00:08,518:INFO:              plotly: 5.22.0
2024-06-12 11:00:08,519:INFO:    plotly-resampler: Not installed
2024-06-12 11:00:08,519:INFO:             kaleido: 0.2.1
2024-06-12 11:00:08,519:INFO:           schemdraw: 0.15
2024-06-12 11:00:08,519:INFO:         statsmodels: 0.14.2
2024-06-12 11:00:08,519:INFO:              sktime: 0.26.0
2024-06-12 11:00:08,519:INFO:               tbats: 1.1.3
2024-06-12 11:00:08,519:INFO:            pmdarima: 2.0.4
2024-06-12 11:00:08,519:INFO:              psutil: 5.9.8
2024-06-12 11:00:08,519:INFO:          markupsafe: 2.1.5
2024-06-12 11:00:08,519:INFO:             pickle5: Not installed
2024-06-12 11:00:08,519:INFO:         cloudpickle: 3.0.0
2024-06-12 11:00:08,519:INFO:         deprecation: 2.1.0
2024-06-12 11:00:08,519:INFO:              xxhash: 3.4.1
2024-06-12 11:00:08,519:INFO:           wurlitzer: Not installed
2024-06-12 11:00:08,519:INFO:PyCaret optional dependencies:
2024-06-12 11:00:08,519:INFO:                shap: Not installed
2024-06-12 11:00:08,519:INFO:           interpret: Not installed
2024-06-12 11:00:08,519:INFO:                umap: Not installed
2024-06-12 11:00:08,519:INFO:     ydata_profiling: Not installed
2024-06-12 11:00:08,520:INFO:  explainerdashboard: Not installed
2024-06-12 11:00:08,520:INFO:             autoviz: Not installed
2024-06-12 11:00:08,520:INFO:           fairlearn: Not installed
2024-06-12 11:00:08,520:INFO:          deepchecks: Not installed
2024-06-12 11:00:08,520:INFO:             xgboost: Not installed
2024-06-12 11:00:08,520:INFO:            catboost: Not installed
2024-06-12 11:00:08,520:INFO:              kmodes: Not installed
2024-06-12 11:00:08,520:INFO:             mlxtend: Not installed
2024-06-12 11:00:08,520:INFO:       statsforecast: Not installed
2024-06-12 11:00:08,520:INFO:        tune_sklearn: Not installed
2024-06-12 11:00:08,520:INFO:                 ray: Not installed
2024-06-12 11:00:08,520:INFO:            hyperopt: Not installed
2024-06-12 11:00:08,520:INFO:              optuna: Not installed
2024-06-12 11:00:08,520:INFO:               skopt: Not installed
2024-06-12 11:00:08,520:INFO:              mlflow: Not installed
2024-06-12 11:00:08,520:INFO:              gradio: Not installed
2024-06-12 11:00:08,521:INFO:             fastapi: Not installed
2024-06-12 11:00:08,521:INFO:             uvicorn: Not installed
2024-06-12 11:00:08,521:INFO:              m2cgen: Not installed
2024-06-12 11:00:08,521:INFO:           evidently: Not installed
2024-06-12 11:00:08,521:INFO:               fugue: Not installed
2024-06-12 11:00:08,521:INFO:           streamlit: 1.35.0
2024-06-12 11:00:08,521:INFO:             prophet: Not installed
2024-06-12 11:00:08,521:INFO:None
2024-06-12 11:00:08,521:INFO:Set up data.
2024-06-12 11:00:08,567:INFO:Set up folding strategy.
2024-06-12 11:00:08,568:INFO:Set up train/test split.
2024-06-12 11:00:08,594:INFO:Set up index.
2024-06-12 11:00:08,594:INFO:Assigning column types.
2024-06-12 11:00:08,594:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 11:00:08,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:00:08,643:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:00:08,681:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:08,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:08,728:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:00:08,728:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:00:08,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:08,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:08,761:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 11:00:08,811:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:00:08,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:08,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:08,893:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:00:08,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:08,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:08,910:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 11:00:08,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:08,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:09,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:09,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:09,081:INFO:Preparing preprocessing pipeline...
2024-06-12 11:00:09,082:INFO:Set up simple imputation.
2024-06-12 11:00:09,095:INFO:Set up encoding of ordinal features.
2024-06-12 11:00:09,098:INFO:Set up encoding of categorical features.
2024-06-12 11:00:09,098:INFO:Set up feature normalization.
2024-06-12 11:00:09,098:INFO:Set up PCA.
2024-06-12 11:00:09,562:INFO:Finished creating preprocessing pipeline.
2024-06-12 11:00:09,594:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 11:00:09,594:INFO:Creating final display dataframe.
2024-06-12 11:00:10,213:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              c6d2
2024-06-12 11:00:10,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:10,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:10,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:10,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:00:10,376:INFO:setup() successfully completed in 1.95s...............
2024-06-12 11:00:10,477:INFO:Initializing create_model()
2024-06-12 11:00:10,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:00:10,477:INFO:Checking exceptions
2024-06-12 11:00:10,480:INFO:Importing libraries
2024-06-12 11:00:10,480:INFO:Copying training dataset
2024-06-12 11:00:10,507:INFO:Defining folds
2024-06-12 11:00:10,507:INFO:Declaring metric variables
2024-06-12 11:00:10,510:INFO:Importing untrained model
2024-06-12 11:00:10,514:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:00:10,519:INFO:Starting cross validation
2024-06-12 11:00:10,522:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:00:12,683:INFO:Calculating mean and std
2024-06-12 11:00:12,683:INFO:Creating metrics dataframe
2024-06-12 11:00:12,692:INFO:Finalizing model
2024-06-12 11:00:13,076:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:00:13,076:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002434 seconds.
2024-06-12 11:00:13,076:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:00:13,076:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:00:13,076:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:00:13,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:00:13,076:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:00:13,343:INFO:Uploading results into container
2024-06-12 11:00:13,343:INFO:Uploading model into container now
2024-06-12 11:00:13,343:INFO:_master_model_container: 1
2024-06-12 11:00:13,343:INFO:_display_container: 2
2024-06-12 11:00:13,343:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:00:13,343:INFO:create_model() successfully completed......................................
2024-06-12 11:00:13,466:INFO:Initializing tune_model()
2024-06-12 11:00:13,466:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 11:00:13,466:INFO:Checking exceptions
2024-06-12 11:00:13,506:INFO:Copying training dataset
2024-06-12 11:00:13,519:INFO:Checking base model
2024-06-12 11:00:13,519:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 11:00:13,523:INFO:Declaring metric variables
2024-06-12 11:00:13,526:INFO:Defining Hyperparameters
2024-06-12 11:00:13,627:INFO:Tuning with n_jobs=-1
2024-06-12 11:00:13,627:INFO:Initializing RandomizedSearchCV
2024-06-12 11:00:43,360:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-12 11:00:43,360:INFO:Hyperparameter search completed
2024-06-12 11:00:43,360:INFO:SubProcess create_model() called ==================================
2024-06-12 11:00:43,360:INFO:Initializing create_model()
2024-06-12 11:00:43,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B095CE28D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-12 11:00:43,360:INFO:Checking exceptions
2024-06-12 11:00:43,360:INFO:Importing libraries
2024-06-12 11:00:43,360:INFO:Copying training dataset
2024-06-12 11:00:43,391:INFO:Defining folds
2024-06-12 11:00:43,391:INFO:Declaring metric variables
2024-06-12 11:00:43,391:INFO:Importing untrained model
2024-06-12 11:00:43,391:INFO:Declaring custom model
2024-06-12 11:00:43,407:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:00:43,423:INFO:Starting cross validation
2024-06-12 11:00:43,424:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:00:45,331:INFO:Calculating mean and std
2024-06-12 11:00:45,331:INFO:Creating metrics dataframe
2024-06-12 11:00:45,339:INFO:Finalizing model
2024-06-12 11:00:45,724:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:45,724:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:45,724:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:45,757:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:45,757:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:45,757:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:45,757:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:00:45,757:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002679 seconds.
2024-06-12 11:00:45,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:00:45,757:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:00:45,772:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:00:45,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:00:45,774:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:00:45,912:INFO:Uploading results into container
2024-06-12 11:00:45,912:INFO:Uploading model into container now
2024-06-12 11:00:45,912:INFO:_master_model_container: 2
2024-06-12 11:00:45,912:INFO:_display_container: 3
2024-06-12 11:00:45,912:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:00:45,912:INFO:create_model() successfully completed......................................
2024-06-12 11:00:46,007:INFO:SubProcess create_model() end ==================================
2024-06-12 11:00:46,007:INFO:choose_better activated
2024-06-12 11:00:46,007:INFO:SubProcess create_model() called ==================================
2024-06-12 11:00:46,007:INFO:Initializing create_model()
2024-06-12 11:00:46,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:00:46,007:INFO:Checking exceptions
2024-06-12 11:00:46,007:INFO:Importing libraries
2024-06-12 11:00:46,007:INFO:Copying training dataset
2024-06-12 11:00:46,023:INFO:Defining folds
2024-06-12 11:00:46,023:INFO:Declaring metric variables
2024-06-12 11:00:46,023:INFO:Importing untrained model
2024-06-12 11:00:46,023:INFO:Declaring custom model
2024-06-12 11:00:46,023:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:00:46,023:INFO:Starting cross validation
2024-06-12 11:00:46,023:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:00:48,076:INFO:Calculating mean and std
2024-06-12 11:00:48,076:INFO:Creating metrics dataframe
2024-06-12 11:00:48,076:INFO:Finalizing model
2024-06-12 11:00:48,536:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:00:48,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003045 seconds.
2024-06-12 11:00:48,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:00:48,536:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:00:48,536:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:00:48,536:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:00:48,536:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:00:48,787:INFO:Uploading results into container
2024-06-12 11:00:48,787:INFO:Uploading model into container now
2024-06-12 11:00:48,787:INFO:_master_model_container: 3
2024-06-12 11:00:48,787:INFO:_display_container: 4
2024-06-12 11:00:48,787:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:00:48,787:INFO:create_model() successfully completed......................................
2024-06-12 11:00:48,881:INFO:SubProcess create_model() end ==================================
2024-06-12 11:00:48,881:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is -0.0003
2024-06-12 11:00:48,881:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0501
2024-06-12 11:00:48,881:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 11:00:48,881:INFO:choose_better completed
2024-06-12 11:00:48,881:INFO:_master_model_container: 3
2024-06-12 11:00:48,881:INFO:_display_container: 3
2024-06-12 11:00:48,897:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:00:48,897:INFO:tune_model() successfully completed......................................
2024-06-12 11:00:48,990:INFO:Initializing plot_model()
2024-06-12 11:00:48,990:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:00:48,990:INFO:Checking exceptions
2024-06-12 11:00:48,993:INFO:Preloading libraries
2024-06-12 11:00:48,993:INFO:Copying training dataset
2024-06-12 11:00:48,993:INFO:Plot type: auc
2024-06-12 11:00:49,187:INFO:Fitting Model
2024-06-12 11:00:49,188:INFO:Scoring test/hold-out set
2024-06-12 11:00:49,191:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:49,191:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:49,191:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:49,196:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:49,196:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:49,196:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:49,460:INFO:Visual Rendered Successfully
2024-06-12 11:00:49,538:INFO:plot_model() successfully completed......................................
2024-06-12 11:00:49,553:INFO:Initializing plot_model()
2024-06-12 11:00:49,553:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:00:49,553:INFO:Checking exceptions
2024-06-12 11:00:49,562:INFO:Preloading libraries
2024-06-12 11:00:49,562:INFO:Copying training dataset
2024-06-12 11:00:49,562:INFO:Plot type: confusion_matrix
2024-06-12 11:00:49,732:INFO:Fitting Model
2024-06-12 11:00:49,733:INFO:Scoring test/hold-out set
2024-06-12 11:00:49,735:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:49,735:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:49,735:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:49,745:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:49,745:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:49,745:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:49,891:INFO:Visual Rendered Successfully
2024-06-12 11:00:49,953:INFO:plot_model() successfully completed......................................
2024-06-12 11:00:49,982:INFO:Initializing finalize_model()
2024-06-12 11:00:49,982:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 11:00:49,983:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:00:49,991:INFO:Initializing create_model()
2024-06-12 11:00:49,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:00:49,991:INFO:Checking exceptions
2024-06-12 11:00:49,991:INFO:Importing libraries
2024-06-12 11:00:49,991:INFO:Copying training dataset
2024-06-12 11:00:49,991:INFO:Defining folds
2024-06-12 11:00:49,991:INFO:Declaring metric variables
2024-06-12 11:00:49,991:INFO:Importing untrained model
2024-06-12 11:00:49,991:INFO:Declaring custom model
2024-06-12 11:00:49,991:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:00:49,991:INFO:Cross validation set to False
2024-06-12 11:00:49,991:INFO:Fitting Model
2024-06-12 11:00:50,460:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:50,460:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:50,460:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:50,520:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:50,521:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:50,521:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:50,521:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 11:00:50,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003608 seconds.
2024-06-12 11:00:50,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:00:50,526:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:00:50,529:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 11:00:50,531:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 11:00:50,531:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 11:00:50,730:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 11:00:50,730:INFO:create_model() successfully completed......................................
2024-06-12 11:00:50,803:INFO:_master_model_container: 3
2024-06-12 11:00:50,803:INFO:_display_container: 3
2024-06-12 11:00:50,835:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 11:00:50,835:INFO:finalize_model() successfully completed......................................
2024-06-12 11:00:50,944:INFO:Initializing plot_model()
2024-06-12 11:00:50,944:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:00:50,944:INFO:Checking exceptions
2024-06-12 11:00:50,960:INFO:Preloading libraries
2024-06-12 11:00:50,972:INFO:Copying training dataset
2024-06-12 11:00:50,972:INFO:Plot type: auc
2024-06-12 11:00:51,135:INFO:Fitting Model
2024-06-12 11:00:51,135:INFO:Scoring test/hold-out set
2024-06-12 11:00:51,150:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:51,150:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:51,150:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:51,150:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:51,150:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:51,150:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:51,396:INFO:Visual Rendered Successfully
2024-06-12 11:00:51,475:INFO:plot_model() successfully completed......................................
2024-06-12 11:00:51,510:INFO:Initializing plot_model()
2024-06-12 11:00:51,510:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:00:51,510:INFO:Checking exceptions
2024-06-12 11:00:51,532:INFO:Preloading libraries
2024-06-12 11:00:51,533:INFO:Copying training dataset
2024-06-12 11:00:51,533:INFO:Plot type: confusion_matrix
2024-06-12 11:00:51,710:INFO:Fitting Model
2024-06-12 11:00:51,711:INFO:Scoring test/hold-out set
2024-06-12 11:00:51,711:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:51,711:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:51,711:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:51,711:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:00:51,711:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:00:51,711:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:00:51,861:INFO:Visual Rendered Successfully
2024-06-12 11:00:51,940:INFO:plot_model() successfully completed......................................
2024-06-12 11:00:51,987:INFO:Initializing predict_model()
2024-06-12 11:00:51,987:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0949B5CD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B095D1DA80>)
2024-06-12 11:00:51,987:INFO:Checking exceptions
2024-06-12 11:00:51,987:INFO:Preloading libraries
2024-06-12 11:00:51,987:INFO:Set up data.
2024-06-12 11:00:52,398:INFO:Set up index.
2024-06-12 11:04:38,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 11:04:38,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 11:04:38,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 11:04:38,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 11:04:39,188:INFO:PyCaret ClassificationExperiment
2024-06-12 11:04:39,189:INFO:Logging name: clf-default-name
2024-06-12 11:04:39,189:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 11:04:39,189:INFO:version 3.3.2
2024-06-12 11:04:39,189:INFO:Initializing setup()
2024-06-12 11:04:39,190:INFO:self.USI: c102
2024-06-12 11:04:39,190:INFO:self._variable_keys: {'is_multiclass', 'html_param', 'X', '_ml_usecase', 'fold_shuffle_param', 'idx', '_available_plots', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'pipeline', 'X_train', 'target_param', 'fold_generator', 'fix_imbalance', 'exp_id', 'logging_param', 'exp_name_log', 'data', 'USI', 'log_plots_param', 'y_test', 'X_test', 'y', 'n_jobs_param', 'seed'}
2024-06-12 11:04:39,190:INFO:Checking environment
2024-06-12 11:04:39,190:INFO:python_version: 3.11.9
2024-06-12 11:04:39,190:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 11:04:39,191:INFO:machine: AMD64
2024-06-12 11:04:39,191:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 11:04:39,191:INFO:Memory: svmem(total=34056318976, available=26933075968, percent=20.9, used=7123243008, free=26933075968)
2024-06-12 11:04:39,191:INFO:Physical Core: 6
2024-06-12 11:04:39,191:INFO:Logical Core: 12
2024-06-12 11:04:39,191:INFO:Checking libraries
2024-06-12 11:04:39,191:INFO:System:
2024-06-12 11:04:39,191:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 11:04:39,191:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 11:04:39,191:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 11:04:39,191:INFO:PyCaret required dependencies:
2024-06-12 11:04:39,257:INFO:                 pip: 24.0
2024-06-12 11:04:39,257:INFO:          setuptools: 69.5.1
2024-06-12 11:04:39,257:INFO:             pycaret: 3.3.2
2024-06-12 11:04:39,257:INFO:             IPython: 8.25.0
2024-06-12 11:04:39,257:INFO:          ipywidgets: 8.1.3
2024-06-12 11:04:39,257:INFO:                tqdm: 4.66.4
2024-06-12 11:04:39,257:INFO:               numpy: 1.26.4
2024-06-12 11:04:39,257:INFO:              pandas: 2.1.4
2024-06-12 11:04:39,257:INFO:              jinja2: 3.1.4
2024-06-12 11:04:39,257:INFO:               scipy: 1.11.4
2024-06-12 11:04:39,257:INFO:              joblib: 1.3.2
2024-06-12 11:04:39,257:INFO:             sklearn: 1.4.2
2024-06-12 11:04:39,257:INFO:                pyod: 2.0.0
2024-06-12 11:04:39,257:INFO:            imblearn: 0.12.3
2024-06-12 11:04:39,257:INFO:   category_encoders: 2.6.3
2024-06-12 11:04:39,257:INFO:            lightgbm: 4.3.0
2024-06-12 11:04:39,257:INFO:               numba: 0.59.1
2024-06-12 11:04:39,258:INFO:            requests: 2.32.3
2024-06-12 11:04:39,258:INFO:          matplotlib: 3.7.5
2024-06-12 11:04:39,258:INFO:          scikitplot: 0.3.7
2024-06-12 11:04:39,258:INFO:         yellowbrick: 1.5
2024-06-12 11:04:39,258:INFO:              plotly: 5.22.0
2024-06-12 11:04:39,258:INFO:    plotly-resampler: Not installed
2024-06-12 11:04:39,258:INFO:             kaleido: 0.2.1
2024-06-12 11:04:39,258:INFO:           schemdraw: 0.15
2024-06-12 11:04:39,258:INFO:         statsmodels: 0.14.2
2024-06-12 11:04:39,258:INFO:              sktime: 0.26.0
2024-06-12 11:04:39,258:INFO:               tbats: 1.1.3
2024-06-12 11:04:39,258:INFO:            pmdarima: 2.0.4
2024-06-12 11:04:39,258:INFO:              psutil: 5.9.8
2024-06-12 11:04:39,258:INFO:          markupsafe: 2.1.5
2024-06-12 11:04:39,258:INFO:             pickle5: Not installed
2024-06-12 11:04:39,258:INFO:         cloudpickle: 3.0.0
2024-06-12 11:04:39,258:INFO:         deprecation: 2.1.0
2024-06-12 11:04:39,258:INFO:              xxhash: 3.4.1
2024-06-12 11:04:39,258:INFO:           wurlitzer: Not installed
2024-06-12 11:04:39,258:INFO:PyCaret optional dependencies:
2024-06-12 11:04:39,268:INFO:                shap: Not installed
2024-06-12 11:04:39,268:INFO:           interpret: Not installed
2024-06-12 11:04:39,268:INFO:                umap: Not installed
2024-06-12 11:04:39,268:INFO:     ydata_profiling: Not installed
2024-06-12 11:04:39,269:INFO:  explainerdashboard: Not installed
2024-06-12 11:04:39,269:INFO:             autoviz: Not installed
2024-06-12 11:04:39,269:INFO:           fairlearn: Not installed
2024-06-12 11:04:39,269:INFO:          deepchecks: Not installed
2024-06-12 11:04:39,269:INFO:             xgboost: Not installed
2024-06-12 11:04:39,269:INFO:            catboost: Not installed
2024-06-12 11:04:39,269:INFO:              kmodes: Not installed
2024-06-12 11:04:39,269:INFO:             mlxtend: Not installed
2024-06-12 11:04:39,269:INFO:       statsforecast: Not installed
2024-06-12 11:04:39,269:INFO:        tune_sklearn: Not installed
2024-06-12 11:04:39,269:INFO:                 ray: Not installed
2024-06-12 11:04:39,269:INFO:            hyperopt: Not installed
2024-06-12 11:04:39,269:INFO:              optuna: Not installed
2024-06-12 11:04:39,269:INFO:               skopt: Not installed
2024-06-12 11:04:39,269:INFO:              mlflow: Not installed
2024-06-12 11:04:39,269:INFO:              gradio: Not installed
2024-06-12 11:04:39,269:INFO:             fastapi: Not installed
2024-06-12 11:04:39,269:INFO:             uvicorn: Not installed
2024-06-12 11:04:39,269:INFO:              m2cgen: Not installed
2024-06-12 11:04:39,269:INFO:           evidently: Not installed
2024-06-12 11:04:39,269:INFO:               fugue: Not installed
2024-06-12 11:04:39,269:INFO:           streamlit: 1.35.0
2024-06-12 11:04:39,269:INFO:             prophet: Not installed
2024-06-12 11:04:39,269:INFO:None
2024-06-12 11:04:39,270:INFO:Set up data.
2024-06-12 11:04:39,305:INFO:Set up folding strategy.
2024-06-12 11:04:39,305:INFO:Set up train/test split.
2024-06-12 11:04:39,321:INFO:Set up index.
2024-06-12 11:04:39,321:INFO:Assigning column types.
2024-06-12 11:04:39,337:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 11:04:39,372:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:04:39,388:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:04:39,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,486:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:04:39,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:04:39,518:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,519:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 11:04:39,558:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:04:39,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,640:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:04:39,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,669:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 11:04:39,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:39,806:INFO:Preparing preprocessing pipeline...
2024-06-12 11:04:39,806:INFO:Set up simple imputation.
2024-06-12 11:04:39,822:INFO:Set up encoding of ordinal features.
2024-06-12 11:04:39,839:INFO:Set up encoding of categorical features.
2024-06-12 11:04:39,839:INFO:Set up feature normalization.
2024-06-12 11:04:39,839:INFO:Set up PCA.
2024-06-12 11:04:40,206:INFO:Finished creating preprocessing pipeline.
2024-06-12 11:04:40,239:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 11:04:40,239:INFO:Creating final display dataframe.
2024-06-12 11:04:40,372:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              c102
2024-06-12 11:04:40,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:40,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:40,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:40,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:04:40,523:INFO:setup() successfully completed in 1.43s...............
2024-06-12 11:04:40,538:INFO:Initializing create_model()
2024-06-12 11:04:40,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:04:40,538:INFO:Checking exceptions
2024-06-12 11:04:40,559:INFO:Importing libraries
2024-06-12 11:04:40,559:INFO:Copying training dataset
2024-06-12 11:04:40,586:INFO:Defining folds
2024-06-12 11:04:40,586:INFO:Declaring metric variables
2024-06-12 11:04:40,590:INFO:Importing untrained model
2024-06-12 11:04:40,594:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:04:40,601:INFO:Starting cross validation
2024-06-12 11:04:40,604:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:04:46,845:INFO:Calculating mean and std
2024-06-12 11:04:46,845:INFO:Creating metrics dataframe
2024-06-12 11:04:46,858:INFO:Finalizing model
2024-06-12 11:04:47,295:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:04:47,298:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002997 seconds.
2024-06-12 11:04:47,298:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:04:47,299:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:04:47,299:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:04:47,300:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:04:47,300:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:04:47,511:INFO:Uploading results into container
2024-06-12 11:04:47,512:INFO:Uploading model into container now
2024-06-12 11:04:47,521:INFO:_master_model_container: 1
2024-06-12 11:04:47,521:INFO:_display_container: 2
2024-06-12 11:04:47,521:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:04:47,521:INFO:create_model() successfully completed......................................
2024-06-12 11:04:47,787:INFO:Initializing tune_model()
2024-06-12 11:04:47,787:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 11:04:47,787:INFO:Checking exceptions
2024-06-12 11:04:47,807:INFO:Copying training dataset
2024-06-12 11:04:47,821:INFO:Checking base model
2024-06-12 11:04:47,821:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 11:04:47,831:INFO:Declaring metric variables
2024-06-12 11:04:47,835:INFO:Defining Hyperparameters
2024-06-12 11:04:47,925:INFO:Tuning with n_jobs=-1
2024-06-12 11:04:47,925:INFO:Initializing RandomizedSearchCV
2024-06-12 11:05:27,426:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-12 11:05:27,426:INFO:Hyperparameter search completed
2024-06-12 11:05:27,426:INFO:SubProcess create_model() called ==================================
2024-06-12 11:05:27,426:INFO:Initializing create_model()
2024-06-12 11:05:27,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1DF64CC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-12 11:05:27,426:INFO:Checking exceptions
2024-06-12 11:05:27,426:INFO:Importing libraries
2024-06-12 11:05:27,426:INFO:Copying training dataset
2024-06-12 11:05:27,453:INFO:Defining folds
2024-06-12 11:05:27,453:INFO:Declaring metric variables
2024-06-12 11:05:27,453:INFO:Importing untrained model
2024-06-12 11:05:27,453:INFO:Declaring custom model
2024-06-12 11:05:27,466:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:05:27,482:INFO:Starting cross validation
2024-06-12 11:05:27,485:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:05:29,500:INFO:Calculating mean and std
2024-06-12 11:05:29,500:INFO:Creating metrics dataframe
2024-06-12 11:05:29,507:INFO:Finalizing model
2024-06-12 11:05:29,901:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:29,901:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:29,901:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:29,948:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:29,948:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:29,948:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:29,948:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:05:29,948:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002715 seconds.
2024-06-12 11:05:29,948:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:05:29,948:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:05:29,948:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:05:29,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:05:29,964:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:05:30,103:INFO:Uploading results into container
2024-06-12 11:05:30,105:INFO:Uploading model into container now
2024-06-12 11:05:30,106:INFO:_master_model_container: 2
2024-06-12 11:05:30,106:INFO:_display_container: 3
2024-06-12 11:05:30,106:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:05:30,106:INFO:create_model() successfully completed......................................
2024-06-12 11:05:30,202:INFO:SubProcess create_model() end ==================================
2024-06-12 11:05:30,202:INFO:choose_better activated
2024-06-12 11:05:30,202:INFO:SubProcess create_model() called ==================================
2024-06-12 11:05:30,202:INFO:Initializing create_model()
2024-06-12 11:05:30,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:05:30,202:INFO:Checking exceptions
2024-06-12 11:05:30,215:INFO:Importing libraries
2024-06-12 11:05:30,215:INFO:Copying training dataset
2024-06-12 11:05:30,233:INFO:Defining folds
2024-06-12 11:05:30,233:INFO:Declaring metric variables
2024-06-12 11:05:30,233:INFO:Importing untrained model
2024-06-12 11:05:30,233:INFO:Declaring custom model
2024-06-12 11:05:30,235:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:05:30,235:INFO:Starting cross validation
2024-06-12 11:05:30,238:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:05:32,587:INFO:Calculating mean and std
2024-06-12 11:05:32,587:INFO:Creating metrics dataframe
2024-06-12 11:05:32,590:INFO:Finalizing model
2024-06-12 11:05:33,018:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:05:33,022:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003438 seconds.
2024-06-12 11:05:33,022:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:05:33,023:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:05:33,023:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:05:33,024:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:05:33,024:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:05:33,238:INFO:Uploading results into container
2024-06-12 11:05:33,239:INFO:Uploading model into container now
2024-06-12 11:05:33,240:INFO:_master_model_container: 3
2024-06-12 11:05:33,240:INFO:_display_container: 4
2024-06-12 11:05:33,240:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:05:33,241:INFO:create_model() successfully completed......................................
2024-06-12 11:05:33,330:INFO:SubProcess create_model() end ==================================
2024-06-12 11:05:33,331:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is -0.0003
2024-06-12 11:05:33,332:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0501
2024-06-12 11:05:33,332:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 11:05:33,333:INFO:choose_better completed
2024-06-12 11:05:33,344:INFO:_master_model_container: 3
2024-06-12 11:05:33,344:INFO:_display_container: 3
2024-06-12 11:05:33,345:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:05:33,345:INFO:tune_model() successfully completed......................................
2024-06-12 11:05:33,499:INFO:Initializing plot_model()
2024-06-12 11:05:33,499:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:05:33,499:INFO:Checking exceptions
2024-06-12 11:05:33,537:INFO:Preloading libraries
2024-06-12 11:05:33,542:INFO:Copying training dataset
2024-06-12 11:05:33,542:INFO:Plot type: auc
2024-06-12 11:05:33,716:INFO:Fitting Model
2024-06-12 11:05:33,716:INFO:Scoring test/hold-out set
2024-06-12 11:05:33,716:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:33,716:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:33,716:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:33,741:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:33,741:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:33,741:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:33,997:INFO:Visual Rendered Successfully
2024-06-12 11:05:34,065:INFO:plot_model() successfully completed......................................
2024-06-12 11:05:34,107:INFO:Initializing plot_model()
2024-06-12 11:05:34,107:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:05:34,108:INFO:Checking exceptions
2024-06-12 11:05:34,122:INFO:Preloading libraries
2024-06-12 11:05:34,133:INFO:Copying training dataset
2024-06-12 11:05:34,133:INFO:Plot type: confusion_matrix
2024-06-12 11:05:34,313:INFO:Fitting Model
2024-06-12 11:05:34,313:INFO:Scoring test/hold-out set
2024-06-12 11:05:34,313:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:34,313:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:34,313:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:34,333:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:34,333:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:34,333:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:34,491:INFO:Visual Rendered Successfully
2024-06-12 11:05:34,558:INFO:plot_model() successfully completed......................................
2024-06-12 11:05:34,574:INFO:Initializing finalize_model()
2024-06-12 11:05:34,574:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 11:05:34,574:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:05:34,581:INFO:Initializing create_model()
2024-06-12 11:05:34,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:05:34,581:INFO:Checking exceptions
2024-06-12 11:05:34,581:INFO:Importing libraries
2024-06-12 11:05:34,581:INFO:Copying training dataset
2024-06-12 11:05:34,590:INFO:Defining folds
2024-06-12 11:05:34,590:INFO:Declaring metric variables
2024-06-12 11:05:34,591:INFO:Importing untrained model
2024-06-12 11:05:34,591:INFO:Declaring custom model
2024-06-12 11:05:34,592:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:05:34,594:INFO:Cross validation set to False
2024-06-12 11:05:34,594:INFO:Fitting Model
2024-06-12 11:05:35,060:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:35,060:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:35,060:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:35,127:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:35,127:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:35,127:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:35,127:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 11:05:35,143:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003752 seconds.
2024-06-12 11:05:35,143:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:05:35,144:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:05:35,144:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 11:05:35,144:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 11:05:35,144:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 11:05:35,344:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 11:05:35,344:INFO:create_model() successfully completed......................................
2024-06-12 11:05:35,429:INFO:_master_model_container: 3
2024-06-12 11:05:35,429:INFO:_display_container: 3
2024-06-12 11:05:35,477:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 11:05:35,477:INFO:finalize_model() successfully completed......................................
2024-06-12 11:05:35,587:INFO:Initializing plot_model()
2024-06-12 11:05:35,587:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:05:35,587:INFO:Checking exceptions
2024-06-12 11:05:35,600:INFO:Preloading libraries
2024-06-12 11:05:35,607:INFO:Copying training dataset
2024-06-12 11:05:35,607:INFO:Plot type: auc
2024-06-12 11:05:35,769:INFO:Fitting Model
2024-06-12 11:05:35,785:INFO:Scoring test/hold-out set
2024-06-12 11:05:35,785:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:35,785:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:35,785:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:35,785:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:35,785:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:35,785:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:36,031:INFO:Visual Rendered Successfully
2024-06-12 11:05:36,113:INFO:plot_model() successfully completed......................................
2024-06-12 11:05:36,161:INFO:Initializing plot_model()
2024-06-12 11:05:36,161:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:05:36,162:INFO:Checking exceptions
2024-06-12 11:05:36,167:INFO:Preloading libraries
2024-06-12 11:05:36,167:INFO:Copying training dataset
2024-06-12 11:05:36,167:INFO:Plot type: confusion_matrix
2024-06-12 11:05:36,332:INFO:Fitting Model
2024-06-12 11:05:36,332:INFO:Scoring test/hold-out set
2024-06-12 11:05:36,332:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:36,332:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:36,332:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:36,347:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:05:36,347:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:05:36,347:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:05:36,513:INFO:Visual Rendered Successfully
2024-06-12 11:05:36,577:INFO:plot_model() successfully completed......................................
2024-06-12 11:05:36,624:INFO:Initializing predict_model()
2024-06-12 11:05:36,624:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFEAFD10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A1E20A79C0>)
2024-06-12 11:05:36,624:INFO:Checking exceptions
2024-06-12 11:05:36,624:INFO:Preloading libraries
2024-06-12 11:05:36,639:INFO:Set up data.
2024-06-12 11:05:37,049:INFO:Set up index.
2024-06-12 11:07:09,152:INFO:PyCaret ClassificationExperiment
2024-06-12 11:07:09,152:INFO:Logging name: clf-default-name
2024-06-12 11:07:09,152:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 11:07:09,152:INFO:version 3.3.2
2024-06-12 11:07:09,152:INFO:Initializing setup()
2024-06-12 11:07:09,152:INFO:self.USI: 34b5
2024-06-12 11:07:09,152:INFO:self._variable_keys: {'is_multiclass', 'html_param', 'X', '_ml_usecase', 'fold_shuffle_param', 'idx', '_available_plots', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'pipeline', 'X_train', 'target_param', 'fold_generator', 'fix_imbalance', 'exp_id', 'logging_param', 'exp_name_log', 'data', 'USI', 'log_plots_param', 'y_test', 'X_test', 'y', 'n_jobs_param', 'seed'}
2024-06-12 11:07:09,152:INFO:Checking environment
2024-06-12 11:07:09,152:INFO:python_version: 3.11.9
2024-06-12 11:07:09,152:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 11:07:09,152:INFO:machine: AMD64
2024-06-12 11:07:09,152:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 11:07:09,152:INFO:Memory: svmem(total=34056318976, available=24920285184, percent=26.8, used=9136033792, free=24920285184)
2024-06-12 11:07:09,152:INFO:Physical Core: 6
2024-06-12 11:07:09,152:INFO:Logical Core: 12
2024-06-12 11:07:09,152:INFO:Checking libraries
2024-06-12 11:07:09,152:INFO:System:
2024-06-12 11:07:09,152:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 11:07:09,152:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 11:07:09,152:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 11:07:09,152:INFO:PyCaret required dependencies:
2024-06-12 11:07:09,152:INFO:                 pip: 24.0
2024-06-12 11:07:09,152:INFO:          setuptools: 69.5.1
2024-06-12 11:07:09,152:INFO:             pycaret: 3.3.2
2024-06-12 11:07:09,152:INFO:             IPython: 8.25.0
2024-06-12 11:07:09,152:INFO:          ipywidgets: 8.1.3
2024-06-12 11:07:09,152:INFO:                tqdm: 4.66.4
2024-06-12 11:07:09,152:INFO:               numpy: 1.26.4
2024-06-12 11:07:09,152:INFO:              pandas: 2.1.4
2024-06-12 11:07:09,152:INFO:              jinja2: 3.1.4
2024-06-12 11:07:09,152:INFO:               scipy: 1.11.4
2024-06-12 11:07:09,152:INFO:              joblib: 1.3.2
2024-06-12 11:07:09,152:INFO:             sklearn: 1.4.2
2024-06-12 11:07:09,152:INFO:                pyod: 2.0.0
2024-06-12 11:07:09,152:INFO:            imblearn: 0.12.3
2024-06-12 11:07:09,152:INFO:   category_encoders: 2.6.3
2024-06-12 11:07:09,152:INFO:            lightgbm: 4.3.0
2024-06-12 11:07:09,152:INFO:               numba: 0.59.1
2024-06-12 11:07:09,152:INFO:            requests: 2.32.3
2024-06-12 11:07:09,152:INFO:          matplotlib: 3.7.5
2024-06-12 11:07:09,152:INFO:          scikitplot: 0.3.7
2024-06-12 11:07:09,152:INFO:         yellowbrick: 1.5
2024-06-12 11:07:09,152:INFO:              plotly: 5.22.0
2024-06-12 11:07:09,152:INFO:    plotly-resampler: Not installed
2024-06-12 11:07:09,152:INFO:             kaleido: 0.2.1
2024-06-12 11:07:09,152:INFO:           schemdraw: 0.15
2024-06-12 11:07:09,152:INFO:         statsmodels: 0.14.2
2024-06-12 11:07:09,152:INFO:              sktime: 0.26.0
2024-06-12 11:07:09,152:INFO:               tbats: 1.1.3
2024-06-12 11:07:09,152:INFO:            pmdarima: 2.0.4
2024-06-12 11:07:09,152:INFO:              psutil: 5.9.8
2024-06-12 11:07:09,152:INFO:          markupsafe: 2.1.5
2024-06-12 11:07:09,152:INFO:             pickle5: Not installed
2024-06-12 11:07:09,152:INFO:         cloudpickle: 3.0.0
2024-06-12 11:07:09,152:INFO:         deprecation: 2.1.0
2024-06-12 11:07:09,152:INFO:              xxhash: 3.4.1
2024-06-12 11:07:09,152:INFO:           wurlitzer: Not installed
2024-06-12 11:07:09,164:INFO:PyCaret optional dependencies:
2024-06-12 11:07:09,164:INFO:                shap: Not installed
2024-06-12 11:07:09,164:INFO:           interpret: Not installed
2024-06-12 11:07:09,164:INFO:                umap: Not installed
2024-06-12 11:07:09,164:INFO:     ydata_profiling: Not installed
2024-06-12 11:07:09,164:INFO:  explainerdashboard: Not installed
2024-06-12 11:07:09,164:INFO:             autoviz: Not installed
2024-06-12 11:07:09,164:INFO:           fairlearn: Not installed
2024-06-12 11:07:09,164:INFO:          deepchecks: Not installed
2024-06-12 11:07:09,164:INFO:             xgboost: Not installed
2024-06-12 11:07:09,164:INFO:            catboost: Not installed
2024-06-12 11:07:09,164:INFO:              kmodes: Not installed
2024-06-12 11:07:09,164:INFO:             mlxtend: Not installed
2024-06-12 11:07:09,164:INFO:       statsforecast: Not installed
2024-06-12 11:07:09,165:INFO:        tune_sklearn: Not installed
2024-06-12 11:07:09,165:INFO:                 ray: Not installed
2024-06-12 11:07:09,165:INFO:            hyperopt: Not installed
2024-06-12 11:07:09,165:INFO:              optuna: Not installed
2024-06-12 11:07:09,165:INFO:               skopt: Not installed
2024-06-12 11:07:09,165:INFO:              mlflow: Not installed
2024-06-12 11:07:09,165:INFO:              gradio: Not installed
2024-06-12 11:07:09,165:INFO:             fastapi: Not installed
2024-06-12 11:07:09,165:INFO:             uvicorn: Not installed
2024-06-12 11:07:09,165:INFO:              m2cgen: Not installed
2024-06-12 11:07:09,165:INFO:           evidently: Not installed
2024-06-12 11:07:09,165:INFO:               fugue: Not installed
2024-06-12 11:07:09,166:INFO:           streamlit: 1.35.0
2024-06-12 11:07:09,166:INFO:             prophet: Not installed
2024-06-12 11:07:09,166:INFO:None
2024-06-12 11:07:09,166:INFO:Set up data.
2024-06-12 11:07:09,199:INFO:Set up folding strategy.
2024-06-12 11:07:09,199:INFO:Set up train/test split.
2024-06-12 11:07:09,231:INFO:Set up index.
2024-06-12 11:07:09,231:INFO:Assigning column types.
2024-06-12 11:07:09,251:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 11:07:09,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:07:09,284:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:07:09,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,365:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:07:09,366:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:07:09,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,381:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 11:07:09,431:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:07:09,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,518:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:07:09,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,552:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 11:07:09,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:09,715:INFO:Preparing preprocessing pipeline...
2024-06-12 11:07:09,730:INFO:Set up simple imputation.
2024-06-12 11:07:09,746:INFO:Set up encoding of ordinal features.
2024-06-12 11:07:09,756:INFO:Set up encoding of categorical features.
2024-06-12 11:07:09,757:INFO:Set up PCA.
2024-06-12 11:07:10,113:INFO:Finished creating preprocessing pipeline.
2024-06-12 11:07:10,132:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 11:07:10,132:INFO:Creating final display dataframe.
2024-06-12 11:07:10,731:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                          PCA              True
17                   PCA method            linear
18               PCA components              None
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              34b5
2024-06-12 11:07:10,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:10,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:10,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:10,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:07:10,895:INFO:setup() successfully completed in 1.85s...............
2024-06-12 11:07:11,018:INFO:Initializing create_model()
2024-06-12 11:07:11,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:07:11,020:INFO:Checking exceptions
2024-06-12 11:07:11,045:INFO:Importing libraries
2024-06-12 11:07:11,045:INFO:Copying training dataset
2024-06-12 11:07:11,080:INFO:Defining folds
2024-06-12 11:07:11,081:INFO:Declaring metric variables
2024-06-12 11:07:11,086:INFO:Importing untrained model
2024-06-12 11:07:11,090:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:07:11,099:INFO:Starting cross validation
2024-06-12 11:07:11,102:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:07:13,502:INFO:Calculating mean and std
2024-06-12 11:07:13,502:INFO:Creating metrics dataframe
2024-06-12 11:07:13,513:INFO:Finalizing model
2024-06-12 11:07:13,883:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:07:13,898:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002660 seconds.
2024-06-12 11:07:13,898:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:07:13,898:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:07:13,899:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:07:13,899:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:07:13,899:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:07:14,091:INFO:Uploading results into container
2024-06-12 11:07:14,092:INFO:Uploading model into container now
2024-06-12 11:07:14,098:INFO:_master_model_container: 1
2024-06-12 11:07:14,098:INFO:_display_container: 2
2024-06-12 11:07:14,098:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:07:14,098:INFO:create_model() successfully completed......................................
2024-06-12 11:07:14,216:INFO:Initializing tune_model()
2024-06-12 11:07:14,216:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 11:07:14,216:INFO:Checking exceptions
2024-06-12 11:07:14,240:INFO:Copying training dataset
2024-06-12 11:07:14,253:INFO:Checking base model
2024-06-12 11:07:14,253:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 11:07:14,258:INFO:Declaring metric variables
2024-06-12 11:07:14,261:INFO:Defining Hyperparameters
2024-06-12 11:07:14,342:INFO:Tuning with n_jobs=-1
2024-06-12 11:07:14,342:INFO:Initializing RandomizedSearchCV
2024-06-12 11:07:41,430:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-12 11:07:41,431:INFO:Hyperparameter search completed
2024-06-12 11:07:41,432:INFO:SubProcess create_model() called ==================================
2024-06-12 11:07:41,433:INFO:Initializing create_model()
2024-06-12 11:07:41,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1DE0276D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-12 11:07:41,433:INFO:Checking exceptions
2024-06-12 11:07:41,434:INFO:Importing libraries
2024-06-12 11:07:41,434:INFO:Copying training dataset
2024-06-12 11:07:41,467:INFO:Defining folds
2024-06-12 11:07:41,467:INFO:Declaring metric variables
2024-06-12 11:07:41,472:INFO:Importing untrained model
2024-06-12 11:07:41,472:INFO:Declaring custom model
2024-06-12 11:07:41,480:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:07:41,491:INFO:Starting cross validation
2024-06-12 11:07:41,496:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:07:45,496:INFO:Calculating mean and std
2024-06-12 11:07:45,498:INFO:Creating metrics dataframe
2024-06-12 11:07:45,505:INFO:Finalizing model
2024-06-12 11:07:45,872:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:45,872:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:45,872:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:45,924:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:45,924:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:45,924:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:45,924:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:07:45,930:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003758 seconds.
2024-06-12 11:07:45,933:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:07:45,933:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:07:45,934:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:07:45,935:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:07:45,935:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:07:45,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:45,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:46,657:INFO:Uploading results into container
2024-06-12 11:07:46,657:INFO:Uploading model into container now
2024-06-12 11:07:46,657:INFO:_master_model_container: 2
2024-06-12 11:07:46,657:INFO:_display_container: 3
2024-06-12 11:07:46,661:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:07:46,661:INFO:create_model() successfully completed......................................
2024-06-12 11:07:46,750:INFO:SubProcess create_model() end ==================================
2024-06-12 11:07:46,750:INFO:choose_better activated
2024-06-12 11:07:46,760:INFO:SubProcess create_model() called ==================================
2024-06-12 11:07:46,761:INFO:Initializing create_model()
2024-06-12 11:07:46,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:07:46,761:INFO:Checking exceptions
2024-06-12 11:07:46,763:INFO:Importing libraries
2024-06-12 11:07:46,763:INFO:Copying training dataset
2024-06-12 11:07:46,780:INFO:Defining folds
2024-06-12 11:07:46,780:INFO:Declaring metric variables
2024-06-12 11:07:46,780:INFO:Importing untrained model
2024-06-12 11:07:46,780:INFO:Declaring custom model
2024-06-12 11:07:46,780:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:07:46,780:INFO:Starting cross validation
2024-06-12 11:07:46,780:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:07:48,706:INFO:Calculating mean and std
2024-06-12 11:07:48,707:INFO:Creating metrics dataframe
2024-06-12 11:07:48,709:INFO:Finalizing model
2024-06-12 11:07:49,134:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:07:49,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004046 seconds.
2024-06-12 11:07:49,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:07:49,139:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:07:49,140:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:07:49,140:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:07:49,141:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:07:49,322:INFO:Uploading results into container
2024-06-12 11:07:49,322:INFO:Uploading model into container now
2024-06-12 11:07:49,322:INFO:_master_model_container: 3
2024-06-12 11:07:49,322:INFO:_display_container: 4
2024-06-12 11:07:49,322:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:07:49,322:INFO:create_model() successfully completed......................................
2024-06-12 11:07:49,416:INFO:SubProcess create_model() end ==================================
2024-06-12 11:07:49,416:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1137
2024-06-12 11:07:49,416:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1296
2024-06-12 11:07:49,427:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 11:07:49,427:INFO:choose_better completed
2024-06-12 11:07:49,434:INFO:_master_model_container: 3
2024-06-12 11:07:49,435:INFO:_display_container: 3
2024-06-12 11:07:49,435:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:07:49,435:INFO:tune_model() successfully completed......................................
2024-06-12 11:07:49,529:INFO:Initializing plot_model()
2024-06-12 11:07:49,529:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:07:49,529:INFO:Checking exceptions
2024-06-12 11:07:49,538:INFO:Preloading libraries
2024-06-12 11:07:49,584:INFO:Copying training dataset
2024-06-12 11:07:49,584:INFO:Plot type: auc
2024-06-12 11:07:49,756:INFO:Fitting Model
2024-06-12 11:07:49,757:INFO:Scoring test/hold-out set
2024-06-12 11:07:49,760:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:49,760:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:49,760:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:49,810:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:49,810:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:49,810:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:50,123:INFO:Visual Rendered Successfully
2024-06-12 11:07:50,194:INFO:plot_model() successfully completed......................................
2024-06-12 11:07:50,230:INFO:Initializing plot_model()
2024-06-12 11:07:50,230:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:07:50,230:INFO:Checking exceptions
2024-06-12 11:07:50,238:INFO:Preloading libraries
2024-06-12 11:07:50,277:INFO:Copying training dataset
2024-06-12 11:07:50,277:INFO:Plot type: confusion_matrix
2024-06-12 11:07:50,442:INFO:Fitting Model
2024-06-12 11:07:50,442:INFO:Scoring test/hold-out set
2024-06-12 11:07:50,442:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:50,442:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:50,442:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:50,505:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:50,507:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:50,507:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:50,688:INFO:Visual Rendered Successfully
2024-06-12 11:07:50,759:INFO:plot_model() successfully completed......................................
2024-06-12 11:07:50,779:INFO:Initializing finalize_model()
2024-06-12 11:07:50,779:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 11:07:50,779:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:07:50,797:INFO:Initializing create_model()
2024-06-12 11:07:50,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:07:50,797:INFO:Checking exceptions
2024-06-12 11:07:50,797:INFO:Importing libraries
2024-06-12 11:07:50,797:INFO:Copying training dataset
2024-06-12 11:07:50,797:INFO:Defining folds
2024-06-12 11:07:50,797:INFO:Declaring metric variables
2024-06-12 11:07:50,797:INFO:Importing untrained model
2024-06-12 11:07:50,797:INFO:Declaring custom model
2024-06-12 11:07:50,797:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:07:50,797:INFO:Cross validation set to False
2024-06-12 11:07:50,797:INFO:Fitting Model
2024-06-12 11:07:51,208:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:51,208:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:51,208:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:51,275:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:51,275:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:51,275:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:51,275:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 11:07:51,275:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003255 seconds.
2024-06-12 11:07:51,275:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:07:51,275:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:07:51,275:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 11:07:51,275:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 11:07:51,275:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 11:07:51,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:51,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:07:52,191:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 11:07:52,191:INFO:create_model() successfully completed......................................
2024-06-12 11:07:52,256:INFO:_master_model_container: 3
2024-06-12 11:07:52,256:INFO:_display_container: 3
2024-06-12 11:07:52,288:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 11:07:52,288:INFO:finalize_model() successfully completed......................................
2024-06-12 11:07:52,398:INFO:Initializing plot_model()
2024-06-12 11:07:52,398:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:07:52,398:INFO:Checking exceptions
2024-06-12 11:07:52,413:INFO:Preloading libraries
2024-06-12 11:07:52,459:INFO:Copying training dataset
2024-06-12 11:07:52,459:INFO:Plot type: auc
2024-06-12 11:07:52,625:INFO:Fitting Model
2024-06-12 11:07:52,625:INFO:Scoring test/hold-out set
2024-06-12 11:07:52,625:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:52,625:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:52,625:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:52,696:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:52,696:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:52,697:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:53,009:INFO:Visual Rendered Successfully
2024-06-12 11:07:53,073:INFO:plot_model() successfully completed......................................
2024-06-12 11:07:53,121:INFO:Initializing plot_model()
2024-06-12 11:07:53,121:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:07:53,121:INFO:Checking exceptions
2024-06-12 11:07:53,141:INFO:Preloading libraries
2024-06-12 11:07:53,181:INFO:Copying training dataset
2024-06-12 11:07:53,181:INFO:Plot type: confusion_matrix
2024-06-12 11:07:53,349:INFO:Fitting Model
2024-06-12 11:07:53,349:INFO:Scoring test/hold-out set
2024-06-12 11:07:53,349:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:53,349:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:53,349:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:53,414:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 11:07:53,414:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 11:07:53,414:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 11:07:53,618:INFO:Visual Rendered Successfully
2024-06-12 11:07:53,697:INFO:plot_model() successfully completed......................................
2024-06-12 11:07:53,735:INFO:Initializing predict_model()
2024-06-12 11:07:53,735:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1DFE7BA90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A1E20A7CE0>)
2024-06-12 11:07:53,735:INFO:Checking exceptions
2024-06-12 11:07:53,735:INFO:Preloading libraries
2024-06-12 11:07:53,735:INFO:Set up data.
2024-06-12 11:07:54,123:INFO:Set up index.
2024-06-12 11:10:07,686:INFO:PyCaret ClassificationExperiment
2024-06-12 11:10:07,686:INFO:Logging name: clf-default-name
2024-06-12 11:10:07,687:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 11:10:07,687:INFO:version 3.3.2
2024-06-12 11:10:07,687:INFO:Initializing setup()
2024-06-12 11:10:07,687:INFO:self.USI: 5d2e
2024-06-12 11:10:07,687:INFO:self._variable_keys: {'is_multiclass', 'html_param', 'X', '_ml_usecase', 'fold_shuffle_param', 'idx', '_available_plots', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'pipeline', 'X_train', 'target_param', 'fold_generator', 'fix_imbalance', 'exp_id', 'logging_param', 'exp_name_log', 'data', 'USI', 'log_plots_param', 'y_test', 'X_test', 'y', 'n_jobs_param', 'seed'}
2024-06-12 11:10:07,687:INFO:Checking environment
2024-06-12 11:10:07,687:INFO:python_version: 3.11.9
2024-06-12 11:10:07,687:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 11:10:07,687:INFO:machine: AMD64
2024-06-12 11:10:07,687:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 11:10:07,687:INFO:Memory: svmem(total=34056318976, available=24977760256, percent=26.7, used=9078558720, free=24977760256)
2024-06-12 11:10:07,687:INFO:Physical Core: 6
2024-06-12 11:10:07,687:INFO:Logical Core: 12
2024-06-12 11:10:07,687:INFO:Checking libraries
2024-06-12 11:10:07,688:INFO:System:
2024-06-12 11:10:07,688:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 11:10:07,688:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 11:10:07,688:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 11:10:07,688:INFO:PyCaret required dependencies:
2024-06-12 11:10:07,688:INFO:                 pip: 24.0
2024-06-12 11:10:07,688:INFO:          setuptools: 69.5.1
2024-06-12 11:10:07,688:INFO:             pycaret: 3.3.2
2024-06-12 11:10:07,688:INFO:             IPython: 8.25.0
2024-06-12 11:10:07,688:INFO:          ipywidgets: 8.1.3
2024-06-12 11:10:07,688:INFO:                tqdm: 4.66.4
2024-06-12 11:10:07,688:INFO:               numpy: 1.26.4
2024-06-12 11:10:07,688:INFO:              pandas: 2.1.4
2024-06-12 11:10:07,688:INFO:              jinja2: 3.1.4
2024-06-12 11:10:07,688:INFO:               scipy: 1.11.4
2024-06-12 11:10:07,688:INFO:              joblib: 1.3.2
2024-06-12 11:10:07,688:INFO:             sklearn: 1.4.2
2024-06-12 11:10:07,689:INFO:                pyod: 2.0.0
2024-06-12 11:10:07,689:INFO:            imblearn: 0.12.3
2024-06-12 11:10:07,689:INFO:   category_encoders: 2.6.3
2024-06-12 11:10:07,689:INFO:            lightgbm: 4.3.0
2024-06-12 11:10:07,689:INFO:               numba: 0.59.1
2024-06-12 11:10:07,689:INFO:            requests: 2.32.3
2024-06-12 11:10:07,689:INFO:          matplotlib: 3.7.5
2024-06-12 11:10:07,689:INFO:          scikitplot: 0.3.7
2024-06-12 11:10:07,689:INFO:         yellowbrick: 1.5
2024-06-12 11:10:07,689:INFO:              plotly: 5.22.0
2024-06-12 11:10:07,690:INFO:    plotly-resampler: Not installed
2024-06-12 11:10:07,690:INFO:             kaleido: 0.2.1
2024-06-12 11:10:07,690:INFO:           schemdraw: 0.15
2024-06-12 11:10:07,690:INFO:         statsmodels: 0.14.2
2024-06-12 11:10:07,690:INFO:              sktime: 0.26.0
2024-06-12 11:10:07,690:INFO:               tbats: 1.1.3
2024-06-12 11:10:07,690:INFO:            pmdarima: 2.0.4
2024-06-12 11:10:07,690:INFO:              psutil: 5.9.8
2024-06-12 11:10:07,691:INFO:          markupsafe: 2.1.5
2024-06-12 11:10:07,691:INFO:             pickle5: Not installed
2024-06-12 11:10:07,691:INFO:         cloudpickle: 3.0.0
2024-06-12 11:10:07,691:INFO:         deprecation: 2.1.0
2024-06-12 11:10:07,691:INFO:              xxhash: 3.4.1
2024-06-12 11:10:07,691:INFO:           wurlitzer: Not installed
2024-06-12 11:10:07,691:INFO:PyCaret optional dependencies:
2024-06-12 11:10:07,691:INFO:                shap: Not installed
2024-06-12 11:10:07,691:INFO:           interpret: Not installed
2024-06-12 11:10:07,691:INFO:                umap: Not installed
2024-06-12 11:10:07,691:INFO:     ydata_profiling: Not installed
2024-06-12 11:10:07,691:INFO:  explainerdashboard: Not installed
2024-06-12 11:10:07,692:INFO:             autoviz: Not installed
2024-06-12 11:10:07,692:INFO:           fairlearn: Not installed
2024-06-12 11:10:07,692:INFO:          deepchecks: Not installed
2024-06-12 11:10:07,692:INFO:             xgboost: Not installed
2024-06-12 11:10:07,692:INFO:            catboost: Not installed
2024-06-12 11:10:07,692:INFO:              kmodes: Not installed
2024-06-12 11:10:07,692:INFO:             mlxtend: Not installed
2024-06-12 11:10:07,692:INFO:       statsforecast: Not installed
2024-06-12 11:10:07,692:INFO:        tune_sklearn: Not installed
2024-06-12 11:10:07,692:INFO:                 ray: Not installed
2024-06-12 11:10:07,692:INFO:            hyperopt: Not installed
2024-06-12 11:10:07,692:INFO:              optuna: Not installed
2024-06-12 11:10:07,692:INFO:               skopt: Not installed
2024-06-12 11:10:07,692:INFO:              mlflow: Not installed
2024-06-12 11:10:07,692:INFO:              gradio: Not installed
2024-06-12 11:10:07,693:INFO:             fastapi: Not installed
2024-06-12 11:10:07,693:INFO:             uvicorn: Not installed
2024-06-12 11:10:07,693:INFO:              m2cgen: Not installed
2024-06-12 11:10:07,693:INFO:           evidently: Not installed
2024-06-12 11:10:07,693:INFO:               fugue: Not installed
2024-06-12 11:10:07,693:INFO:           streamlit: 1.35.0
2024-06-12 11:10:07,693:INFO:             prophet: Not installed
2024-06-12 11:10:07,693:INFO:None
2024-06-12 11:10:07,693:INFO:Set up data.
2024-06-12 11:10:07,742:INFO:Set up folding strategy.
2024-06-12 11:10:07,742:INFO:Set up train/test split.
2024-06-12 11:10:07,758:INFO:Set up index.
2024-06-12 11:10:07,758:INFO:Assigning column types.
2024-06-12 11:10:07,782:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 11:10:07,827:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:10:07,827:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:10:07,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:07,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:07,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:10:07,921:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:10:07,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:07,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:07,951:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 11:10:07,999:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:10:08,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,088:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:10:08,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,112:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 11:10:08,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,278:INFO:Preparing preprocessing pipeline...
2024-06-12 11:10:08,278:INFO:Set up simple imputation.
2024-06-12 11:10:08,291:INFO:Set up encoding of ordinal features.
2024-06-12 11:10:08,291:INFO:Set up encoding of categorical features.
2024-06-12 11:10:08,608:INFO:Finished creating preprocessing pipeline.
2024-06-12 11:10:08,659:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-06-12 11:10:08,659:INFO:Creating final display dataframe.
2024-06-12 11:10:08,808:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              5d2e
2024-06-12 11:10:08,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:10:08,957:INFO:setup() successfully completed in 1.37s...............
2024-06-12 11:10:09,041:INFO:Initializing create_model()
2024-06-12 11:10:09,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:10:09,041:INFO:Checking exceptions
2024-06-12 11:10:09,049:INFO:Importing libraries
2024-06-12 11:10:09,049:INFO:Copying training dataset
2024-06-12 11:10:09,071:INFO:Defining folds
2024-06-12 11:10:09,071:INFO:Declaring metric variables
2024-06-12 11:10:09,074:INFO:Importing untrained model
2024-06-12 11:10:09,078:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:10:09,084:INFO:Starting cross validation
2024-06-12 11:10:09,086:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:10:10,768:INFO:Calculating mean and std
2024-06-12 11:10:10,768:INFO:Creating metrics dataframe
2024-06-12 11:10:10,778:INFO:Finalizing model
2024-06-12 11:10:11,095:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 11:10:11,096:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:10:11,098:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.
2024-06-12 11:10:11,098:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 11:10:11,098:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 11:10:11,098:INFO:[LightGBM] [Info] Total Bins 623
2024-06-12 11:10:11,098:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:10:11,098:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:10:11,098:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:10:11,212:INFO:Uploading results into container
2024-06-12 11:10:11,212:INFO:Uploading model into container now
2024-06-12 11:10:11,229:INFO:_master_model_container: 1
2024-06-12 11:10:11,229:INFO:_display_container: 2
2024-06-12 11:10:11,229:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:10:11,229:INFO:create_model() successfully completed......................................
2024-06-12 11:10:11,346:INFO:Initializing tune_model()
2024-06-12 11:10:11,346:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 11:10:11,346:INFO:Checking exceptions
2024-06-12 11:10:11,398:INFO:Copying training dataset
2024-06-12 11:10:11,417:INFO:Checking base model
2024-06-12 11:10:11,418:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 11:10:11,422:INFO:Declaring metric variables
2024-06-12 11:10:11,425:INFO:Defining Hyperparameters
2024-06-12 11:10:11,495:INFO:Tuning with n_jobs=-1
2024-06-12 11:10:11,495:INFO:Initializing RandomizedSearchCV
2024-06-12 11:10:28,420:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-12 11:10:28,420:INFO:Hyperparameter search completed
2024-06-12 11:10:28,420:INFO:SubProcess create_model() called ==================================
2024-06-12 11:10:28,420:INFO:Initializing create_model()
2024-06-12 11:10:28,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1E143AB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-12 11:10:28,420:INFO:Checking exceptions
2024-06-12 11:10:28,420:INFO:Importing libraries
2024-06-12 11:10:28,420:INFO:Copying training dataset
2024-06-12 11:10:28,453:INFO:Defining folds
2024-06-12 11:10:28,453:INFO:Declaring metric variables
2024-06-12 11:10:28,459:INFO:Importing untrained model
2024-06-12 11:10:28,459:INFO:Declaring custom model
2024-06-12 11:10:28,465:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:10:28,475:INFO:Starting cross validation
2024-06-12 11:10:28,479:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:10:30,695:INFO:Calculating mean and std
2024-06-12 11:10:30,695:INFO:Creating metrics dataframe
2024-06-12 11:10:30,695:INFO:Finalizing model
2024-06-12 11:10:30,985:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:30,985:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:30,985:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:30,996:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 11:10:30,996:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:30,996:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:30,996:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:30,996:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:10:31,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001576 seconds.
2024-06-12 11:10:31,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 11:10:31,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 11:10:31,013:INFO:[LightGBM] [Info] Total Bins 619
2024-06-12 11:10:31,013:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 27
2024-06-12 11:10:31,013:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:10:31,013:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:10:31,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:31,270:INFO:Uploading results into container
2024-06-12 11:10:31,271:INFO:Uploading model into container now
2024-06-12 11:10:31,271:INFO:_master_model_container: 2
2024-06-12 11:10:31,271:INFO:_display_container: 3
2024-06-12 11:10:31,271:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:10:31,271:INFO:create_model() successfully completed......................................
2024-06-12 11:10:31,366:INFO:SubProcess create_model() end ==================================
2024-06-12 11:10:31,366:INFO:choose_better activated
2024-06-12 11:10:31,369:INFO:SubProcess create_model() called ==================================
2024-06-12 11:10:31,370:INFO:Initializing create_model()
2024-06-12 11:10:31,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:10:31,370:INFO:Checking exceptions
2024-06-12 11:10:31,371:INFO:Importing libraries
2024-06-12 11:10:31,371:INFO:Copying training dataset
2024-06-12 11:10:31,387:INFO:Defining folds
2024-06-12 11:10:31,387:INFO:Declaring metric variables
2024-06-12 11:10:31,387:INFO:Importing untrained model
2024-06-12 11:10:31,387:INFO:Declaring custom model
2024-06-12 11:10:31,388:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:10:31,388:INFO:Starting cross validation
2024-06-12 11:10:31,389:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:10:32,748:INFO:Calculating mean and std
2024-06-12 11:10:32,748:INFO:Creating metrics dataframe
2024-06-12 11:10:32,748:INFO:Finalizing model
2024-06-12 11:10:33,050:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 11:10:33,051:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:10:33,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001315 seconds.
2024-06-12 11:10:33,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 11:10:33,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 11:10:33,055:INFO:[LightGBM] [Info] Total Bins 623
2024-06-12 11:10:33,055:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:10:33,055:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:10:33,055:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:10:33,255:INFO:Uploading results into container
2024-06-12 11:10:33,255:INFO:Uploading model into container now
2024-06-12 11:10:33,255:INFO:_master_model_container: 3
2024-06-12 11:10:33,255:INFO:_display_container: 4
2024-06-12 11:10:33,255:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:10:33,255:INFO:create_model() successfully completed......................................
2024-06-12 11:10:33,342:INFO:SubProcess create_model() end ==================================
2024-06-12 11:10:33,343:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.134
2024-06-12 11:10:33,344:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1351
2024-06-12 11:10:33,344:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 11:10:33,344:INFO:choose_better completed
2024-06-12 11:10:33,352:INFO:_master_model_container: 3
2024-06-12 11:10:33,352:INFO:_display_container: 3
2024-06-12 11:10:33,353:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:10:33,353:INFO:tune_model() successfully completed......................................
2024-06-12 11:10:33,445:INFO:Initializing plot_model()
2024-06-12 11:10:33,446:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:10:33,447:INFO:Checking exceptions
2024-06-12 11:10:33,472:INFO:Preloading libraries
2024-06-12 11:10:33,482:INFO:Copying training dataset
2024-06-12 11:10:33,482:INFO:Plot type: auc
2024-06-12 11:10:33,661:INFO:Fitting Model
2024-06-12 11:10:33,662:INFO:Scoring test/hold-out set
2024-06-12 11:10:33,664:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:33,665:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:33,665:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:33,679:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:33,679:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:33,679:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:33,930:INFO:Visual Rendered Successfully
2024-06-12 11:10:34,005:INFO:plot_model() successfully completed......................................
2024-06-12 11:10:34,019:INFO:Initializing plot_model()
2024-06-12 11:10:34,019:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:10:34,019:INFO:Checking exceptions
2024-06-12 11:10:34,032:INFO:Preloading libraries
2024-06-12 11:10:34,032:INFO:Copying training dataset
2024-06-12 11:10:34,032:INFO:Plot type: confusion_matrix
2024-06-12 11:10:34,229:INFO:Fitting Model
2024-06-12 11:10:34,230:INFO:Scoring test/hold-out set
2024-06-12 11:10:34,232:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:34,232:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:34,232:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:34,247:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:34,247:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:34,247:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:34,407:INFO:Visual Rendered Successfully
2024-06-12 11:10:34,490:INFO:plot_model() successfully completed......................................
2024-06-12 11:10:34,491:INFO:Initializing finalize_model()
2024-06-12 11:10:34,491:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 11:10:34,491:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:10:34,505:INFO:Initializing create_model()
2024-06-12 11:10:34,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:10:34,505:INFO:Checking exceptions
2024-06-12 11:10:34,505:INFO:Importing libraries
2024-06-12 11:10:34,505:INFO:Copying training dataset
2024-06-12 11:10:34,505:INFO:Defining folds
2024-06-12 11:10:34,505:INFO:Declaring metric variables
2024-06-12 11:10:34,505:INFO:Importing untrained model
2024-06-12 11:10:34,505:INFO:Declaring custom model
2024-06-12 11:10:34,505:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:10:34,505:INFO:Cross validation set to False
2024-06-12 11:10:34,505:INFO:Fitting Model
2024-06-12 11:10:34,850:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:34,850:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:34,850:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:34,881:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 11:10:34,881:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:34,881:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:34,881:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:34,881:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 11:10:34,881:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.
2024-06-12 11:10:34,881:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 11:10:34,881:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 11:10:34,881:INFO:[LightGBM] [Info] Total Bins 619
2024-06-12 11:10:34,881:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 27
2024-06-12 11:10:34,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 11:10:34,881:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 11:10:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:34,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:34,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:34,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 11:10:35,238:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 11:10:35,238:INFO:create_model() successfully completed......................................
2024-06-12 11:10:35,322:INFO:_master_model_container: 3
2024-06-12 11:10:35,322:INFO:_display_container: 3
2024-06-12 11:10:35,338:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 11:10:35,338:INFO:finalize_model() successfully completed......................................
2024-06-12 11:10:35,464:INFO:Initializing plot_model()
2024-06-12 11:10:35,464:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:10:35,464:INFO:Checking exceptions
2024-06-12 11:10:35,480:INFO:Preloading libraries
2024-06-12 11:10:35,495:INFO:Copying training dataset
2024-06-12 11:10:35,495:INFO:Plot type: auc
2024-06-12 11:10:35,660:INFO:Fitting Model
2024-06-12 11:10:35,661:INFO:Scoring test/hold-out set
2024-06-12 11:10:35,663:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:35,663:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:35,663:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:35,679:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:35,679:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:35,679:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:35,934:INFO:Visual Rendered Successfully
2024-06-12 11:10:36,018:INFO:plot_model() successfully completed......................................
2024-06-12 11:10:36,052:INFO:Initializing plot_model()
2024-06-12 11:10:36,052:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:10:36,052:INFO:Checking exceptions
2024-06-12 11:10:36,067:INFO:Preloading libraries
2024-06-12 11:10:36,067:INFO:Copying training dataset
2024-06-12 11:10:36,067:INFO:Plot type: confusion_matrix
2024-06-12 11:10:36,233:INFO:Fitting Model
2024-06-12 11:10:36,233:INFO:Scoring test/hold-out set
2024-06-12 11:10:36,233:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:36,233:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:36,233:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:36,265:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:10:36,265:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:10:36,265:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:10:36,427:INFO:Visual Rendered Successfully
2024-06-12 11:10:36,505:INFO:plot_model() successfully completed......................................
2024-06-12 11:10:36,558:INFO:Initializing predict_model()
2024-06-12 11:10:36,558:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1179690>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A1E20A6A20>)
2024-06-12 11:10:36,558:INFO:Checking exceptions
2024-06-12 11:10:36,558:INFO:Preloading libraries
2024-06-12 11:10:36,560:INFO:Set up data.
2024-06-12 11:10:36,943:INFO:Set up index.
2024-06-12 11:13:43,420:INFO:PyCaret ClassificationExperiment
2024-06-12 11:13:43,420:INFO:Logging name: clf-default-name
2024-06-12 11:13:43,420:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 11:13:43,420:INFO:version 3.3.2
2024-06-12 11:13:43,420:INFO:Initializing setup()
2024-06-12 11:13:43,420:INFO:self.USI: bec9
2024-06-12 11:13:43,420:INFO:self._variable_keys: {'is_multiclass', 'html_param', 'X', '_ml_usecase', 'fold_shuffle_param', 'idx', '_available_plots', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'pipeline', 'X_train', 'target_param', 'fold_generator', 'fix_imbalance', 'exp_id', 'logging_param', 'exp_name_log', 'data', 'USI', 'log_plots_param', 'y_test', 'X_test', 'y', 'n_jobs_param', 'seed'}
2024-06-12 11:13:43,420:INFO:Checking environment
2024-06-12 11:13:43,420:INFO:python_version: 3.11.9
2024-06-12 11:13:43,420:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 11:13:43,420:INFO:machine: AMD64
2024-06-12 11:13:43,420:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 11:13:43,420:INFO:Memory: svmem(total=34056318976, available=24907948032, percent=26.9, used=9148370944, free=24907948032)
2024-06-12 11:13:43,420:INFO:Physical Core: 6
2024-06-12 11:13:43,420:INFO:Logical Core: 12
2024-06-12 11:13:43,420:INFO:Checking libraries
2024-06-12 11:13:43,420:INFO:System:
2024-06-12 11:13:43,436:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 11:13:43,436:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 11:13:43,436:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 11:13:43,436:INFO:PyCaret required dependencies:
2024-06-12 11:13:43,436:INFO:                 pip: 24.0
2024-06-12 11:13:43,436:INFO:          setuptools: 69.5.1
2024-06-12 11:13:43,436:INFO:             pycaret: 3.3.2
2024-06-12 11:13:43,436:INFO:             IPython: 8.25.0
2024-06-12 11:13:43,437:INFO:          ipywidgets: 8.1.3
2024-06-12 11:13:43,437:INFO:                tqdm: 4.66.4
2024-06-12 11:13:43,437:INFO:               numpy: 1.26.4
2024-06-12 11:13:43,437:INFO:              pandas: 2.1.4
2024-06-12 11:13:43,437:INFO:              jinja2: 3.1.4
2024-06-12 11:13:43,437:INFO:               scipy: 1.11.4
2024-06-12 11:13:43,437:INFO:              joblib: 1.3.2
2024-06-12 11:13:43,437:INFO:             sklearn: 1.4.2
2024-06-12 11:13:43,437:INFO:                pyod: 2.0.0
2024-06-12 11:13:43,437:INFO:            imblearn: 0.12.3
2024-06-12 11:13:43,437:INFO:   category_encoders: 2.6.3
2024-06-12 11:13:43,437:INFO:            lightgbm: 4.3.0
2024-06-12 11:13:43,437:INFO:               numba: 0.59.1
2024-06-12 11:13:43,438:INFO:            requests: 2.32.3
2024-06-12 11:13:43,438:INFO:          matplotlib: 3.7.5
2024-06-12 11:13:43,438:INFO:          scikitplot: 0.3.7
2024-06-12 11:13:43,438:INFO:         yellowbrick: 1.5
2024-06-12 11:13:43,438:INFO:              plotly: 5.22.0
2024-06-12 11:13:43,438:INFO:    plotly-resampler: Not installed
2024-06-12 11:13:43,438:INFO:             kaleido: 0.2.1
2024-06-12 11:13:43,438:INFO:           schemdraw: 0.15
2024-06-12 11:13:43,438:INFO:         statsmodels: 0.14.2
2024-06-12 11:13:43,438:INFO:              sktime: 0.26.0
2024-06-12 11:13:43,438:INFO:               tbats: 1.1.3
2024-06-12 11:13:43,438:INFO:            pmdarima: 2.0.4
2024-06-12 11:13:43,438:INFO:              psutil: 5.9.8
2024-06-12 11:13:43,438:INFO:          markupsafe: 2.1.5
2024-06-12 11:13:43,438:INFO:             pickle5: Not installed
2024-06-12 11:13:43,438:INFO:         cloudpickle: 3.0.0
2024-06-12 11:13:43,438:INFO:         deprecation: 2.1.0
2024-06-12 11:13:43,438:INFO:              xxhash: 3.4.1
2024-06-12 11:13:43,438:INFO:           wurlitzer: Not installed
2024-06-12 11:13:43,438:INFO:PyCaret optional dependencies:
2024-06-12 11:13:43,439:INFO:                shap: Not installed
2024-06-12 11:13:43,439:INFO:           interpret: Not installed
2024-06-12 11:13:43,439:INFO:                umap: Not installed
2024-06-12 11:13:43,439:INFO:     ydata_profiling: Not installed
2024-06-12 11:13:43,439:INFO:  explainerdashboard: Not installed
2024-06-12 11:13:43,439:INFO:             autoviz: Not installed
2024-06-12 11:13:43,439:INFO:           fairlearn: Not installed
2024-06-12 11:13:43,439:INFO:          deepchecks: Not installed
2024-06-12 11:13:43,439:INFO:             xgboost: Not installed
2024-06-12 11:13:43,439:INFO:            catboost: Not installed
2024-06-12 11:13:43,439:INFO:              kmodes: Not installed
2024-06-12 11:13:43,439:INFO:             mlxtend: Not installed
2024-06-12 11:13:43,439:INFO:       statsforecast: Not installed
2024-06-12 11:13:43,439:INFO:        tune_sklearn: Not installed
2024-06-12 11:13:43,439:INFO:                 ray: Not installed
2024-06-12 11:13:43,439:INFO:            hyperopt: Not installed
2024-06-12 11:13:43,439:INFO:              optuna: Not installed
2024-06-12 11:13:43,439:INFO:               skopt: Not installed
2024-06-12 11:13:43,439:INFO:              mlflow: Not installed
2024-06-12 11:13:43,440:INFO:              gradio: Not installed
2024-06-12 11:13:43,440:INFO:             fastapi: Not installed
2024-06-12 11:13:43,440:INFO:             uvicorn: Not installed
2024-06-12 11:13:43,440:INFO:              m2cgen: Not installed
2024-06-12 11:13:43,440:INFO:           evidently: Not installed
2024-06-12 11:13:43,440:INFO:               fugue: Not installed
2024-06-12 11:13:43,440:INFO:           streamlit: 1.35.0
2024-06-12 11:13:43,440:INFO:             prophet: Not installed
2024-06-12 11:13:43,440:INFO:None
2024-06-12 11:13:43,440:INFO:Set up data.
2024-06-12 11:13:43,481:INFO:Set up folding strategy.
2024-06-12 11:13:43,481:INFO:Set up train/test split.
2024-06-12 11:13:43,505:INFO:Set up index.
2024-06-12 11:13:43,506:INFO:Assigning column types.
2024-06-12 11:13:43,515:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 11:13:43,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:13:43,559:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:13:43,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:43,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:43,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:13:43,641:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:13:43,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:43,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:43,671:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 11:13:43,723:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:13:43,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:43,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:43,808:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:13:43,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:43,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:43,839:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 11:13:43,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:43,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:44,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:44,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:44,004:INFO:Preparing preprocessing pipeline...
2024-06-12 11:13:44,004:INFO:Set up simple imputation.
2024-06-12 11:13:44,024:INFO:Set up encoding of ordinal features.
2024-06-12 11:13:44,036:INFO:Set up encoding of categorical features.
2024-06-12 11:13:44,036:INFO:Set up feature normalization.
2024-06-12 11:13:44,036:INFO:Set up PCA.
2024-06-12 11:13:44,453:INFO:Finished creating preprocessing pipeline.
2024-06-12 11:13:44,488:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 11:13:44,488:INFO:Creating final display dataframe.
2024-06-12 11:13:45,120:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            robust
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              bec9
2024-06-12 11:13:45,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:45,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:45,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:45,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:13:45,255:INFO:setup() successfully completed in 1.91s...............
2024-06-12 11:13:45,351:INFO:Initializing create_model()
2024-06-12 11:13:45,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:13:45,351:INFO:Checking exceptions
2024-06-12 11:13:45,359:INFO:Importing libraries
2024-06-12 11:13:45,359:INFO:Copying training dataset
2024-06-12 11:13:45,381:INFO:Defining folds
2024-06-12 11:13:45,381:INFO:Declaring metric variables
2024-06-12 11:13:45,384:INFO:Importing untrained model
2024-06-12 11:13:45,388:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:13:45,393:INFO:Starting cross validation
2024-06-12 11:13:45,396:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:13:47,479:INFO:Calculating mean and std
2024-06-12 11:13:47,479:INFO:Creating metrics dataframe
2024-06-12 11:13:47,488:INFO:Finalizing model
2024-06-12 11:13:47,917:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:13:47,923:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003538 seconds.
2024-06-12 11:13:47,923:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:13:47,923:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:13:47,924:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:13:47,925:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:13:47,925:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:13:48,108:INFO:Uploading results into container
2024-06-12 11:13:48,110:INFO:Uploading model into container now
2024-06-12 11:13:48,121:INFO:_master_model_container: 1
2024-06-12 11:13:48,121:INFO:_display_container: 2
2024-06-12 11:13:48,121:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:13:48,122:INFO:create_model() successfully completed......................................
2024-06-12 11:13:48,228:INFO:Initializing tune_model()
2024-06-12 11:13:48,228:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 11:13:48,228:INFO:Checking exceptions
2024-06-12 11:13:48,271:INFO:Copying training dataset
2024-06-12 11:13:48,283:INFO:Checking base model
2024-06-12 11:13:48,284:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 11:13:48,287:INFO:Declaring metric variables
2024-06-12 11:13:48,291:INFO:Defining Hyperparameters
2024-06-12 11:13:48,371:INFO:Tuning with n_jobs=-1
2024-06-12 11:13:48,371:INFO:Initializing RandomizedSearchCV
2024-06-12 11:14:14,075:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-12 11:14:14,075:INFO:Hyperparameter search completed
2024-06-12 11:14:14,075:INFO:SubProcess create_model() called ==================================
2024-06-12 11:14:14,075:INFO:Initializing create_model()
2024-06-12 11:14:14,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1ABE068D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-12 11:14:14,075:INFO:Checking exceptions
2024-06-12 11:14:14,075:INFO:Importing libraries
2024-06-12 11:14:14,075:INFO:Copying training dataset
2024-06-12 11:14:14,101:INFO:Defining folds
2024-06-12 11:14:14,110:INFO:Declaring metric variables
2024-06-12 11:14:14,114:INFO:Importing untrained model
2024-06-12 11:14:14,114:INFO:Declaring custom model
2024-06-12 11:14:14,121:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:14:14,132:INFO:Starting cross validation
2024-06-12 11:14:14,136:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:14:17,262:INFO:Calculating mean and std
2024-06-12 11:14:17,262:INFO:Creating metrics dataframe
2024-06-12 11:14:17,270:INFO:Finalizing model
2024-06-12 11:14:17,638:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:17,638:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:17,638:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:17,688:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:17,688:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:17,688:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:17,689:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:14:17,692:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002593 seconds.
2024-06-12 11:14:17,692:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:14:17,693:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:14:17,694:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:14:17,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:14:17,696:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:14:18,091:INFO:Uploading results into container
2024-06-12 11:14:18,093:INFO:Uploading model into container now
2024-06-12 11:14:18,093:INFO:_master_model_container: 2
2024-06-12 11:14:18,093:INFO:_display_container: 3
2024-06-12 11:14:18,093:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:14:18,093:INFO:create_model() successfully completed......................................
2024-06-12 11:14:18,190:INFO:SubProcess create_model() end ==================================
2024-06-12 11:14:18,191:INFO:choose_better activated
2024-06-12 11:14:18,194:INFO:SubProcess create_model() called ==================================
2024-06-12 11:14:18,194:INFO:Initializing create_model()
2024-06-12 11:14:18,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:14:18,194:INFO:Checking exceptions
2024-06-12 11:14:18,196:INFO:Importing libraries
2024-06-12 11:14:18,196:INFO:Copying training dataset
2024-06-12 11:14:18,212:INFO:Defining folds
2024-06-12 11:14:18,212:INFO:Declaring metric variables
2024-06-12 11:14:18,212:INFO:Importing untrained model
2024-06-12 11:14:18,212:INFO:Declaring custom model
2024-06-12 11:14:18,213:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:14:18,213:INFO:Starting cross validation
2024-06-12 11:14:18,215:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:14:20,291:INFO:Calculating mean and std
2024-06-12 11:14:20,292:INFO:Creating metrics dataframe
2024-06-12 11:14:20,294:INFO:Finalizing model
2024-06-12 11:14:20,691:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:14:20,694:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002790 seconds.
2024-06-12 11:14:20,695:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:14:20,695:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:14:20,695:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:14:20,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:14:20,696:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:14:20,852:INFO:Uploading results into container
2024-06-12 11:14:20,852:INFO:Uploading model into container now
2024-06-12 11:14:20,852:INFO:_master_model_container: 3
2024-06-12 11:14:20,852:INFO:_display_container: 4
2024-06-12 11:14:20,852:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:14:20,852:INFO:create_model() successfully completed......................................
2024-06-12 11:14:20,948:INFO:SubProcess create_model() end ==================================
2024-06-12 11:14:20,949:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1022
2024-06-12 11:14:20,950:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1159
2024-06-12 11:14:20,950:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 11:14:20,950:INFO:choose_better completed
2024-06-12 11:14:20,950:INFO:_master_model_container: 3
2024-06-12 11:14:20,950:INFO:_display_container: 3
2024-06-12 11:14:20,950:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:14:20,950:INFO:tune_model() successfully completed......................................
2024-06-12 11:14:21,056:INFO:Initializing plot_model()
2024-06-12 11:14:21,056:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:14:21,056:INFO:Checking exceptions
2024-06-12 11:14:21,073:INFO:Preloading libraries
2024-06-12 11:14:21,087:INFO:Copying training dataset
2024-06-12 11:14:21,087:INFO:Plot type: auc
2024-06-12 11:14:21,253:INFO:Fitting Model
2024-06-12 11:14:21,253:INFO:Scoring test/hold-out set
2024-06-12 11:14:21,253:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:21,253:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:21,253:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:21,286:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:21,286:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:21,286:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:21,535:INFO:Visual Rendered Successfully
2024-06-12 11:14:21,601:INFO:plot_model() successfully completed......................................
2024-06-12 11:14:21,623:INFO:Initializing plot_model()
2024-06-12 11:14:21,623:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:14:21,623:INFO:Checking exceptions
2024-06-12 11:14:21,637:INFO:Preloading libraries
2024-06-12 11:14:21,648:INFO:Copying training dataset
2024-06-12 11:14:21,648:INFO:Plot type: confusion_matrix
2024-06-12 11:14:21,826:INFO:Fitting Model
2024-06-12 11:14:21,827:INFO:Scoring test/hold-out set
2024-06-12 11:14:21,828:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:21,828:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:21,828:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:21,846:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:21,846:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:21,846:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:22,006:INFO:Visual Rendered Successfully
2024-06-12 11:14:22,085:INFO:plot_model() successfully completed......................................
2024-06-12 11:14:22,095:INFO:Initializing finalize_model()
2024-06-12 11:14:22,095:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 11:14:22,095:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:14:22,111:INFO:Initializing create_model()
2024-06-12 11:14:22,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:14:22,111:INFO:Checking exceptions
2024-06-12 11:14:22,111:INFO:Importing libraries
2024-06-12 11:14:22,111:INFO:Copying training dataset
2024-06-12 11:14:22,111:INFO:Defining folds
2024-06-12 11:14:22,111:INFO:Declaring metric variables
2024-06-12 11:14:22,111:INFO:Importing untrained model
2024-06-12 11:14:22,111:INFO:Declaring custom model
2024-06-12 11:14:22,119:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:14:22,121:INFO:Cross validation set to False
2024-06-12 11:14:22,121:INFO:Fitting Model
2024-06-12 11:14:22,568:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:22,568:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:22,568:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:22,615:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:22,615:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:22,615:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:22,615:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 11:14:22,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004418 seconds.
2024-06-12 11:14:22,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:14:22,635:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:14:22,636:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 11:14:22,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 11:14:22,639:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 11:14:23,068:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 11:14:23,068:INFO:create_model() successfully completed......................................
2024-06-12 11:14:23,146:INFO:_master_model_container: 3
2024-06-12 11:14:23,146:INFO:_display_container: 3
2024-06-12 11:14:23,177:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 11:14:23,177:INFO:finalize_model() successfully completed......................................
2024-06-12 11:14:23,307:INFO:Initializing plot_model()
2024-06-12 11:14:23,307:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:14:23,307:INFO:Checking exceptions
2024-06-12 11:14:23,309:INFO:Preloading libraries
2024-06-12 11:14:23,325:INFO:Copying training dataset
2024-06-12 11:14:23,325:INFO:Plot type: auc
2024-06-12 11:14:23,475:INFO:Fitting Model
2024-06-12 11:14:23,475:INFO:Scoring test/hold-out set
2024-06-12 11:14:23,475:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:23,475:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:23,475:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:23,506:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:23,506:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:23,506:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:23,746:INFO:Visual Rendered Successfully
2024-06-12 11:14:23,825:INFO:plot_model() successfully completed......................................
2024-06-12 11:14:23,860:INFO:Initializing plot_model()
2024-06-12 11:14:23,860:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:14:23,860:INFO:Checking exceptions
2024-06-12 11:14:23,875:INFO:Preloading libraries
2024-06-12 11:14:23,887:INFO:Copying training dataset
2024-06-12 11:14:23,887:INFO:Plot type: confusion_matrix
2024-06-12 11:14:24,048:INFO:Fitting Model
2024-06-12 11:14:24,048:INFO:Scoring test/hold-out set
2024-06-12 11:14:24,048:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:24,048:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:24,048:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:24,064:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:14:24,064:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 11:14:24,064:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 11:14:24,241:INFO:Visual Rendered Successfully
2024-06-12 11:14:24,308:INFO:plot_model() successfully completed......................................
2024-06-12 11:14:24,351:INFO:Initializing predict_model()
2024-06-12 11:14:24,351:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E1090BD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A1E20616C0>)
2024-06-12 11:14:24,351:INFO:Checking exceptions
2024-06-12 11:14:24,351:INFO:Preloading libraries
2024-06-12 11:14:24,351:INFO:Set up data.
2024-06-12 11:14:24,733:INFO:Set up index.
2024-06-12 11:17:56,013:INFO:PyCaret ClassificationExperiment
2024-06-12 11:17:56,013:INFO:Logging name: clf-default-name
2024-06-12 11:17:56,013:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 11:17:56,013:INFO:version 3.3.2
2024-06-12 11:17:56,013:INFO:Initializing setup()
2024-06-12 11:17:56,013:INFO:self.USI: e7c5
2024-06-12 11:17:56,013:INFO:self._variable_keys: {'is_multiclass', 'html_param', 'X', '_ml_usecase', 'fold_shuffle_param', 'idx', '_available_plots', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'pipeline', 'X_train', 'target_param', 'fold_generator', 'fix_imbalance', 'exp_id', 'logging_param', 'exp_name_log', 'data', 'USI', 'log_plots_param', 'y_test', 'X_test', 'y', 'n_jobs_param', 'seed'}
2024-06-12 11:17:56,013:INFO:Checking environment
2024-06-12 11:17:56,013:INFO:python_version: 3.11.9
2024-06-12 11:17:56,013:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 11:17:56,013:INFO:machine: AMD64
2024-06-12 11:17:56,013:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 11:17:56,013:INFO:Memory: svmem(total=34056318976, available=24625053696, percent=27.7, used=9431265280, free=24625053696)
2024-06-12 11:17:56,013:INFO:Physical Core: 6
2024-06-12 11:17:56,013:INFO:Logical Core: 12
2024-06-12 11:17:56,013:INFO:Checking libraries
2024-06-12 11:17:56,013:INFO:System:
2024-06-12 11:17:56,013:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 11:17:56,013:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 11:17:56,013:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 11:17:56,013:INFO:PyCaret required dependencies:
2024-06-12 11:17:56,013:INFO:                 pip: 24.0
2024-06-12 11:17:56,013:INFO:          setuptools: 69.5.1
2024-06-12 11:17:56,013:INFO:             pycaret: 3.3.2
2024-06-12 11:17:56,013:INFO:             IPython: 8.25.0
2024-06-12 11:17:56,013:INFO:          ipywidgets: 8.1.3
2024-06-12 11:17:56,013:INFO:                tqdm: 4.66.4
2024-06-12 11:17:56,013:INFO:               numpy: 1.26.4
2024-06-12 11:17:56,013:INFO:              pandas: 2.1.4
2024-06-12 11:17:56,013:INFO:              jinja2: 3.1.4
2024-06-12 11:17:56,013:INFO:               scipy: 1.11.4
2024-06-12 11:17:56,013:INFO:              joblib: 1.3.2
2024-06-12 11:17:56,013:INFO:             sklearn: 1.4.2
2024-06-12 11:17:56,013:INFO:                pyod: 2.0.0
2024-06-12 11:17:56,013:INFO:            imblearn: 0.12.3
2024-06-12 11:17:56,013:INFO:   category_encoders: 2.6.3
2024-06-12 11:17:56,013:INFO:            lightgbm: 4.3.0
2024-06-12 11:17:56,013:INFO:               numba: 0.59.1
2024-06-12 11:17:56,013:INFO:            requests: 2.32.3
2024-06-12 11:17:56,013:INFO:          matplotlib: 3.7.5
2024-06-12 11:17:56,013:INFO:          scikitplot: 0.3.7
2024-06-12 11:17:56,013:INFO:         yellowbrick: 1.5
2024-06-12 11:17:56,013:INFO:              plotly: 5.22.0
2024-06-12 11:17:56,013:INFO:    plotly-resampler: Not installed
2024-06-12 11:17:56,013:INFO:             kaleido: 0.2.1
2024-06-12 11:17:56,013:INFO:           schemdraw: 0.15
2024-06-12 11:17:56,013:INFO:         statsmodels: 0.14.2
2024-06-12 11:17:56,013:INFO:              sktime: 0.26.0
2024-06-12 11:17:56,013:INFO:               tbats: 1.1.3
2024-06-12 11:17:56,013:INFO:            pmdarima: 2.0.4
2024-06-12 11:17:56,013:INFO:              psutil: 5.9.8
2024-06-12 11:17:56,013:INFO:          markupsafe: 2.1.5
2024-06-12 11:17:56,013:INFO:             pickle5: Not installed
2024-06-12 11:17:56,013:INFO:         cloudpickle: 3.0.0
2024-06-12 11:17:56,013:INFO:         deprecation: 2.1.0
2024-06-12 11:17:56,013:INFO:              xxhash: 3.4.1
2024-06-12 11:17:56,013:INFO:           wurlitzer: Not installed
2024-06-12 11:17:56,013:INFO:PyCaret optional dependencies:
2024-06-12 11:17:56,013:INFO:                shap: Not installed
2024-06-12 11:17:56,013:INFO:           interpret: Not installed
2024-06-12 11:17:56,013:INFO:                umap: Not installed
2024-06-12 11:17:56,013:INFO:     ydata_profiling: Not installed
2024-06-12 11:17:56,013:INFO:  explainerdashboard: Not installed
2024-06-12 11:17:56,013:INFO:             autoviz: Not installed
2024-06-12 11:17:56,013:INFO:           fairlearn: Not installed
2024-06-12 11:17:56,013:INFO:          deepchecks: Not installed
2024-06-12 11:17:56,013:INFO:             xgboost: Not installed
2024-06-12 11:17:56,013:INFO:            catboost: Not installed
2024-06-12 11:17:56,013:INFO:              kmodes: Not installed
2024-06-12 11:17:56,013:INFO:             mlxtend: Not installed
2024-06-12 11:17:56,013:INFO:       statsforecast: Not installed
2024-06-12 11:17:56,013:INFO:        tune_sklearn: Not installed
2024-06-12 11:17:56,013:INFO:                 ray: Not installed
2024-06-12 11:17:56,013:INFO:            hyperopt: Not installed
2024-06-12 11:17:56,013:INFO:              optuna: Not installed
2024-06-12 11:17:56,013:INFO:               skopt: Not installed
2024-06-12 11:17:56,013:INFO:              mlflow: Not installed
2024-06-12 11:17:56,013:INFO:              gradio: Not installed
2024-06-12 11:17:56,013:INFO:             fastapi: Not installed
2024-06-12 11:17:56,013:INFO:             uvicorn: Not installed
2024-06-12 11:17:56,013:INFO:              m2cgen: Not installed
2024-06-12 11:17:56,013:INFO:           evidently: Not installed
2024-06-12 11:17:56,013:INFO:               fugue: Not installed
2024-06-12 11:17:56,013:INFO:           streamlit: 1.35.0
2024-06-12 11:17:56,013:INFO:             prophet: Not installed
2024-06-12 11:17:56,013:INFO:None
2024-06-12 11:17:56,013:INFO:Set up data.
2024-06-12 11:17:56,069:INFO:Set up folding strategy.
2024-06-12 11:17:56,069:INFO:Set up train/test split.
2024-06-12 11:17:56,096:INFO:Set up index.
2024-06-12 11:17:56,096:INFO:Assigning column types.
2024-06-12 11:17:56,096:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 11:17:56,149:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:17:56,149:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:17:56,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:17:56,229:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:17:56,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,256:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 11:17:56,301:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:17:56,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,384:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:17:56,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,396:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 11:17:56,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:56,563:INFO:Preparing preprocessing pipeline...
2024-06-12 11:17:56,563:INFO:Set up simple imputation.
2024-06-12 11:17:56,563:INFO:Set up encoding of ordinal features.
2024-06-12 11:17:56,585:INFO:Set up encoding of categorical features.
2024-06-12 11:17:56,585:INFO:Set up feature normalization.
2024-06-12 11:17:56,585:INFO:Set up PCA.
2024-06-12 11:17:56,997:INFO:Finished creating preprocessing pipeline.
2024-06-12 11:17:57,040:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 11:17:57,040:INFO:Creating final display dataframe.
2024-06-12 11:17:57,646:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            minmax
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              e7c5
2024-06-12 11:17:57,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:57,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:57,809:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:57,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:17:57,809:INFO:setup() successfully completed in 1.89s...............
2024-06-12 11:17:57,896:INFO:Initializing create_model()
2024-06-12 11:17:57,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:17:57,896:INFO:Checking exceptions
2024-06-12 11:17:57,917:INFO:Importing libraries
2024-06-12 11:17:57,917:INFO:Copying training dataset
2024-06-12 11:17:57,944:INFO:Defining folds
2024-06-12 11:17:57,945:INFO:Declaring metric variables
2024-06-12 11:17:57,949:INFO:Importing untrained model
2024-06-12 11:17:57,953:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:17:57,961:INFO:Starting cross validation
2024-06-12 11:17:57,963:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:18:00,473:INFO:Calculating mean and std
2024-06-12 11:18:00,473:INFO:Creating metrics dataframe
2024-06-12 11:18:00,479:INFO:Finalizing model
2024-06-12 11:18:00,896:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:18:00,896:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002646 seconds.
2024-06-12 11:18:00,896:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:18:00,896:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:18:00,896:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:18:00,896:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:18:00,896:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:18:01,152:INFO:Uploading results into container
2024-06-12 11:18:01,154:INFO:Uploading model into container now
2024-06-12 11:18:01,164:INFO:_master_model_container: 1
2024-06-12 11:18:01,164:INFO:_display_container: 2
2024-06-12 11:18:01,164:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:18:01,164:INFO:create_model() successfully completed......................................
2024-06-12 11:18:01,296:INFO:Initializing tune_model()
2024-06-12 11:18:01,296:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 11:18:01,296:INFO:Checking exceptions
2024-06-12 11:18:01,332:INFO:Copying training dataset
2024-06-12 11:18:01,344:INFO:Checking base model
2024-06-12 11:18:01,344:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 11:18:01,349:INFO:Declaring metric variables
2024-06-12 11:18:01,352:INFO:Defining Hyperparameters
2024-06-12 11:18:01,428:INFO:Tuning with n_jobs=-1
2024-06-12 11:18:01,428:INFO:Initializing RandomizedSearchCV
2024-06-12 11:18:30,630:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-12 11:18:30,631:INFO:Hyperparameter search completed
2024-06-12 11:18:30,631:INFO:SubProcess create_model() called ==================================
2024-06-12 11:18:30,632:INFO:Initializing create_model()
2024-06-12 11:18:30,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1E1355F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-12 11:18:30,633:INFO:Checking exceptions
2024-06-12 11:18:30,633:INFO:Importing libraries
2024-06-12 11:18:30,633:INFO:Copying training dataset
2024-06-12 11:18:30,665:INFO:Defining folds
2024-06-12 11:18:30,666:INFO:Declaring metric variables
2024-06-12 11:18:30,670:INFO:Importing untrained model
2024-06-12 11:18:30,671:INFO:Declaring custom model
2024-06-12 11:18:30,678:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:18:30,689:INFO:Starting cross validation
2024-06-12 11:18:30,695:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:18:32,535:INFO:Calculating mean and std
2024-06-12 11:18:32,537:INFO:Creating metrics dataframe
2024-06-12 11:18:32,542:INFO:Finalizing model
2024-06-12 11:18:32,939:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:32,939:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:32,939:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:32,987:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:32,987:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:32,987:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:32,987:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:18:32,992:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003407 seconds.
2024-06-12 11:18:32,992:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:18:32,992:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:18:32,992:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:18:32,992:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:18:32,992:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:18:33,134:INFO:Uploading results into container
2024-06-12 11:18:33,135:INFO:Uploading model into container now
2024-06-12 11:18:33,135:INFO:_master_model_container: 2
2024-06-12 11:18:33,135:INFO:_display_container: 3
2024-06-12 11:18:33,135:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:18:33,135:INFO:create_model() successfully completed......................................
2024-06-12 11:18:33,233:INFO:SubProcess create_model() end ==================================
2024-06-12 11:18:33,233:INFO:choose_better activated
2024-06-12 11:18:33,236:INFO:SubProcess create_model() called ==================================
2024-06-12 11:18:33,236:INFO:Initializing create_model()
2024-06-12 11:18:33,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:18:33,237:INFO:Checking exceptions
2024-06-12 11:18:33,238:INFO:Importing libraries
2024-06-12 11:18:33,238:INFO:Copying training dataset
2024-06-12 11:18:33,255:INFO:Defining folds
2024-06-12 11:18:33,255:INFO:Declaring metric variables
2024-06-12 11:18:33,255:INFO:Importing untrained model
2024-06-12 11:18:33,255:INFO:Declaring custom model
2024-06-12 11:18:33,256:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:18:33,256:INFO:Starting cross validation
2024-06-12 11:18:33,258:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:18:35,173:INFO:Calculating mean and std
2024-06-12 11:18:35,174:INFO:Creating metrics dataframe
2024-06-12 11:18:35,176:INFO:Finalizing model
2024-06-12 11:18:35,591:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:18:35,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002822 seconds.
2024-06-12 11:18:35,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:18:35,591:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:18:35,591:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:18:35,591:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:18:35,591:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:18:35,796:INFO:Uploading results into container
2024-06-12 11:18:35,796:INFO:Uploading model into container now
2024-06-12 11:18:35,796:INFO:_master_model_container: 3
2024-06-12 11:18:35,796:INFO:_display_container: 4
2024-06-12 11:18:35,796:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:18:35,808:INFO:create_model() successfully completed......................................
2024-06-12 11:18:35,888:INFO:SubProcess create_model() end ==================================
2024-06-12 11:18:35,888:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0168
2024-06-12 11:18:35,888:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0626
2024-06-12 11:18:35,888:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 11:18:35,888:INFO:choose_better completed
2024-06-12 11:18:35,909:INFO:_master_model_container: 3
2024-06-12 11:18:35,909:INFO:_display_container: 3
2024-06-12 11:18:35,909:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:18:35,909:INFO:tune_model() successfully completed......................................
2024-06-12 11:18:35,997:INFO:Initializing plot_model()
2024-06-12 11:18:35,997:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:18:35,997:INFO:Checking exceptions
2024-06-12 11:18:36,013:INFO:Preloading libraries
2024-06-12 11:18:36,021:INFO:Copying training dataset
2024-06-12 11:18:36,021:INFO:Plot type: auc
2024-06-12 11:18:36,193:INFO:Fitting Model
2024-06-12 11:18:36,193:INFO:Scoring test/hold-out set
2024-06-12 11:18:36,193:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:36,193:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:36,193:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:36,209:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:36,209:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:36,209:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:36,458:INFO:Visual Rendered Successfully
2024-06-12 11:18:36,534:INFO:plot_model() successfully completed......................................
2024-06-12 11:18:36,548:INFO:Initializing plot_model()
2024-06-12 11:18:36,548:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:18:36,548:INFO:Checking exceptions
2024-06-12 11:18:36,563:INFO:Preloading libraries
2024-06-12 11:18:36,568:INFO:Copying training dataset
2024-06-12 11:18:36,568:INFO:Plot type: confusion_matrix
2024-06-12 11:18:36,738:INFO:Fitting Model
2024-06-12 11:18:36,738:INFO:Scoring test/hold-out set
2024-06-12 11:18:36,738:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:36,738:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:36,738:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:36,755:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:36,755:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:36,755:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:36,902:INFO:Visual Rendered Successfully
2024-06-12 11:18:36,966:INFO:plot_model() successfully completed......................................
2024-06-12 11:18:36,983:INFO:Initializing finalize_model()
2024-06-12 11:18:36,998:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 11:18:36,998:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:18:36,998:INFO:Initializing create_model()
2024-06-12 11:18:36,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:18:36,998:INFO:Checking exceptions
2024-06-12 11:18:36,998:INFO:Importing libraries
2024-06-12 11:18:36,998:INFO:Copying training dataset
2024-06-12 11:18:36,998:INFO:Defining folds
2024-06-12 11:18:36,998:INFO:Declaring metric variables
2024-06-12 11:18:36,998:INFO:Importing untrained model
2024-06-12 11:18:36,998:INFO:Declaring custom model
2024-06-12 11:18:36,998:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:18:36,998:INFO:Cross validation set to False
2024-06-12 11:18:36,998:INFO:Fitting Model
2024-06-12 11:18:37,421:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:37,421:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:37,421:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:37,483:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:37,483:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:37,483:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:37,483:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 11:18:37,483:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003213 seconds.
2024-06-12 11:18:37,483:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:18:37,483:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:18:37,483:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 11:18:37,483:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 11:18:37,483:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 11:18:37,676:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 11:18:37,692:INFO:create_model() successfully completed......................................
2024-06-12 11:18:37,770:INFO:_master_model_container: 3
2024-06-12 11:18:37,770:INFO:_display_container: 3
2024-06-12 11:18:37,803:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 11:18:37,804:INFO:finalize_model() successfully completed......................................
2024-06-12 11:18:37,937:INFO:Initializing plot_model()
2024-06-12 11:18:37,937:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:18:37,937:INFO:Checking exceptions
2024-06-12 11:18:37,940:INFO:Preloading libraries
2024-06-12 11:18:37,951:INFO:Copying training dataset
2024-06-12 11:18:37,951:INFO:Plot type: auc
2024-06-12 11:18:38,128:INFO:Fitting Model
2024-06-12 11:18:38,128:INFO:Scoring test/hold-out set
2024-06-12 11:18:38,128:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:38,128:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:38,128:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:38,128:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:38,128:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:38,128:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:38,390:INFO:Visual Rendered Successfully
2024-06-12 11:18:38,459:INFO:plot_model() successfully completed......................................
2024-06-12 11:18:38,507:INFO:Initializing plot_model()
2024-06-12 11:18:38,507:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:18:38,507:INFO:Checking exceptions
2024-06-12 11:18:38,522:INFO:Preloading libraries
2024-06-12 11:18:38,522:INFO:Copying training dataset
2024-06-12 11:18:38,522:INFO:Plot type: confusion_matrix
2024-06-12 11:18:38,687:INFO:Fitting Model
2024-06-12 11:18:38,687:INFO:Scoring test/hold-out set
2024-06-12 11:18:38,703:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:38,703:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:38,703:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:38,703:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:18:38,703:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:18:38,703:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:18:38,852:INFO:Visual Rendered Successfully
2024-06-12 11:18:38,932:INFO:plot_model() successfully completed......................................
2024-06-12 11:18:38,980:INFO:Initializing predict_model()
2024-06-12 11:18:38,980:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E12E1610>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A1E2256200>)
2024-06-12 11:18:38,980:INFO:Checking exceptions
2024-06-12 11:18:38,980:INFO:Preloading libraries
2024-06-12 11:18:38,987:INFO:Set up data.
2024-06-12 11:18:39,389:INFO:Set up index.
2024-06-12 11:22:05,932:INFO:PyCaret ClassificationExperiment
2024-06-12 11:22:05,932:INFO:Logging name: clf-default-name
2024-06-12 11:22:05,932:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 11:22:05,932:INFO:version 3.3.2
2024-06-12 11:22:05,932:INFO:Initializing setup()
2024-06-12 11:22:05,932:INFO:self.USI: 4553
2024-06-12 11:22:05,932:INFO:self._variable_keys: {'is_multiclass', 'html_param', 'X', '_ml_usecase', 'fold_shuffle_param', 'idx', '_available_plots', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'pipeline', 'X_train', 'target_param', 'fold_generator', 'fix_imbalance', 'exp_id', 'logging_param', 'exp_name_log', 'data', 'USI', 'log_plots_param', 'y_test', 'X_test', 'y', 'n_jobs_param', 'seed'}
2024-06-12 11:22:05,932:INFO:Checking environment
2024-06-12 11:22:05,932:INFO:python_version: 3.11.9
2024-06-12 11:22:05,932:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 11:22:05,932:INFO:machine: AMD64
2024-06-12 11:22:05,932:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 11:22:05,932:INFO:Memory: svmem(total=34056318976, available=24508170240, percent=28.0, used=9548148736, free=24508170240)
2024-06-12 11:22:05,932:INFO:Physical Core: 6
2024-06-12 11:22:05,932:INFO:Logical Core: 12
2024-06-12 11:22:05,932:INFO:Checking libraries
2024-06-12 11:22:05,932:INFO:System:
2024-06-12 11:22:05,932:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 11:22:05,932:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 11:22:05,932:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 11:22:05,932:INFO:PyCaret required dependencies:
2024-06-12 11:22:05,932:INFO:                 pip: 24.0
2024-06-12 11:22:05,932:INFO:          setuptools: 69.5.1
2024-06-12 11:22:05,932:INFO:             pycaret: 3.3.2
2024-06-12 11:22:05,932:INFO:             IPython: 8.25.0
2024-06-12 11:22:05,932:INFO:          ipywidgets: 8.1.3
2024-06-12 11:22:05,932:INFO:                tqdm: 4.66.4
2024-06-12 11:22:05,932:INFO:               numpy: 1.26.4
2024-06-12 11:22:05,932:INFO:              pandas: 2.1.4
2024-06-12 11:22:05,932:INFO:              jinja2: 3.1.4
2024-06-12 11:22:05,932:INFO:               scipy: 1.11.4
2024-06-12 11:22:05,932:INFO:              joblib: 1.3.2
2024-06-12 11:22:05,932:INFO:             sklearn: 1.4.2
2024-06-12 11:22:05,932:INFO:                pyod: 2.0.0
2024-06-12 11:22:05,932:INFO:            imblearn: 0.12.3
2024-06-12 11:22:05,932:INFO:   category_encoders: 2.6.3
2024-06-12 11:22:05,932:INFO:            lightgbm: 4.3.0
2024-06-12 11:22:05,932:INFO:               numba: 0.59.1
2024-06-12 11:22:05,932:INFO:            requests: 2.32.3
2024-06-12 11:22:05,932:INFO:          matplotlib: 3.7.5
2024-06-12 11:22:05,932:INFO:          scikitplot: 0.3.7
2024-06-12 11:22:05,932:INFO:         yellowbrick: 1.5
2024-06-12 11:22:05,932:INFO:              plotly: 5.22.0
2024-06-12 11:22:05,932:INFO:    plotly-resampler: Not installed
2024-06-12 11:22:05,932:INFO:             kaleido: 0.2.1
2024-06-12 11:22:05,932:INFO:           schemdraw: 0.15
2024-06-12 11:22:05,932:INFO:         statsmodels: 0.14.2
2024-06-12 11:22:05,932:INFO:              sktime: 0.26.0
2024-06-12 11:22:05,932:INFO:               tbats: 1.1.3
2024-06-12 11:22:05,932:INFO:            pmdarima: 2.0.4
2024-06-12 11:22:05,932:INFO:              psutil: 5.9.8
2024-06-12 11:22:05,932:INFO:          markupsafe: 2.1.5
2024-06-12 11:22:05,932:INFO:             pickle5: Not installed
2024-06-12 11:22:05,932:INFO:         cloudpickle: 3.0.0
2024-06-12 11:22:05,932:INFO:         deprecation: 2.1.0
2024-06-12 11:22:05,932:INFO:              xxhash: 3.4.1
2024-06-12 11:22:05,932:INFO:           wurlitzer: Not installed
2024-06-12 11:22:05,932:INFO:PyCaret optional dependencies:
2024-06-12 11:22:05,932:INFO:                shap: Not installed
2024-06-12 11:22:05,932:INFO:           interpret: Not installed
2024-06-12 11:22:05,932:INFO:                umap: Not installed
2024-06-12 11:22:05,932:INFO:     ydata_profiling: Not installed
2024-06-12 11:22:05,932:INFO:  explainerdashboard: Not installed
2024-06-12 11:22:05,932:INFO:             autoviz: Not installed
2024-06-12 11:22:05,932:INFO:           fairlearn: Not installed
2024-06-12 11:22:05,932:INFO:          deepchecks: Not installed
2024-06-12 11:22:05,932:INFO:             xgboost: Not installed
2024-06-12 11:22:05,932:INFO:            catboost: Not installed
2024-06-12 11:22:05,932:INFO:              kmodes: Not installed
2024-06-12 11:22:05,932:INFO:             mlxtend: Not installed
2024-06-12 11:22:05,932:INFO:       statsforecast: Not installed
2024-06-12 11:22:05,932:INFO:        tune_sklearn: Not installed
2024-06-12 11:22:05,932:INFO:                 ray: Not installed
2024-06-12 11:22:05,945:INFO:            hyperopt: Not installed
2024-06-12 11:22:05,945:INFO:              optuna: Not installed
2024-06-12 11:22:05,945:INFO:               skopt: Not installed
2024-06-12 11:22:05,945:INFO:              mlflow: Not installed
2024-06-12 11:22:05,945:INFO:              gradio: Not installed
2024-06-12 11:22:05,945:INFO:             fastapi: Not installed
2024-06-12 11:22:05,945:INFO:             uvicorn: Not installed
2024-06-12 11:22:05,945:INFO:              m2cgen: Not installed
2024-06-12 11:22:05,945:INFO:           evidently: Not installed
2024-06-12 11:22:05,945:INFO:               fugue: Not installed
2024-06-12 11:22:05,945:INFO:           streamlit: 1.35.0
2024-06-12 11:22:05,945:INFO:             prophet: Not installed
2024-06-12 11:22:05,945:INFO:None
2024-06-12 11:22:05,945:INFO:Set up data.
2024-06-12 11:22:05,982:INFO:Set up folding strategy.
2024-06-12 11:22:05,982:INFO:Set up train/test split.
2024-06-12 11:22:06,028:INFO:Set up index.
2024-06-12 11:22:06,028:INFO:Assigning column types.
2024-06-12 11:22:06,045:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 11:22:06,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:22:06,096:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:22:06,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:22:06,175:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:22:06,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,196:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 11:22:06,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:22:06,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,347:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:22:06,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,379:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 11:22:06,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,512:INFO:Preparing preprocessing pipeline...
2024-06-12 11:22:06,512:INFO:Set up simple imputation.
2024-06-12 11:22:06,534:INFO:Set up encoding of ordinal features.
2024-06-12 11:22:06,551:INFO:Set up encoding of categorical features.
2024-06-12 11:22:06,551:INFO:Set up feature normalization.
2024-06-12 11:22:06,551:INFO:Set up PCA.
2024-06-12 11:22:06,929:INFO:Finished creating preprocessing pipeline.
2024-06-12 11:22:06,962:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MaxAbsScaler(copy=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 11:22:06,962:INFO:Creating final display dataframe.
2024-06-12 11:22:07,595:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            maxabs
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              4553
2024-06-12 11:22:07,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:07,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:07,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:07,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:07,744:INFO:setup() successfully completed in 1.91s...............
2024-06-12 11:22:07,861:INFO:Initializing create_model()
2024-06-12 11:22:07,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:07,861:INFO:Checking exceptions
2024-06-12 11:22:07,865:INFO:Importing libraries
2024-06-12 11:22:07,865:INFO:Copying training dataset
2024-06-12 11:22:07,901:INFO:Defining folds
2024-06-12 11:22:07,901:INFO:Declaring metric variables
2024-06-12 11:22:07,907:INFO:Importing untrained model
2024-06-12 11:22:07,914:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:22:07,931:INFO:Starting cross validation
2024-06-12 11:22:07,935:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:10,168:INFO:Calculating mean and std
2024-06-12 11:22:10,168:INFO:Creating metrics dataframe
2024-06-12 11:22:10,168:INFO:Finalizing model
2024-06-12 11:22:10,556:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:22:10,571:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002823 seconds.
2024-06-12 11:22:10,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:22:10,571:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:22:10,571:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:22:10,571:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:22:10,571:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:22:10,808:INFO:Uploading results into container
2024-06-12 11:22:10,808:INFO:Uploading model into container now
2024-06-12 11:22:10,817:INFO:_master_model_container: 1
2024-06-12 11:22:10,817:INFO:_display_container: 2
2024-06-12 11:22:10,817:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:22:10,817:INFO:create_model() successfully completed......................................
2024-06-12 11:22:10,959:INFO:Initializing tune_model()
2024-06-12 11:22:10,959:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 11:22:10,959:INFO:Checking exceptions
2024-06-12 11:22:10,990:INFO:Copying training dataset
2024-06-12 11:22:11,007:INFO:Checking base model
2024-06-12 11:22:11,008:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 11:22:11,012:INFO:Declaring metric variables
2024-06-12 11:22:11,017:INFO:Defining Hyperparameters
2024-06-12 11:22:11,096:INFO:Tuning with n_jobs=-1
2024-06-12 11:22:11,096:INFO:Initializing RandomizedSearchCV
2024-06-12 11:22:39,383:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-12 11:22:39,383:INFO:Hyperparameter search completed
2024-06-12 11:22:39,383:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:39,388:INFO:Initializing create_model()
2024-06-12 11:22:39,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1E10BEF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-12 11:22:39,388:INFO:Checking exceptions
2024-06-12 11:22:39,388:INFO:Importing libraries
2024-06-12 11:22:39,388:INFO:Copying training dataset
2024-06-12 11:22:39,408:INFO:Defining folds
2024-06-12 11:22:39,408:INFO:Declaring metric variables
2024-06-12 11:22:39,428:INFO:Importing untrained model
2024-06-12 11:22:39,428:INFO:Declaring custom model
2024-06-12 11:22:39,434:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:22:39,446:INFO:Starting cross validation
2024-06-12 11:22:39,450:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:41,240:INFO:Calculating mean and std
2024-06-12 11:22:41,240:INFO:Creating metrics dataframe
2024-06-12 11:22:41,247:INFO:Finalizing model
2024-06-12 11:22:41,606:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:41,606:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:41,606:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:41,653:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:41,653:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:41,653:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:41,653:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:22:41,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003382 seconds.
2024-06-12 11:22:41,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:22:41,669:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:22:41,669:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:22:41,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:22:41,669:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:22:41,816:INFO:Uploading results into container
2024-06-12 11:22:41,816:INFO:Uploading model into container now
2024-06-12 11:22:41,816:INFO:_master_model_container: 2
2024-06-12 11:22:41,816:INFO:_display_container: 3
2024-06-12 11:22:41,816:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:22:41,816:INFO:create_model() successfully completed......................................
2024-06-12 11:22:41,908:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:41,908:INFO:choose_better activated
2024-06-12 11:22:41,908:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:41,908:INFO:Initializing create_model()
2024-06-12 11:22:41,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:41,908:INFO:Checking exceptions
2024-06-12 11:22:41,908:INFO:Importing libraries
2024-06-12 11:22:41,908:INFO:Copying training dataset
2024-06-12 11:22:41,934:INFO:Defining folds
2024-06-12 11:22:41,934:INFO:Declaring metric variables
2024-06-12 11:22:41,934:INFO:Importing untrained model
2024-06-12 11:22:41,935:INFO:Declaring custom model
2024-06-12 11:22:41,935:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:22:41,935:INFO:Starting cross validation
2024-06-12 11:22:41,937:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:43,984:INFO:Calculating mean and std
2024-06-12 11:22:43,984:INFO:Creating metrics dataframe
2024-06-12 11:22:43,984:INFO:Finalizing model
2024-06-12 11:22:44,407:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 11:22:44,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002936 seconds.
2024-06-12 11:22:44,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:22:44,411:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:22:44,411:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 11:22:44,412:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 11:22:44,412:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 11:22:44,600:INFO:Uploading results into container
2024-06-12 11:22:44,601:INFO:Uploading model into container now
2024-06-12 11:22:44,602:INFO:_master_model_container: 3
2024-06-12 11:22:44,602:INFO:_display_container: 4
2024-06-12 11:22:44,602:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:22:44,602:INFO:create_model() successfully completed......................................
2024-06-12 11:22:44,690:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:44,691:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0128
2024-06-12 11:22:44,692:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0694
2024-06-12 11:22:44,693:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 11:22:44,693:INFO:choose_better completed
2024-06-12 11:22:44,704:INFO:_master_model_container: 3
2024-06-12 11:22:44,704:INFO:_display_container: 3
2024-06-12 11:22:44,705:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:22:44,705:INFO:tune_model() successfully completed......................................
2024-06-12 11:22:44,796:INFO:Initializing plot_model()
2024-06-12 11:22:44,796:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:22:44,796:INFO:Checking exceptions
2024-06-12 11:22:44,812:INFO:Preloading libraries
2024-06-12 11:22:44,812:INFO:Copying training dataset
2024-06-12 11:22:44,812:INFO:Plot type: auc
2024-06-12 11:22:44,987:INFO:Fitting Model
2024-06-12 11:22:44,988:INFO:Scoring test/hold-out set
2024-06-12 11:22:44,990:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:44,990:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:44,990:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:44,990:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:44,990:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:44,990:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:45,225:INFO:Visual Rendered Successfully
2024-06-12 11:22:45,308:INFO:plot_model() successfully completed......................................
2024-06-12 11:22:45,327:INFO:Initializing plot_model()
2024-06-12 11:22:45,327:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:22:45,327:INFO:Checking exceptions
2024-06-12 11:22:45,335:INFO:Preloading libraries
2024-06-12 11:22:45,344:INFO:Copying training dataset
2024-06-12 11:22:45,345:INFO:Plot type: confusion_matrix
2024-06-12 11:22:45,506:INFO:Fitting Model
2024-06-12 11:22:45,506:INFO:Scoring test/hold-out set
2024-06-12 11:22:45,521:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:45,522:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:45,522:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:45,534:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:45,534:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:45,535:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:45,685:INFO:Visual Rendered Successfully
2024-06-12 11:22:45,765:INFO:plot_model() successfully completed......................................
2024-06-12 11:22:45,781:INFO:Initializing finalize_model()
2024-06-12 11:22:45,781:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 11:22:45,781:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 11:22:45,793:INFO:Initializing create_model()
2024-06-12 11:22:45,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:45,793:INFO:Checking exceptions
2024-06-12 11:22:45,793:INFO:Importing libraries
2024-06-12 11:22:45,793:INFO:Copying training dataset
2024-06-12 11:22:45,793:INFO:Defining folds
2024-06-12 11:22:45,793:INFO:Declaring metric variables
2024-06-12 11:22:45,793:INFO:Importing untrained model
2024-06-12 11:22:45,793:INFO:Declaring custom model
2024-06-12 11:22:45,793:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 11:22:45,802:INFO:Cross validation set to False
2024-06-12 11:22:45,803:INFO:Fitting Model
2024-06-12 11:22:46,242:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:46,242:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:46,242:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:46,314:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:46,314:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:46,314:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:46,314:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 11:22:46,319:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003247 seconds.
2024-06-12 11:22:46,319:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 11:22:46,319:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 11:22:46,321:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 11:22:46,323:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 11:22:46,323:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 11:22:46,508:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 11:22:46,508:INFO:create_model() successfully completed......................................
2024-06-12 11:22:46,586:INFO:_master_model_container: 3
2024-06-12 11:22:46,587:INFO:_display_container: 3
2024-06-12 11:22:46,611:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 11:22:46,611:INFO:finalize_model() successfully completed......................................
2024-06-12 11:22:46,721:INFO:Initializing plot_model()
2024-06-12 11:22:46,721:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:22:46,721:INFO:Checking exceptions
2024-06-12 11:22:46,737:INFO:Preloading libraries
2024-06-12 11:22:46,737:INFO:Copying training dataset
2024-06-12 11:22:46,737:INFO:Plot type: auc
2024-06-12 11:22:46,903:INFO:Fitting Model
2024-06-12 11:22:46,919:INFO:Scoring test/hold-out set
2024-06-12 11:22:46,919:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:46,919:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:46,919:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:46,919:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:46,919:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:46,919:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:47,172:INFO:Visual Rendered Successfully
2024-06-12 11:22:47,235:INFO:plot_model() successfully completed......................................
2024-06-12 11:22:47,332:INFO:Initializing plot_model()
2024-06-12 11:22:47,332:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 11:22:47,332:INFO:Checking exceptions
2024-06-12 11:22:47,340:INFO:Preloading libraries
2024-06-12 11:22:47,345:INFO:Copying training dataset
2024-06-12 11:22:47,345:INFO:Plot type: confusion_matrix
2024-06-12 11:22:47,534:INFO:Fitting Model
2024-06-12 11:22:47,534:INFO:Scoring test/hold-out set
2024-06-12 11:22:47,534:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:47,534:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:47,534:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:47,553:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 11:22:47,553:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 11:22:47,553:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 11:22:47,714:INFO:Visual Rendered Successfully
2024-06-12 11:22:47,798:INFO:plot_model() successfully completed......................................
2024-06-12 11:22:47,870:INFO:Initializing predict_model()
2024-06-12 11:22:47,870:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1E11C3BD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A1E2254540>)
2024-06-12 11:22:47,870:INFO:Checking exceptions
2024-06-12 11:22:47,870:INFO:Preloading libraries
2024-06-12 11:22:47,872:INFO:Set up data.
2024-06-12 11:22:48,283:INFO:Set up index.
2024-06-12 12:01:39,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 12:01:39,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 12:01:39,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 12:01:39,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 12:01:40,830:INFO:PyCaret ClassificationExperiment
2024-06-12 12:01:40,830:INFO:Logging name: clf-default-name
2024-06-12 12:01:40,830:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 12:01:40,830:INFO:version 3.3.2
2024-06-12 12:01:40,830:INFO:Initializing setup()
2024-06-12 12:01:40,830:INFO:self.USI: 27ff
2024-06-12 12:01:40,830:INFO:self._variable_keys: {'X_train', 'target_param', 'idx', 'pipeline', 'exp_name_log', 'n_jobs_param', 'fold_generator', 'fix_imbalance', 'seed', '_available_plots', 'exp_id', 'gpu_n_jobs_param', 'log_plots_param', 'html_param', '_ml_usecase', 'y_train', 'data', 'memory', 'USI', 'X_test', 'y', 'is_multiclass', 'gpu_param', 'y_test', 'X', 'fold_shuffle_param', 'fold_groups_param', 'logging_param'}
2024-06-12 12:01:40,830:INFO:Checking environment
2024-06-12 12:01:40,830:INFO:python_version: 3.11.9
2024-06-12 12:01:40,830:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 12:01:40,830:INFO:machine: AMD64
2024-06-12 12:01:40,830:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 12:01:40,830:INFO:Memory: svmem(total=34056318976, available=26555740160, percent=22.0, used=7500578816, free=26555740160)
2024-06-12 12:01:40,830:INFO:Physical Core: 6
2024-06-12 12:01:40,830:INFO:Logical Core: 12
2024-06-12 12:01:40,830:INFO:Checking libraries
2024-06-12 12:01:40,830:INFO:System:
2024-06-12 12:01:40,830:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 12:01:40,830:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 12:01:40,830:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 12:01:40,830:INFO:PyCaret required dependencies:
2024-06-12 12:01:40,920:INFO:                 pip: 24.0
2024-06-12 12:01:40,920:INFO:          setuptools: 69.5.1
2024-06-12 12:01:40,920:INFO:             pycaret: 3.3.2
2024-06-12 12:01:40,920:INFO:             IPython: 8.25.0
2024-06-12 12:01:40,920:INFO:          ipywidgets: 8.1.3
2024-06-12 12:01:40,921:INFO:                tqdm: 4.66.4
2024-06-12 12:01:40,921:INFO:               numpy: 1.26.4
2024-06-12 12:01:40,921:INFO:              pandas: 2.1.4
2024-06-12 12:01:40,921:INFO:              jinja2: 3.1.4
2024-06-12 12:01:40,921:INFO:               scipy: 1.11.4
2024-06-12 12:01:40,921:INFO:              joblib: 1.3.2
2024-06-12 12:01:40,921:INFO:             sklearn: 1.4.2
2024-06-12 12:01:40,921:INFO:                pyod: 2.0.0
2024-06-12 12:01:40,921:INFO:            imblearn: 0.12.3
2024-06-12 12:01:40,921:INFO:   category_encoders: 2.6.3
2024-06-12 12:01:40,921:INFO:            lightgbm: 4.3.0
2024-06-12 12:01:40,921:INFO:               numba: 0.59.1
2024-06-12 12:01:40,921:INFO:            requests: 2.32.3
2024-06-12 12:01:40,921:INFO:          matplotlib: 3.7.5
2024-06-12 12:01:40,921:INFO:          scikitplot: 0.3.7
2024-06-12 12:01:40,921:INFO:         yellowbrick: 1.5
2024-06-12 12:01:40,921:INFO:              plotly: 5.22.0
2024-06-12 12:01:40,921:INFO:    plotly-resampler: Not installed
2024-06-12 12:01:40,921:INFO:             kaleido: 0.2.1
2024-06-12 12:01:40,921:INFO:           schemdraw: 0.15
2024-06-12 12:01:40,921:INFO:         statsmodels: 0.14.2
2024-06-12 12:01:40,921:INFO:              sktime: 0.26.0
2024-06-12 12:01:40,921:INFO:               tbats: 1.1.3
2024-06-12 12:01:40,922:INFO:            pmdarima: 2.0.4
2024-06-12 12:01:40,922:INFO:              psutil: 5.9.8
2024-06-12 12:01:40,922:INFO:          markupsafe: 2.1.5
2024-06-12 12:01:40,922:INFO:             pickle5: Not installed
2024-06-12 12:01:40,922:INFO:         cloudpickle: 3.0.0
2024-06-12 12:01:40,922:INFO:         deprecation: 2.1.0
2024-06-12 12:01:40,922:INFO:              xxhash: 3.4.1
2024-06-12 12:01:40,922:INFO:           wurlitzer: Not installed
2024-06-12 12:01:40,922:INFO:PyCaret optional dependencies:
2024-06-12 12:01:40,932:INFO:                shap: Not installed
2024-06-12 12:01:40,933:INFO:           interpret: Not installed
2024-06-12 12:01:40,933:INFO:                umap: Not installed
2024-06-12 12:01:40,933:INFO:     ydata_profiling: Not installed
2024-06-12 12:01:40,933:INFO:  explainerdashboard: Not installed
2024-06-12 12:01:40,933:INFO:             autoviz: Not installed
2024-06-12 12:01:40,933:INFO:           fairlearn: Not installed
2024-06-12 12:01:40,933:INFO:          deepchecks: Not installed
2024-06-12 12:01:40,933:INFO:             xgboost: Not installed
2024-06-12 12:01:40,933:INFO:            catboost: Not installed
2024-06-12 12:01:40,933:INFO:              kmodes: Not installed
2024-06-12 12:01:40,933:INFO:             mlxtend: Not installed
2024-06-12 12:01:40,934:INFO:       statsforecast: Not installed
2024-06-12 12:01:40,934:INFO:        tune_sklearn: Not installed
2024-06-12 12:01:40,934:INFO:                 ray: Not installed
2024-06-12 12:01:40,934:INFO:            hyperopt: Not installed
2024-06-12 12:01:40,934:INFO:              optuna: Not installed
2024-06-12 12:01:40,934:INFO:               skopt: Not installed
2024-06-12 12:01:40,934:INFO:              mlflow: Not installed
2024-06-12 12:01:40,934:INFO:              gradio: Not installed
2024-06-12 12:01:40,934:INFO:             fastapi: Not installed
2024-06-12 12:01:40,934:INFO:             uvicorn: Not installed
2024-06-12 12:01:40,934:INFO:              m2cgen: Not installed
2024-06-12 12:01:40,934:INFO:           evidently: Not installed
2024-06-12 12:01:40,934:INFO:               fugue: Not installed
2024-06-12 12:01:40,934:INFO:           streamlit: 1.35.0
2024-06-12 12:01:40,934:INFO:             prophet: Not installed
2024-06-12 12:01:40,934:INFO:None
2024-06-12 12:01:40,934:INFO:Set up data.
2024-06-12 12:01:40,966:INFO:Set up folding strategy.
2024-06-12 12:01:40,966:INFO:Set up train/test split.
2024-06-12 12:01:40,996:INFO:Set up index.
2024-06-12 12:01:40,997:INFO:Assigning column types.
2024-06-12 12:01:41,007:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 12:01:41,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 12:01:41,059:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:01:41,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 12:01:41,130:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:01:41,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,163:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 12:01:41,206:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:01:41,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,279:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:01:41,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,296:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 12:01:41,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:41,430:INFO:Preparing preprocessing pipeline...
2024-06-12 12:01:41,430:INFO:Set up simple imputation.
2024-06-12 12:01:41,446:INFO:Set up encoding of ordinal features.
2024-06-12 12:01:41,463:INFO:Set up encoding of categorical features.
2024-06-12 12:01:41,463:INFO:Set up feature normalization.
2024-06-12 12:01:41,464:INFO:Set up PCA.
2024-06-12 12:01:41,830:INFO:Finished creating preprocessing pipeline.
2024-06-12 12:01:41,863:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MaxAbsScaler(copy=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 12:01:41,863:INFO:Creating final display dataframe.
2024-06-12 12:01:41,995:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            maxabs
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              27ff
2024-06-12 12:01:42,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:42,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:42,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:42,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:01:42,143:INFO:setup() successfully completed in 1.41s...............
2024-06-12 12:01:42,159:INFO:Initializing create_model()
2024-06-12 12:01:42,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:01:42,159:INFO:Checking exceptions
2024-06-12 12:01:42,166:INFO:Importing libraries
2024-06-12 12:01:42,179:INFO:Copying training dataset
2024-06-12 12:01:42,180:INFO:Defining folds
2024-06-12 12:01:42,195:INFO:Declaring metric variables
2024-06-12 12:01:42,198:INFO:Importing untrained model
2024-06-12 12:01:42,202:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:01:42,208:INFO:Starting cross validation
2024-06-12 12:01:42,210:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:01:47,482:INFO:Calculating mean and std
2024-06-12 12:01:47,484:INFO:Creating metrics dataframe
2024-06-12 12:01:47,485:INFO:Finalizing model
2024-06-12 12:01:47,863:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:01:47,863:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002696 seconds.
2024-06-12 12:01:47,863:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:01:47,863:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:01:47,863:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:01:47,863:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:01:47,863:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:01:48,058:INFO:Uploading results into container
2024-06-12 12:01:48,058:INFO:Uploading model into container now
2024-06-12 12:01:48,074:INFO:_master_model_container: 1
2024-06-12 12:01:48,074:INFO:_display_container: 2
2024-06-12 12:01:48,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:01:48,074:INFO:create_model() successfully completed......................................
2024-06-12 12:01:48,215:INFO:Initializing tune_model()
2024-06-12 12:01:48,215:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 12:01:48,215:INFO:Checking exceptions
2024-06-12 12:01:48,246:INFO:Copying training dataset
2024-06-12 12:01:48,274:INFO:Checking base model
2024-06-12 12:01:48,274:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 12:01:48,278:INFO:Declaring metric variables
2024-06-12 12:01:48,281:INFO:Defining Hyperparameters
2024-06-12 12:01:48,342:INFO:Tuning with n_jobs=-1
2024-06-12 12:01:48,342:INFO:Initializing RandomizedSearchCV
2024-06-12 12:02:24,786:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-12 12:02:24,786:INFO:Hyperparameter search completed
2024-06-12 12:02:24,786:INFO:SubProcess create_model() called ==================================
2024-06-12 12:02:24,786:INFO:Initializing create_model()
2024-06-12 12:02:24,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C42FBE85D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-12 12:02:24,786:INFO:Checking exceptions
2024-06-12 12:02:24,786:INFO:Importing libraries
2024-06-12 12:02:24,786:INFO:Copying training dataset
2024-06-12 12:02:24,812:INFO:Defining folds
2024-06-12 12:02:24,812:INFO:Declaring metric variables
2024-06-12 12:02:24,812:INFO:Importing untrained model
2024-06-12 12:02:24,812:INFO:Declaring custom model
2024-06-12 12:02:24,828:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:02:24,828:INFO:Starting cross validation
2024-06-12 12:02:24,828:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:02:26,981:INFO:Calculating mean and std
2024-06-12 12:02:26,982:INFO:Creating metrics dataframe
2024-06-12 12:02:26,990:INFO:Finalizing model
2024-06-12 12:02:27,347:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:27,347:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:27,347:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:27,394:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:27,394:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:27,394:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:27,394:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:02:27,394:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003498 seconds.
2024-06-12 12:02:27,394:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:02:27,394:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:02:27,410:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:02:27,410:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:02:27,410:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:02:27,622:INFO:Uploading results into container
2024-06-12 12:02:27,638:INFO:Uploading model into container now
2024-06-12 12:02:27,638:INFO:_master_model_container: 2
2024-06-12 12:02:27,638:INFO:_display_container: 3
2024-06-12 12:02:27,638:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:02:27,638:INFO:create_model() successfully completed......................................
2024-06-12 12:02:27,716:INFO:SubProcess create_model() end ==================================
2024-06-12 12:02:27,716:INFO:choose_better activated
2024-06-12 12:02:27,732:INFO:SubProcess create_model() called ==================================
2024-06-12 12:02:27,732:INFO:Initializing create_model()
2024-06-12 12:02:27,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:02:27,732:INFO:Checking exceptions
2024-06-12 12:02:27,732:INFO:Importing libraries
2024-06-12 12:02:27,732:INFO:Copying training dataset
2024-06-12 12:02:27,747:INFO:Defining folds
2024-06-12 12:02:27,747:INFO:Declaring metric variables
2024-06-12 12:02:27,747:INFO:Importing untrained model
2024-06-12 12:02:27,747:INFO:Declaring custom model
2024-06-12 12:02:27,747:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:02:27,747:INFO:Starting cross validation
2024-06-12 12:02:27,747:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:02:29,821:INFO:Calculating mean and std
2024-06-12 12:02:29,822:INFO:Creating metrics dataframe
2024-06-12 12:02:29,822:INFO:Finalizing model
2024-06-12 12:02:30,262:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:02:30,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003162 seconds.
2024-06-12 12:02:30,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:02:30,266:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:02:30,267:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:02:30,267:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:02:30,267:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:02:30,523:INFO:Uploading results into container
2024-06-12 12:02:30,523:INFO:Uploading model into container now
2024-06-12 12:02:30,523:INFO:_master_model_container: 3
2024-06-12 12:02:30,523:INFO:_display_container: 4
2024-06-12 12:02:30,523:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:02:30,523:INFO:create_model() successfully completed......................................
2024-06-12 12:02:30,623:INFO:SubProcess create_model() end ==================================
2024-06-12 12:02:30,623:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0128
2024-06-12 12:02:30,623:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0694
2024-06-12 12:02:30,623:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 12:02:30,623:INFO:choose_better completed
2024-06-12 12:02:30,623:INFO:_master_model_container: 3
2024-06-12 12:02:30,623:INFO:_display_container: 3
2024-06-12 12:02:30,639:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:02:30,639:INFO:tune_model() successfully completed......................................
2024-06-12 12:02:30,748:INFO:Initializing plot_model()
2024-06-12 12:02:30,748:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:02:30,748:INFO:Checking exceptions
2024-06-12 12:02:30,771:INFO:Preloading libraries
2024-06-12 12:02:30,783:INFO:Copying training dataset
2024-06-12 12:02:30,783:INFO:Plot type: auc
2024-06-12 12:02:30,961:INFO:Fitting Model
2024-06-12 12:02:30,963:INFO:Scoring test/hold-out set
2024-06-12 12:02:30,965:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:30,965:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:30,965:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:30,966:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:30,966:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:30,966:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:31,234:INFO:Visual Rendered Successfully
2024-06-12 12:02:31,301:INFO:plot_model() successfully completed......................................
2024-06-12 12:02:31,325:INFO:Initializing plot_model()
2024-06-12 12:02:31,325:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:02:31,325:INFO:Checking exceptions
2024-06-12 12:02:31,335:INFO:Preloading libraries
2024-06-12 12:02:31,336:INFO:Copying training dataset
2024-06-12 12:02:31,336:INFO:Plot type: confusion_matrix
2024-06-12 12:02:31,514:INFO:Fitting Model
2024-06-12 12:02:31,515:INFO:Scoring test/hold-out set
2024-06-12 12:02:31,517:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:31,517:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:31,517:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:31,526:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:31,526:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:31,526:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:31,677:INFO:Visual Rendered Successfully
2024-06-12 12:02:31,741:INFO:plot_model() successfully completed......................................
2024-06-12 12:02:31,758:INFO:Initializing finalize_model()
2024-06-12 12:02:31,758:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 12:02:31,758:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:02:31,773:INFO:Initializing create_model()
2024-06-12 12:02:31,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:02:31,773:INFO:Checking exceptions
2024-06-12 12:02:31,773:INFO:Importing libraries
2024-06-12 12:02:31,773:INFO:Copying training dataset
2024-06-12 12:02:31,773:INFO:Defining folds
2024-06-12 12:02:31,773:INFO:Declaring metric variables
2024-06-12 12:02:31,773:INFO:Importing untrained model
2024-06-12 12:02:31,773:INFO:Declaring custom model
2024-06-12 12:02:31,773:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:02:31,773:INFO:Cross validation set to False
2024-06-12 12:02:31,773:INFO:Fitting Model
2024-06-12 12:02:32,210:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:32,210:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:32,210:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:32,273:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:32,273:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:32,273:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:32,273:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 12:02:32,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004408 seconds.
2024-06-12 12:02:32,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:02:32,291:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:02:32,294:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 12:02:32,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 12:02:32,297:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 12:02:32,503:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 12:02:32,503:INFO:create_model() successfully completed......................................
2024-06-12 12:02:32,585:INFO:_master_model_container: 3
2024-06-12 12:02:32,585:INFO:_display_container: 3
2024-06-12 12:02:32,618:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-12 12:02:32,618:INFO:finalize_model() successfully completed......................................
2024-06-12 12:02:32,731:INFO:Initializing plot_model()
2024-06-12 12:02:32,731:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:02:32,731:INFO:Checking exceptions
2024-06-12 12:02:32,748:INFO:Preloading libraries
2024-06-12 12:02:32,748:INFO:Copying training dataset
2024-06-12 12:02:32,748:INFO:Plot type: auc
2024-06-12 12:02:32,913:INFO:Fitting Model
2024-06-12 12:02:32,913:INFO:Scoring test/hold-out set
2024-06-12 12:02:32,929:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:32,929:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:32,929:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:32,929:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:32,929:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:32,929:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:33,190:INFO:Visual Rendered Successfully
2024-06-12 12:02:33,274:INFO:plot_model() successfully completed......................................
2024-06-12 12:02:33,308:INFO:Initializing plot_model()
2024-06-12 12:02:33,308:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:02:33,308:INFO:Checking exceptions
2024-06-12 12:02:33,323:INFO:Preloading libraries
2024-06-12 12:02:33,323:INFO:Copying training dataset
2024-06-12 12:02:33,323:INFO:Plot type: confusion_matrix
2024-06-12 12:02:33,507:INFO:Fitting Model
2024-06-12 12:02:33,507:INFO:Scoring test/hold-out set
2024-06-12 12:02:33,507:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:33,507:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:33,507:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:33,523:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:02:33,523:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-12 12:02:33,523:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-12 12:02:33,674:INFO:Visual Rendered Successfully
2024-06-12 12:02:33,739:INFO:plot_model() successfully completed......................................
2024-06-12 12:02:33,786:INFO:Initializing predict_model()
2024-06-12 12:02:33,786:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E9F7FD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C4310EBE20>)
2024-06-12 12:02:33,786:INFO:Checking exceptions
2024-06-12 12:02:33,786:INFO:Preloading libraries
2024-06-12 12:02:33,794:INFO:Set up data.
2024-06-12 12:02:34,206:INFO:Set up index.
2024-06-12 12:02:55,934:INFO:PyCaret ClassificationExperiment
2024-06-12 12:02:55,935:INFO:Logging name: clf-default-name
2024-06-12 12:02:55,935:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 12:02:55,935:INFO:version 3.3.2
2024-06-12 12:02:55,935:INFO:Initializing setup()
2024-06-12 12:02:55,935:INFO:self.USI: 9a40
2024-06-12 12:02:55,935:INFO:self._variable_keys: {'X_train', 'target_param', 'idx', 'pipeline', 'exp_name_log', 'n_jobs_param', 'fold_generator', 'fix_imbalance', 'seed', '_available_plots', 'exp_id', 'gpu_n_jobs_param', 'log_plots_param', 'html_param', '_ml_usecase', 'y_train', 'data', 'memory', 'USI', 'X_test', 'y', 'is_multiclass', 'gpu_param', 'y_test', 'X', 'fold_shuffle_param', 'fold_groups_param', 'logging_param'}
2024-06-12 12:02:55,935:INFO:Checking environment
2024-06-12 12:02:55,935:INFO:python_version: 3.11.9
2024-06-12 12:02:55,935:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 12:02:55,935:INFO:machine: AMD64
2024-06-12 12:02:55,935:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 12:02:55,936:INFO:Memory: svmem(total=34056318976, available=24627576832, percent=27.7, used=9428742144, free=24627576832)
2024-06-12 12:02:55,936:INFO:Physical Core: 6
2024-06-12 12:02:55,936:INFO:Logical Core: 12
2024-06-12 12:02:55,936:INFO:Checking libraries
2024-06-12 12:02:55,936:INFO:System:
2024-06-12 12:02:55,936:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 12:02:55,936:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 12:02:55,936:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 12:02:55,936:INFO:PyCaret required dependencies:
2024-06-12 12:02:55,936:INFO:                 pip: 24.0
2024-06-12 12:02:55,936:INFO:          setuptools: 69.5.1
2024-06-12 12:02:55,936:INFO:             pycaret: 3.3.2
2024-06-12 12:02:55,936:INFO:             IPython: 8.25.0
2024-06-12 12:02:55,936:INFO:          ipywidgets: 8.1.3
2024-06-12 12:02:55,936:INFO:                tqdm: 4.66.4
2024-06-12 12:02:55,936:INFO:               numpy: 1.26.4
2024-06-12 12:02:55,937:INFO:              pandas: 2.1.4
2024-06-12 12:02:55,937:INFO:              jinja2: 3.1.4
2024-06-12 12:02:55,937:INFO:               scipy: 1.11.4
2024-06-12 12:02:55,937:INFO:              joblib: 1.3.2
2024-06-12 12:02:55,937:INFO:             sklearn: 1.4.2
2024-06-12 12:02:55,937:INFO:                pyod: 2.0.0
2024-06-12 12:02:55,937:INFO:            imblearn: 0.12.3
2024-06-12 12:02:55,937:INFO:   category_encoders: 2.6.3
2024-06-12 12:02:55,937:INFO:            lightgbm: 4.3.0
2024-06-12 12:02:55,937:INFO:               numba: 0.59.1
2024-06-12 12:02:55,937:INFO:            requests: 2.32.3
2024-06-12 12:02:55,937:INFO:          matplotlib: 3.7.5
2024-06-12 12:02:55,937:INFO:          scikitplot: 0.3.7
2024-06-12 12:02:55,937:INFO:         yellowbrick: 1.5
2024-06-12 12:02:55,937:INFO:              plotly: 5.22.0
2024-06-12 12:02:55,937:INFO:    plotly-resampler: Not installed
2024-06-12 12:02:55,937:INFO:             kaleido: 0.2.1
2024-06-12 12:02:55,937:INFO:           schemdraw: 0.15
2024-06-12 12:02:55,937:INFO:         statsmodels: 0.14.2
2024-06-12 12:02:55,937:INFO:              sktime: 0.26.0
2024-06-12 12:02:55,938:INFO:               tbats: 1.1.3
2024-06-12 12:02:55,938:INFO:            pmdarima: 2.0.4
2024-06-12 12:02:55,938:INFO:              psutil: 5.9.8
2024-06-12 12:02:55,938:INFO:          markupsafe: 2.1.5
2024-06-12 12:02:55,938:INFO:             pickle5: Not installed
2024-06-12 12:02:55,938:INFO:         cloudpickle: 3.0.0
2024-06-12 12:02:55,938:INFO:         deprecation: 2.1.0
2024-06-12 12:02:55,938:INFO:              xxhash: 3.4.1
2024-06-12 12:02:55,938:INFO:           wurlitzer: Not installed
2024-06-12 12:02:55,938:INFO:PyCaret optional dependencies:
2024-06-12 12:02:55,938:INFO:                shap: Not installed
2024-06-12 12:02:55,938:INFO:           interpret: Not installed
2024-06-12 12:02:55,938:INFO:                umap: Not installed
2024-06-12 12:02:55,938:INFO:     ydata_profiling: Not installed
2024-06-12 12:02:55,938:INFO:  explainerdashboard: Not installed
2024-06-12 12:02:55,938:INFO:             autoviz: Not installed
2024-06-12 12:02:55,939:INFO:           fairlearn: Not installed
2024-06-12 12:02:55,939:INFO:          deepchecks: Not installed
2024-06-12 12:02:55,939:INFO:             xgboost: Not installed
2024-06-12 12:02:55,939:INFO:            catboost: Not installed
2024-06-12 12:02:55,939:INFO:              kmodes: Not installed
2024-06-12 12:02:55,939:INFO:             mlxtend: Not installed
2024-06-12 12:02:55,939:INFO:       statsforecast: Not installed
2024-06-12 12:02:55,939:INFO:        tune_sklearn: Not installed
2024-06-12 12:02:55,939:INFO:                 ray: Not installed
2024-06-12 12:02:55,939:INFO:            hyperopt: Not installed
2024-06-12 12:02:55,939:INFO:              optuna: Not installed
2024-06-12 12:02:55,939:INFO:               skopt: Not installed
2024-06-12 12:02:55,939:INFO:              mlflow: Not installed
2024-06-12 12:02:55,939:INFO:              gradio: Not installed
2024-06-12 12:02:55,939:INFO:             fastapi: Not installed
2024-06-12 12:02:55,939:INFO:             uvicorn: Not installed
2024-06-12 12:02:55,939:INFO:              m2cgen: Not installed
2024-06-12 12:02:55,939:INFO:           evidently: Not installed
2024-06-12 12:02:55,939:INFO:               fugue: Not installed
2024-06-12 12:02:55,939:INFO:           streamlit: 1.35.0
2024-06-12 12:02:55,940:INFO:             prophet: Not installed
2024-06-12 12:02:55,940:INFO:None
2024-06-12 12:02:55,940:INFO:Set up data.
2024-06-12 12:02:55,981:INFO:Set up folding strategy.
2024-06-12 12:02:55,981:INFO:Set up train/test split.
2024-06-12 12:02:56,006:INFO:Set up index.
2024-06-12 12:02:56,007:INFO:Assigning column types.
2024-06-12 12:02:56,008:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 12:02:56,058:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 12:02:56,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:02:56,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 12:02:56,184:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:02:56,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,214:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 12:02:56,259:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:02:56,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,377:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:02:56,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,410:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 12:02:56,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:56,599:INFO:Preparing preprocessing pipeline...
2024-06-12 12:02:56,602:INFO:Set up simple imputation.
2024-06-12 12:02:56,611:INFO:Set up encoding of ordinal features.
2024-06-12 12:02:56,625:INFO:Set up encoding of categorical features.
2024-06-12 12:02:56,926:INFO:Finished creating preprocessing pipeline.
2024-06-12 12:02:56,959:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-06-12 12:02:56,959:INFO:Creating final display dataframe.
2024-06-12 12:02:57,109:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              9a40
2024-06-12 12:02:57,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:57,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:57,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:57,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:02:57,260:INFO:setup() successfully completed in 1.43s...............
2024-06-12 12:02:57,349:INFO:Initializing create_model()
2024-06-12 12:02:57,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:02:57,349:INFO:Checking exceptions
2024-06-12 12:02:57,375:INFO:Importing libraries
2024-06-12 12:02:57,375:INFO:Copying training dataset
2024-06-12 12:02:57,406:INFO:Defining folds
2024-06-12 12:02:57,407:INFO:Declaring metric variables
2024-06-12 12:02:57,410:INFO:Importing untrained model
2024-06-12 12:02:57,414:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:02:57,424:INFO:Starting cross validation
2024-06-12 12:02:57,427:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:02:59,080:INFO:Calculating mean and std
2024-06-12 12:02:59,080:INFO:Creating metrics dataframe
2024-06-12 12:02:59,080:INFO:Finalizing model
2024-06-12 12:02:59,383:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 12:02:59,383:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:02:59,383:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001222 seconds.
2024-06-12 12:02:59,383:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 12:02:59,383:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 12:02:59,383:INFO:[LightGBM] [Info] Total Bins 623
2024-06-12 12:02:59,383:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:02:59,383:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:02:59,383:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:02:59,510:INFO:Uploading results into container
2024-06-12 12:02:59,512:INFO:Uploading model into container now
2024-06-12 12:02:59,523:INFO:_master_model_container: 1
2024-06-12 12:02:59,523:INFO:_display_container: 2
2024-06-12 12:02:59,524:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:02:59,524:INFO:create_model() successfully completed......................................
2024-06-12 12:02:59,614:INFO:Initializing tune_model()
2024-06-12 12:02:59,614:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 12:02:59,614:INFO:Checking exceptions
2024-06-12 12:02:59,642:INFO:Copying training dataset
2024-06-12 12:02:59,659:INFO:Checking base model
2024-06-12 12:02:59,659:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 12:02:59,662:INFO:Declaring metric variables
2024-06-12 12:02:59,665:INFO:Defining Hyperparameters
2024-06-12 12:02:59,736:INFO:Tuning with n_jobs=-1
2024-06-12 12:02:59,736:INFO:Initializing RandomizedSearchCV
2024-06-12 12:03:16,620:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-12 12:03:16,620:INFO:Hyperparameter search completed
2024-06-12 12:03:16,620:INFO:SubProcess create_model() called ==================================
2024-06-12 12:03:16,620:INFO:Initializing create_model()
2024-06-12 12:03:16,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C42DF80510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-12 12:03:16,620:INFO:Checking exceptions
2024-06-12 12:03:16,620:INFO:Importing libraries
2024-06-12 12:03:16,620:INFO:Copying training dataset
2024-06-12 12:03:16,655:INFO:Defining folds
2024-06-12 12:03:16,655:INFO:Declaring metric variables
2024-06-12 12:03:16,655:INFO:Importing untrained model
2024-06-12 12:03:16,655:INFO:Declaring custom model
2024-06-12 12:03:16,664:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:03:16,680:INFO:Starting cross validation
2024-06-12 12:03:16,680:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:03:19,045:INFO:Calculating mean and std
2024-06-12 12:03:19,045:INFO:Creating metrics dataframe
2024-06-12 12:03:19,045:INFO:Finalizing model
2024-06-12 12:03:19,330:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:19,330:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:19,330:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:19,346:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 12:03:19,346:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:19,346:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:19,346:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:19,346:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:03:19,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001345 seconds.
2024-06-12 12:03:19,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 12:03:19,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 12:03:19,363:INFO:[LightGBM] [Info] Total Bins 619
2024-06-12 12:03:19,363:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 27
2024-06-12 12:03:19,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:03:19,364:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:03:19,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:19,632:INFO:Uploading results into container
2024-06-12 12:03:19,632:INFO:Uploading model into container now
2024-06-12 12:03:19,632:INFO:_master_model_container: 2
2024-06-12 12:03:19,632:INFO:_display_container: 3
2024-06-12 12:03:19,632:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:03:19,632:INFO:create_model() successfully completed......................................
2024-06-12 12:03:19,728:INFO:SubProcess create_model() end ==================================
2024-06-12 12:03:19,728:INFO:choose_better activated
2024-06-12 12:03:19,731:INFO:SubProcess create_model() called ==================================
2024-06-12 12:03:19,732:INFO:Initializing create_model()
2024-06-12 12:03:19,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:03:19,732:INFO:Checking exceptions
2024-06-12 12:03:19,733:INFO:Importing libraries
2024-06-12 12:03:19,733:INFO:Copying training dataset
2024-06-12 12:03:19,746:INFO:Defining folds
2024-06-12 12:03:19,746:INFO:Declaring metric variables
2024-06-12 12:03:19,746:INFO:Importing untrained model
2024-06-12 12:03:19,746:INFO:Declaring custom model
2024-06-12 12:03:19,746:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:03:19,746:INFO:Starting cross validation
2024-06-12 12:03:19,746:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:03:21,080:INFO:Calculating mean and std
2024-06-12 12:03:21,080:INFO:Creating metrics dataframe
2024-06-12 12:03:21,080:INFO:Finalizing model
2024-06-12 12:03:21,376:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 12:03:21,376:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:03:21,376:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001239 seconds.
2024-06-12 12:03:21,376:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 12:03:21,376:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 12:03:21,376:INFO:[LightGBM] [Info] Total Bins 623
2024-06-12 12:03:21,376:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:03:21,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:03:21,376:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:03:21,493:INFO:Uploading results into container
2024-06-12 12:03:21,494:INFO:Uploading model into container now
2024-06-12 12:03:21,494:INFO:_master_model_container: 3
2024-06-12 12:03:21,495:INFO:_display_container: 4
2024-06-12 12:03:21,495:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:03:21,495:INFO:create_model() successfully completed......................................
2024-06-12 12:03:21,568:INFO:SubProcess create_model() end ==================================
2024-06-12 12:03:21,568:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.134
2024-06-12 12:03:21,568:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1351
2024-06-12 12:03:21,584:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 12:03:21,584:INFO:choose_better completed
2024-06-12 12:03:21,584:INFO:_master_model_container: 3
2024-06-12 12:03:21,584:INFO:_display_container: 3
2024-06-12 12:03:21,584:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:03:21,584:INFO:tune_model() successfully completed......................................
2024-06-12 12:03:21,709:INFO:Initializing plot_model()
2024-06-12 12:03:21,709:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:03:21,710:INFO:Checking exceptions
2024-06-12 12:03:21,717:INFO:Preloading libraries
2024-06-12 12:03:21,745:INFO:Copying training dataset
2024-06-12 12:03:21,745:INFO:Plot type: auc
2024-06-12 12:03:21,912:INFO:Fitting Model
2024-06-12 12:03:21,912:INFO:Scoring test/hold-out set
2024-06-12 12:03:21,912:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:21,912:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:21,912:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:21,944:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:21,944:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:21,944:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:22,241:INFO:Visual Rendered Successfully
2024-06-12 12:03:22,302:INFO:plot_model() successfully completed......................................
2024-06-12 12:03:22,319:INFO:Initializing plot_model()
2024-06-12 12:03:22,319:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:03:22,319:INFO:Checking exceptions
2024-06-12 12:03:22,339:INFO:Preloading libraries
2024-06-12 12:03:22,346:INFO:Copying training dataset
2024-06-12 12:03:22,346:INFO:Plot type: confusion_matrix
2024-06-12 12:03:22,528:INFO:Fitting Model
2024-06-12 12:03:22,529:INFO:Scoring test/hold-out set
2024-06-12 12:03:22,531:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:22,531:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:22,531:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:22,551:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:22,551:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:22,551:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:22,727:INFO:Visual Rendered Successfully
2024-06-12 12:03:22,790:INFO:plot_model() successfully completed......................................
2024-06-12 12:03:22,814:INFO:Initializing finalize_model()
2024-06-12 12:03:22,814:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 12:03:22,814:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:03:22,823:INFO:Initializing create_model()
2024-06-12 12:03:22,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:03:22,823:INFO:Checking exceptions
2024-06-12 12:03:22,823:INFO:Importing libraries
2024-06-12 12:03:22,823:INFO:Copying training dataset
2024-06-12 12:03:22,823:INFO:Defining folds
2024-06-12 12:03:22,823:INFO:Declaring metric variables
2024-06-12 12:03:22,823:INFO:Importing untrained model
2024-06-12 12:03:22,823:INFO:Declaring custom model
2024-06-12 12:03:22,823:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:03:22,823:INFO:Cross validation set to False
2024-06-12 12:03:22,823:INFO:Fitting Model
2024-06-12 12:03:23,174:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:23,174:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:23,174:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:23,205:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-12 12:03:23,205:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:23,205:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:23,205:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:23,205:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 12:03:23,205:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002407 seconds.
2024-06-12 12:03:23,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-12 12:03:23,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-12 12:03:23,205:INFO:[LightGBM] [Info] Total Bins 619
2024-06-12 12:03:23,205:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 27
2024-06-12 12:03:23,221:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 12:03:23,221:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 12:03:23,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:03:23,595:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 12:03:23,595:INFO:create_model() successfully completed......................................
2024-06-12 12:03:23,673:INFO:_master_model_container: 3
2024-06-12 12:03:23,673:INFO:_display_container: 3
2024-06-12 12:03:23,704:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 12:03:23,704:INFO:finalize_model() successfully completed......................................
2024-06-12 12:03:23,822:INFO:Initializing plot_model()
2024-06-12 12:03:23,822:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:03:23,822:INFO:Checking exceptions
2024-06-12 12:03:23,830:INFO:Preloading libraries
2024-06-12 12:03:23,846:INFO:Copying training dataset
2024-06-12 12:03:23,846:INFO:Plot type: auc
2024-06-12 12:03:24,017:INFO:Fitting Model
2024-06-12 12:03:24,018:INFO:Scoring test/hold-out set
2024-06-12 12:03:24,020:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:24,020:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:24,020:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:24,032:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:24,032:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:24,032:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:24,300:INFO:Visual Rendered Successfully
2024-06-12 12:03:24,368:INFO:plot_model() successfully completed......................................
2024-06-12 12:03:24,415:INFO:Initializing plot_model()
2024-06-12 12:03:24,415:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:03:24,415:INFO:Checking exceptions
2024-06-12 12:03:24,415:INFO:Preloading libraries
2024-06-12 12:03:24,431:INFO:Copying training dataset
2024-06-12 12:03:24,431:INFO:Plot type: confusion_matrix
2024-06-12 12:03:24,596:INFO:Fitting Model
2024-06-12 12:03:24,596:INFO:Scoring test/hold-out set
2024-06-12 12:03:24,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:24,612:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:24,612:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:24,627:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:03:24,627:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:03:24,627:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:03:24,803:INFO:Visual Rendered Successfully
2024-06-12 12:03:24,867:INFO:plot_model() successfully completed......................................
2024-06-12 12:03:24,921:INFO:Initializing predict_model()
2024-06-12 12:03:24,921:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FC09310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C43128E200>)
2024-06-12 12:03:24,922:INFO:Checking exceptions
2024-06-12 12:03:24,922:INFO:Preloading libraries
2024-06-12 12:03:24,925:INFO:Set up data.
2024-06-12 12:03:25,340:INFO:Set up index.
2024-06-12 12:05:24,686:INFO:PyCaret ClassificationExperiment
2024-06-12 12:05:24,686:INFO:Logging name: clf-default-name
2024-06-12 12:05:24,686:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 12:05:24,686:INFO:version 3.3.2
2024-06-12 12:05:24,686:INFO:Initializing setup()
2024-06-12 12:05:24,686:INFO:self.USI: 93b5
2024-06-12 12:05:24,686:INFO:self._variable_keys: {'X_train', 'target_param', 'idx', 'pipeline', 'exp_name_log', 'n_jobs_param', 'fold_generator', 'fix_imbalance', 'seed', '_available_plots', 'exp_id', 'gpu_n_jobs_param', 'log_plots_param', 'html_param', '_ml_usecase', 'y_train', 'data', 'memory', 'USI', 'X_test', 'y', 'is_multiclass', 'gpu_param', 'y_test', 'X', 'fold_shuffle_param', 'fold_groups_param', 'logging_param'}
2024-06-12 12:05:24,686:INFO:Checking environment
2024-06-12 12:05:24,687:INFO:python_version: 3.11.9
2024-06-12 12:05:24,687:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 12:05:24,687:INFO:machine: AMD64
2024-06-12 12:05:24,687:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 12:05:24,687:INFO:Memory: svmem(total=34056318976, available=24508870656, percent=28.0, used=9547448320, free=24508870656)
2024-06-12 12:05:24,687:INFO:Physical Core: 6
2024-06-12 12:05:24,687:INFO:Logical Core: 12
2024-06-12 12:05:24,687:INFO:Checking libraries
2024-06-12 12:05:24,687:INFO:System:
2024-06-12 12:05:24,687:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 12:05:24,687:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 12:05:24,687:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 12:05:24,687:INFO:PyCaret required dependencies:
2024-06-12 12:05:24,687:INFO:                 pip: 24.0
2024-06-12 12:05:24,687:INFO:          setuptools: 69.5.1
2024-06-12 12:05:24,687:INFO:             pycaret: 3.3.2
2024-06-12 12:05:24,688:INFO:             IPython: 8.25.0
2024-06-12 12:05:24,688:INFO:          ipywidgets: 8.1.3
2024-06-12 12:05:24,688:INFO:                tqdm: 4.66.4
2024-06-12 12:05:24,688:INFO:               numpy: 1.26.4
2024-06-12 12:05:24,688:INFO:              pandas: 2.1.4
2024-06-12 12:05:24,688:INFO:              jinja2: 3.1.4
2024-06-12 12:05:24,688:INFO:               scipy: 1.11.4
2024-06-12 12:05:24,688:INFO:              joblib: 1.3.2
2024-06-12 12:05:24,688:INFO:             sklearn: 1.4.2
2024-06-12 12:05:24,688:INFO:                pyod: 2.0.0
2024-06-12 12:05:24,688:INFO:            imblearn: 0.12.3
2024-06-12 12:05:24,688:INFO:   category_encoders: 2.6.3
2024-06-12 12:05:24,688:INFO:            lightgbm: 4.3.0
2024-06-12 12:05:24,688:INFO:               numba: 0.59.1
2024-06-12 12:05:24,688:INFO:            requests: 2.32.3
2024-06-12 12:05:24,688:INFO:          matplotlib: 3.7.5
2024-06-12 12:05:24,688:INFO:          scikitplot: 0.3.7
2024-06-12 12:05:24,688:INFO:         yellowbrick: 1.5
2024-06-12 12:05:24,688:INFO:              plotly: 5.22.0
2024-06-12 12:05:24,688:INFO:    plotly-resampler: Not installed
2024-06-12 12:05:24,689:INFO:             kaleido: 0.2.1
2024-06-12 12:05:24,689:INFO:           schemdraw: 0.15
2024-06-12 12:05:24,689:INFO:         statsmodels: 0.14.2
2024-06-12 12:05:24,689:INFO:              sktime: 0.26.0
2024-06-12 12:05:24,689:INFO:               tbats: 1.1.3
2024-06-12 12:05:24,689:INFO:            pmdarima: 2.0.4
2024-06-12 12:05:24,689:INFO:              psutil: 5.9.8
2024-06-12 12:05:24,689:INFO:          markupsafe: 2.1.5
2024-06-12 12:05:24,689:INFO:             pickle5: Not installed
2024-06-12 12:05:24,689:INFO:         cloudpickle: 3.0.0
2024-06-12 12:05:24,689:INFO:         deprecation: 2.1.0
2024-06-12 12:05:24,689:INFO:              xxhash: 3.4.1
2024-06-12 12:05:24,689:INFO:           wurlitzer: Not installed
2024-06-12 12:05:24,689:INFO:PyCaret optional dependencies:
2024-06-12 12:05:24,689:INFO:                shap: Not installed
2024-06-12 12:05:24,689:INFO:           interpret: Not installed
2024-06-12 12:05:24,690:INFO:                umap: Not installed
2024-06-12 12:05:24,690:INFO:     ydata_profiling: Not installed
2024-06-12 12:05:24,690:INFO:  explainerdashboard: Not installed
2024-06-12 12:05:24,690:INFO:             autoviz: Not installed
2024-06-12 12:05:24,690:INFO:           fairlearn: Not installed
2024-06-12 12:05:24,690:INFO:          deepchecks: Not installed
2024-06-12 12:05:24,690:INFO:             xgboost: Not installed
2024-06-12 12:05:24,691:INFO:            catboost: Not installed
2024-06-12 12:05:24,691:INFO:              kmodes: Not installed
2024-06-12 12:05:24,691:INFO:             mlxtend: Not installed
2024-06-12 12:05:24,691:INFO:       statsforecast: Not installed
2024-06-12 12:05:24,691:INFO:        tune_sklearn: Not installed
2024-06-12 12:05:24,691:INFO:                 ray: Not installed
2024-06-12 12:05:24,691:INFO:            hyperopt: Not installed
2024-06-12 12:05:24,691:INFO:              optuna: Not installed
2024-06-12 12:05:24,691:INFO:               skopt: Not installed
2024-06-12 12:05:24,691:INFO:              mlflow: Not installed
2024-06-12 12:05:24,691:INFO:              gradio: Not installed
2024-06-12 12:05:24,691:INFO:             fastapi: Not installed
2024-06-12 12:05:24,691:INFO:             uvicorn: Not installed
2024-06-12 12:05:24,692:INFO:              m2cgen: Not installed
2024-06-12 12:05:24,692:INFO:           evidently: Not installed
2024-06-12 12:05:24,692:INFO:               fugue: Not installed
2024-06-12 12:05:24,692:INFO:           streamlit: 1.35.0
2024-06-12 12:05:24,692:INFO:             prophet: Not installed
2024-06-12 12:05:24,692:INFO:None
2024-06-12 12:05:24,692:INFO:Set up data.
2024-06-12 12:05:24,731:INFO:Set up folding strategy.
2024-06-12 12:05:24,731:INFO:Set up train/test split.
2024-06-12 12:05:24,741:INFO:Set up index.
2024-06-12 12:05:24,741:INFO:Assigning column types.
2024-06-12 12:05:24,766:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 12:05:24,808:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 12:05:24,808:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:05:24,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:24,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:24,889:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 12:05:24,891:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:05:24,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:24,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:24,907:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 12:05:24,958:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:05:24,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:24,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,049:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:05:25,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,079:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 12:05:25,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,241:INFO:Preparing preprocessing pipeline...
2024-06-12 12:05:25,241:INFO:Set up simple imputation.
2024-06-12 12:05:25,263:INFO:Set up encoding of ordinal features.
2024-06-12 12:05:25,276:INFO:Set up encoding of categorical features.
2024-06-12 12:05:25,276:INFO:Set up PCA.
2024-06-12 12:05:25,641:INFO:Finished creating preprocessing pipeline.
2024-06-12 12:05:25,675:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 12:05:25,675:INFO:Creating final display dataframe.
2024-06-12 12:05:25,808:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                          PCA              True
17                   PCA method            linear
18               PCA components              None
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              93b5
2024-06-12 12:05:25,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:05:25,961:INFO:setup() successfully completed in 1.4s...............
2024-06-12 12:05:26,077:INFO:Initializing create_model()
2024-06-12 12:05:26,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:05:26,077:INFO:Checking exceptions
2024-06-12 12:05:26,094:INFO:Importing libraries
2024-06-12 12:05:26,094:INFO:Copying training dataset
2024-06-12 12:05:26,111:INFO:Defining folds
2024-06-12 12:05:26,111:INFO:Declaring metric variables
2024-06-12 12:05:26,118:INFO:Importing untrained model
2024-06-12 12:05:26,121:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:05:26,127:INFO:Starting cross validation
2024-06-12 12:05:26,131:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:05:28,251:INFO:Calculating mean and std
2024-06-12 12:05:28,251:INFO:Creating metrics dataframe
2024-06-12 12:05:28,259:INFO:Finalizing model
2024-06-12 12:05:28,658:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:05:28,658:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002502 seconds.
2024-06-12 12:05:28,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:05:28,658:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:05:28,658:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:05:28,658:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:05:28,658:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:05:28,817:INFO:Uploading results into container
2024-06-12 12:05:28,818:INFO:Uploading model into container now
2024-06-12 12:05:28,828:INFO:_master_model_container: 1
2024-06-12 12:05:28,828:INFO:_display_container: 2
2024-06-12 12:05:28,829:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:05:28,829:INFO:create_model() successfully completed......................................
2024-06-12 12:05:28,917:INFO:Initializing tune_model()
2024-06-12 12:05:28,917:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 12:05:28,917:INFO:Checking exceptions
2024-06-12 12:05:28,952:INFO:Copying training dataset
2024-06-12 12:05:28,967:INFO:Checking base model
2024-06-12 12:05:28,968:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 12:05:28,971:INFO:Declaring metric variables
2024-06-12 12:05:28,975:INFO:Defining Hyperparameters
2024-06-12 12:05:29,052:INFO:Tuning with n_jobs=-1
2024-06-12 12:05:29,053:INFO:Initializing RandomizedSearchCV
2024-06-12 12:05:54,568:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-12 12:05:54,568:INFO:Hyperparameter search completed
2024-06-12 12:05:54,568:INFO:SubProcess create_model() called ==================================
2024-06-12 12:05:54,568:INFO:Initializing create_model()
2024-06-12 12:05:54,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C42DF5EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-12 12:05:54,568:INFO:Checking exceptions
2024-06-12 12:05:54,568:INFO:Importing libraries
2024-06-12 12:05:54,568:INFO:Copying training dataset
2024-06-12 12:05:54,597:INFO:Defining folds
2024-06-12 12:05:54,597:INFO:Declaring metric variables
2024-06-12 12:05:54,612:INFO:Importing untrained model
2024-06-12 12:05:54,612:INFO:Declaring custom model
2024-06-12 12:05:54,614:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:05:54,629:INFO:Starting cross validation
2024-06-12 12:05:54,633:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:05:58,832:INFO:Calculating mean and std
2024-06-12 12:05:58,832:INFO:Creating metrics dataframe
2024-06-12 12:05:58,832:INFO:Finalizing model
2024-06-12 12:05:59,178:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:05:59,178:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:05:59,178:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:05:59,225:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:05:59,225:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:05:59,225:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:05:59,225:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:05:59,225:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003443 seconds.
2024-06-12 12:05:59,225:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:05:59,225:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:05:59,225:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:05:59,225:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:05:59,225:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:05:59,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:05:59,767:INFO:Uploading results into container
2024-06-12 12:05:59,769:INFO:Uploading model into container now
2024-06-12 12:05:59,769:INFO:_master_model_container: 2
2024-06-12 12:05:59,769:INFO:_display_container: 3
2024-06-12 12:05:59,769:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:05:59,769:INFO:create_model() successfully completed......................................
2024-06-12 12:05:59,861:INFO:SubProcess create_model() end ==================================
2024-06-12 12:05:59,861:INFO:choose_better activated
2024-06-12 12:05:59,863:INFO:SubProcess create_model() called ==================================
2024-06-12 12:05:59,864:INFO:Initializing create_model()
2024-06-12 12:05:59,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:05:59,864:INFO:Checking exceptions
2024-06-12 12:05:59,866:INFO:Importing libraries
2024-06-12 12:05:59,866:INFO:Copying training dataset
2024-06-12 12:05:59,881:INFO:Defining folds
2024-06-12 12:05:59,881:INFO:Declaring metric variables
2024-06-12 12:05:59,881:INFO:Importing untrained model
2024-06-12 12:05:59,881:INFO:Declaring custom model
2024-06-12 12:05:59,882:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:05:59,882:INFO:Starting cross validation
2024-06-12 12:05:59,883:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:06:01,807:INFO:Calculating mean and std
2024-06-12 12:06:01,808:INFO:Creating metrics dataframe
2024-06-12 12:06:01,810:INFO:Finalizing model
2024-06-12 12:06:02,173:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:06:02,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003125 seconds.
2024-06-12 12:06:02,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:06:02,177:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:06:02,179:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:06:02,179:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:06:02,179:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:06:02,344:INFO:Uploading results into container
2024-06-12 12:06:02,344:INFO:Uploading model into container now
2024-06-12 12:06:02,344:INFO:_master_model_container: 3
2024-06-12 12:06:02,344:INFO:_display_container: 4
2024-06-12 12:06:02,344:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:06:02,344:INFO:create_model() successfully completed......................................
2024-06-12 12:06:02,438:INFO:SubProcess create_model() end ==================================
2024-06-12 12:06:02,438:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1137
2024-06-12 12:06:02,438:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1296
2024-06-12 12:06:02,438:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 12:06:02,438:INFO:choose_better completed
2024-06-12 12:06:02,454:INFO:_master_model_container: 3
2024-06-12 12:06:02,454:INFO:_display_container: 3
2024-06-12 12:06:02,454:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:06:02,454:INFO:tune_model() successfully completed......................................
2024-06-12 12:06:02,549:INFO:Initializing plot_model()
2024-06-12 12:06:02,549:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:06:02,549:INFO:Checking exceptions
2024-06-12 12:06:02,559:INFO:Preloading libraries
2024-06-12 12:06:02,595:INFO:Copying training dataset
2024-06-12 12:06:02,595:INFO:Plot type: auc
2024-06-12 12:06:02,747:INFO:Fitting Model
2024-06-12 12:06:02,747:INFO:Scoring test/hold-out set
2024-06-12 12:06:02,763:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:02,763:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:02,763:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:02,814:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:02,814:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:02,814:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:03,093:INFO:Visual Rendered Successfully
2024-06-12 12:06:03,163:INFO:plot_model() successfully completed......................................
2024-06-12 12:06:03,191:INFO:Initializing plot_model()
2024-06-12 12:06:03,191:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:06:03,191:INFO:Checking exceptions
2024-06-12 12:06:03,203:INFO:Preloading libraries
2024-06-12 12:06:03,236:INFO:Copying training dataset
2024-06-12 12:06:03,236:INFO:Plot type: confusion_matrix
2024-06-12 12:06:03,411:INFO:Fitting Model
2024-06-12 12:06:03,411:INFO:Scoring test/hold-out set
2024-06-12 12:06:03,411:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:03,411:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:03,411:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:03,470:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:03,471:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:03,471:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:03,672:INFO:Visual Rendered Successfully
2024-06-12 12:06:03,756:INFO:plot_model() successfully completed......................................
2024-06-12 12:06:03,771:INFO:Initializing finalize_model()
2024-06-12 12:06:03,771:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 12:06:03,771:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:06:03,780:INFO:Initializing create_model()
2024-06-12 12:06:03,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:06:03,780:INFO:Checking exceptions
2024-06-12 12:06:03,780:INFO:Importing libraries
2024-06-12 12:06:03,780:INFO:Copying training dataset
2024-06-12 12:06:03,780:INFO:Defining folds
2024-06-12 12:06:03,780:INFO:Declaring metric variables
2024-06-12 12:06:03,780:INFO:Importing untrained model
2024-06-12 12:06:03,780:INFO:Declaring custom model
2024-06-12 12:06:03,780:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:06:03,780:INFO:Cross validation set to False
2024-06-12 12:06:03,780:INFO:Fitting Model
2024-06-12 12:06:04,197:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:04,197:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:04,197:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:04,259:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:04,259:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:04,259:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:04,259:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 12:06:04,259:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003128 seconds.
2024-06-12 12:06:04,259:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:06:04,259:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:06:04,259:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 12:06:04,259:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 12:06:04,259:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 12:06:04,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:04,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-12 12:06:05,026:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 12:06:05,026:INFO:create_model() successfully completed......................................
2024-06-12 12:06:05,095:INFO:_master_model_container: 3
2024-06-12 12:06:05,095:INFO:_display_container: 3
2024-06-12 12:06:05,126:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 12:06:05,126:INFO:finalize_model() successfully completed......................................
2024-06-12 12:06:05,236:INFO:Initializing plot_model()
2024-06-12 12:06:05,236:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:06:05,236:INFO:Checking exceptions
2024-06-12 12:06:05,252:INFO:Preloading libraries
2024-06-12 12:06:05,282:INFO:Copying training dataset
2024-06-12 12:06:05,282:INFO:Plot type: auc
2024-06-12 12:06:05,446:INFO:Fitting Model
2024-06-12 12:06:05,446:INFO:Scoring test/hold-out set
2024-06-12 12:06:05,446:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:05,446:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:05,446:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:05,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:05,510:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:05,510:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:05,821:INFO:Visual Rendered Successfully
2024-06-12 12:06:05,899:INFO:plot_model() successfully completed......................................
2024-06-12 12:06:05,935:INFO:Initializing plot_model()
2024-06-12 12:06:05,935:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:06:05,935:INFO:Checking exceptions
2024-06-12 12:06:05,950:INFO:Preloading libraries
2024-06-12 12:06:05,983:INFO:Copying training dataset
2024-06-12 12:06:05,983:INFO:Plot type: confusion_matrix
2024-06-12 12:06:06,131:INFO:Fitting Model
2024-06-12 12:06:06,131:INFO:Scoring test/hold-out set
2024-06-12 12:06:06,131:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:06,131:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:06,131:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:06,193:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-12 12:06:06,193:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-12 12:06:06,193:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-12 12:06:06,385:INFO:Visual Rendered Successfully
2024-06-12 12:06:06,457:INFO:plot_model() successfully completed......................................
2024-06-12 12:06:06,505:INFO:Initializing predict_model()
2024-06-12 12:06:06,505:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42FBFBA10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C4310EB9C0>)
2024-06-12 12:06:06,505:INFO:Checking exceptions
2024-06-12 12:06:06,505:INFO:Preloading libraries
2024-06-12 12:06:06,505:INFO:Set up data.
2024-06-12 12:06:06,891:INFO:Set up index.
2024-06-12 12:11:23,066:INFO:PyCaret ClassificationExperiment
2024-06-12 12:11:23,066:INFO:Logging name: clf-default-name
2024-06-12 12:11:23,066:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 12:11:23,066:INFO:version 3.3.2
2024-06-12 12:11:23,066:INFO:Initializing setup()
2024-06-12 12:11:23,066:INFO:self.USI: 3279
2024-06-12 12:11:23,066:INFO:self._variable_keys: {'X_train', 'target_param', 'idx', 'pipeline', 'exp_name_log', 'n_jobs_param', 'fold_generator', 'fix_imbalance', 'seed', '_available_plots', 'exp_id', 'gpu_n_jobs_param', 'log_plots_param', 'html_param', '_ml_usecase', 'y_train', 'data', 'memory', 'USI', 'X_test', 'y', 'is_multiclass', 'gpu_param', 'y_test', 'X', 'fold_shuffle_param', 'fold_groups_param', 'logging_param'}
2024-06-12 12:11:23,066:INFO:Checking environment
2024-06-12 12:11:23,066:INFO:python_version: 3.11.9
2024-06-12 12:11:23,066:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-12 12:11:23,066:INFO:machine: AMD64
2024-06-12 12:11:23,066:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 12:11:23,066:INFO:Memory: svmem(total=34056318976, available=26382270464, percent=22.5, used=7674048512, free=26382270464)
2024-06-12 12:11:23,066:INFO:Physical Core: 6
2024-06-12 12:11:23,066:INFO:Logical Core: 12
2024-06-12 12:11:23,066:INFO:Checking libraries
2024-06-12 12:11:23,066:INFO:System:
2024-06-12 12:11:23,066:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-12 12:11:23,066:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-12 12:11:23,066:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 12:11:23,066:INFO:PyCaret required dependencies:
2024-06-12 12:11:23,066:INFO:                 pip: 24.0
2024-06-12 12:11:23,066:INFO:          setuptools: 69.5.1
2024-06-12 12:11:23,066:INFO:             pycaret: 3.3.2
2024-06-12 12:11:23,066:INFO:             IPython: 8.25.0
2024-06-12 12:11:23,066:INFO:          ipywidgets: 8.1.3
2024-06-12 12:11:23,066:INFO:                tqdm: 4.66.4
2024-06-12 12:11:23,066:INFO:               numpy: 1.26.4
2024-06-12 12:11:23,066:INFO:              pandas: 2.1.4
2024-06-12 12:11:23,066:INFO:              jinja2: 3.1.4
2024-06-12 12:11:23,066:INFO:               scipy: 1.11.4
2024-06-12 12:11:23,066:INFO:              joblib: 1.3.2
2024-06-12 12:11:23,066:INFO:             sklearn: 1.4.2
2024-06-12 12:11:23,066:INFO:                pyod: 2.0.0
2024-06-12 12:11:23,066:INFO:            imblearn: 0.12.3
2024-06-12 12:11:23,066:INFO:   category_encoders: 2.6.3
2024-06-12 12:11:23,066:INFO:            lightgbm: 4.3.0
2024-06-12 12:11:23,066:INFO:               numba: 0.59.1
2024-06-12 12:11:23,066:INFO:            requests: 2.32.3
2024-06-12 12:11:23,066:INFO:          matplotlib: 3.7.5
2024-06-12 12:11:23,066:INFO:          scikitplot: 0.3.7
2024-06-12 12:11:23,066:INFO:         yellowbrick: 1.5
2024-06-12 12:11:23,066:INFO:              plotly: 5.22.0
2024-06-12 12:11:23,066:INFO:    plotly-resampler: Not installed
2024-06-12 12:11:23,066:INFO:             kaleido: 0.2.1
2024-06-12 12:11:23,066:INFO:           schemdraw: 0.15
2024-06-12 12:11:23,066:INFO:         statsmodels: 0.14.2
2024-06-12 12:11:23,066:INFO:              sktime: 0.26.0
2024-06-12 12:11:23,066:INFO:               tbats: 1.1.3
2024-06-12 12:11:23,066:INFO:            pmdarima: 2.0.4
2024-06-12 12:11:23,066:INFO:              psutil: 5.9.8
2024-06-12 12:11:23,066:INFO:          markupsafe: 2.1.5
2024-06-12 12:11:23,066:INFO:             pickle5: Not installed
2024-06-12 12:11:23,066:INFO:         cloudpickle: 3.0.0
2024-06-12 12:11:23,066:INFO:         deprecation: 2.1.0
2024-06-12 12:11:23,066:INFO:              xxhash: 3.4.1
2024-06-12 12:11:23,066:INFO:           wurlitzer: Not installed
2024-06-12 12:11:23,066:INFO:PyCaret optional dependencies:
2024-06-12 12:11:23,066:INFO:                shap: Not installed
2024-06-12 12:11:23,066:INFO:           interpret: Not installed
2024-06-12 12:11:23,066:INFO:                umap: Not installed
2024-06-12 12:11:23,066:INFO:     ydata_profiling: Not installed
2024-06-12 12:11:23,066:INFO:  explainerdashboard: Not installed
2024-06-12 12:11:23,066:INFO:             autoviz: Not installed
2024-06-12 12:11:23,066:INFO:           fairlearn: Not installed
2024-06-12 12:11:23,066:INFO:          deepchecks: Not installed
2024-06-12 12:11:23,066:INFO:             xgboost: Not installed
2024-06-12 12:11:23,066:INFO:            catboost: Not installed
2024-06-12 12:11:23,066:INFO:              kmodes: Not installed
2024-06-12 12:11:23,066:INFO:             mlxtend: Not installed
2024-06-12 12:11:23,066:INFO:       statsforecast: Not installed
2024-06-12 12:11:23,066:INFO:        tune_sklearn: Not installed
2024-06-12 12:11:23,066:INFO:                 ray: Not installed
2024-06-12 12:11:23,066:INFO:            hyperopt: Not installed
2024-06-12 12:11:23,066:INFO:              optuna: Not installed
2024-06-12 12:11:23,066:INFO:               skopt: Not installed
2024-06-12 12:11:23,066:INFO:              mlflow: Not installed
2024-06-12 12:11:23,066:INFO:              gradio: Not installed
2024-06-12 12:11:23,066:INFO:             fastapi: Not installed
2024-06-12 12:11:23,066:INFO:             uvicorn: Not installed
2024-06-12 12:11:23,066:INFO:              m2cgen: Not installed
2024-06-12 12:11:23,066:INFO:           evidently: Not installed
2024-06-12 12:11:23,066:INFO:               fugue: Not installed
2024-06-12 12:11:23,066:INFO:           streamlit: 1.35.0
2024-06-12 12:11:23,066:INFO:             prophet: Not installed
2024-06-12 12:11:23,066:INFO:None
2024-06-12 12:11:23,066:INFO:Set up data.
2024-06-12 12:11:23,117:INFO:Set up folding strategy.
2024-06-12 12:11:23,117:INFO:Set up train/test split.
2024-06-12 12:11:23,141:INFO:Set up index.
2024-06-12 12:11:23,142:INFO:Assigning column types.
2024-06-12 12:11:23,151:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 12:11:23,193:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 12:11:23,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:11:23,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 12:11:23,271:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:11:23,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,301:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 12:11:23,346:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:11:23,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,429:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 12:11:23,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,460:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 12:11:23,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:23,599:INFO:Preparing preprocessing pipeline...
2024-06-12 12:11:23,616:INFO:Set up simple imputation.
2024-06-12 12:11:23,616:INFO:Set up encoding of ordinal features.
2024-06-12 12:11:23,632:INFO:Set up encoding of categorical features.
2024-06-12 12:11:23,632:INFO:Set up feature normalization.
2024-06-12 12:11:23,632:INFO:Set up PCA.
2024-06-12 12:11:24,068:INFO:Finished creating preprocessing pipeline.
2024-06-12 12:11:24,099:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-12 12:11:24,099:INFO:Creating final display dataframe.
2024-06-12 12:11:24,266:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            robust
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              3279
2024-06-12 12:11:24,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:24,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:24,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:24,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 12:11:24,416:INFO:setup() successfully completed in 1.45s...............
2024-06-12 12:11:24,517:INFO:Initializing create_model()
2024-06-12 12:11:24,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:11:24,518:INFO:Checking exceptions
2024-06-12 12:11:24,532:INFO:Importing libraries
2024-06-12 12:11:24,532:INFO:Copying training dataset
2024-06-12 12:11:24,550:INFO:Defining folds
2024-06-12 12:11:24,551:INFO:Declaring metric variables
2024-06-12 12:11:24,554:INFO:Importing untrained model
2024-06-12 12:11:24,557:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:11:24,563:INFO:Starting cross validation
2024-06-12 12:11:24,565:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:11:30,171:INFO:Calculating mean and std
2024-06-12 12:11:30,171:INFO:Creating metrics dataframe
2024-06-12 12:11:30,176:INFO:Finalizing model
2024-06-12 12:11:30,575:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:11:30,575:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002534 seconds.
2024-06-12 12:11:30,575:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:11:30,575:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:11:30,575:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:11:30,575:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:11:30,575:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:11:30,744:INFO:Uploading results into container
2024-06-12 12:11:30,745:INFO:Uploading model into container now
2024-06-12 12:11:30,745:INFO:_master_model_container: 1
2024-06-12 12:11:30,745:INFO:_display_container: 2
2024-06-12 12:11:30,745:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:11:30,745:INFO:create_model() successfully completed......................................
2024-06-12 12:11:30,870:INFO:Initializing tune_model()
2024-06-12 12:11:30,870:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-12 12:11:30,870:INFO:Checking exceptions
2024-06-12 12:11:30,895:INFO:Copying training dataset
2024-06-12 12:11:30,898:INFO:Checking base model
2024-06-12 12:11:30,898:INFO:Base model : Light Gradient Boosting Machine
2024-06-12 12:11:30,898:INFO:Declaring metric variables
2024-06-12 12:11:30,911:INFO:Defining Hyperparameters
2024-06-12 12:11:30,988:INFO:Tuning with n_jobs=-1
2024-06-12 12:11:30,990:INFO:Initializing RandomizedSearchCV
2024-06-12 12:12:07,757:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-12 12:12:07,757:INFO:Hyperparameter search completed
2024-06-12 12:12:07,757:INFO:SubProcess create_model() called ==================================
2024-06-12 12:12:07,757:INFO:Initializing create_model()
2024-06-12 12:12:07,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C47A601390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-12 12:12:07,757:INFO:Checking exceptions
2024-06-12 12:12:07,757:INFO:Importing libraries
2024-06-12 12:12:07,757:INFO:Copying training dataset
2024-06-12 12:12:07,790:INFO:Defining folds
2024-06-12 12:12:07,790:INFO:Declaring metric variables
2024-06-12 12:12:07,790:INFO:Importing untrained model
2024-06-12 12:12:07,790:INFO:Declaring custom model
2024-06-12 12:12:07,790:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:12:07,807:INFO:Starting cross validation
2024-06-12 12:12:07,807:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:12:11,400:INFO:Calculating mean and std
2024-06-12 12:12:11,400:INFO:Creating metrics dataframe
2024-06-12 12:12:11,400:INFO:Finalizing model
2024-06-12 12:12:11,809:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:11,809:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:11,809:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:11,856:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:11,856:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:11,856:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:11,856:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:12:11,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002575 seconds.
2024-06-12 12:12:11,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:12:11,856:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:12:11,856:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:12:11,856:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:12:11,856:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:12:12,235:INFO:Uploading results into container
2024-06-12 12:12:12,236:INFO:Uploading model into container now
2024-06-12 12:12:12,237:INFO:_master_model_container: 2
2024-06-12 12:12:12,237:INFO:_display_container: 3
2024-06-12 12:12:12,238:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:12:12,239:INFO:create_model() successfully completed......................................
2024-06-12 12:12:12,328:INFO:SubProcess create_model() end ==================================
2024-06-12 12:12:12,328:INFO:choose_better activated
2024-06-12 12:12:12,340:INFO:SubProcess create_model() called ==================================
2024-06-12 12:12:12,342:INFO:Initializing create_model()
2024-06-12 12:12:12,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:12:12,342:INFO:Checking exceptions
2024-06-12 12:12:12,344:INFO:Importing libraries
2024-06-12 12:12:12,344:INFO:Copying training dataset
2024-06-12 12:12:12,360:INFO:Defining folds
2024-06-12 12:12:12,360:INFO:Declaring metric variables
2024-06-12 12:12:12,360:INFO:Importing untrained model
2024-06-12 12:12:12,360:INFO:Declaring custom model
2024-06-12 12:12:12,361:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:12:12,361:INFO:Starting cross validation
2024-06-12 12:12:12,363:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 12:12:14,334:INFO:Calculating mean and std
2024-06-12 12:12:14,335:INFO:Creating metrics dataframe
2024-06-12 12:12:14,337:INFO:Finalizing model
2024-06-12 12:12:14,774:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-12 12:12:14,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002845 seconds.
2024-06-12 12:12:14,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:12:14,777:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:12:14,778:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-12 12:12:14,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-12 12:12:14,779:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-12 12:12:14,990:INFO:Uploading results into container
2024-06-12 12:12:14,990:INFO:Uploading model into container now
2024-06-12 12:12:14,990:INFO:_master_model_container: 3
2024-06-12 12:12:14,990:INFO:_display_container: 4
2024-06-12 12:12:14,990:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:12:14,990:INFO:create_model() successfully completed......................................
2024-06-12 12:12:15,072:INFO:SubProcess create_model() end ==================================
2024-06-12 12:12:15,072:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1022
2024-06-12 12:12:15,072:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1159
2024-06-12 12:12:15,072:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-12 12:12:15,072:INFO:choose_better completed
2024-06-12 12:12:15,088:INFO:_master_model_container: 3
2024-06-12 12:12:15,088:INFO:_display_container: 3
2024-06-12 12:12:15,088:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:12:15,088:INFO:tune_model() successfully completed......................................
2024-06-12 12:12:15,208:INFO:Initializing plot_model()
2024-06-12 12:12:15,208:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:12:15,209:INFO:Checking exceptions
2024-06-12 12:12:15,210:INFO:Preloading libraries
2024-06-12 12:12:15,230:INFO:Copying training dataset
2024-06-12 12:12:15,230:INFO:Plot type: auc
2024-06-12 12:12:15,406:INFO:Fitting Model
2024-06-12 12:12:15,406:INFO:Scoring test/hold-out set
2024-06-12 12:12:15,406:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:15,406:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:15,406:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:15,438:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:15,438:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:15,438:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:15,706:INFO:Visual Rendered Successfully
2024-06-12 12:12:15,790:INFO:plot_model() successfully completed......................................
2024-06-12 12:12:15,809:INFO:Initializing plot_model()
2024-06-12 12:12:15,809:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:12:15,809:INFO:Checking exceptions
2024-06-12 12:12:15,819:INFO:Preloading libraries
2024-06-12 12:12:15,823:INFO:Copying training dataset
2024-06-12 12:12:15,823:INFO:Plot type: confusion_matrix
2024-06-12 12:12:16,002:INFO:Fitting Model
2024-06-12 12:12:16,002:INFO:Scoring test/hold-out set
2024-06-12 12:12:16,004:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:16,004:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:16,004:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:16,023:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:16,023:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:16,023:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:16,184:INFO:Visual Rendered Successfully
2024-06-12 12:12:16,261:INFO:plot_model() successfully completed......................................
2024-06-12 12:12:16,269:INFO:Initializing finalize_model()
2024-06-12 12:12:16,269:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 12:12:16,269:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-12 12:12:16,285:INFO:Initializing create_model()
2024-06-12 12:12:16,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 12:12:16,285:INFO:Checking exceptions
2024-06-12 12:12:16,285:INFO:Importing libraries
2024-06-12 12:12:16,285:INFO:Copying training dataset
2024-06-12 12:12:16,285:INFO:Defining folds
2024-06-12 12:12:16,285:INFO:Declaring metric variables
2024-06-12 12:12:16,285:INFO:Importing untrained model
2024-06-12 12:12:16,285:INFO:Declaring custom model
2024-06-12 12:12:16,285:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-12 12:12:16,285:INFO:Cross validation set to False
2024-06-12 12:12:16,285:INFO:Fitting Model
2024-06-12 12:12:16,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:16,727:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:16,727:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:16,789:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:16,790:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:16,790:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:16,790:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-12 12:12:16,794:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003099 seconds.
2024-06-12 12:12:16,794:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-12 12:12:16,794:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-12 12:12:16,794:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-12 12:12:16,794:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-12 12:12:16,794:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-12 12:12:17,242:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 12:12:17,242:INFO:create_model() successfully completed......................................
2024-06-12 12:12:17,339:INFO:_master_model_container: 3
2024-06-12 12:12:17,339:INFO:_display_container: 3
2024-06-12 12:12:17,358:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-12 12:12:17,358:INFO:finalize_model() successfully completed......................................
2024-06-12 12:12:17,493:INFO:Initializing plot_model()
2024-06-12 12:12:17,493:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:12:17,493:INFO:Checking exceptions
2024-06-12 12:12:17,498:INFO:Preloading libraries
2024-06-12 12:12:17,498:INFO:Copying training dataset
2024-06-12 12:12:17,498:INFO:Plot type: auc
2024-06-12 12:12:17,661:INFO:Fitting Model
2024-06-12 12:12:17,661:INFO:Scoring test/hold-out set
2024-06-12 12:12:17,661:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:17,661:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:17,661:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:17,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:17,693:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:17,693:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:17,937:INFO:Visual Rendered Successfully
2024-06-12 12:12:18,010:INFO:plot_model() successfully completed......................................
2024-06-12 12:12:18,070:INFO:Initializing plot_model()
2024-06-12 12:12:18,070:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-12 12:12:18,070:INFO:Checking exceptions
2024-06-12 12:12:18,085:INFO:Preloading libraries
2024-06-12 12:12:18,101:INFO:Copying training dataset
2024-06-12 12:12:18,101:INFO:Plot type: confusion_matrix
2024-06-12 12:12:18,264:INFO:Fitting Model
2024-06-12 12:12:18,264:INFO:Scoring test/hold-out set
2024-06-12 12:12:18,264:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:18,280:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:18,280:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:18,295:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-12 12:12:18,295:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-12 12:12:18,295:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-12 12:12:18,473:INFO:Visual Rendered Successfully
2024-06-12 12:12:18,528:INFO:plot_model() successfully completed......................................
2024-06-12 12:12:18,582:INFO:Initializing predict_model()
2024-06-12 12:12:18,582:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C42E7C9D10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C43128C0E0>)
2024-06-12 12:12:18,582:INFO:Checking exceptions
2024-06-12 12:12:18,582:INFO:Preloading libraries
2024-06-12 12:12:18,582:INFO:Set up data.
2024-06-12 12:12:18,981:INFO:Set up index.
2024-06-12 16:34:07,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:34:07,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:34:07,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:34:07,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:41:06,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:41:06,648:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:41:06,648:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:41:06,648:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:43:14,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:43:14,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:43:14,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:43:14,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 16:46:15,384:WARNING:C:\Users\Marcelo\Documents\EBAC-Exercicios\Exerccio_Cientista_de_dados_Mdulo38\Projeto\script.py:216: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots(figsize=(5,4))

2024-06-13 11:44:55,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 11:44:55,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 11:44:55,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 11:44:55,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 11:44:56,354:INFO:PyCaret ClassificationExperiment
2024-06-13 11:44:56,354:INFO:Logging name: clf-default-name
2024-06-13 11:44:56,354:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-13 11:44:56,354:INFO:version 3.3.2
2024-06-13 11:44:56,354:INFO:Initializing setup()
2024-06-13 11:44:56,354:INFO:self.USI: 1839
2024-06-13 11:44:56,354:INFO:self._variable_keys: {'n_jobs_param', 'pipeline', 'logging_param', '_ml_usecase', 'X_train', 'target_param', 'is_multiclass', 'seed', 'memory', 'idx', 'fold_shuffle_param', 'fold_groups_param', 'fold_generator', 'fix_imbalance', 'USI', 'y_test', '_available_plots', 'data', 'log_plots_param', 'X_test', 'html_param', 'y_train', 'gpu_n_jobs_param', 'exp_name_log', 'gpu_param', 'X', 'exp_id', 'y'}
2024-06-13 11:44:56,354:INFO:Checking environment
2024-06-13 11:44:56,354:INFO:python_version: 3.11.9
2024-06-13 11:44:56,354:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-13 11:44:56,354:INFO:machine: AMD64
2024-06-13 11:44:56,355:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-13 11:44:56,355:INFO:Memory: svmem(total=34056318976, available=25295114240, percent=25.7, used=8761204736, free=25295114240)
2024-06-13 11:44:56,355:INFO:Physical Core: 6
2024-06-13 11:44:56,355:INFO:Logical Core: 12
2024-06-13 11:44:56,355:INFO:Checking libraries
2024-06-13 11:44:56,355:INFO:System:
2024-06-13 11:44:56,355:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-13 11:44:56,355:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-13 11:44:56,355:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-13 11:44:56,355:INFO:PyCaret required dependencies:
2024-06-13 11:44:56,429:INFO:                 pip: 24.0
2024-06-13 11:44:56,429:INFO:          setuptools: 69.5.1
2024-06-13 11:44:56,429:INFO:             pycaret: 3.3.2
2024-06-13 11:44:56,429:INFO:             IPython: 8.25.0
2024-06-13 11:44:56,429:INFO:          ipywidgets: 8.1.3
2024-06-13 11:44:56,429:INFO:                tqdm: 4.66.4
2024-06-13 11:44:56,429:INFO:               numpy: 1.26.4
2024-06-13 11:44:56,429:INFO:              pandas: 2.1.4
2024-06-13 11:44:56,429:INFO:              jinja2: 3.1.4
2024-06-13 11:44:56,429:INFO:               scipy: 1.11.4
2024-06-13 11:44:56,429:INFO:              joblib: 1.3.2
2024-06-13 11:44:56,429:INFO:             sklearn: 1.4.2
2024-06-13 11:44:56,429:INFO:                pyod: 2.0.0
2024-06-13 11:44:56,429:INFO:            imblearn: 0.12.3
2024-06-13 11:44:56,430:INFO:   category_encoders: 2.6.3
2024-06-13 11:44:56,430:INFO:            lightgbm: 4.3.0
2024-06-13 11:44:56,430:INFO:               numba: 0.59.1
2024-06-13 11:44:56,430:INFO:            requests: 2.32.3
2024-06-13 11:44:56,430:INFO:          matplotlib: 3.7.5
2024-06-13 11:44:56,430:INFO:          scikitplot: 0.3.7
2024-06-13 11:44:56,430:INFO:         yellowbrick: 1.5
2024-06-13 11:44:56,430:INFO:              plotly: 5.22.0
2024-06-13 11:44:56,430:INFO:    plotly-resampler: Not installed
2024-06-13 11:44:56,430:INFO:             kaleido: 0.2.1
2024-06-13 11:44:56,430:INFO:           schemdraw: 0.15
2024-06-13 11:44:56,430:INFO:         statsmodels: 0.14.2
2024-06-13 11:44:56,430:INFO:              sktime: 0.26.0
2024-06-13 11:44:56,430:INFO:               tbats: 1.1.3
2024-06-13 11:44:56,430:INFO:            pmdarima: 2.0.4
2024-06-13 11:44:56,430:INFO:              psutil: 5.9.8
2024-06-13 11:44:56,430:INFO:          markupsafe: 2.1.5
2024-06-13 11:44:56,430:INFO:             pickle5: Not installed
2024-06-13 11:44:56,430:INFO:         cloudpickle: 3.0.0
2024-06-13 11:44:56,430:INFO:         deprecation: 2.1.0
2024-06-13 11:44:56,430:INFO:              xxhash: 3.4.1
2024-06-13 11:44:56,430:INFO:           wurlitzer: Not installed
2024-06-13 11:44:56,430:INFO:PyCaret optional dependencies:
2024-06-13 11:44:56,440:INFO:                shap: Not installed
2024-06-13 11:44:56,441:INFO:           interpret: Not installed
2024-06-13 11:44:56,441:INFO:                umap: Not installed
2024-06-13 11:44:56,441:INFO:     ydata_profiling: Not installed
2024-06-13 11:44:56,441:INFO:  explainerdashboard: Not installed
2024-06-13 11:44:56,441:INFO:             autoviz: Not installed
2024-06-13 11:44:56,441:INFO:           fairlearn: Not installed
2024-06-13 11:44:56,441:INFO:          deepchecks: Not installed
2024-06-13 11:44:56,441:INFO:             xgboost: Not installed
2024-06-13 11:44:56,441:INFO:            catboost: Not installed
2024-06-13 11:44:56,441:INFO:              kmodes: Not installed
2024-06-13 11:44:56,441:INFO:             mlxtend: Not installed
2024-06-13 11:44:56,441:INFO:       statsforecast: Not installed
2024-06-13 11:44:56,441:INFO:        tune_sklearn: Not installed
2024-06-13 11:44:56,441:INFO:                 ray: Not installed
2024-06-13 11:44:56,441:INFO:            hyperopt: Not installed
2024-06-13 11:44:56,441:INFO:              optuna: Not installed
2024-06-13 11:44:56,441:INFO:               skopt: Not installed
2024-06-13 11:44:56,441:INFO:              mlflow: Not installed
2024-06-13 11:44:56,442:INFO:              gradio: Not installed
2024-06-13 11:44:56,442:INFO:             fastapi: Not installed
2024-06-13 11:44:56,442:INFO:             uvicorn: Not installed
2024-06-13 11:44:56,442:INFO:              m2cgen: Not installed
2024-06-13 11:44:56,442:INFO:           evidently: Not installed
2024-06-13 11:44:56,442:INFO:               fugue: Not installed
2024-06-13 11:44:56,442:INFO:           streamlit: 1.35.0
2024-06-13 11:44:56,442:INFO:             prophet: Not installed
2024-06-13 11:44:56,442:INFO:None
2024-06-13 11:44:56,442:INFO:Set up data.
2024-06-13 11:44:56,480:INFO:Set up folding strategy.
2024-06-13 11:44:56,480:INFO:Set up train/test split.
2024-06-13 11:44:56,505:INFO:Set up index.
2024-06-13 11:44:56,507:INFO:Assigning column types.
2024-06-13 11:44:56,516:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-13 11:44:56,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 11:44:56,562:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:44:56,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,641:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 11:44:56,642:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:44:56,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,669:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-13 11:44:56,711:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:44:56,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,780:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:44:56,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,808:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-13 11:44:56,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:56,948:INFO:Preparing preprocessing pipeline...
2024-06-13 11:44:56,950:INFO:Set up simple imputation.
2024-06-13 11:44:56,961:INFO:Set up encoding of ordinal features.
2024-06-13 11:44:56,970:INFO:Set up encoding of categorical features.
2024-06-13 11:44:56,970:INFO:Set up feature normalization.
2024-06-13 11:44:56,970:INFO:Set up PCA.
2024-06-13 11:44:57,362:INFO:Finished creating preprocessing pipeline.
2024-06-13 11:44:57,395:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-13 11:44:57,395:INFO:Creating final display dataframe.
2024-06-13 11:44:57,538:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            robust
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              1839
2024-06-13 11:44:57,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:57,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:57,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:57,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:44:57,719:INFO:setup() successfully completed in 1.55s...............
2024-06-13 11:44:57,736:INFO:Initializing create_model()
2024-06-13 11:44:57,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:44:57,736:INFO:Checking exceptions
2024-06-13 11:44:57,752:INFO:Importing libraries
2024-06-13 11:44:57,753:INFO:Copying training dataset
2024-06-13 11:44:57,769:INFO:Defining folds
2024-06-13 11:44:57,770:INFO:Declaring metric variables
2024-06-13 11:44:57,773:INFO:Importing untrained model
2024-06-13 11:44:57,776:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:44:57,782:INFO:Starting cross validation
2024-06-13 11:44:57,785:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:45:03,877:INFO:Calculating mean and std
2024-06-13 11:45:03,882:INFO:Creating metrics dataframe
2024-06-13 11:45:03,895:INFO:Finalizing model
2024-06-13 11:45:04,389:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-13 11:45:04,394:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004142 seconds.
2024-06-13 11:45:04,394:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:45:04,395:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:45:04,395:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-13 11:45:04,396:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-13 11:45:04,396:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-13 11:45:04,634:INFO:Uploading results into container
2024-06-13 11:45:04,635:INFO:Uploading model into container now
2024-06-13 11:45:04,653:INFO:_master_model_container: 1
2024-06-13 11:45:04,654:INFO:_display_container: 2
2024-06-13 11:45:04,655:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:45:04,655:INFO:create_model() successfully completed......................................
2024-06-13 11:45:04,805:INFO:Initializing tune_model()
2024-06-13 11:45:04,805:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-13 11:45:04,805:INFO:Checking exceptions
2024-06-13 11:45:04,833:INFO:Copying training dataset
2024-06-13 11:45:04,845:INFO:Checking base model
2024-06-13 11:45:04,845:INFO:Base model : Light Gradient Boosting Machine
2024-06-13 11:45:04,849:INFO:Declaring metric variables
2024-06-13 11:45:04,851:INFO:Defining Hyperparameters
2024-06-13 11:45:04,922:INFO:Tuning with n_jobs=-1
2024-06-13 11:45:04,923:INFO:Initializing RandomizedSearchCV
2024-06-13 11:45:45,074:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-06-13 11:45:45,076:INFO:Hyperparameter search completed
2024-06-13 11:45:45,076:INFO:SubProcess create_model() called ==================================
2024-06-13 11:45:45,078:INFO:Initializing create_model()
2024-06-13 11:45:45,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AD17D137D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-06-13 11:45:45,078:INFO:Checking exceptions
2024-06-13 11:45:45,078:INFO:Importing libraries
2024-06-13 11:45:45,079:INFO:Copying training dataset
2024-06-13 11:45:45,115:INFO:Defining folds
2024-06-13 11:45:45,115:INFO:Declaring metric variables
2024-06-13 11:45:45,121:INFO:Importing untrained model
2024-06-13 11:45:45,122:INFO:Declaring custom model
2024-06-13 11:45:45,134:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:45:45,153:INFO:Starting cross validation
2024-06-13 11:45:45,160:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:45:49,592:INFO:Calculating mean and std
2024-06-13 11:45:49,594:INFO:Creating metrics dataframe
2024-06-13 11:45:49,602:INFO:Finalizing model
2024-06-13 11:45:50,266:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:50,266:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:50,266:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:50,311:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:50,311:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:50,312:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:50,312:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-13 11:45:50,316:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003180 seconds.
2024-06-13 11:45:50,316:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:45:50,317:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:45:50,318:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-13 11:45:50,320:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-13 11:45:50,320:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-13 11:45:50,744:INFO:Uploading results into container
2024-06-13 11:45:50,745:INFO:Uploading model into container now
2024-06-13 11:45:50,746:INFO:_master_model_container: 2
2024-06-13 11:45:50,746:INFO:_display_container: 3
2024-06-13 11:45:50,747:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:45:50,747:INFO:create_model() successfully completed......................................
2024-06-13 11:45:50,846:INFO:SubProcess create_model() end ==================================
2024-06-13 11:45:50,847:INFO:choose_better activated
2024-06-13 11:45:50,850:INFO:SubProcess create_model() called ==================================
2024-06-13 11:45:50,851:INFO:Initializing create_model()
2024-06-13 11:45:50,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:45:50,851:INFO:Checking exceptions
2024-06-13 11:45:50,853:INFO:Importing libraries
2024-06-13 11:45:50,853:INFO:Copying training dataset
2024-06-13 11:45:50,872:INFO:Defining folds
2024-06-13 11:45:50,872:INFO:Declaring metric variables
2024-06-13 11:45:50,872:INFO:Importing untrained model
2024-06-13 11:45:50,872:INFO:Declaring custom model
2024-06-13 11:45:50,873:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:45:50,873:INFO:Starting cross validation
2024-06-13 11:45:50,875:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:45:53,186:INFO:Calculating mean and std
2024-06-13 11:45:53,187:INFO:Creating metrics dataframe
2024-06-13 11:45:53,190:INFO:Finalizing model
2024-06-13 11:45:53,679:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-13 11:45:53,683:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003188 seconds.
2024-06-13 11:45:53,683:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:45:53,683:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:45:53,684:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-13 11:45:53,685:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-13 11:45:53,685:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-13 11:45:53,886:INFO:Uploading results into container
2024-06-13 11:45:53,887:INFO:Uploading model into container now
2024-06-13 11:45:53,888:INFO:_master_model_container: 3
2024-06-13 11:45:53,888:INFO:_display_container: 4
2024-06-13 11:45:53,888:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:45:53,888:INFO:create_model() successfully completed......................................
2024-06-13 11:45:53,979:INFO:SubProcess create_model() end ==================================
2024-06-13 11:45:53,980:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1022
2024-06-13 11:45:53,981:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.1159
2024-06-13 11:45:53,981:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-13 11:45:53,982:INFO:choose_better completed
2024-06-13 11:45:53,991:INFO:_master_model_container: 3
2024-06-13 11:45:53,992:INFO:_display_container: 3
2024-06-13 11:45:53,992:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:45:53,992:INFO:tune_model() successfully completed......................................
2024-06-13 11:45:54,509:INFO:Initializing plot_model()
2024-06-13 11:45:54,509:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:45:54,510:INFO:Checking exceptions
2024-06-13 11:45:54,522:INFO:Preloading libraries
2024-06-13 11:45:54,541:INFO:Copying training dataset
2024-06-13 11:45:54,542:INFO:Plot type: auc
2024-06-13 11:45:54,742:INFO:Fitting Model
2024-06-13 11:45:54,743:INFO:Scoring test/hold-out set
2024-06-13 11:45:54,745:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:54,745:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:54,745:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:54,788:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:54,788:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:54,788:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:55,108:INFO:Visual Rendered Successfully
2024-06-13 11:45:55,177:INFO:plot_model() successfully completed......................................
2024-06-13 11:45:55,261:INFO:Initializing plot_model()
2024-06-13 11:45:55,261:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:45:55,261:INFO:Checking exceptions
2024-06-13 11:45:55,269:INFO:Preloading libraries
2024-06-13 11:45:55,289:INFO:Copying training dataset
2024-06-13 11:45:55,289:INFO:Plot type: confusion_matrix
2024-06-13 11:45:55,460:INFO:Fitting Model
2024-06-13 11:45:55,460:INFO:Scoring test/hold-out set
2024-06-13 11:45:55,462:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:55,462:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:55,462:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:55,488:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:55,488:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:55,488:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:55,671:INFO:Visual Rendered Successfully
2024-06-13 11:45:55,742:INFO:plot_model() successfully completed......................................
2024-06-13 11:45:55,756:INFO:Initializing finalize_model()
2024-06-13 11:45:55,756:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 11:45:55,756:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:45:55,764:INFO:Initializing create_model()
2024-06-13 11:45:55,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:45:55,765:INFO:Checking exceptions
2024-06-13 11:45:55,766:INFO:Importing libraries
2024-06-13 11:45:55,766:INFO:Copying training dataset
2024-06-13 11:45:55,768:INFO:Defining folds
2024-06-13 11:45:55,768:INFO:Declaring metric variables
2024-06-13 11:45:55,768:INFO:Importing untrained model
2024-06-13 11:45:55,768:INFO:Declaring custom model
2024-06-13 11:45:55,769:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:45:55,771:INFO:Cross validation set to False
2024-06-13 11:45:55,771:INFO:Fitting Model
2024-06-13 11:45:56,257:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:56,257:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:56,257:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:56,333:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:56,333:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:56,334:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:56,334:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-13 11:45:56,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003214 seconds.
2024-06-13 11:45:56,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:45:56,339:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:45:56,341:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-13 11:45:56,342:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-13 11:45:56,343:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-13 11:45:56,846:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 11:45:56,846:INFO:create_model() successfully completed......................................
2024-06-13 11:45:56,929:INFO:_master_model_container: 3
2024-06-13 11:45:56,929:INFO:_display_container: 3
2024-06-13 11:45:56,965:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 11:45:56,965:INFO:finalize_model() successfully completed......................................
2024-06-13 11:45:57,084:INFO:Initializing plot_model()
2024-06-13 11:45:57,084:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:45:57,084:INFO:Checking exceptions
2024-06-13 11:45:57,093:INFO:Preloading libraries
2024-06-13 11:45:57,106:INFO:Copying training dataset
2024-06-13 11:45:57,107:INFO:Plot type: auc
2024-06-13 11:45:57,272:INFO:Fitting Model
2024-06-13 11:45:57,273:INFO:Scoring test/hold-out set
2024-06-13 11:45:57,275:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:57,275:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:57,275:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:57,304:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:57,305:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:57,305:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:57,559:INFO:Visual Rendered Successfully
2024-06-13 11:45:57,646:INFO:plot_model() successfully completed......................................
2024-06-13 11:45:57,692:INFO:Initializing plot_model()
2024-06-13 11:45:57,692:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:45:57,692:INFO:Checking exceptions
2024-06-13 11:45:57,701:INFO:Preloading libraries
2024-06-13 11:45:57,720:INFO:Copying training dataset
2024-06-13 11:45:57,720:INFO:Plot type: confusion_matrix
2024-06-13 11:45:57,888:INFO:Fitting Model
2024-06-13 11:45:57,888:INFO:Scoring test/hold-out set
2024-06-13 11:45:57,890:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:57,890:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:57,890:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:57,920:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:45:57,920:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-06-13 11:45:57,920:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-06-13 11:45:58,088:INFO:Visual Rendered Successfully
2024-06-13 11:45:58,158:INFO:plot_model() successfully completed......................................
2024-06-13 11:45:58,206:INFO:Initializing predict_model()
2024-06-13 11:45:58,206:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD18588C90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=66,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=90, n_jobs=-1, num_leaves=90,
                                objective=None, random_state=123,
                                reg_alpha=0.0005, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AD1A8BAD40>)
2024-06-13 11:45:58,207:INFO:Checking exceptions
2024-06-13 11:45:58,207:INFO:Preloading libraries
2024-06-13 11:45:58,209:INFO:Set up data.
2024-06-13 11:45:58,613:INFO:Set up index.
2024-06-13 11:50:28,820:INFO:PyCaret ClassificationExperiment
2024-06-13 11:50:28,820:INFO:Logging name: clf-default-name
2024-06-13 11:50:28,820:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-13 11:50:28,820:INFO:version 3.3.2
2024-06-13 11:50:28,820:INFO:Initializing setup()
2024-06-13 11:50:28,820:INFO:self.USI: e021
2024-06-13 11:50:28,820:INFO:self._variable_keys: {'n_jobs_param', 'pipeline', 'logging_param', '_ml_usecase', 'X_train', 'target_param', 'is_multiclass', 'seed', 'memory', 'idx', 'fold_shuffle_param', 'fold_groups_param', 'fold_generator', 'fix_imbalance', 'USI', 'y_test', '_available_plots', 'data', 'log_plots_param', 'X_test', 'html_param', 'y_train', 'gpu_n_jobs_param', 'exp_name_log', 'gpu_param', 'X', 'exp_id', 'y'}
2024-06-13 11:50:28,820:INFO:Checking environment
2024-06-13 11:50:28,821:INFO:python_version: 3.11.9
2024-06-13 11:50:28,821:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-13 11:50:28,821:INFO:machine: AMD64
2024-06-13 11:50:28,821:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-13 11:50:28,821:INFO:Memory: svmem(total=34056318976, available=23398912000, percent=31.3, used=10657406976, free=23398912000)
2024-06-13 11:50:28,821:INFO:Physical Core: 6
2024-06-13 11:50:28,821:INFO:Logical Core: 12
2024-06-13 11:50:28,821:INFO:Checking libraries
2024-06-13 11:50:28,821:INFO:System:
2024-06-13 11:50:28,821:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-13 11:50:28,821:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-13 11:50:28,821:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-13 11:50:28,821:INFO:PyCaret required dependencies:
2024-06-13 11:50:28,821:INFO:                 pip: 24.0
2024-06-13 11:50:28,821:INFO:          setuptools: 69.5.1
2024-06-13 11:50:28,821:INFO:             pycaret: 3.3.2
2024-06-13 11:50:28,822:INFO:             IPython: 8.25.0
2024-06-13 11:50:28,822:INFO:          ipywidgets: 8.1.3
2024-06-13 11:50:28,822:INFO:                tqdm: 4.66.4
2024-06-13 11:50:28,822:INFO:               numpy: 1.26.4
2024-06-13 11:50:28,822:INFO:              pandas: 2.1.4
2024-06-13 11:50:28,822:INFO:              jinja2: 3.1.4
2024-06-13 11:50:28,822:INFO:               scipy: 1.11.4
2024-06-13 11:50:28,822:INFO:              joblib: 1.3.2
2024-06-13 11:50:28,822:INFO:             sklearn: 1.4.2
2024-06-13 11:50:28,822:INFO:                pyod: 2.0.0
2024-06-13 11:50:28,822:INFO:            imblearn: 0.12.3
2024-06-13 11:50:28,822:INFO:   category_encoders: 2.6.3
2024-06-13 11:50:28,822:INFO:            lightgbm: 4.3.0
2024-06-13 11:50:28,822:INFO:               numba: 0.59.1
2024-06-13 11:50:28,822:INFO:            requests: 2.32.3
2024-06-13 11:50:28,822:INFO:          matplotlib: 3.7.5
2024-06-13 11:50:28,822:INFO:          scikitplot: 0.3.7
2024-06-13 11:50:28,822:INFO:         yellowbrick: 1.5
2024-06-13 11:50:28,822:INFO:              plotly: 5.22.0
2024-06-13 11:50:28,822:INFO:    plotly-resampler: Not installed
2024-06-13 11:50:28,823:INFO:             kaleido: 0.2.1
2024-06-13 11:50:28,823:INFO:           schemdraw: 0.15
2024-06-13 11:50:28,823:INFO:         statsmodels: 0.14.2
2024-06-13 11:50:28,823:INFO:              sktime: 0.26.0
2024-06-13 11:50:28,823:INFO:               tbats: 1.1.3
2024-06-13 11:50:28,823:INFO:            pmdarima: 2.0.4
2024-06-13 11:50:28,823:INFO:              psutil: 5.9.8
2024-06-13 11:50:28,823:INFO:          markupsafe: 2.1.5
2024-06-13 11:50:28,823:INFO:             pickle5: Not installed
2024-06-13 11:50:28,823:INFO:         cloudpickle: 3.0.0
2024-06-13 11:50:28,823:INFO:         deprecation: 2.1.0
2024-06-13 11:50:28,823:INFO:              xxhash: 3.4.1
2024-06-13 11:50:28,823:INFO:           wurlitzer: Not installed
2024-06-13 11:50:28,823:INFO:PyCaret optional dependencies:
2024-06-13 11:50:28,823:INFO:                shap: Not installed
2024-06-13 11:50:28,823:INFO:           interpret: Not installed
2024-06-13 11:50:28,823:INFO:                umap: Not installed
2024-06-13 11:50:28,823:INFO:     ydata_profiling: Not installed
2024-06-13 11:50:28,823:INFO:  explainerdashboard: Not installed
2024-06-13 11:50:28,823:INFO:             autoviz: Not installed
2024-06-13 11:50:28,823:INFO:           fairlearn: Not installed
2024-06-13 11:50:28,824:INFO:          deepchecks: Not installed
2024-06-13 11:50:28,824:INFO:             xgboost: Not installed
2024-06-13 11:50:28,824:INFO:            catboost: Not installed
2024-06-13 11:50:28,824:INFO:              kmodes: Not installed
2024-06-13 11:50:28,824:INFO:             mlxtend: Not installed
2024-06-13 11:50:28,824:INFO:       statsforecast: Not installed
2024-06-13 11:50:28,824:INFO:        tune_sklearn: Not installed
2024-06-13 11:50:28,824:INFO:                 ray: Not installed
2024-06-13 11:50:28,824:INFO:            hyperopt: Not installed
2024-06-13 11:50:28,824:INFO:              optuna: Not installed
2024-06-13 11:50:28,824:INFO:               skopt: Not installed
2024-06-13 11:50:28,824:INFO:              mlflow: Not installed
2024-06-13 11:50:28,824:INFO:              gradio: Not installed
2024-06-13 11:50:28,824:INFO:             fastapi: Not installed
2024-06-13 11:50:28,824:INFO:             uvicorn: Not installed
2024-06-13 11:50:28,824:INFO:              m2cgen: Not installed
2024-06-13 11:50:28,824:INFO:           evidently: Not installed
2024-06-13 11:50:28,824:INFO:               fugue: Not installed
2024-06-13 11:50:28,825:INFO:           streamlit: 1.35.0
2024-06-13 11:50:28,825:INFO:             prophet: Not installed
2024-06-13 11:50:28,825:INFO:None
2024-06-13 11:50:28,825:INFO:Set up data.
2024-06-13 11:50:28,862:INFO:Set up folding strategy.
2024-06-13 11:50:28,862:INFO:Set up train/test split.
2024-06-13 11:50:28,883:INFO:Set up index.
2024-06-13 11:50:28,885:INFO:Assigning column types.
2024-06-13 11:50:28,894:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-13 11:50:28,938:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 11:50:28,938:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:50:28,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:28,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 11:50:29,011:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:50:29,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,038:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-13 11:50:29,081:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:50:29,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,153:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:50:29,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,181:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-13 11:50:29,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,321:INFO:Preparing preprocessing pipeline...
2024-06-13 11:50:29,323:INFO:Set up simple imputation.
2024-06-13 11:50:29,333:INFO:Set up encoding of ordinal features.
2024-06-13 11:50:29,342:INFO:Set up encoding of categorical features.
2024-06-13 11:50:29,342:INFO:Set up feature normalization.
2024-06-13 11:50:29,342:INFO:Set up PCA.
2024-06-13 11:50:29,684:INFO:Finished creating preprocessing pipeline.
2024-06-13 11:50:29,713:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-13 11:50:29,713:INFO:Creating final display dataframe.
2024-06-13 11:50:29,865:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            minmax
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              e021
2024-06-13 11:50:29,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:29,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:30,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:30,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:50:30,028:INFO:setup() successfully completed in 1.29s...............
2024-06-13 11:50:30,130:INFO:Initializing create_model()
2024-06-13 11:50:30,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:50:30,130:INFO:Checking exceptions
2024-06-13 11:50:30,150:INFO:Importing libraries
2024-06-13 11:50:30,151:INFO:Copying training dataset
2024-06-13 11:50:30,181:INFO:Defining folds
2024-06-13 11:50:30,182:INFO:Declaring metric variables
2024-06-13 11:50:30,188:INFO:Importing untrained model
2024-06-13 11:50:30,192:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:50:30,199:INFO:Starting cross validation
2024-06-13 11:50:30,202:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:50:32,520:INFO:Calculating mean and std
2024-06-13 11:50:32,522:INFO:Creating metrics dataframe
2024-06-13 11:50:32,528:INFO:Finalizing model
2024-06-13 11:50:32,990:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-13 11:50:32,994:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003445 seconds.
2024-06-13 11:50:32,994:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:50:32,995:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:50:32,995:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-13 11:50:32,996:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-13 11:50:32,996:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-13 11:50:33,284:INFO:Uploading results into container
2024-06-13 11:50:33,285:INFO:Uploading model into container now
2024-06-13 11:50:33,298:INFO:_master_model_container: 1
2024-06-13 11:50:33,298:INFO:_display_container: 2
2024-06-13 11:50:33,299:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:50:33,300:INFO:create_model() successfully completed......................................
2024-06-13 11:50:33,415:INFO:Initializing tune_model()
2024-06-13 11:50:33,415:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-13 11:50:33,415:INFO:Checking exceptions
2024-06-13 11:50:33,438:INFO:Copying training dataset
2024-06-13 11:50:33,450:INFO:Checking base model
2024-06-13 11:50:33,450:INFO:Base model : Light Gradient Boosting Machine
2024-06-13 11:50:33,453:INFO:Declaring metric variables
2024-06-13 11:50:33,457:INFO:Defining Hyperparameters
2024-06-13 11:50:33,544:INFO:Tuning with n_jobs=-1
2024-06-13 11:50:33,544:INFO:Initializing RandomizedSearchCV
2024-06-13 11:51:00,389:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-13 11:51:00,391:INFO:Hyperparameter search completed
2024-06-13 11:51:00,391:INFO:SubProcess create_model() called ==================================
2024-06-13 11:51:00,392:INFO:Initializing create_model()
2024-06-13 11:51:00,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AD1A73BD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-13 11:51:00,393:INFO:Checking exceptions
2024-06-13 11:51:00,393:INFO:Importing libraries
2024-06-13 11:51:00,393:INFO:Copying training dataset
2024-06-13 11:51:00,423:INFO:Defining folds
2024-06-13 11:51:00,423:INFO:Declaring metric variables
2024-06-13 11:51:00,428:INFO:Importing untrained model
2024-06-13 11:51:00,428:INFO:Declaring custom model
2024-06-13 11:51:00,435:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:51:00,446:INFO:Starting cross validation
2024-06-13 11:51:00,450:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:51:02,376:INFO:Calculating mean and std
2024-06-13 11:51:02,378:INFO:Creating metrics dataframe
2024-06-13 11:51:02,385:INFO:Finalizing model
2024-06-13 11:51:02,725:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:02,725:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:02,725:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:02,764:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:02,764:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:02,764:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:02,764:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-13 11:51:02,769:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003217 seconds.
2024-06-13 11:51:02,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:51:02,769:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:51:02,771:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-13 11:51:02,773:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-13 11:51:02,773:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-13 11:51:02,901:INFO:Uploading results into container
2024-06-13 11:51:02,902:INFO:Uploading model into container now
2024-06-13 11:51:02,903:INFO:_master_model_container: 2
2024-06-13 11:51:02,903:INFO:_display_container: 3
2024-06-13 11:51:02,904:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:51:02,904:INFO:create_model() successfully completed......................................
2024-06-13 11:51:03,012:INFO:SubProcess create_model() end ==================================
2024-06-13 11:51:03,012:INFO:choose_better activated
2024-06-13 11:51:03,015:INFO:SubProcess create_model() called ==================================
2024-06-13 11:51:03,015:INFO:Initializing create_model()
2024-06-13 11:51:03,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:51:03,015:INFO:Checking exceptions
2024-06-13 11:51:03,017:INFO:Importing libraries
2024-06-13 11:51:03,017:INFO:Copying training dataset
2024-06-13 11:51:03,042:INFO:Defining folds
2024-06-13 11:51:03,043:INFO:Declaring metric variables
2024-06-13 11:51:03,043:INFO:Importing untrained model
2024-06-13 11:51:03,043:INFO:Declaring custom model
2024-06-13 11:51:03,044:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:51:03,044:INFO:Starting cross validation
2024-06-13 11:51:03,046:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:51:04,983:INFO:Calculating mean and std
2024-06-13 11:51:04,984:INFO:Creating metrics dataframe
2024-06-13 11:51:04,986:INFO:Finalizing model
2024-06-13 11:51:05,384:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-13 11:51:05,387:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002569 seconds.
2024-06-13 11:51:05,387:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:51:05,387:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:51:05,388:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-13 11:51:05,388:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-13 11:51:05,388:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-13 11:51:05,570:INFO:Uploading results into container
2024-06-13 11:51:05,571:INFO:Uploading model into container now
2024-06-13 11:51:05,571:INFO:_master_model_container: 3
2024-06-13 11:51:05,571:INFO:_display_container: 4
2024-06-13 11:51:05,572:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:51:05,572:INFO:create_model() successfully completed......................................
2024-06-13 11:51:05,657:INFO:SubProcess create_model() end ==================================
2024-06-13 11:51:05,658:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0168
2024-06-13 11:51:05,659:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0626
2024-06-13 11:51:05,659:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-13 11:51:05,659:INFO:choose_better completed
2024-06-13 11:51:05,670:INFO:_master_model_container: 3
2024-06-13 11:51:05,671:INFO:_display_container: 3
2024-06-13 11:51:05,672:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:51:05,672:INFO:tune_model() successfully completed......................................
2024-06-13 11:51:05,763:INFO:Initializing plot_model()
2024-06-13 11:51:05,763:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:51:05,763:INFO:Checking exceptions
2024-06-13 11:51:05,773:INFO:Preloading libraries
2024-06-13 11:51:05,778:INFO:Copying training dataset
2024-06-13 11:51:05,778:INFO:Plot type: auc
2024-06-13 11:51:05,952:INFO:Fitting Model
2024-06-13 11:51:05,953:INFO:Scoring test/hold-out set
2024-06-13 11:51:05,955:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:05,955:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:05,955:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:05,965:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:05,965:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:05,965:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:06,188:INFO:Visual Rendered Successfully
2024-06-13 11:51:06,260:INFO:plot_model() successfully completed......................................
2024-06-13 11:51:06,276:INFO:Initializing plot_model()
2024-06-13 11:51:06,276:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:51:06,276:INFO:Checking exceptions
2024-06-13 11:51:06,286:INFO:Preloading libraries
2024-06-13 11:51:06,291:INFO:Copying training dataset
2024-06-13 11:51:06,291:INFO:Plot type: confusion_matrix
2024-06-13 11:51:06,464:INFO:Fitting Model
2024-06-13 11:51:06,465:INFO:Scoring test/hold-out set
2024-06-13 11:51:06,466:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:06,467:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:06,467:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:06,475:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:06,475:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:06,476:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:06,625:INFO:Visual Rendered Successfully
2024-06-13 11:51:06,693:INFO:plot_model() successfully completed......................................
2024-06-13 11:51:06,710:INFO:Initializing finalize_model()
2024-06-13 11:51:06,710:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 11:51:06,711:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:51:06,722:INFO:Initializing create_model()
2024-06-13 11:51:06,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:51:06,722:INFO:Checking exceptions
2024-06-13 11:51:06,723:INFO:Importing libraries
2024-06-13 11:51:06,723:INFO:Copying training dataset
2024-06-13 11:51:06,724:INFO:Defining folds
2024-06-13 11:51:06,724:INFO:Declaring metric variables
2024-06-13 11:51:06,725:INFO:Importing untrained model
2024-06-13 11:51:06,725:INFO:Declaring custom model
2024-06-13 11:51:06,725:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:51:06,727:INFO:Cross validation set to False
2024-06-13 11:51:06,728:INFO:Fitting Model
2024-06-13 11:51:07,156:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:07,156:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:07,156:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:07,213:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:07,213:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:07,213:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:07,213:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-13 11:51:07,217:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003096 seconds.
2024-06-13 11:51:07,218:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:51:07,218:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:51:07,220:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-13 11:51:07,222:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-13 11:51:07,222:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-13 11:51:07,410:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-13 11:51:07,410:INFO:create_model() successfully completed......................................
2024-06-13 11:51:07,487:INFO:_master_model_container: 3
2024-06-13 11:51:07,487:INFO:_display_container: 3
2024-06-13 11:51:07,520:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-13 11:51:07,520:INFO:finalize_model() successfully completed......................................
2024-06-13 11:51:07,636:INFO:Initializing plot_model()
2024-06-13 11:51:07,636:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:51:07,636:INFO:Checking exceptions
2024-06-13 11:51:07,645:INFO:Preloading libraries
2024-06-13 11:51:07,655:INFO:Copying training dataset
2024-06-13 11:51:07,655:INFO:Plot type: auc
2024-06-13 11:51:07,829:INFO:Fitting Model
2024-06-13 11:51:07,830:INFO:Scoring test/hold-out set
2024-06-13 11:51:07,832:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:07,832:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:07,832:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:07,841:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:07,841:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:07,841:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:08,072:INFO:Visual Rendered Successfully
2024-06-13 11:51:08,141:INFO:plot_model() successfully completed......................................
2024-06-13 11:51:08,191:INFO:Initializing plot_model()
2024-06-13 11:51:08,191:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:51:08,191:INFO:Checking exceptions
2024-06-13 11:51:08,199:INFO:Preloading libraries
2024-06-13 11:51:08,204:INFO:Copying training dataset
2024-06-13 11:51:08,205:INFO:Plot type: confusion_matrix
2024-06-13 11:51:08,365:INFO:Fitting Model
2024-06-13 11:51:08,365:INFO:Scoring test/hold-out set
2024-06-13 11:51:08,367:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:08,367:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:08,367:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:08,379:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:51:08,380:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:51:08,380:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:51:08,521:INFO:Visual Rendered Successfully
2024-06-13 11:51:08,590:INFO:plot_model() successfully completed......................................
2024-06-13 11:51:08,640:INFO:Initializing predict_model()
2024-06-13 11:51:08,640:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FC310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AD1AB2EDE0>)
2024-06-13 11:51:08,640:INFO:Checking exceptions
2024-06-13 11:51:08,640:INFO:Preloading libraries
2024-06-13 11:51:08,642:INFO:Set up data.
2024-06-13 11:51:09,035:INFO:Set up index.
2024-06-13 11:53:32,423:INFO:PyCaret ClassificationExperiment
2024-06-13 11:53:32,423:INFO:Logging name: clf-default-name
2024-06-13 11:53:32,423:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-13 11:53:32,423:INFO:version 3.3.2
2024-06-13 11:53:32,423:INFO:Initializing setup()
2024-06-13 11:53:32,423:INFO:self.USI: d16e
2024-06-13 11:53:32,424:INFO:self._variable_keys: {'n_jobs_param', 'pipeline', 'logging_param', '_ml_usecase', 'X_train', 'target_param', 'is_multiclass', 'seed', 'memory', 'idx', 'fold_shuffle_param', 'fold_groups_param', 'fold_generator', 'fix_imbalance', 'USI', 'y_test', '_available_plots', 'data', 'log_plots_param', 'X_test', 'html_param', 'y_train', 'gpu_n_jobs_param', 'exp_name_log', 'gpu_param', 'X', 'exp_id', 'y'}
2024-06-13 11:53:32,424:INFO:Checking environment
2024-06-13 11:53:32,424:INFO:python_version: 3.11.9
2024-06-13 11:53:32,424:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-13 11:53:32,424:INFO:machine: AMD64
2024-06-13 11:53:32,424:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-13 11:53:32,424:INFO:Memory: svmem(total=34056318976, available=23479144448, percent=31.1, used=10577174528, free=23479144448)
2024-06-13 11:53:32,424:INFO:Physical Core: 6
2024-06-13 11:53:32,424:INFO:Logical Core: 12
2024-06-13 11:53:32,424:INFO:Checking libraries
2024-06-13 11:53:32,424:INFO:System:
2024-06-13 11:53:32,425:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-13 11:53:32,425:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-13 11:53:32,425:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-13 11:53:32,425:INFO:PyCaret required dependencies:
2024-06-13 11:53:32,425:INFO:                 pip: 24.0
2024-06-13 11:53:32,425:INFO:          setuptools: 69.5.1
2024-06-13 11:53:32,425:INFO:             pycaret: 3.3.2
2024-06-13 11:53:32,425:INFO:             IPython: 8.25.0
2024-06-13 11:53:32,425:INFO:          ipywidgets: 8.1.3
2024-06-13 11:53:32,425:INFO:                tqdm: 4.66.4
2024-06-13 11:53:32,425:INFO:               numpy: 1.26.4
2024-06-13 11:53:32,425:INFO:              pandas: 2.1.4
2024-06-13 11:53:32,426:INFO:              jinja2: 3.1.4
2024-06-13 11:53:32,426:INFO:               scipy: 1.11.4
2024-06-13 11:53:32,426:INFO:              joblib: 1.3.2
2024-06-13 11:53:32,426:INFO:             sklearn: 1.4.2
2024-06-13 11:53:32,426:INFO:                pyod: 2.0.0
2024-06-13 11:53:32,426:INFO:            imblearn: 0.12.3
2024-06-13 11:53:32,426:INFO:   category_encoders: 2.6.3
2024-06-13 11:53:32,426:INFO:            lightgbm: 4.3.0
2024-06-13 11:53:32,426:INFO:               numba: 0.59.1
2024-06-13 11:53:32,426:INFO:            requests: 2.32.3
2024-06-13 11:53:32,426:INFO:          matplotlib: 3.7.5
2024-06-13 11:53:32,426:INFO:          scikitplot: 0.3.7
2024-06-13 11:53:32,426:INFO:         yellowbrick: 1.5
2024-06-13 11:53:32,426:INFO:              plotly: 5.22.0
2024-06-13 11:53:32,427:INFO:    plotly-resampler: Not installed
2024-06-13 11:53:32,427:INFO:             kaleido: 0.2.1
2024-06-13 11:53:32,427:INFO:           schemdraw: 0.15
2024-06-13 11:53:32,427:INFO:         statsmodels: 0.14.2
2024-06-13 11:53:32,427:INFO:              sktime: 0.26.0
2024-06-13 11:53:32,427:INFO:               tbats: 1.1.3
2024-06-13 11:53:32,427:INFO:            pmdarima: 2.0.4
2024-06-13 11:53:32,427:INFO:              psutil: 5.9.8
2024-06-13 11:53:32,427:INFO:          markupsafe: 2.1.5
2024-06-13 11:53:32,427:INFO:             pickle5: Not installed
2024-06-13 11:53:32,427:INFO:         cloudpickle: 3.0.0
2024-06-13 11:53:32,427:INFO:         deprecation: 2.1.0
2024-06-13 11:53:32,427:INFO:              xxhash: 3.4.1
2024-06-13 11:53:32,427:INFO:           wurlitzer: Not installed
2024-06-13 11:53:32,428:INFO:PyCaret optional dependencies:
2024-06-13 11:53:32,428:INFO:                shap: Not installed
2024-06-13 11:53:32,428:INFO:           interpret: Not installed
2024-06-13 11:53:32,428:INFO:                umap: Not installed
2024-06-13 11:53:32,428:INFO:     ydata_profiling: Not installed
2024-06-13 11:53:32,428:INFO:  explainerdashboard: Not installed
2024-06-13 11:53:32,428:INFO:             autoviz: Not installed
2024-06-13 11:53:32,428:INFO:           fairlearn: Not installed
2024-06-13 11:53:32,428:INFO:          deepchecks: Not installed
2024-06-13 11:53:32,428:INFO:             xgboost: Not installed
2024-06-13 11:53:32,428:INFO:            catboost: Not installed
2024-06-13 11:53:32,428:INFO:              kmodes: Not installed
2024-06-13 11:53:32,428:INFO:             mlxtend: Not installed
2024-06-13 11:53:32,429:INFO:       statsforecast: Not installed
2024-06-13 11:53:32,429:INFO:        tune_sklearn: Not installed
2024-06-13 11:53:32,429:INFO:                 ray: Not installed
2024-06-13 11:53:32,429:INFO:            hyperopt: Not installed
2024-06-13 11:53:32,429:INFO:              optuna: Not installed
2024-06-13 11:53:32,429:INFO:               skopt: Not installed
2024-06-13 11:53:32,429:INFO:              mlflow: Not installed
2024-06-13 11:53:32,429:INFO:              gradio: Not installed
2024-06-13 11:53:32,429:INFO:             fastapi: Not installed
2024-06-13 11:53:32,429:INFO:             uvicorn: Not installed
2024-06-13 11:53:32,429:INFO:              m2cgen: Not installed
2024-06-13 11:53:32,429:INFO:           evidently: Not installed
2024-06-13 11:53:32,429:INFO:               fugue: Not installed
2024-06-13 11:53:32,429:INFO:           streamlit: 1.35.0
2024-06-13 11:53:32,429:INFO:             prophet: Not installed
2024-06-13 11:53:32,429:INFO:None
2024-06-13 11:53:32,430:INFO:Set up data.
2024-06-13 11:53:32,468:INFO:Set up folding strategy.
2024-06-13 11:53:32,468:INFO:Set up train/test split.
2024-06-13 11:53:32,490:INFO:Set up index.
2024-06-13 11:53:32,491:INFO:Assigning column types.
2024-06-13 11:53:32,500:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-13 11:53:32,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 11:53:32,545:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:53:32,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:32,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:32,623:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 11:53:32,625:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:53:32,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:32,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:32,652:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-13 11:53:32,706:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:53:32,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:32,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:32,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:53:32,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:32,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:32,845:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-13 11:53:32,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:32,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:33,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:33,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:33,059:INFO:Preparing preprocessing pipeline...
2024-06-13 11:53:33,063:INFO:Set up simple imputation.
2024-06-13 11:53:33,079:INFO:Set up encoding of ordinal features.
2024-06-13 11:53:33,091:INFO:Set up encoding of categorical features.
2024-06-13 11:53:33,091:INFO:Set up feature normalization.
2024-06-13 11:53:33,091:INFO:Set up PCA.
2024-06-13 11:53:33,487:INFO:Finished creating preprocessing pipeline.
2024-06-13 11:53:33,515:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MaxAbsScaler(copy=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-13 11:53:33,516:INFO:Creating final display dataframe.
2024-06-13 11:53:33,675:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (50000, 30)
5   Transformed train set shape       (35000, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            maxabs
18                          PCA              True
19                   PCA method            linear
20               PCA components              None
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              d16e
2024-06-13 11:53:33,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:33,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:33,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:33,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:53:33,828:INFO:setup() successfully completed in 1.5s...............
2024-06-13 11:53:33,913:INFO:Initializing create_model()
2024-06-13 11:53:33,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:53:33,913:INFO:Checking exceptions
2024-06-13 11:53:33,926:INFO:Importing libraries
2024-06-13 11:53:33,926:INFO:Copying training dataset
2024-06-13 11:53:33,942:INFO:Defining folds
2024-06-13 11:53:33,943:INFO:Declaring metric variables
2024-06-13 11:53:33,945:INFO:Importing untrained model
2024-06-13 11:53:33,949:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:53:33,955:INFO:Starting cross validation
2024-06-13 11:53:33,957:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:53:36,105:INFO:Calculating mean and std
2024-06-13 11:53:36,106:INFO:Creating metrics dataframe
2024-06-13 11:53:36,113:INFO:Finalizing model
2024-06-13 11:53:36,541:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-13 11:53:36,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003276 seconds.
2024-06-13 11:53:36,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:53:36,545:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:53:36,546:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-13 11:53:36,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-13 11:53:36,547:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-13 11:53:36,772:INFO:Uploading results into container
2024-06-13 11:53:36,773:INFO:Uploading model into container now
2024-06-13 11:53:36,787:INFO:_master_model_container: 1
2024-06-13 11:53:36,787:INFO:_display_container: 2
2024-06-13 11:53:36,788:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:53:36,788:INFO:create_model() successfully completed......................................
2024-06-13 11:53:36,910:INFO:Initializing tune_model()
2024-06-13 11:53:36,910:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-13 11:53:36,910:INFO:Checking exceptions
2024-06-13 11:53:36,938:INFO:Copying training dataset
2024-06-13 11:53:36,953:INFO:Checking base model
2024-06-13 11:53:36,954:INFO:Base model : Light Gradient Boosting Machine
2024-06-13 11:53:36,957:INFO:Declaring metric variables
2024-06-13 11:53:36,961:INFO:Defining Hyperparameters
2024-06-13 11:53:37,046:INFO:Tuning with n_jobs=-1
2024-06-13 11:53:37,046:INFO:Initializing RandomizedSearchCV
2024-06-13 11:54:08,317:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2024-06-13 11:54:08,318:INFO:Hyperparameter search completed
2024-06-13 11:54:08,319:INFO:SubProcess create_model() called ==================================
2024-06-13 11:54:08,320:INFO:Initializing create_model()
2024-06-13 11:54:08,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AD162273D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2024-06-13 11:54:08,320:INFO:Checking exceptions
2024-06-13 11:54:08,321:INFO:Importing libraries
2024-06-13 11:54:08,321:INFO:Copying training dataset
2024-06-13 11:54:08,353:INFO:Defining folds
2024-06-13 11:54:08,353:INFO:Declaring metric variables
2024-06-13 11:54:08,358:INFO:Importing untrained model
2024-06-13 11:54:08,359:INFO:Declaring custom model
2024-06-13 11:54:08,366:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:54:08,375:INFO:Starting cross validation
2024-06-13 11:54:08,379:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:54:10,254:INFO:Calculating mean and std
2024-06-13 11:54:10,256:INFO:Creating metrics dataframe
2024-06-13 11:54:10,263:INFO:Finalizing model
2024-06-13 11:54:10,652:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:10,653:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:10,653:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:10,701:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:10,702:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:10,702:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:10,702:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-13 11:54:10,706:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002849 seconds.
2024-06-13 11:54:10,706:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:54:10,706:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:54:10,709:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-13 11:54:10,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-13 11:54:10,711:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-13 11:54:10,890:INFO:Uploading results into container
2024-06-13 11:54:10,892:INFO:Uploading model into container now
2024-06-13 11:54:10,893:INFO:_master_model_container: 2
2024-06-13 11:54:10,894:INFO:_display_container: 3
2024-06-13 11:54:10,895:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:54:10,895:INFO:create_model() successfully completed......................................
2024-06-13 11:54:10,989:INFO:SubProcess create_model() end ==================================
2024-06-13 11:54:10,989:INFO:choose_better activated
2024-06-13 11:54:10,993:INFO:SubProcess create_model() called ==================================
2024-06-13 11:54:10,994:INFO:Initializing create_model()
2024-06-13 11:54:10,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:54:10,994:INFO:Checking exceptions
2024-06-13 11:54:10,996:INFO:Importing libraries
2024-06-13 11:54:10,996:INFO:Copying training dataset
2024-06-13 11:54:11,014:INFO:Defining folds
2024-06-13 11:54:11,014:INFO:Declaring metric variables
2024-06-13 11:54:11,015:INFO:Importing untrained model
2024-06-13 11:54:11,015:INFO:Declaring custom model
2024-06-13 11:54:11,015:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:54:11,016:INFO:Starting cross validation
2024-06-13 11:54:11,018:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:54:13,623:INFO:Calculating mean and std
2024-06-13 11:54:13,624:INFO:Creating metrics dataframe
2024-06-13 11:54:13,626:INFO:Finalizing model
2024-06-13 11:54:14,033:INFO:[LightGBM] [Info] Number of positive: 2794, number of negative: 32206
2024-06-13 11:54:14,036:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002495 seconds.
2024-06-13 11:54:14,036:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:54:14,036:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:54:14,037:INFO:[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 29
2024-06-13 11:54:14,038:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079829 -> initscore=-2.444679
2024-06-13 11:54:14,038:INFO:[LightGBM] [Info] Start training from score -2.444679
2024-06-13 11:54:14,217:INFO:Uploading results into container
2024-06-13 11:54:14,218:INFO:Uploading model into container now
2024-06-13 11:54:14,218:INFO:_master_model_container: 3
2024-06-13 11:54:14,219:INFO:_display_container: 4
2024-06-13 11:54:14,219:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:54:14,219:INFO:create_model() successfully completed......................................
2024-06-13 11:54:14,303:INFO:SubProcess create_model() end ==================================
2024-06-13 11:54:14,304:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0128
2024-06-13 11:54:14,305:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0694
2024-06-13 11:54:14,305:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-13 11:54:14,305:INFO:choose_better completed
2024-06-13 11:54:14,315:INFO:_master_model_container: 3
2024-06-13 11:54:14,316:INFO:_display_container: 3
2024-06-13 11:54:14,316:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:54:14,316:INFO:tune_model() successfully completed......................................
2024-06-13 11:54:14,599:INFO:Initializing plot_model()
2024-06-13 11:54:14,600:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:54:14,600:INFO:Checking exceptions
2024-06-13 11:54:14,609:INFO:Preloading libraries
2024-06-13 11:54:14,615:INFO:Copying training dataset
2024-06-13 11:54:14,615:INFO:Plot type: auc
2024-06-13 11:54:14,791:INFO:Fitting Model
2024-06-13 11:54:14,792:INFO:Scoring test/hold-out set
2024-06-13 11:54:14,794:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:14,794:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:14,794:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:14,803:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:14,804:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:14,804:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:15,038:INFO:Visual Rendered Successfully
2024-06-13 11:54:15,112:INFO:plot_model() successfully completed......................................
2024-06-13 11:54:15,142:INFO:Initializing plot_model()
2024-06-13 11:54:15,142:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:54:15,143:INFO:Checking exceptions
2024-06-13 11:54:15,152:INFO:Preloading libraries
2024-06-13 11:54:15,158:INFO:Copying training dataset
2024-06-13 11:54:15,158:INFO:Plot type: confusion_matrix
2024-06-13 11:54:15,324:INFO:Fitting Model
2024-06-13 11:54:15,325:INFO:Scoring test/hold-out set
2024-06-13 11:54:15,327:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:15,327:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:15,327:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:15,336:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:15,336:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:15,337:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:15,482:INFO:Visual Rendered Successfully
2024-06-13 11:54:15,551:INFO:plot_model() successfully completed......................................
2024-06-13 11:54:15,566:INFO:Initializing finalize_model()
2024-06-13 11:54:15,566:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 11:54:15,566:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:54:15,576:INFO:Initializing create_model()
2024-06-13 11:54:15,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:54:15,576:INFO:Checking exceptions
2024-06-13 11:54:15,577:INFO:Importing libraries
2024-06-13 11:54:15,577:INFO:Copying training dataset
2024-06-13 11:54:15,578:INFO:Defining folds
2024-06-13 11:54:15,578:INFO:Declaring metric variables
2024-06-13 11:54:15,579:INFO:Importing untrained model
2024-06-13 11:54:15,579:INFO:Declaring custom model
2024-06-13 11:54:15,579:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:54:15,581:INFO:Cross validation set to False
2024-06-13 11:54:15,581:INFO:Fitting Model
2024-06-13 11:54:16,023:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:16,023:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:16,024:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:16,086:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:16,086:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:16,086:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:16,086:INFO:[LightGBM] [Info] Number of positive: 3991, number of negative: 46009
2024-06-13 11:54:16,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003929 seconds.
2024-06-13 11:54:16,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:54:16,092:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:54:16,095:INFO:[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 29
2024-06-13 11:54:16,097:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079820 -> initscore=-2.444795
2024-06-13 11:54:16,097:INFO:[LightGBM] [Info] Start training from score -2.444795
2024-06-13 11:54:16,306:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-13 11:54:16,306:INFO:create_model() successfully completed......................................
2024-06-13 11:54:16,387:INFO:_master_model_container: 3
2024-06-13 11:54:16,387:INFO:_display_container: 3
2024-06-13 11:54:16,421:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2024-06-13 11:54:16,421:INFO:finalize_model() successfully completed......................................
2024-06-13 11:54:16,556:INFO:Initializing plot_model()
2024-06-13 11:54:16,556:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:54:16,556:INFO:Checking exceptions
2024-06-13 11:54:16,565:INFO:Preloading libraries
2024-06-13 11:54:16,571:INFO:Copying training dataset
2024-06-13 11:54:16,571:INFO:Plot type: auc
2024-06-13 11:54:16,741:INFO:Fitting Model
2024-06-13 11:54:16,742:INFO:Scoring test/hold-out set
2024-06-13 11:54:16,744:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:16,744:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:16,744:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:16,754:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:16,754:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:16,754:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:16,991:INFO:Visual Rendered Successfully
2024-06-13 11:54:17,064:INFO:plot_model() successfully completed......................................
2024-06-13 11:54:17,115:INFO:Initializing plot_model()
2024-06-13 11:54:17,115:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:54:17,116:INFO:Checking exceptions
2024-06-13 11:54:17,123:INFO:Preloading libraries
2024-06-13 11:54:17,128:INFO:Copying training dataset
2024-06-13 11:54:17,128:INFO:Plot type: confusion_matrix
2024-06-13 11:54:17,319:INFO:Fitting Model
2024-06-13 11:54:17,320:INFO:Scoring test/hold-out set
2024-06-13 11:54:17,322:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:17,322:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:17,322:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:17,335:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-06-13 11:54:17,335:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-06-13 11:54:17,335:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-06-13 11:54:17,507:INFO:Visual Rendered Successfully
2024-06-13 11:54:17,597:INFO:plot_model() successfully completed......................................
2024-06-13 11:54:17,638:INFO:Initializing predict_model()
2024-06-13 11:54:17,639:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A7FE150>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AD1AC079C0>)
2024-06-13 11:54:17,639:INFO:Checking exceptions
2024-06-13 11:54:17,639:INFO:Preloading libraries
2024-06-13 11:54:17,642:INFO:Set up data.
2024-06-13 11:54:18,035:INFO:Set up index.
2024-06-13 11:55:04,925:INFO:PyCaret ClassificationExperiment
2024-06-13 11:55:04,925:INFO:Logging name: clf-default-name
2024-06-13 11:55:04,925:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-13 11:55:04,925:INFO:version 3.3.2
2024-06-13 11:55:04,925:INFO:Initializing setup()
2024-06-13 11:55:04,925:INFO:self.USI: b930
2024-06-13 11:55:04,925:INFO:self._variable_keys: {'n_jobs_param', 'pipeline', 'logging_param', '_ml_usecase', 'X_train', 'target_param', 'is_multiclass', 'seed', 'memory', 'idx', 'fold_shuffle_param', 'fold_groups_param', 'fold_generator', 'fix_imbalance', 'USI', 'y_test', '_available_plots', 'data', 'log_plots_param', 'X_test', 'html_param', 'y_train', 'gpu_n_jobs_param', 'exp_name_log', 'gpu_param', 'X', 'exp_id', 'y'}
2024-06-13 11:55:04,925:INFO:Checking environment
2024-06-13 11:55:04,925:INFO:python_version: 3.11.9
2024-06-13 11:55:04,925:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-13 11:55:04,925:INFO:machine: AMD64
2024-06-13 11:55:04,925:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-13 11:55:04,926:INFO:Memory: svmem(total=34056318976, available=23327174656, percent=31.5, used=10729144320, free=23327174656)
2024-06-13 11:55:04,926:INFO:Physical Core: 6
2024-06-13 11:55:04,926:INFO:Logical Core: 12
2024-06-13 11:55:04,926:INFO:Checking libraries
2024-06-13 11:55:04,926:INFO:System:
2024-06-13 11:55:04,926:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-13 11:55:04,926:INFO:executable: c:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-13 11:55:04,926:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-13 11:55:04,926:INFO:PyCaret required dependencies:
2024-06-13 11:55:04,926:INFO:                 pip: 24.0
2024-06-13 11:55:04,926:INFO:          setuptools: 69.5.1
2024-06-13 11:55:04,926:INFO:             pycaret: 3.3.2
2024-06-13 11:55:04,926:INFO:             IPython: 8.25.0
2024-06-13 11:55:04,926:INFO:          ipywidgets: 8.1.3
2024-06-13 11:55:04,926:INFO:                tqdm: 4.66.4
2024-06-13 11:55:04,926:INFO:               numpy: 1.26.4
2024-06-13 11:55:04,926:INFO:              pandas: 2.1.4
2024-06-13 11:55:04,927:INFO:              jinja2: 3.1.4
2024-06-13 11:55:04,927:INFO:               scipy: 1.11.4
2024-06-13 11:55:04,927:INFO:              joblib: 1.3.2
2024-06-13 11:55:04,927:INFO:             sklearn: 1.4.2
2024-06-13 11:55:04,927:INFO:                pyod: 2.0.0
2024-06-13 11:55:04,927:INFO:            imblearn: 0.12.3
2024-06-13 11:55:04,927:INFO:   category_encoders: 2.6.3
2024-06-13 11:55:04,927:INFO:            lightgbm: 4.3.0
2024-06-13 11:55:04,927:INFO:               numba: 0.59.1
2024-06-13 11:55:04,927:INFO:            requests: 2.32.3
2024-06-13 11:55:04,927:INFO:          matplotlib: 3.7.5
2024-06-13 11:55:04,927:INFO:          scikitplot: 0.3.7
2024-06-13 11:55:04,927:INFO:         yellowbrick: 1.5
2024-06-13 11:55:04,927:INFO:              plotly: 5.22.0
2024-06-13 11:55:04,927:INFO:    plotly-resampler: Not installed
2024-06-13 11:55:04,927:INFO:             kaleido: 0.2.1
2024-06-13 11:55:04,927:INFO:           schemdraw: 0.15
2024-06-13 11:55:04,927:INFO:         statsmodels: 0.14.2
2024-06-13 11:55:04,927:INFO:              sktime: 0.26.0
2024-06-13 11:55:04,927:INFO:               tbats: 1.1.3
2024-06-13 11:55:04,928:INFO:            pmdarima: 2.0.4
2024-06-13 11:55:04,928:INFO:              psutil: 5.9.8
2024-06-13 11:55:04,928:INFO:          markupsafe: 2.1.5
2024-06-13 11:55:04,928:INFO:             pickle5: Not installed
2024-06-13 11:55:04,928:INFO:         cloudpickle: 3.0.0
2024-06-13 11:55:04,928:INFO:         deprecation: 2.1.0
2024-06-13 11:55:04,928:INFO:              xxhash: 3.4.1
2024-06-13 11:55:04,928:INFO:           wurlitzer: Not installed
2024-06-13 11:55:04,928:INFO:PyCaret optional dependencies:
2024-06-13 11:55:04,928:INFO:                shap: Not installed
2024-06-13 11:55:04,928:INFO:           interpret: Not installed
2024-06-13 11:55:04,928:INFO:                umap: Not installed
2024-06-13 11:55:04,928:INFO:     ydata_profiling: Not installed
2024-06-13 11:55:04,928:INFO:  explainerdashboard: Not installed
2024-06-13 11:55:04,928:INFO:             autoviz: Not installed
2024-06-13 11:55:04,929:INFO:           fairlearn: Not installed
2024-06-13 11:55:04,929:INFO:          deepchecks: Not installed
2024-06-13 11:55:04,929:INFO:             xgboost: Not installed
2024-06-13 11:55:04,929:INFO:            catboost: Not installed
2024-06-13 11:55:04,929:INFO:              kmodes: Not installed
2024-06-13 11:55:04,929:INFO:             mlxtend: Not installed
2024-06-13 11:55:04,929:INFO:       statsforecast: Not installed
2024-06-13 11:55:04,929:INFO:        tune_sklearn: Not installed
2024-06-13 11:55:04,929:INFO:                 ray: Not installed
2024-06-13 11:55:04,929:INFO:            hyperopt: Not installed
2024-06-13 11:55:04,929:INFO:              optuna: Not installed
2024-06-13 11:55:04,929:INFO:               skopt: Not installed
2024-06-13 11:55:04,929:INFO:              mlflow: Not installed
2024-06-13 11:55:04,929:INFO:              gradio: Not installed
2024-06-13 11:55:04,929:INFO:             fastapi: Not installed
2024-06-13 11:55:04,929:INFO:             uvicorn: Not installed
2024-06-13 11:55:04,929:INFO:              m2cgen: Not installed
2024-06-13 11:55:04,929:INFO:           evidently: Not installed
2024-06-13 11:55:04,929:INFO:               fugue: Not installed
2024-06-13 11:55:04,929:INFO:           streamlit: 1.35.0
2024-06-13 11:55:04,930:INFO:             prophet: Not installed
2024-06-13 11:55:04,930:INFO:None
2024-06-13 11:55:04,930:INFO:Set up data.
2024-06-13 11:55:04,966:INFO:Set up folding strategy.
2024-06-13 11:55:04,966:INFO:Set up train/test split.
2024-06-13 11:55:04,988:INFO:Set up index.
2024-06-13 11:55:04,989:INFO:Assigning column types.
2024-06-13 11:55:04,998:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-13 11:55:05,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 11:55:05,041:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:55:05,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 11:55:05,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:55:05,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,137:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,138:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-13 11:55:05,180:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:55:05,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,250:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 11:55:05,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,279:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-13 11:55:05,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:05,459:INFO:Preparing preprocessing pipeline...
2024-06-13 11:55:05,463:INFO:Set up simple imputation.
2024-06-13 11:55:05,498:INFO:Set up encoding of ordinal features.
2024-06-13 11:55:05,521:INFO:Set up encoding of categorical features.
2024-06-13 11:55:05,521:INFO:Set up removing outliers.
2024-06-13 11:55:05,521:INFO:Set up feature normalization.
2024-06-13 11:55:05,521:INFO:Set up PCA.
2024-06-13 11:55:05,958:INFO:Finished creating preprocessing pipeline.
2024-06-13 11:55:05,999:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-13 11:55:06,000:INFO:Creating final display dataframe.
2024-06-13 11:55:06,655:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (48252, 30)
5   Transformed train set shape       (33252, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                    Normalize              True
19             Normalize method            robust
20                          PCA              True
21                   PCA method            linear
22               PCA components              None
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              b930
2024-06-13 11:55:06,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:06,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:06,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:06,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 11:55:06,835:INFO:setup() successfully completed in 2.0s...............
2024-06-13 11:55:06,926:INFO:Initializing create_model()
2024-06-13 11:55:06,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:55:06,926:INFO:Checking exceptions
2024-06-13 11:55:06,941:INFO:Importing libraries
2024-06-13 11:55:06,941:INFO:Copying training dataset
2024-06-13 11:55:06,958:INFO:Defining folds
2024-06-13 11:55:06,958:INFO:Declaring metric variables
2024-06-13 11:55:06,961:INFO:Importing untrained model
2024-06-13 11:55:06,965:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:55:06,971:INFO:Starting cross validation
2024-06-13 11:55:06,973:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:55:09,533:INFO:Calculating mean and std
2024-06-13 11:55:09,535:INFO:Creating metrics dataframe
2024-06-13 11:55:09,542:INFO:Finalizing model
2024-06-13 11:55:10,498:INFO:[LightGBM] [Info] Number of positive: 2655, number of negative: 30597
2024-06-13 11:55:10,501:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002321 seconds.
2024-06-13 11:55:10,501:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:55:10,502:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:55:10,502:INFO:[LightGBM] [Info] Number of data points in the train set: 33252, number of used features: 29
2024-06-13 11:55:10,503:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079845 -> initscore=-2.444457
2024-06-13 11:55:10,503:INFO:[LightGBM] [Info] Start training from score -2.444457
2024-06-13 11:55:10,662:INFO:Uploading results into container
2024-06-13 11:55:10,663:INFO:Uploading model into container now
2024-06-13 11:55:10,674:INFO:_master_model_container: 1
2024-06-13 11:55:10,674:INFO:_display_container: 2
2024-06-13 11:55:10,675:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:55:10,675:INFO:create_model() successfully completed......................................
2024-06-13 11:55:10,774:INFO:Initializing tune_model()
2024-06-13 11:55:10,774:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-13 11:55:10,775:INFO:Checking exceptions
2024-06-13 11:55:10,797:INFO:Copying training dataset
2024-06-13 11:55:10,807:INFO:Checking base model
2024-06-13 11:55:10,807:INFO:Base model : Light Gradient Boosting Machine
2024-06-13 11:55:10,810:INFO:Declaring metric variables
2024-06-13 11:55:10,816:INFO:Defining Hyperparameters
2024-06-13 11:55:10,896:INFO:Tuning with n_jobs=-1
2024-06-13 11:55:10,896:INFO:Initializing RandomizedSearchCV
2024-06-13 11:55:50,085:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-06-13 11:55:50,087:INFO:Hyperparameter search completed
2024-06-13 11:55:50,087:INFO:SubProcess create_model() called ==================================
2024-06-13 11:55:50,088:INFO:Initializing create_model()
2024-06-13 11:55:50,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AD17CFEF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-06-13 11:55:50,089:INFO:Checking exceptions
2024-06-13 11:55:50,089:INFO:Importing libraries
2024-06-13 11:55:50,089:INFO:Copying training dataset
2024-06-13 11:55:50,124:INFO:Defining folds
2024-06-13 11:55:50,124:INFO:Declaring metric variables
2024-06-13 11:55:50,131:INFO:Importing untrained model
2024-06-13 11:55:50,131:INFO:Declaring custom model
2024-06-13 11:55:50,140:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:55:50,156:INFO:Starting cross validation
2024-06-13 11:55:50,161:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:55:55,912:INFO:Calculating mean and std
2024-06-13 11:55:55,914:INFO:Creating metrics dataframe
2024-06-13 11:55:55,925:INFO:Finalizing model
2024-06-13 11:55:56,929:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:55:56,929:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:55:56,930:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:55:56,966:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:55:56,966:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:55:56,966:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:55:56,967:INFO:[LightGBM] [Info] Number of positive: 2655, number of negative: 30597
2024-06-13 11:55:56,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002675 seconds.
2024-06-13 11:55:56,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:55:56,970:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:55:56,972:INFO:[LightGBM] [Info] Number of data points in the train set: 33252, number of used features: 29
2024-06-13 11:55:56,973:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079845 -> initscore=-2.444457
2024-06-13 11:55:56,973:INFO:[LightGBM] [Info] Start training from score -2.444457
2024-06-13 11:55:56,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:56,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:56,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:56,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:55:57,634:INFO:Uploading results into container
2024-06-13 11:55:57,635:INFO:Uploading model into container now
2024-06-13 11:55:57,637:INFO:_master_model_container: 2
2024-06-13 11:55:57,637:INFO:_display_container: 3
2024-06-13 11:55:57,638:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:55:57,639:INFO:create_model() successfully completed......................................
2024-06-13 11:55:57,768:INFO:SubProcess create_model() end ==================================
2024-06-13 11:55:57,768:INFO:choose_better activated
2024-06-13 11:55:57,773:INFO:SubProcess create_model() called ==================================
2024-06-13 11:55:57,774:INFO:Initializing create_model()
2024-06-13 11:55:57,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:55:57,775:INFO:Checking exceptions
2024-06-13 11:55:57,777:INFO:Importing libraries
2024-06-13 11:55:57,778:INFO:Copying training dataset
2024-06-13 11:55:57,804:INFO:Defining folds
2024-06-13 11:55:57,804:INFO:Declaring metric variables
2024-06-13 11:55:57,804:INFO:Importing untrained model
2024-06-13 11:55:57,804:INFO:Declaring custom model
2024-06-13 11:55:57,805:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:55:57,805:INFO:Starting cross validation
2024-06-13 11:55:57,808:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 11:56:01,273:INFO:Calculating mean and std
2024-06-13 11:56:01,274:INFO:Creating metrics dataframe
2024-06-13 11:56:01,277:INFO:Finalizing model
2024-06-13 11:56:02,292:INFO:[LightGBM] [Info] Number of positive: 2655, number of negative: 30597
2024-06-13 11:56:02,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002781 seconds.
2024-06-13 11:56:02,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:56:02,295:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:56:02,296:INFO:[LightGBM] [Info] Number of data points in the train set: 33252, number of used features: 29
2024-06-13 11:56:02,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079845 -> initscore=-2.444457
2024-06-13 11:56:02,297:INFO:[LightGBM] [Info] Start training from score -2.444457
2024-06-13 11:56:02,494:INFO:Uploading results into container
2024-06-13 11:56:02,496:INFO:Uploading model into container now
2024-06-13 11:56:02,497:INFO:_master_model_container: 3
2024-06-13 11:56:02,497:INFO:_display_container: 4
2024-06-13 11:56:02,498:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:56:02,498:INFO:create_model() successfully completed......................................
2024-06-13 11:56:02,613:INFO:SubProcess create_model() end ==================================
2024-06-13 11:56:02,614:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.0954
2024-06-13 11:56:02,615:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for MCC is 0.115
2024-06-13 11:56:02,616:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-13 11:56:02,616:INFO:choose_better completed
2024-06-13 11:56:02,628:INFO:_master_model_container: 3
2024-06-13 11:56:02,629:INFO:_display_container: 3
2024-06-13 11:56:02,630:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:56:02,630:INFO:tune_model() successfully completed......................................
2024-06-13 11:56:03,240:INFO:Initializing plot_model()
2024-06-13 11:56:03,240:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:56:03,240:INFO:Checking exceptions
2024-06-13 11:56:03,258:INFO:Preloading libraries
2024-06-13 11:56:03,313:INFO:Copying training dataset
2024-06-13 11:56:03,313:INFO:Plot type: auc
2024-06-13 11:56:03,515:INFO:Fitting Model
2024-06-13 11:56:03,516:INFO:Scoring test/hold-out set
2024-06-13 11:56:03,519:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:03,519:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:03,519:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:03,573:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:03,573:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:03,573:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:03,908:INFO:Visual Rendered Successfully
2024-06-13 11:56:03,982:INFO:plot_model() successfully completed......................................
2024-06-13 11:56:04,009:INFO:Initializing plot_model()
2024-06-13 11:56:04,009:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:56:04,010:INFO:Checking exceptions
2024-06-13 11:56:04,018:INFO:Preloading libraries
2024-06-13 11:56:04,048:INFO:Copying training dataset
2024-06-13 11:56:04,048:INFO:Plot type: confusion_matrix
2024-06-13 11:56:04,244:INFO:Fitting Model
2024-06-13 11:56:04,245:INFO:Scoring test/hold-out set
2024-06-13 11:56:04,247:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:04,247:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:04,247:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:04,309:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:04,309:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:04,309:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:04,559:INFO:Visual Rendered Successfully
2024-06-13 11:56:04,635:INFO:plot_model() successfully completed......................................
2024-06-13 11:56:04,658:INFO:Initializing finalize_model()
2024-06-13 11:56:04,659:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 11:56:04,659:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 11:56:04,669:INFO:Initializing create_model()
2024-06-13 11:56:04,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 11:56:04,669:INFO:Checking exceptions
2024-06-13 11:56:04,670:INFO:Importing libraries
2024-06-13 11:56:04,670:INFO:Copying training dataset
2024-06-13 11:56:04,671:INFO:Defining folds
2024-06-13 11:56:04,671:INFO:Declaring metric variables
2024-06-13 11:56:04,672:INFO:Importing untrained model
2024-06-13 11:56:04,672:INFO:Declaring custom model
2024-06-13 11:56:04,672:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 11:56:04,675:INFO:Cross validation set to False
2024-06-13 11:56:04,675:INFO:Fitting Model
2024-06-13 11:56:05,901:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:05,901:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:05,901:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:05,961:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:05,961:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:05,962:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:05,962:INFO:[LightGBM] [Info] Number of positive: 3814, number of negative: 43687
2024-06-13 11:56:05,968:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004481 seconds.
2024-06-13 11:56:05,968:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 11:56:05,968:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 11:56:05,969:INFO:[LightGBM] [Info] Number of data points in the train set: 47501, number of used features: 29
2024-06-13 11:56:05,971:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080293 -> initscore=-2.438372
2024-06-13 11:56:05,971:INFO:[LightGBM] [Info] Start training from score -2.438372
2024-06-13 11:56:05,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:05,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:05,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:05,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:06,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-06-13 11:56:07,160:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 11:56:07,160:INFO:create_model() successfully completed......................................
2024-06-13 11:56:07,250:INFO:_master_model_container: 3
2024-06-13 11:56:07,250:INFO:_display_container: 3
2024-06-13 11:56:07,292:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 11:56:07,292:INFO:finalize_model() successfully completed......................................
2024-06-13 11:56:07,425:INFO:Initializing plot_model()
2024-06-13 11:56:07,425:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:56:07,425:INFO:Checking exceptions
2024-06-13 11:56:07,433:INFO:Preloading libraries
2024-06-13 11:56:07,464:INFO:Copying training dataset
2024-06-13 11:56:07,464:INFO:Plot type: auc
2024-06-13 11:56:07,657:INFO:Fitting Model
2024-06-13 11:56:07,659:INFO:Scoring test/hold-out set
2024-06-13 11:56:07,661:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:07,661:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:07,661:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:07,756:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:07,756:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:07,757:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:08,134:INFO:Visual Rendered Successfully
2024-06-13 11:56:08,209:INFO:plot_model() successfully completed......................................
2024-06-13 11:56:08,263:INFO:Initializing plot_model()
2024-06-13 11:56:08,263:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 11:56:08,263:INFO:Checking exceptions
2024-06-13 11:56:08,272:INFO:Preloading libraries
2024-06-13 11:56:08,308:INFO:Copying training dataset
2024-06-13 11:56:08,308:INFO:Plot type: confusion_matrix
2024-06-13 11:56:08,524:INFO:Fitting Model
2024-06-13 11:56:08,524:INFO:Scoring test/hold-out set
2024-06-13 11:56:08,527:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:08,527:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:08,527:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:08,621:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-06-13 11:56:08,621:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 11:56:08,621:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-06-13 11:56:08,906:INFO:Visual Rendered Successfully
2024-06-13 11:56:08,990:INFO:plot_model() successfully completed......................................
2024-06-13 11:56:09,051:INFO:Initializing predict_model()
2024-06-13 11:56:09,051:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AD1A73A810>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.4,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=41,
                                min_child_weight=0.001, min_split_gain=0.9,
                                n_estimators=260, n_jobs=-1, num_leaves=70,
                                objective=None, random_state=123, reg_alpha=2,
                                reg_lambda=3, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AD1AB2DB20>)
2024-06-13 11:56:09,051:INFO:Checking exceptions
2024-06-13 11:56:09,051:INFO:Preloading libraries
2024-06-13 11:56:09,053:INFO:Set up data.
2024-06-13 11:56:09,536:INFO:Set up index.
2024-06-13 11:56:20,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 11:56:20,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 11:56:20,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 11:56:20,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:08:06,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:08:06,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:08:06,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:08:06,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:12:26,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:12:26,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:12:26,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:12:26,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:15:36,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:15:36,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:15:36,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:15:36,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:18:44,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:18:44,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:18:44,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:18:44,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:20:05,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:20:05,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:20:05,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:20:05,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:24:04,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:24:04,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:24:04,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:24:04,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 12:31:38,482:INFO:PyCaret ClassificationExperiment
2024-06-13 12:31:38,482:INFO:Logging name: clf-default-name
2024-06-13 12:31:38,482:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-13 12:31:38,482:INFO:version 3.3.2
2024-06-13 12:31:38,482:INFO:Initializing setup()
2024-06-13 12:31:38,482:INFO:self.USI: 3637
2024-06-13 12:31:38,482:INFO:self._variable_keys: {'X_train', '_ml_usecase', 'memory', 'html_param', 'fold_shuffle_param', 'fold_groups_param', 'USI', 'target_param', 'fix_imbalance', 'pipeline', 'gpu_param', 'idx', '_available_plots', 'X_test', 'seed', 'gpu_n_jobs_param', 'y_train', 'exp_name_log', 'is_multiclass', 'data', 'exp_id', 'log_plots_param', 'y_test', 'n_jobs_param', 'X', 'y', 'fold_generator', 'logging_param'}
2024-06-13 12:31:38,482:INFO:Checking environment
2024-06-13 12:31:38,483:INFO:python_version: 3.11.9
2024-06-13 12:31:38,483:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-06-13 12:31:38,483:INFO:machine: AMD64
2024-06-13 12:31:38,498:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-13 12:31:38,498:INFO:Memory: svmem(total=34056318976, available=24401002496, percent=28.4, used=9655316480, free=24401002496)
2024-06-13 12:31:38,499:INFO:Physical Core: 6
2024-06-13 12:31:38,499:INFO:Logical Core: 12
2024-06-13 12:31:38,499:INFO:Checking libraries
2024-06-13 12:31:38,499:INFO:System:
2024-06-13 12:31:38,499:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-06-13 12:31:38,499:INFO:executable: C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\python.exe
2024-06-13 12:31:38,499:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-13 12:31:38,499:INFO:PyCaret required dependencies:
2024-06-13 12:31:38,578:INFO:                 pip: 24.0
2024-06-13 12:31:38,578:INFO:          setuptools: 69.5.1
2024-06-13 12:31:38,578:INFO:             pycaret: 3.3.2
2024-06-13 12:31:38,579:INFO:             IPython: 8.25.0
2024-06-13 12:31:38,579:INFO:          ipywidgets: 8.1.3
2024-06-13 12:31:38,579:INFO:                tqdm: 4.66.4
2024-06-13 12:31:38,579:INFO:               numpy: 1.26.4
2024-06-13 12:31:38,579:INFO:              pandas: 2.1.4
2024-06-13 12:31:38,579:INFO:              jinja2: 3.1.4
2024-06-13 12:31:38,579:INFO:               scipy: 1.11.4
2024-06-13 12:31:38,579:INFO:              joblib: 1.3.2
2024-06-13 12:31:38,579:INFO:             sklearn: 1.4.2
2024-06-13 12:31:38,579:INFO:                pyod: 2.0.0
2024-06-13 12:31:38,579:INFO:            imblearn: 0.12.3
2024-06-13 12:31:38,579:INFO:   category_encoders: 2.6.3
2024-06-13 12:31:38,579:INFO:            lightgbm: 4.3.0
2024-06-13 12:31:38,579:INFO:               numba: 0.59.1
2024-06-13 12:31:38,579:INFO:            requests: 2.32.3
2024-06-13 12:31:38,579:INFO:          matplotlib: 3.7.5
2024-06-13 12:31:38,579:INFO:          scikitplot: 0.3.7
2024-06-13 12:31:38,579:INFO:         yellowbrick: 1.5
2024-06-13 12:31:38,579:INFO:              plotly: 5.22.0
2024-06-13 12:31:38,579:INFO:    plotly-resampler: Not installed
2024-06-13 12:31:38,579:INFO:             kaleido: 0.2.1
2024-06-13 12:31:38,579:INFO:           schemdraw: 0.15
2024-06-13 12:31:38,579:INFO:         statsmodels: 0.14.2
2024-06-13 12:31:38,580:INFO:              sktime: 0.26.0
2024-06-13 12:31:38,580:INFO:               tbats: 1.1.3
2024-06-13 12:31:38,580:INFO:            pmdarima: 2.0.4
2024-06-13 12:31:38,580:INFO:              psutil: 5.9.8
2024-06-13 12:31:38,580:INFO:          markupsafe: 2.1.5
2024-06-13 12:31:38,580:INFO:             pickle5: Not installed
2024-06-13 12:31:38,580:INFO:         cloudpickle: 3.0.0
2024-06-13 12:31:38,580:INFO:         deprecation: 2.1.0
2024-06-13 12:31:38,580:INFO:              xxhash: 3.4.1
2024-06-13 12:31:38,580:INFO:           wurlitzer: Not installed
2024-06-13 12:31:38,580:INFO:PyCaret optional dependencies:
2024-06-13 12:31:38,590:INFO:                shap: Not installed
2024-06-13 12:31:38,590:INFO:           interpret: Not installed
2024-06-13 12:31:38,590:INFO:                umap: Not installed
2024-06-13 12:31:38,590:INFO:     ydata_profiling: Not installed
2024-06-13 12:31:38,590:INFO:  explainerdashboard: Not installed
2024-06-13 12:31:38,590:INFO:             autoviz: Not installed
2024-06-13 12:31:38,590:INFO:           fairlearn: Not installed
2024-06-13 12:31:38,590:INFO:          deepchecks: Not installed
2024-06-13 12:31:38,590:INFO:             xgboost: Not installed
2024-06-13 12:31:38,590:INFO:            catboost: Not installed
2024-06-13 12:31:38,590:INFO:              kmodes: Not installed
2024-06-13 12:31:38,590:INFO:             mlxtend: Not installed
2024-06-13 12:31:38,590:INFO:       statsforecast: Not installed
2024-06-13 12:31:38,590:INFO:        tune_sklearn: Not installed
2024-06-13 12:31:38,590:INFO:                 ray: Not installed
2024-06-13 12:31:38,590:INFO:            hyperopt: Not installed
2024-06-13 12:31:38,590:INFO:              optuna: Not installed
2024-06-13 12:31:38,590:INFO:               skopt: Not installed
2024-06-13 12:31:38,591:INFO:              mlflow: Not installed
2024-06-13 12:31:38,591:INFO:              gradio: Not installed
2024-06-13 12:31:38,591:INFO:             fastapi: Not installed
2024-06-13 12:31:38,591:INFO:             uvicorn: Not installed
2024-06-13 12:31:38,591:INFO:              m2cgen: Not installed
2024-06-13 12:31:38,591:INFO:           evidently: Not installed
2024-06-13 12:31:38,591:INFO:               fugue: Not installed
2024-06-13 12:31:38,591:INFO:           streamlit: 1.35.0
2024-06-13 12:31:38,591:INFO:             prophet: Not installed
2024-06-13 12:31:38,591:INFO:None
2024-06-13 12:31:38,591:INFO:Set up data.
2024-06-13 12:31:38,622:INFO:Set up folding strategy.
2024-06-13 12:31:38,622:INFO:Set up train/test split.
2024-06-13 12:31:38,642:INFO:Set up index.
2024-06-13 12:31:38,643:INFO:Assigning column types.
2024-06-13 12:31:38,651:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-13 12:31:38,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 12:31:38,696:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 12:31:38,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:38,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:38,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 12:31:38,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 12:31:38,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:38,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:38,794:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-13 12:31:38,834:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 12:31:38,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:38,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:38,909:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 12:31:38,935:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:38,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:38,936:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-13 12:31:39,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:39,007:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:39,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:39,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:39,078:INFO:Preparing preprocessing pipeline...
2024-06-13 12:31:39,080:INFO:Set up simple imputation.
2024-06-13 12:31:39,090:INFO:Set up encoding of ordinal features.
2024-06-13 12:31:39,099:INFO:Set up encoding of categorical features.
2024-06-13 12:31:39,099:INFO:Set up removing outliers.
2024-06-13 12:31:39,099:INFO:Set up imbalanced handling.
2024-06-13 12:31:39,099:INFO:Set up feature normalization.
2024-06-13 12:31:39,099:INFO:Set up PCA.
2024-06-13 12:31:41,757:INFO:Finished creating preprocessing pipeline.
2024-06-13 12:31:41,795:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Marcelo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='consta...
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('pca',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=PCA(copy=True,
                                                    iterated_power='auto',
                                                    n_components=None,
                                                    n_oversamples=10,
                                                    power_iteration_normalizer='auto',
                                                    random_state=None,
                                                    svd_solver='auto', tol=0.0,
                                                    whiten=False)))],
         verbose=False)
2024-06-13 12:31:41,795:INFO:Creating final display dataframe.
2024-06-13 12:31:44,632:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (50000, 13)
4        Transformed data shape       (47390, 30)
5   Transformed train set shape       (32390, 30)
6    Transformed test set shape       (15000, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation                -1
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method        TomekLinks
20                    Normalize              True
21             Normalize method            robust
22                          PCA              True
23                   PCA method            linear
24               PCA components              None
25               Fold Generator   StratifiedKFold
26                  Fold Number                10
27                     CPU Jobs                -1
28                      Use GPU             False
29               Log Experiment             False
30              Experiment Name  clf-default-name
31                          USI              3637
2024-06-13 12:31:44,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:44,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:44,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:44,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:44,776:INFO:setup() successfully completed in 6.36s...............
2024-06-13 12:31:44,788:INFO:gpu_param set to False
2024-06-13 12:31:44,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:44,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:44,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:44,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:44,949:INFO:gpu_param set to False
2024-06-13 12:31:45,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,090:INFO:gpu_param set to False
2024-06-13 12:31:45,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,228:INFO:gpu_param set to False
2024-06-13 12:31:45,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 12:31:45,367:INFO:Initializing create_model()
2024-06-13 12:31:45,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 12:31:45,368:INFO:Checking exceptions
2024-06-13 12:31:45,376:INFO:Importing libraries
2024-06-13 12:31:45,376:INFO:Copying training dataset
2024-06-13 12:31:45,390:INFO:Defining folds
2024-06-13 12:31:45,390:INFO:Declaring metric variables
2024-06-13 12:31:45,390:INFO:Importing untrained model
2024-06-13 12:31:45,390:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 12:31:45,391:INFO:Starting cross validation
2024-06-13 12:31:45,400:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 12:31:56,285:INFO:Calculating mean and std
2024-06-13 12:31:56,287:INFO:Creating metrics dataframe
2024-06-13 12:31:56,290:INFO:Finalizing model
2024-06-13 12:31:58,465:INFO:[LightGBM] [Info] Number of positive: 2660, number of negative: 29730
2024-06-13 12:31:58,468:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002633 seconds.
2024-06-13 12:31:58,468:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 12:31:58,468:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 12:31:58,469:INFO:[LightGBM] [Info] Number of data points in the train set: 32390, number of used features: 29
2024-06-13 12:31:58,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082124 -> initscore=-2.413831
2024-06-13 12:31:58,469:INFO:[LightGBM] [Info] Start training from score -2.413831
2024-06-13 12:31:58,631:INFO:Uploading results into container
2024-06-13 12:31:58,631:INFO:Uploading model into container now
2024-06-13 12:31:58,643:INFO:_master_model_container: 1
2024-06-13 12:31:58,643:INFO:_display_container: 2
2024-06-13 12:31:58,643:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 12:31:58,644:INFO:create_model() successfully completed......................................
2024-06-13 12:31:58,756:INFO:Initializing tune_model()
2024-06-13 12:31:58,756:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-06-13 12:31:58,756:INFO:Checking exceptions
2024-06-13 12:31:58,775:INFO:Copying training dataset
2024-06-13 12:31:58,790:INFO:Checking base model
2024-06-13 12:31:58,791:INFO:Base model : Light Gradient Boosting Machine
2024-06-13 12:31:58,791:INFO:Declaring metric variables
2024-06-13 12:31:58,792:INFO:Defining Hyperparameters
2024-06-13 12:31:58,888:INFO:Tuning with n_jobs=-1
2024-06-13 12:31:58,888:INFO:Initializing RandomizedSearchCV
2024-06-13 12:32:28,431:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:32:28,455:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:32:32,758:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:32:33,889:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:32:37,007:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:32:40,016:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:32:44,098:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:32:52,117:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:32:54,398:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:01,957:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:04,757:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:07,030:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:07,635:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:07,942:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:21,606:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:22,037:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:22,327:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:28,582:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:34,838:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:33:35,243:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:06,552:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:15,100:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:15,585:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:15,773:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:16,205:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:17,392:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:17,952:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:18,403:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:18,567:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:18,744:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-13 12:34:18,755:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2024-06-13 12:34:18,756:INFO:Hyperparameter search completed
2024-06-13 12:34:18,756:INFO:SubProcess create_model() called ==================================
2024-06-13 12:34:18,758:INFO:Initializing create_model()
2024-06-13 12:34:18,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187D2686F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2024-06-13 12:34:18,758:INFO:Checking exceptions
2024-06-13 12:34:18,758:INFO:Importing libraries
2024-06-13 12:34:18,758:INFO:Copying training dataset
2024-06-13 12:34:18,791:INFO:Defining folds
2024-06-13 12:34:18,791:INFO:Declaring metric variables
2024-06-13 12:34:18,791:INFO:Importing untrained model
2024-06-13 12:34:18,792:INFO:Declaring custom model
2024-06-13 12:34:18,793:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 12:34:18,794:INFO:Starting cross validation
2024-06-13 12:34:18,814:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 12:34:27,890:INFO:Calculating mean and std
2024-06-13 12:34:27,891:INFO:Creating metrics dataframe
2024-06-13 12:34:27,894:INFO:Finalizing model
2024-06-13 12:34:30,462:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:30,462:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:30,462:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:30,502:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:30,502:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:30,502:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:30,502:INFO:[LightGBM] [Info] Number of positive: 2660, number of negative: 29730
2024-06-13 12:34:30,506:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002830 seconds.
2024-06-13 12:34:30,506:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 12:34:30,506:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 12:34:30,506:INFO:[LightGBM] [Info] Number of data points in the train set: 32390, number of used features: 29
2024-06-13 12:34:30,508:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082124 -> initscore=-2.413831
2024-06-13 12:34:30,508:INFO:[LightGBM] [Info] Start training from score -2.413831
2024-06-13 12:34:30,741:INFO:Uploading results into container
2024-06-13 12:34:30,742:INFO:Uploading model into container now
2024-06-13 12:34:30,743:INFO:_master_model_container: 2
2024-06-13 12:34:30,743:INFO:_display_container: 3
2024-06-13 12:34:30,744:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 12:34:30,744:INFO:create_model() successfully completed......................................
2024-06-13 12:34:30,851:INFO:SubProcess create_model() end ==================================
2024-06-13 12:34:30,851:INFO:choose_better activated
2024-06-13 12:34:30,851:INFO:SubProcess create_model() called ==================================
2024-06-13 12:34:30,852:INFO:Initializing create_model()
2024-06-13 12:34:30,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 12:34:30,852:INFO:Checking exceptions
2024-06-13 12:34:30,853:INFO:Importing libraries
2024-06-13 12:34:30,853:INFO:Copying training dataset
2024-06-13 12:34:30,871:INFO:Defining folds
2024-06-13 12:34:30,871:INFO:Declaring metric variables
2024-06-13 12:34:30,871:INFO:Importing untrained model
2024-06-13 12:34:30,872:INFO:Declaring custom model
2024-06-13 12:34:30,872:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 12:34:30,873:INFO:Starting cross validation
2024-06-13 12:34:30,885:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 12:34:39,918:INFO:Calculating mean and std
2024-06-13 12:34:39,918:INFO:Creating metrics dataframe
2024-06-13 12:34:39,921:INFO:Finalizing model
2024-06-13 12:34:43,098:INFO:[LightGBM] [Info] Number of positive: 2660, number of negative: 29730
2024-06-13 12:34:43,102:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002965 seconds.
2024-06-13 12:34:43,102:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 12:34:43,102:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 12:34:43,103:INFO:[LightGBM] [Info] Number of data points in the train set: 32390, number of used features: 29
2024-06-13 12:34:43,103:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082124 -> initscore=-2.413831
2024-06-13 12:34:43,104:INFO:[LightGBM] [Info] Start training from score -2.413831
2024-06-13 12:34:43,291:INFO:Uploading results into container
2024-06-13 12:34:43,292:INFO:Uploading model into container now
2024-06-13 12:34:43,293:INFO:_master_model_container: 3
2024-06-13 12:34:43,293:INFO:_display_container: 4
2024-06-13 12:34:43,293:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-13 12:34:43,294:INFO:create_model() successfully completed......................................
2024-06-13 12:34:43,398:INFO:SubProcess create_model() end ==================================
2024-06-13 12:34:43,399:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.4126
2024-06-13 12:34:43,399:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.4888
2024-06-13 12:34:43,400:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-06-13 12:34:43,400:INFO:choose_better completed
2024-06-13 12:34:43,410:INFO:_master_model_container: 3
2024-06-13 12:34:43,410:INFO:_display_container: 3
2024-06-13 12:34:43,411:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 12:34:43,411:INFO:tune_model() successfully completed......................................
2024-06-13 12:34:43,539:INFO:Initializing plot_model()
2024-06-13 12:34:43,539:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 12:34:43,539:INFO:Checking exceptions
2024-06-13 12:34:43,550:INFO:Preloading libraries
2024-06-13 12:34:43,559:INFO:Copying training dataset
2024-06-13 12:34:43,559:INFO:Plot type: auc
2024-06-13 12:34:43,941:INFO:Fitting Model
2024-06-13 12:34:43,942:INFO:Scoring test/hold-out set
2024-06-13 12:34:43,944:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:43,944:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:43,944:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:43,967:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:43,968:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:43,968:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:44,018:INFO:Saving './output\AUC.png'
2024-06-13 12:34:44,269:INFO:Visual Rendered Successfully
2024-06-13 12:34:44,345:INFO:plot_model() successfully completed......................................
2024-06-13 12:34:44,355:INFO:Initializing plot_model()
2024-06-13 12:34:44,355:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=ks, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 12:34:44,356:INFO:Checking exceptions
2024-06-13 12:34:44,362:INFO:Preloading libraries
2024-06-13 12:34:44,369:INFO:Copying training dataset
2024-06-13 12:34:44,369:INFO:Plot type: ks
2024-06-13 12:34:44,370:INFO:Generating predictions / predict_proba on X_test
2024-06-13 12:34:44,501:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:44,501:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:44,502:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:44,742:INFO:Saving './output\KS Statistic Plot.png'
2024-06-13 12:34:44,930:INFO:Visual Rendered Successfully
2024-06-13 12:34:44,999:INFO:plot_model() successfully completed......................................
2024-06-13 12:34:45,045:INFO:Initializing plot_model()
2024-06-13 12:34:45,045:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 12:34:45,046:INFO:Checking exceptions
2024-06-13 12:34:45,052:INFO:Preloading libraries
2024-06-13 12:34:45,059:INFO:Copying training dataset
2024-06-13 12:34:45,059:INFO:Plot type: pr
2024-06-13 12:34:45,418:INFO:Fitting Model
2024-06-13 12:34:45,419:INFO:Scoring test/hold-out set
2024-06-13 12:34:45,421:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:45,421:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:45,421:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:45,445:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:45,446:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:45,446:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:45,481:INFO:Saving './output\Precision Recall.png'
2024-06-13 12:34:45,719:INFO:Visual Rendered Successfully
2024-06-13 12:34:45,796:INFO:plot_model() successfully completed......................................
2024-06-13 12:34:45,804:INFO:Initializing plot_model()
2024-06-13 12:34:45,804:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 12:34:45,805:INFO:Checking exceptions
2024-06-13 12:34:45,811:INFO:Preloading libraries
2024-06-13 12:34:45,819:INFO:Copying training dataset
2024-06-13 12:34:45,819:INFO:Plot type: feature
2024-06-13 12:34:45,820:WARNING:No coef_ found. Trying feature_importances_
2024-06-13 12:34:45,984:INFO:Saving './output\Feature Importance.png'
2024-06-13 12:34:46,122:INFO:Visual Rendered Successfully
2024-06-13 12:34:46,192:INFO:plot_model() successfully completed......................................
2024-06-13 12:34:46,232:INFO:Initializing plot_model()
2024-06-13 12:34:46,232:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 12:34:46,232:INFO:Checking exceptions
2024-06-13 12:34:46,238:INFO:Preloading libraries
2024-06-13 12:34:46,245:INFO:Copying training dataset
2024-06-13 12:34:46,245:INFO:Plot type: confusion_matrix
2024-06-13 12:34:46,582:INFO:Fitting Model
2024-06-13 12:34:46,583:INFO:Scoring test/hold-out set
2024-06-13 12:34:46,585:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:46,585:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:46,585:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:46,610:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:46,611:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:46,611:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:46,637:INFO:Saving './output\Confusion Matrix.png'
2024-06-13 12:34:46,786:INFO:Visual Rendered Successfully
2024-06-13 12:34:46,866:INFO:plot_model() successfully completed......................................
2024-06-13 12:34:46,874:INFO:Initializing finalize_model()
2024-06-13 12:34:46,874:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 12:34:46,875:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-06-13 12:34:46,883:INFO:Initializing create_model()
2024-06-13 12:34:46,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 12:34:46,883:INFO:Checking exceptions
2024-06-13 12:34:46,884:INFO:Importing libraries
2024-06-13 12:34:46,884:INFO:Copying training dataset
2024-06-13 12:34:46,885:INFO:Defining folds
2024-06-13 12:34:46,885:INFO:Declaring metric variables
2024-06-13 12:34:46,885:INFO:Importing untrained model
2024-06-13 12:34:46,885:INFO:Declaring custom model
2024-06-13 12:34:46,886:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-13 12:34:46,897:INFO:Cross validation set to False
2024-06-13 12:34:46,897:INFO:Fitting Model
2024-06-13 12:34:51,667:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:51,667:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:51,667:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:51,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:51,727:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:51,727:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:51,727:INFO:[LightGBM] [Info] Number of positive: 3823, number of negative: 42615
2024-06-13 12:34:51,731:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003629 seconds.
2024-06-13 12:34:51,731:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-13 12:34:51,732:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-13 12:34:51,732:INFO:[LightGBM] [Info] Number of data points in the train set: 46438, number of used features: 29
2024-06-13 12:34:51,734:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082325 -> initscore=-2.411171
2024-06-13 12:34:51,734:INFO:[LightGBM] [Info] Start training from score -2.411171
2024-06-13 12:34:52,028:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 12:34:52,028:INFO:create_model() successfully completed......................................
2024-06-13 12:34:52,109:INFO:_master_model_container: 3
2024-06-13 12:34:52,109:INFO:_display_container: 3
2024-06-13 12:34:52,149:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-13 12:34:52,149:INFO:finalize_model() successfully completed......................................
2024-06-13 12:34:52,219:INFO:Initializing predict_model()
2024-06-13 12:34:52,219:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001878FFC9300>)
2024-06-13 12:34:52,219:INFO:Checking exceptions
2024-06-13 12:34:52,219:INFO:Preloading libraries
2024-06-13 12:34:52,605:INFO:Initializing plot_model()
2024-06-13 12:34:52,605:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=./output, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-13 12:34:52,605:INFO:Checking exceptions
2024-06-13 12:34:52,611:INFO:Preloading libraries
2024-06-13 12:34:52,619:INFO:Copying training dataset
2024-06-13 12:34:52,619:INFO:Plot type: auc
2024-06-13 12:34:52,944:INFO:Fitting Model
2024-06-13 12:34:52,945:INFO:Scoring test/hold-out set
2024-06-13 12:34:52,947:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:52,947:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:52,947:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:52,970:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-06-13 12:34:52,971:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-06-13 12:34:52,971:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-06-13 12:34:53,038:INFO:Saving './output\AUC.png'
2024-06-13 12:34:53,273:INFO:Visual Rendered Successfully
2024-06-13 12:34:53,348:INFO:plot_model() successfully completed......................................
2024-06-13 12:34:53,402:INFO:Initializing evaluate_model()
2024-06-13 12:34:53,402:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=5, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-13 12:34:53,530:INFO:Initializing plot_model()
2024-06-13 12:34:53,530:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187CF287050>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=-1,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='constant'))),
                ('categorical_imputer',
                 TransformerW...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=0.05,
                                max_depth=-1, min_child_samples=96,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=180, n_jobs=-1, num_leaves=10,
                                objective=None, random_state=123,
                                reg_alpha=0.0001, reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-13 12:34:53,531:INFO:Checking exceptions
2024-06-13 12:34:53,535:INFO:Preloading libraries
2024-06-13 12:34:53,542:INFO:Copying training dataset
2024-06-13 12:34:53,542:INFO:Plot type: pipeline
2024-06-13 12:34:53,746:WARNING:C:\Users\Marcelo\anaconda3\envs\ProjetoFinal\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:582: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2024-06-13 12:34:53,746:INFO:Visual Rendered Successfully
2024-06-13 12:34:53,820:INFO:plot_model() successfully completed......................................
2024-06-13 12:35:53,246:WARNING:C:\Users\Marcelo\Documents\EBAC-Exercicios\Exerccio_Cientista_de_dados_Mdulo38\Projeto\script.py:216: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots(figsize=(5,4))

2024-06-13 12:35:59,811:WARNING:C:\Users\Marcelo\Documents\EBAC-Exercicios\Exerccio_Cientista_de_dados_Mdulo38\Projeto\script.py:216: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots(figsize=(5,4))

